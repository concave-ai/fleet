{
  "total_cost": 0,
  "task_id": "pytest-dev__pytest-7220",
  "model": "gpt-4o-2024-08-06",
  "spans": [
    {
      "name": "KeywordExtract",
      "metadata": {
        "start": "2024-08-19T12:17:04.247690",
        "usage": "1652.480125427246 ms"
      },
      "request": {
        "repo_tokens": [
          "pytest_collect_directory",
          "add_attribute",
          "_getobj",
          "delattr",
          "_assertion_pass",
          "disabled",
          "compile",
          "fullsource",
          "_ensure_relative_to_basetemp",
          "_teardown_yield_fixture",
          "store_mark",
          "Frame",
          "find_spec",
          "resolve_from_str",
          "MarkGenerator",
          "catch_warnings_for_item",
          "_folded_skips",
          "exitstatus",
          "MODULE_NOT_FOUND_ERROR",
          "reprtraceback",
          "_match_lines",
          "run",
          "not_expr",
          "DEFAULT_ABSOLUTE_TOLERANCE",
          "_should_truncate_item",
          "toterminal",
          "getfailedcollections",
          "Source",
          "STRING_TYPES",
          "_is_setup_py",
          "_visit_filter",
          "_getnextfixturedef",
          "append_skipped",
          "expression",
          "REPORT_COLLECTING_RESOLUTION",
          "runpython",
          "PYC_EXT",
          "_getlines",
          "mkpydir",
          "scopemismatch",
          "reset",
          "print_teardown_sections",
          "_E",
          "_inject_setup_function_fixture",
          "Expression",
          "tmp_path",
          "explanation_param",
          "CLOSE_STDIN",
          "get",
          "get_closest_marker",
          "FunctionDefinition",
          "PytestArg",
          "pytest",
          "FormattedExcinfo",
          "scope",
          "main",
          "_fillfixtures",
          "pytestconfig",
          "maketxtfile",
          "_getconftestmodules",
          "_find_spec",
          "cached_result",
          "ApproxDecimal",
          "_parse_parametrize_args",
          "safeformat",
          "check_interactive_exception",
          "recursionindex",
          "cleanup_numbered_dir",
          "append_failure",
          "_with_exception",
          "applymarker",
          "_check_all_skipped",
          "ApproxNumpy",
          "bin_xml_escape",
          "set_location",
          "exprinfo",
          "RESULT_LOG",
          "_dump_lines",
          "check_xfail_no_run",
          "_yield_comparisons",
          "re_match_lines_random",
          "_recursive_debug",
          "classnamefilter",
          "makepyfile",
          "FUNCARGNAMES",
          "INTERNAL_ERROR",
          "repr_instance",
          "record_tuples",
          "CollectReport",
          "_get_pdb_wrapper_class",
          "setuponly",
          "_import_plugin_specs",
          "pytest_runtest_teardown",
          "getstatementrange",
          "RunResult",
          "UnitTestCase",
          "write_log_entry",
          "DummyRewriteHook",
          "deprecated_call",
          "_write_pyc_fp",
          "get_terminal_writer",
          "_param_ids_from",
          "exec_",
          "visit_Call",
          "inline_genitems",
          "writeorg",
          "__eq__",
          "update_testcase_duration",
          "USAGE_MSG",
          "_init_checker_class",
          "collect_one_node",
          "_code",
          "_check_non_top_pytest_plugins",
          "append_pass",
          "_iter_rewritable_modules",
          "teardown",
          "setattr",
          "_determine_main_color",
          "DontReadFromInput",
          "_start",
          "push_format_context",
          "OR",
          "value",
          "consider_preparse",
          "unittest",
          "_param_ids_generated",
          "_PYTEST_DIR",
          "exconly",
          "add_stats",
          "ReprTraceback",
          "exec_module",
          "InvocationParams",
          "_colorama_workaround",
          "get_source",
          "set_level",
          "_pformat_dispatch",
          "consider_pluginarg",
          "FixtureDef",
          "_format_args",
          "add_property",
          "source",
          "NFPlugin",
          "pytest_deselected",
          "_format_assertmsg",
          "from_parent",
          "_exec_lsof",
          "__module__",
          "_set_opt_strings",
          "pytest_fixture_setup",
          "pytest_runtest_call",
          "FIXTURE_POSITIONAL_ARGUMENTS",
          "RaisesContext",
          "_excinfo",
          "get_direct_param_fixture_func",
          "_getcrashline",
          "AssertionRewriter",
          "LsofFdLeakChecker",
          "_recursive_list_map",
          "isattrs",
          "junitxml",
          "_mk_tmp",
          "_ascii_escaped_by_config",
          "_pyfuncitem",
          "getcall",
          "write_fspath_result",
          "_matches_prefix_or_glob_option",
          "_trace",
          "HelpAction",
          "NODE_USE_FROM_PARENT",
          "pytest_assertion_pass",
          "LEVELNAME_FMT_REGEX",
          "_get_pos",
          "notset",
          "Cache",
          "stop_capturing",
          "get_location",
          "T",
          "_log_cli_enabled",
          "on_rm_rf_error",
          "processoption",
          "_config",
          "LFPluginCollSkipfiles",
          "TestCaseFunction",
          "PYTESTER_COPY_EXAMPLE",
          "__contains__",
          "get_timeout_config_value",
          "DOCTEST_REPORT_CHOICES",
          "ParameterSet",
          "hasplugin",
          "capstdout",
          "iscoroutinefunction",
          "pytest_pycollect_makeitem",
          "_compare_eq_sequence",
          "PYTEST_COLLECT_MODULE",
          "location",
          "_report_kwargs_from_json",
          "genitems",
          "isinitpath",
          "stop",
          "_getfailureheadline",
          "getcrashentry",
          "CFG_PYTEST_SECTION",
          "DEFAULT_RELATIVE_TOLERANCE",
          "log_outcome",
          "pytest_runtest_makereport",
          "append_collect_skipped",
          "register",
          "get_default_arg_names",
          "cleanup_candidates",
          "EMPTY_PARAMETERSET_OPTION",
          "_check_record_param_type",
          "format_explanation",
          "makeconftest",
          "ParsedCall",
          "_finalize",
          "_addfinalizer",
          "pytest_fixture_post_finalizer",
          "_get_flag_lookup",
          "resume_fixture",
          "findsource",
          "doctest",
          "fileno",
          "_validate_usepdb_cls",
          "Class",
          "_non_printable_ascii_translate_table",
          "cut",
          "_readline_workaround",
          "helpconfig",
          "getfirstlinesource",
          "DOCTEST_REPORT_CHOICE_NDIFF",
          "reprentries",
          "old_mark_config_key",
          "create_cleanup_lock",
          "ensure_deletable",
          "rewrite",
          "scopename2class",
          "verbosity",
          "derive_importpath",
          "make_numbered_dir",
          "resolve",
          "_inject_setup_module_fixture",
          "entrysep",
          "DoctestTextfile",
          "RPAREN",
          "families",
          "pytest_terminal_summary",
          "_inject_setup_method_fixture",
          "PyobjMixin",
          "__array_priority__",
          "get_scope_node",
          "TerminalRepr",
          "getmodpath",
          "pastebin",
          "_should_repr_global_name",
          "Junit",
          "fnmatch_lines_random",
          "_get_marks",
          "repr_args",
          "_node_location_to_relpath",
          "skipping",
          "_get_allow_bytes_flag",
          "section",
          "_ensure_unconfigure",
          "_getscopeitem",
          "warning_types",
          "messages",
          "filter_traceback",
          "getimfunc",
          "getcalls",
          "isatty",
          "README_CONTENT",
          "name2fixturedefs",
          "SysModulesSnapshot",
          "get_log_level_for_setting",
          "showlocals",
          "match",
          "PytestUnhandledCoroutineWarning",
          "get_empty_parameterset_mark",
          "tmpdir",
          "_resolve_arg_value_types",
          "call_runtest_hook",
          "done",
          "_get_teardown_reports",
          "add_report_section",
          "PytestPluginManager",
          "getnode",
          "COLLECT_DIRECTORY_HOOK",
          "try_makedirs",
          "suspend",
          "_get_increasing_order",
          "getplugin",
          "pos",
          "D",
          "at_level",
          "attrs",
          "popen",
          "_importtestmodule",
          "visit_Attribute",
          "PrintHelp",
          "reject",
          "MyOptionParser",
          "_gethookproxy",
          "parseconfig",
          "pytest_doctest_prepare_content",
          "scope2index",
          "getbasetemp",
          "_addexcinfo",
          "_width_of_current_line",
          "startTest",
          "_report_keyboardinterrupt",
          "snap",
          "_result",
          "is_true",
          "evalcache_key",
          "_format",
          "format_session_duration",
          "from_item",
          "parseoutcomes",
          "warn",
          "reorder_items_atscope",
          "monkeypatch",
          "variable",
          "resolve_fixture_function",
          "default_plugins",
          "_log_text",
          "resume_capturing",
          "_add_simple",
          "raises",
          "COLLECT_FAKEMODULE_ATTRIBUTES",
          "_assert_state",
          "execute",
          "approx",
          "matchreport",
          "LineComp",
          "add_global_property",
          "FaultHandlerHooks",
          "path_matches_patterns",
          "stop_global_capturing",
          "capstderr",
          "_version",
          "illegal_xml_re",
          "hookspec",
          "wrap_pytest_function_for_tracing",
          "short_test_summary",
          "parse_num",
          "_checkargnotcontained",
          "collect_by_name",
          "parsefactories",
          "getmodulecol",
          "getpathnode",
          "result",
          "__test__",
          "EOF",
          "ColoredLevelFormatter",
          "node_reporter",
          "merge_family",
          "DOCTEST_REPORT_CHOICE_NONE",
          "_rget_with_confmod",
          "pytester",
          "fail",
          "TeeCaptureIO",
          "pytest_unconfigure",
          "listoutcomes",
          "_validate_args",
          "mark_rewrite",
          "showversion",
          "iter_markers_with_node",
          "getvalue",
          "reorder_items",
          "_warn_incompatibility_with_xunit2",
          "_is_marked_for_rewrite",
          "_add_stats",
          "repr",
          "evaluate",
          "SEP",
          "SubRequest",
          "getreportopt",
          "ApproxScalar",
          "PytestUnknownMarkWarning",
          "_ET",
          "get_exconly",
          "get_open_files",
          "CACHEDIR_TAG_CONTENT",
          "hasopt",
          "_get_main_color",
          "check_testcase_implements_trial_reporter",
          "_is_numpy_array",
          "getsource",
          "ids",
          "tmp_path_factory",
          "_disable_output_capturing_for_darwin",
          "is_globally_capturing",
          "LPAREN",
          "display",
          "pytest_collectreport",
          "LOCK_TIMEOUT",
          "DEFAULT_LOG_FORMAT",
          "global_and_fixture_disabled",
          "fixture",
          "_expecting_failure",
          "pytest_cmdline_parse",
          "_enter_pdb",
          "add_marker",
          "cache_key",
          "freeze_includes",
          "node",
          "from_item_and_call",
          "linecomp",
          "makeini",
          "_format_action_invocation",
          "_getglobals",
          "generic_visit",
          "_W",
          "extract_from",
          "pytest_collection_modifyitems",
          "create_new_paste",
          "getinicfg",
          "_report_unserialization_failure",
          "setupplan",
          "issequence",
          "StoreKey",
          "isset",
          "makefile",
          "LoggingPlugin",
          "__hash__",
          "DoctestItem",
          "traceback",
          "_ALLOW_MARKERS",
          "head_line",
          "_assert_expr_to_lineno",
          "autouse",
          "_importconftest",
          "PYTEST_TAG",
          "args",
          "_FileHandler",
          "_checkversion",
          "copy",
          "FastFilesCompleter",
          "PytestDeprecationWarning",
          "set_fixture",
          "visit_Compare",
          "_ensure_removed_sysmodule",
          "showfspath",
          "_parsearg",
          "start_capturing",
          "ArgumentError",
          "_truncate_by_char_count",
          "_prepareconfig",
          "pytest_pycollect_makemodule",
          "char_width",
          "_has_param_ids",
          "__array_ufunc__",
          "summary_errors",
          "AlwaysDispatchingPrettyPrinter",
          "_ellipsize",
          "pytest_collection",
          "get_data",
          "pytest_report_collectionfinish",
          "DOCTEST_REPORT_CHOICE_UDIFF",
          "conftest_options",
          "find_prefixed",
          "accept",
          "_check_scope",
          "outcomes",
          "_format_boolop",
          "DropShorterLongHelpFormatter",
          "_is_doctest",
          "HookRecorder",
          "getreports",
          "showhelp",
          "pytest_cmdline_main",
          "__attrs_post_init__",
          "MARK_GEN",
          "fspath",
          "USAGE_ERROR",
          "_opentestcase",
          "_recurse",
          "create_terminal_writer",
          "mark",
          "register_assert_rewrite",
          "MINUS_K_COLON",
          "syspath_prepend",
          "rm_rf",
          "fixturenames",
          "write_line",
          "MarkDecorator",
          "tb",
          "addUnexpectedSuccess",
          "pytest_collection_finish",
          "getstatementrange_ast",
          "ReprFuncArgs",
          "find_suffixes",
          "fill_unfilled",
          "syspathinsert",
          "_S",
          "num_mock_patch_args",
          "UsageError",
          "teardown_nose",
          "resume_global_capture",
          "IGNORE_PAM",
          "indent",
          "istext",
          "istrue",
          "showlongtestinfo",
          "Code",
          "terminal",
          "_split_explanation",
          "assert_contains",
          "runpython_c",
          "_io",
          "cwd_relative_nodeid",
          "show_fixtures_per_test",
          "NOT",
          "_get_plugin_specs_as_list",
          "_strtobool",
          "addsection",
          "deindent",
          "set_when",
          "delenv",
          "_perform_collect",
          "_format_repr_exception",
          "should_do_markup",
          "fromdictargs",
          "__setitem__",
          "_genfunctions",
          "fault_handler_stderr_key",
          "raiseerror",
          "fnmatch_ex",
          "reprfuncargs",
          "Traceback",
          "pytest_runtestloop",
          "_setupstate",
          "item_capture",
          "TestReport",
          "longrepr",
          "capfd",
          "_try_repr_or_str",
          "repr_excinfo",
          "__init__",
          "_truncate_recursive_traceback",
          "emit",
          "_resume",
          "getini",
          "_warn_already_imported",
          "argnames",
          "repr_failure",
          "_get_multicapture",
          "cls",
          "getlocation",
          "parseconfigure",
          "repr_locals",
          "_argcomplete",
          "obj",
          "assert_outcomes",
          "_validate_ids",
          "visit_Name",
          "report_collect",
          "finish",
          "_compilecounter",
          "iter_markers",
          "_patch_unwrap_mock_aware",
          "_get_line_with_reprcrash_message",
          "AssertionState",
          "ihook",
          "call_optional",
          "_highlight",
          "_get_override_ini_value",
          "ExceptionRepr",
          "putaround",
          "deactivate_fixture",
          "set_log_path",
          "wrap_session",
          "pytest_warning_captured",
          "filename_arg",
          "get_plugin_manager",
          "function",
          "ReprExceptionInfo",
          "getfuncargnames",
          "suspend_fixture",
          "SafeRepr",
          "LOGLEVEL_COLOROPTS",
          "__len__",
          "_is_last_item",
          "summary_stats",
          "__next__",
          "getrawcode",
          "_initrequest",
          "_CACHE_PREFIX_DIRS",
          "path",
          "inline_run",
          "pytest_make_parametrize_id",
          "name",
          "catch_log_handler_key",
          "set_trace",
          "parse_known_and_unknown_args",
          "PseudoFixtureDef",
          "_fail",
          "_callfinalizers",
          "CollectErrorRepr",
          "KeywordMatcher",
          "runner",
          "call_fixture_func",
          "teardown_all",
          "errisinstance",
          "hookimpl",
          "capfdbinary",
          "addini",
          "IDENT",
          "runpytest_inprocess",
          "Failed",
          "flow_marker",
          "_AnyPurePath",
          "extract_suffixes",
          "_color_for_type_default",
          "pytest_collectstart",
          "setenv",
          "_schedule_finalizers",
          "isiterable",
          "FSCollector",
          "BINOP_MAP",
          "style",
          "_log",
          "pytest_internalerror",
          "pytest_enter_pdb",
          "visit_Starred",
          "_update_message",
          "FixtureLookupError",
          "FixtureManager",
          "doctest_namespace",
          "_getentrysource",
          "makedir",
          "_bytes_to_ascii",
          "ensure_newline",
          "saferepr",
          "_basetemp",
          "chdir",
          "_matchfactories",
          "activate_fixture",
          "DOCTEST_REPORT_CHOICE_CDIFF",
          "gethookproxy",
          "_get_assertion_exprs",
          "Exception",
          "mode",
          "CaptureResult",
          "str",
          "isparseable",
          "OK",
          "get_unpacked_marks",
          "tbfilter",
          "pytest_report_teststatus",
          "pytestPDB",
          "_setup_fixtures",
          "_running_on_ci",
          "is_generator",
          "_idval",
          "_write_progress_information_filling_space",
          "getpluginversioninfo",
          "stopTest",
          "_consider_importhook",
          "PdbInvoke",
          "caplog",
          "evalxfail_key",
          "OptionGroup",
          "error",
          "LFPluginCollWrapper",
          "NodeMeta",
          "_is_capturing",
          "FixtureRequest",
          "_esctable",
          "_cachedir",
          "_get_global_properties_node",
          "_write_report_lines_from_hooks",
          "_iter_all_modules",
          "_bestrelpath_cache",
          "extraline",
          "ReprFileLocation",
          "format",
          "reprlocals",
          "_ANSI_ESCAPE_SEQ",
          "_create",
          "set",
          "pytest_report_from_serializable",
          "essential_plugins",
          "invocation_dir",
          "_get_first_non_fixture_func",
          "scopeproperty",
          "getitem",
          "_sys_snapshot",
          "names",
          "is_capturing",
          "install_importhook",
          "DEFAULT_MAX_LINES",
          "initialnames",
          "LogXML",
          "__getitem__",
          "count_towards_summary",
          "for_config",
          "get_config",
          "FuncFixtureInfo",
          "Testdir",
          "exists",
          "parse_hookimpl_opts",
          "tracebackcutdir",
          "addExpectedFailure",
          "get_public_names",
          "cacheshow",
          "TracebackEntry",
          "relline",
          "_get_auto_indent",
          "_getconftest_pathlist",
          "get_scope_package",
          "Package",
          "patchsysdict",
          "start_global_capturing",
          "record_testsuite_property",
          "warns",
          "_pytest",
          "pytest_itemcollected",
          "compile_",
          "assert_contains_lines",
          "chain",
          "parts",
          "FSHookProxy",
          "_NodeReporter",
          "_locationline",
          "TempdirFactory",
          "helper",
          "and_expr",
          "_write_entry_lines",
          "_teardown_towards",
          "undo",
          "MultipleDoctestFailures",
          "set_session",
          "async_warn_and_skip",
          "lineno",
          "MoreQuietAction",
          "Token",
          "LineMatcher",
          "context",
          "fixtures",
          "__call__",
          "countoutcomes",
          "nose",
          "_makeitem",
          "reports",
          "TYPE_CHECKING",
          "_compute_fixture_value",
          "_outrep_summary",
          "debugging",
          "assertrepr_compare",
          "_read_pyc",
          "_approx_scalar",
          "_issue_warning_captured",
          "get_cache_dir",
          "PytestAssertRewriteWarning",
          "scope2props",
          "records",
          "Argument",
          "_getvaluepath",
          "_import_pdb_cls",
          "listchain",
          "get_dirs_from_args",
          "_early_rewrite_bailout",
          "freeze_support",
          "CaptureIO",
          "params",
          "isnosetest",
          "get_real_func",
          "get_common_ancestor",
          "warnings",
          "skipped_by_mark_key",
          "config",
          "list",
          "newinstance",
          "getfixturemarker",
          "fslocation",
          "wrap_function_to_error_out_if_called_directly",
          "delitem",
          "abspath",
          "_getautousenames",
          "_try_load_conftest",
          "for_later",
          "_plugin_nameversions",
          "repr_traceback",
          "_postmortem_traceback",
          "EncodedFile",
          "TERMINALWRITER_WRITER",
          "mkdir",
          "ishidden",
          "getitems",
          "_addoption_instance",
          "PytestWarning",
          "_processopt",
          "_force_symlink",
          "REGEX_TYPE",
          "assign",
          "_getindent",
          "finish_recording",
          "own_mark_names",
          "_format_lines",
          "plugins",
          "setdefault",
          "FILLFUNCARGS",
          "reportinfo",
          "fnmatch_lines",
          "gethookrecorder",
          "get_terminal_width",
          "MonkeyPatch",
          "NOTSET",
          "_to_json",
          "Mark",
          "_handle_teardown_sections",
          "ExceptionInfo",
          "encoding",
          "annotated_getattr",
          "_remove_ansi_escape_sequences",
          "readlines",
          "console_main",
          "cmdline",
          "__delitem__",
          "inline_runsource",
          "summary_warnings",
          "pytest_exception_interact",
          "typename",
          "CaptureFixture",
          "write_captured_output",
          "CHECKER_CLASS",
          "_warn_about_missing_assertion",
          "SysCaptureBinary",
          "_make_xunit_fixture",
          "get_option_ini",
          "WarningReport",
          "NO_TESTS_COLLECTED",
          "close",
          "register_cleanup_lock_removal",
          "_inject_setup_teardown_fixtures",
          "deprecated",
          "eval",
          "_is_skipped",
          "ExceptionChainRepr",
          "pytest_generate_tests",
          "_testcase",
          "handleError",
          "_show_fixtures_per_test",
          "collect",
          "showfixtures",
          "_traceback",
          "astcache",
          "RUNNER_CLASS",
          "_get_runner",
          "pytest_runtest_logstart",
          "get_user",
          "TimeoutExpired",
          "_given_basetemp",
          "skip",
          "SysCapture",
          "addfinalizer",
          "start",
          "pytest_runtest_protocol",
          "hasnew",
          "from_current",
          "text",
          "MarkEvaluator",
          "ConftestImportFailure",
          "append",
          "assertoutcome",
          "pytest_runtest_logfinish",
          "names_closure",
          "readline",
          "fail_marker",
          "pytest_plugin_registered",
          "pytest_pyfunc_call",
          "cached_eval",
          "writer",
          "prune_dependency_tree",
          "set_repr_style",
          "make_properties_node",
          "__slots__",
          "FixtureFunctionMarker",
          "rex_session_duration",
          "__bool__",
          "_parse_lsof_output",
          "_LiveLoggingStreamHandler",
          "popcall",
          "perform_collect",
          "simple",
          "clear",
          "get_line_width",
          "_get_direct_parametrize_args",
          "_truncate_explanation",
          "Collector",
          "Notset",
          "message",
          "ApproxSequencelike",
          "_update_current_test_var",
          "_compare_eq_iterable",
          "listnames",
          "assertstate_key",
          "kwargs",
          "cache",
          "isdatacls",
          "truncate_if_required",
          "_PluggyPlugin",
          "no_re_match_line",
          "TokenType",
          "restore",
          "MINUS_K_DASH",
          "__exit__",
          "runpytest",
          "is_async_function",
          "_get_allow_unicode_flag",
          "_from_json",
          "pytest_load_initial_conftests",
          "try_cleanup",
          "_no_match_line",
          "_showfixtures_main",
          "_is_mocked",
          "to_xml",
          "instance",
          "repr_traceback_entry",
          "PytestConfigWarning",
          "getrepr",
          "Node",
          "parametrize",
          "is_rewrite_disabled",
          "write_sep",
          "truncate_locals",
          "_names",
          "_write_source",
          "_factorytraceback",
          "WarningsRecorder",
          "resultlog",
          "statement",
          "pytest_assertrepr_compare",
          "get_sections",
          "_makepath",
          "get_lock_path",
          "__repr__",
          "spawn",
          "_legal_chars",
          "pop",
          "determine_setup",
          "fix_cache_order",
          "_parse_filter",
          "ReprEntry",
          "_reprcompare",
          "pytest_runtest_logreport",
          "_makefile",
          "CallSpec2",
          "_fixturemanager",
          "id",
          "_init_runner_class",
          "getfixturevalue",
          "_assert_start_repr",
          "_saferepr",
          "StepwisePlugin",
          "when",
          "make_hook_recorder",
          "summary_failures",
          "pastebinfile_key",
          "_report_to_json",
          "CwdSnapshot",
          "_init_pdb",
          "_pluginmanager",
          "getfailures",
          "testdir",
          "expr",
          "_notin_text",
          "visit_BinOp",
          "ApproxMapping",
          "fullwidth",
          "ExitCode",
          "ResultLog",
          "FDCapture",
          "_ensure_supporting_files",
          "_seen",
          "lines",
          "_CACHE_PREFIX_VALUES",
          "MarkMatcher",
          "Interrupted",
          "unset_fixture",
          "_repr_failure_py",
          "keywords",
          "TerminalReporter",
          "strip",
          "_wrapped_pdb_cls",
          "JUNIT_XML_DEFAULT_FAMILY",
          "pytest_report_header",
          "_saved",
          "ReprFailDoctest",
          "copy_example",
          "getexplanation",
          "_initini",
          "_validate_if_using_arg_names",
          "parse_args",
          "EMPTY_BUFFER",
          "_get_number_flag",
          "recwarn",
          "mktemp",
          "summary_passes",
          "pytest_keyboard_interrupt",
          "addSuccess",
          "File",
          "directory_arg",
          "_T",
          "notify_exception",
          "__getattr__",
          "template",
          "_determine_show_progress_info",
          "_getreprcrash",
          "scopes",
          "_ensure_basetemp",
          "parse_known_args",
          "_PY_DIR",
          "xfail",
          "__ne__",
          "build_summary_stats_line",
          "_check_if_assertion_pass_impl",
          "unexpectedsuccess_key",
          "Exit",
          "stream",
          "_legal_xml_re",
          "setup",
          "nodeid",
          "consider_env",
          "normalize_mark_list",
          "_repr_style",
          "getcfg",
          "exit",
          "mangle_test_address",
          "_should_rewrite",
          "pytest_cmdline_preparse",
          "LineMatcher_fixture",
          "longreprtext",
          "_parse_parametrize_parameters",
          "buffer",
          "safe_getattr",
          "_get_continue_on_failure",
          "_match_lines_random",
          "from_config",
          "handler",
          "NoCapture",
          "_rewrite_test",
          "PercentStyleMultiline",
          "_check_initialpaths_for_relpath",
          "__take_sys_modules_snapshot",
          "_split_lines",
          "reprfileloc",
          "Store",
          "FakeCollectModule",
          "suspend_capturing",
          "CollectError",
          "_config_for_test",
          "_compare_eq_set",
          "_surrounding_parens_on_own_lines",
          "get_statement_startend2",
          "_addoption",
          "pytest_addoption",
          "Function",
          "_collect",
          "_call_assertion_pass",
          "_compare_eq_dict",
          "pytest_runtest_setup",
          "UnformattedWarning",
          "_get_verbose_word",
          "__dir__",
          "lex",
          "pytest_sessionfinish",
          "_getparser",
          "resume",
          "INTERRUPTED",
          "showheader",
          "_call_reprcompare",
          "is_potential_nosetest",
          "pytest_make_collect_report",
          "getfixtureinfo",
          "failed",
          "getfixturedefs",
          "funcargs",
          "_ensure_immutable_ids",
          "_get_report_choice",
          "addError",
          "pytest_collect_file",
          "width_of_current_line",
          "wasvalid",
          "_in_venv",
          "matching_platform",
          "BaseReport",
          "DEPRECATED_EXTERNAL_PLUGINS",
          "write_docstring",
          "add_cleanup",
          "frame",
          "Parser",
          "_getpytestargs",
          "_translate_non_printable",
          "readouterr",
          "__version_tuple__",
          "python_api",
          "param",
          "_for_parametrize",
          "type",
          "sections",
          "__version__",
          "locals",
          "ensure_reset_dir",
          "visit_Assert",
          "stepwise",
          "_markers",
          "record_xml_attribute",
          "getfslineno",
          "getslaveinfoline",
          "_make_plural",
          "co_equal",
          "python",
          "version",
          "pytest_leave_pdb",
          "funcnamefilter",
          "_create_formatter",
          "_F",
          "_preparse",
          "AND",
          "idmaker",
          "FDCaptureBinary",
          "funcargnames",
          "cacheprovider",
          "cache_dir_from_config",
          "_non_numeric_type_error",
          "with_args",
          "_get_active_fixturedef",
          "yield_fixture",
          "ascii_escaped",
          "pop_format_context",
          "builtin_plugins",
          "re_match_lines",
          "write_ensure_prefix",
          "setitem",
          "skipped",
          "_eval_scope_callable",
          "listextrakeywords",
          "SysPathsSnapshot",
          "PytestCacheWarning",
          "addSkip",
          "get_parametrized_fixture_keys",
          "duration",
          "ApproxBase",
          "_get_stderr_fileno",
          "_py_ext_re",
          "rex_outcome",
          "importorskip",
          "TempPathFactory",
          "pytest_ignore_collect",
          "WarningsChecker",
          "check_strict_xfail",
          "from_exc_info",
          "_pop_and_teardown",
          "isdict",
          "teardown_exact",
          "PYC_TAIL",
          "getoption",
          "PdbTrace",
          "add_funcarg_pseudo_fixture_def",
          "RE_IMPORT_ERROR_NAME",
          "SetupState",
          "KNOWN_TYPES",
          "fillfixtures",
          "markname",
          "append_error",
          "Session",
          "read",
          "maybe_wrap_pytest_function_for_tracing",
          "_state",
          "_in_suspended",
          "_PLUGGY_DIR",
          "_tmppath_factory",
          "getparam",
          "prepare",
          "maybe_delete_a_numbered_dir",
          "LFPlugin",
          "DoctestModule",
          "from_call",
          "NodeKeywords",
          "finalize",
          "_prunetraceback",
          "addinivalue_line",
          "markup",
          "faulthandler",
          "PytestCollectionWarning",
          "append_collect_error",
          "compat",
          "parse",
          "MultiCapture",
          "runpytest_subprocess",
          "pytest_report_to_serializable",
          "runtestprotocol",
          "logging",
          "_suspend",
          "getvalueorskip",
          "pytest_configure",
          "OutcomeException",
          "_inject_setup_class_fixture",
          "excinfo",
          "AssertionRewritingHook",
          "_prepare_content",
          "runitem",
          "clear_cache",
          "_istrue",
          "PyCollector",
          "record_testreport",
          "_diff_text",
          "_mark_plugins_for_rewrite",
          "consider_module",
          "_REPORTCHARS_DEFAULT",
          "XFailed",
          "LogCaptureFixture",
          "runtest",
          "rewrite_asserts",
          "create_module",
          "FILE_OR_DIR",
          "module",
          "_get_fixturestack",
          "pytest_sessionstart",
          "_show_fixture_action",
          "dir",
          "show_test_item",
          "record_property",
          "tmpdir_factory",
          "CallInfo",
          "get_optionflags",
          "_check_type",
          "make_numbered_dir_with_cleanup",
          "call_and_report",
          "nofuncargs",
          "Config",
          "_runtest_for",
          "get_lines_after",
          "version_tuple",
          "DEFAULT_MAX_CHARS",
          "invalidraise",
          "Module",
          "Item",
          "_idvalset",
          "MatcherAdapter",
          "pytest_addhooks",
          "catch_log_records_key",
          "no_fnmatch_line",
          "__all__",
          "xml_key",
          "matchnodes",
          "read_global_capture",
          "_color_for_type",
          "Scanner",
          "_getini",
          "istestfunction",
          "_LiveLoggingNullHandler",
          "ParseError",
          "warning_record_to_str",
          "DEFAULT_LOG_DATE_FORMAT",
          "_compare_eq_cls",
          "_write_content",
          "assertion",
          "_PytestWrapper",
          "Metafunc",
          "_main",
          "_teardown_with_finalization",
          "_tryconvertpyarg",
          "resultlog_key",
          "get_real_method",
          "BASE_TYPE",
          "prog",
          "nodes",
          "reprcrash",
          "_resolve_arg_ids",
          "_assertion_supported",
          "getparent",
          "combined_with",
          "NoMatch",
          "_get_progress_information_message",
          "filter",
          "parse_setoption",
          "DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE",
          "_do_configure",
          "addoption",
          "getfixtureclosure",
          "TEST_OUTCOME",
          "ReprEntryNative",
          "_striptext",
          "_call_with_optional_argument",
          "get_records",
          "getgroup",
          "_get_checker",
          "deselect_by_keyword",
          "_compare_eq_verbose",
          "capsysbinary",
          "capsys",
          "pop_outerr_to_orig",
          "category",
          "_set_initial_conftests",
          "_printcollecteditems",
          "Instance",
          "ReprTracebackNative",
          "pathlib",
          "nextitem",
          "parse_hookspec_opts",
          "formatrepr",
          "flush",
          "FixtureLookupErrorRepr",
          "_splitnode",
          "fail_fixturefunc",
          "visit_UnaryOp",
          "CaptureManager",
          "PytestExperimentalApiWarning",
          "getargs",
          "__enter__",
          "suspend_global_capture",
          "LogCaptureHandler",
          "__str__",
          "ischildnode",
          "_legal_ranges",
          "consider_conftest",
          "line",
          "write",
          "UNARY_MAP",
          "get_fslocation_from_item",
          "session",
          "store",
          "deselect_by_mark",
          "TESTS_FAILED",
          "spawn_pytest",
          "scopenum_function",
          "_WithException",
          "_matchnodes",
          "import_plugin",
          "TerminalWriter",
          "istestclass",
          "_py36_windowsconsoleio_workaround",
          "__missing__",
          "hasinit",
          "visit_BoolOp",
          "post_mortem",
          "__iter__",
          "passed",
          "istestfunc",
          "ReprLocals",
          "getstatement",
          "_find_parametrized_scope",
          "_set_main_color",
          "builtin",
          "get_last_failed_paths",
          "_collectfile",
          "sep",
          "catching_logs",
          "addFailure",
          "setmulti2",
          "Skipped",
          "capture",
          "safe_isclass",
          "_typ_map",
          "tolerance"
        ]
      },
      "response": {
        "keywords": [
          "pytest_fixture_setup",
          "pytest_runtest_call",
          "chdir",
          "pytest_runtest_makereport",
          "cwd_relative_nodeid",
          "pytest_runtest_setup",
          "nodeid",
          "getfslineno",
          "pytest_sessionstart",
          "pytest_unconfigure"
        ]
      }
    },
    {
      "name": "FilesKeywordSearch",
      "metadata": {
        "start": "2024-08-19T12:17:05.900227",
        "usage": "269.24896240234375 ms"
      },
      "request": {
        "tokens": [
          "pytest_fixture_setup",
          "pytest_runtest_call",
          "chdir",
          "pytest_runtest_makereport",
          "cwd_relative_nodeid",
          "pytest_runtest_setup",
          "nodeid",
          "getfslineno",
          "pytest_sessionstart",
          "pytest_unconfigure"
        ]
      },
      "response": {
        "results": {
          "pytest_fixture_setup": [
            "src/_pytest/fixtures.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/setupplan.py"
          ],
          "pytest_runtest_setup": [
            "src/_pytest/runner.py",
            "src/_pytest/nose.py",
            "src/_pytest/capture.py",
            "src/_pytest/logging.py",
            "src/_pytest/skipping.py",
            "src/_pytest/assertion/util.py",
            "src/_pytest/hookspec.py"
          ],
          "pytest_unconfigure": [
            "src/_pytest/mark/__init__.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/doctest.py",
            "src/_pytest/logging.py",
            "src/_pytest/debugging.py",
            "src/_pytest/resultlog.py",
            "src/_pytest/terminal.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/junitxml.py"
          ],
          "nodeid": [
            "src/_pytest/stepwise.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/reports.py",
            "src/_pytest/runner.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/pytester.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/terminal.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/resultlog.py",
            "src/_pytest/python.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/nodes.py",
            "src/_pytest/main.py"
          ],
          "pytest_runtest_makereport": [
            "src/_pytest/hookspec.py",
            "src/_pytest/skipping.py",
            "src/_pytest/runner.py",
            "src/_pytest/unittest.py"
          ],
          "chdir": [
            "src/_pytest/monkeypatch.py",
            "src/_pytest/pytester.py",
            "src/_pytest/main.py"
          ],
          "pytest_sessionstart": [
            "src/_pytest/stepwise.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/runner.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/pytester.py",
            "src/_pytest/logging.py",
            "src/_pytest/terminal.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/main.py"
          ],
          "pytest_runtest_call": [
            "src/_pytest/capture.py",
            "src/_pytest/runner.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/logging.py"
          ],
          "getfslineno": [
            "src/_pytest/_code/__init__.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/python.py",
            "src/_pytest/nodes.py"
          ],
          "cwd_relative_nodeid": [
            "src/_pytest/config/__init__.py",
            "src/_pytest/terminal.py"
          ]
        }
      }
    },
    {
      "name": "FilesFilter",
      "metadata": {
        "start": "2024-08-19T12:17:06.169491",
        "usage": "6702.372074127197 ms"
      },
      "request": {
        "keyword_search_results": {
          "pytest_fixture_setup": [
            "src/_pytest/fixtures.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/setupplan.py"
          ],
          "pytest_runtest_setup": [
            "src/_pytest/runner.py",
            "src/_pytest/nose.py",
            "src/_pytest/capture.py",
            "src/_pytest/logging.py",
            "src/_pytest/skipping.py",
            "src/_pytest/assertion/util.py",
            "src/_pytest/hookspec.py"
          ],
          "pytest_unconfigure": [
            "src/_pytest/mark/__init__.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/doctest.py",
            "src/_pytest/logging.py",
            "src/_pytest/debugging.py",
            "src/_pytest/resultlog.py",
            "src/_pytest/terminal.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/junitxml.py"
          ],
          "nodeid": [
            "src/_pytest/stepwise.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/reports.py",
            "src/_pytest/runner.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/pytester.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/terminal.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/resultlog.py",
            "src/_pytest/python.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/nodes.py",
            "src/_pytest/main.py"
          ],
          "pytest_runtest_makereport": [
            "src/_pytest/hookspec.py",
            "src/_pytest/skipping.py",
            "src/_pytest/runner.py",
            "src/_pytest/unittest.py"
          ],
          "chdir": [
            "src/_pytest/monkeypatch.py",
            "src/_pytest/pytester.py",
            "src/_pytest/main.py"
          ],
          "pytest_sessionstart": [
            "src/_pytest/stepwise.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/runner.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/pytester.py",
            "src/_pytest/logging.py",
            "src/_pytest/terminal.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/main.py"
          ],
          "pytest_runtest_call": [
            "src/_pytest/capture.py",
            "src/_pytest/runner.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/logging.py"
          ],
          "getfslineno": [
            "src/_pytest/_code/__init__.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/python.py",
            "src/_pytest/nodes.py"
          ],
          "cwd_relative_nodeid": [
            "src/_pytest/config/__init__.py",
            "src/_pytest/terminal.py"
          ]
        }
      },
      "response": {
        "scratch_pad": "The issue is about the wrong path being displayed due to the working directory being changed in a fixture when a test fails. The key problem relates to how file paths are represented when the current working directory changes. \n\n### Key Points from the Issue:\n- A fixture (`private_dir`) changes the directory, causing file paths to be displayed incorrectly.\n- Pytest should show paths relative to the original directory.\n- The main pytest areas that could deal with nodes and paths be involved.\n\n### Keywords:\n1. **`chdir`:**\n   - `src/_pytest/monkeypatch.py`: Monkeypatching could be responsible for altering the working directory.\n   - `src/_pytest/pytester.py`: This may involve fixtures and test running orders.\n   - `src/_pytest/main.py`: Main configurations may be influencing the handling of paths/directory.\n\n2. **`cwd_relative_nodeid`:**\n   - `src/_pytest/config/__init__.py`: Configuration dealing with directory settings.\n   - `src/_pytest/terminal.py`: Responsible for displaying information in the terminal, likely where the path gets printed.\n\n3. **`nodeid`:**\n   The `nodeid` often relates to the identification of tests and their paths, possibly influencing the (mis)representation of test paths.\n   - `src/_pytest/nodes.py`: Likely responsible for managing test node IDs, including path handling.\n   - `src/_pytest/terminal.py`: This could have a role in how node IDs are displayed in the output terminal.\n   - `src/_pytest/reports.py`: Deals with test report generation which includes path information.\n\nConsidering the given issue, `chdir` and `cwd_relative_nodeid` keywords have higher significance as they directly relate to current directory implementations and path management.\n\n### Conclusions:\n`src/_pytest/terminal.py`, `src/_pytest/config/__init__.py`, and potentially `src/_pytest/nodes.py` might have the code related to the problem of altering path representation when current directory changes.",
        "file_paths": [
          "src/_pytest/terminal.py",
          "src/_pytest/config/__init__.py",
          "src/_pytest/nodes.py",
          "src/_pytest/monkeypatch.py",
          "src/_pytest/pytester.py"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T12:17:12.871890",
        "usage": "10725.273132324219 ms"
      },
      "request": {
        "file_path": "src/_pytest/terminal.py"
      },
      "response": {
        "scratch_pad": "### Analyzing User Instructions:\n1. **Issue Description**:\n   - The problem is related to path reporting of test files in pytest when using fixtures that change the working directory. The test failure reports the file path relative to the current directory (changed by the fixture) rather than the original directory.\n   - Expected path shown in errors: `test_path_error.py:29`\n   - Displayed path in errors: `../test_path_error.py:29`\n   \n2. **Reproduction Steps**:\n   - The issue occurs when a fixture modifies the current working directory, affecting the relative path in pytest's output.\n   - In this case, the fixture `private_dir` in `test_path_error.py` changes the working directory before running tests.\n\n3. **Issue Cause**:\n   - Pytest is displaying paths relative to the current working directory as set in the fixture, creating confusion when trying to jump to the reported test.\n   - The `os.chdir(out_dir)` line in the fixture changes the working directory, and pytest then reports paths relative to this changed directory.\n\n4. **User Expectation**:\n   - The user expects the file path in error messages to remain relative to the original directory, even after the working directory has been changed by the fixture.\n  \n5. **Potential Causes**:\n   - Pytest's terminal reporting hooks or the configuration involving path resolution and current working directory might be failing to resolve the initial directory correctly.\n   \n6. **Possible Solutions**:\n   - Implement a mechanism to store or revert to the initial directory (cwd) within pytest's error reporting mechanisms.\n   - Adjust the way file paths are resolved or displayed in reports to compensate for changes in working dir by fixtures.\n   - Ensure that pytest's path resolution methods take into account the original invocation directory as the basis for relative paths.\n\n\n### Analyzing File Content:\n1. This script seems heavily concerned with terminal reporting and output control in pytest.\n\n2. **Relevant Function/Classes**:\n   - `TerminalReporter`: This class deals with terminal reporting of test results and seems to hold information about paths (`self.startdir`, `self.config.cwd_relative_nodeid`).\n   - Method `_locationline(self, nodeid, fspath, lineno, domain)`: Appears to handle the formatting and possible correction of fspath in location lines.\n\n3. **Evaluation**:\n   - The class `TerminalReporter` potentially affects how file paths are shown during test reports.\n   - The manipulation within `_locationline` by using `self.startdir.bestrelpath(fspath)` suggests this could be influencing the path representation directly. Fixating on original directory usage.\n\n4. **References to Original Directory**:\n   - The file may rely on initialization of `self.startdir`, indicating original directory capture.\n\nConclusion:\n- This file seems relevant; its function `_locationline` is a strong candidate impacting path output.\n- It might affect how paths are displayed when working directories change via fixtures.",
        "relevant": true,
        "root_cause": true,
        "relevant_files": [],
        "relevant_symbols": [
          "TerminalReporter",
          "TerminalReporter._locationline",
          "TerminalReporter.write_fspath_result"
        ],
        "root_cause_symbols": [
          "TerminalReporter._locationline"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T12:17:23.597189",
        "usage": "10405.232906341553 ms"
      },
      "request": {
        "file_path": "src/_pytest/config/__init__.py"
      },
      "response": {
        "scratch_pad": "### Analysis of User Instructions\n1.1 The issue revolves around a wrong path to the test file being displayed when a directory is changed within a fixture. The displayed path becomes relative to the directory changed in a fixture, leading to incorrect reporting for test files and hindering navigation to error lines by editors.\n\n1.2 The user provides a script with a fixture `private_dir` that changes the current working directory and then an assertion that fails, causing pytest to show the file path relative to the changed directory.\n\n1.3 This issue is caused because the current working directory is temporarily changed in the `private_dir` fixture. Pytest reports paths relative to the current directory, so if the current directory is changed during test execution, the paths become incorrect.\n\n1.4 The user's expectation is for file paths to remain consistent relative to the original invocation directory, even if the working directory changes during test execution. This expectation is crucial to ensure that error reporting in test outputs is consistently reliable for navigation by an editor.\n\n1.5 The issue arises due to how pytest calculates and returns the file path relative to `os.getcwd()`. A possible solution might be to have pytest store the original working directory and return paths relative to that instead.\n\n1.6 Proposed solutions:\n  - Ensure that path calculations in pytest consider an initial, immutable current directory.\n  - Modify how paths are stored or referenced during test lifecycle to prevent interferences from directory changes.\n  - Adjust fixture setups to prevent altering the `os.getcwd()` if possible or manage directory changes via mocks that don't affect external file path calculations.\n\n### Current File Evaluation\n2.1-2.4 The file provided (`src/_pytest/config/__init__.py`) contains various functions and classes related to plugin management and configuration handling in pytest.\n\n2.5 Relevant code sections:\n- Function `Config.cwd_relative_nodeid` and the `Config` class are relevant because they handle path calculations and may influence how pytest constructs the reported path.\n\n2.6 The file may not be the immediate root cause but is relevant because the issue may stem from how pytest configuration interacts with directory changes.\n\n2.7 Suggest evaluating if the reporting mechanisms or plugins configured in this config file lead to path mis-reporting.",
        "relevant": true,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/pathlib.py",
          "src/_pytest/_io.py",
          "src/_pytest/assertion/rewrite.py"
        ],
        "relevant_symbols": [
          "Config.cwd_relative_nodeid",
          "Config"
        ],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T12:17:34.002454",
        "usage": "7223.851919174194 ms"
      },
      "request": {
        "file_path": "src/_pytest/nodes.py"
      },
      "response": {
        "scratch_pad": "1. Analyze User Instructions:\n1.1 The user is describing an issue where the path to a test file is displayed incorrectly when the working directory is changed within a pytest fixture. This issue makes it difficult for developers to navigate to the failure point using the editor due to the incorrect relative path.\n\n1.2 The user has provided code and reproduction steps using a fixture that changes the directory. When the directory is changed, pytest still needs to reference paths relative to the original directory, but it appears to be displaying paths relative to the new directory instead.\n\n1.3 The issue is caused because the working directory is changed in the fixture, and as a result, paths are being displayed relative to this new working directory instead of the original one.\n\n1.4 The user's expectation is that paths should remain relative to the original directory irrespective of the changes made in the working directory within fixtures. The pytest framework is not handling the directory change properly when displaying file paths for assertions and errors.\n\n1.5 As a solution, the code handling path display should account for the working directory change and still calculate paths with respect to the original directory.\n\n2. Make file evaluation:\n2.1 The relevant parts of the code are likely where paths are constructed or displayed.\n2.2 The file seems to contain relevant classes like Node, Collector, and functions related to them.\n2.3 Functions like repr_failure or _repr_failure_py might be handling traceback and path formations and could adjust path representation.\n2.4 Specifically, focus on methods involving fspath or fs_location, which deal directly with file paths.\n\n",
        "relevant": true,
        "root_cause": true,
        "relevant_files": [],
        "relevant_symbols": [
          "Node.repr_failure",
          "Node._repr_failure_py",
          "get_fslocation_from_item"
        ],
        "root_cause_symbols": [
          "Node.repr_failure",
          "Node._repr_failure_py",
          "get_fslocation_from_item"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T12:17:41.226356",
        "usage": "8202.66580581665 ms"
      },
      "request": {
        "file_path": "src/_pytest/monkeypatch.py"
      },
      "response": {
        "scratch_pad": "1. **Analyzing User Instructions:**\n   - The reported issue occurs when the working directory is changed in a pytest fixture. Specifically, when using the `monkeypatch.chdir(out_dir)`, the error paths displayed in test failures become incorrect, or as the user notes, they appear relative to the new directory instead of the original one.\n   - The user's expectation is that the error path should remain relative to the original directory despite the directory changes made during test execution. The incorrect path makes it difficult to locate the file containing the error in editors.\n   - This problem is most likely caused by a misconfiguration with how the directory change is handled and reported in pytest's output when using directory manipulation inside a fixture.\n   - Proposed solutions could involve modifying how directory changes are logged so paths to error files remain relative to the original directory, or ensuring any directory changes are properly undone or accounted for when reporting errors.\n\n2. **File Evaluation:**\n   - The file `src/_pytest/monkeypatch.py` provides the `monkeypatch` fixture which allows modification of the environment and includes methods for altering the working directory like `monkeypatch.chdir(path)`.\n   - The `chdir` method appears responsible for changing the current working directory. This is achieved using `os.chdir`.\n   - `undo` method is crucial as it is supposed to reverse any changes made, including restoring the original working directory if it was changed.\n   - Upon inspection, there is no apparent logic in place for maintaining or altering how error report paths should reflect the original directory when changes are made using `monkeypatch.chdir`.\n   - The root cause might be the lack of coordination between this file's `monkeypatch` capabilities and how pytest maintains its idea of the running script's path context during error logging.\n   - Additionally, the underlying issue could be in another part of the pytest codebase responsible for error reporting or path handling.\n\n3. **Conclusion:**\n   - The file `src/_pytest/monkeypatch.py` is relevant because it contains the method that changes the directory (`MonkeyPatch.chdir`).\n   - It might contribute to the problem, but it does not directly cause the incorrect path issue; rather, it lacks a mechanism to ensure paths remain relative to the original directory in error logs.",
        "relevant": true,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/nodes.py",
          "src/_pytest/config.py"
        ],
        "relevant_symbols": [
          "MonkeyPatch.chdir",
          "MonkeyPatch.undo"
        ],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T12:17:49.429049",
        "usage": "8695.22500038147 ms"
      },
      "request": {
        "file_path": "src/_pytest/pytester.py"
      },
      "response": {
        "scratch_pad": "1. Analyzing the reported issue:\n\n1.1 The issue pertains to incorrect file paths displayed when a test fails due to a change in the working directory within a pytest fixture. The problem arises because the path is displayed relative to the changed directory, not the original directory from which pytest was executed.\n\n1.2 The reproduction steps involve changing the directory in a fixture (`private_dir`) using `os.chdir()`. This results in pytest showing the wrong path (`../test_path_error.py:29`) relative to the new directory, instead of the expected `test_path_error.py:29`.\n\n1.3 This issue is caused by changing the current working directory using `os.chdir()` before yielding control back to the test. When pytest captures the failure, it reflects paths relative to the new current directory, not the original one.\n\n1.4 The user expects file paths in test reports to remain relative to the root directory where pytest was executed, regardless of directory changes in fixtures.\n\n1.5 One potential solution could be to capture the original working directory path and modify how pytest constructs file paths, ensuring they are always resolved relative to this original path despite directory changes.\n\n2. Evaluating the provided file (`src/_pytest/pytester.py`):\n\n2.1 The file includes fixtures and methods related to test execution, directory and path manipulation, notably `Testdir`.\n\n2.2 The class `Testdir` appears to encapsulate functionality relevant to creating and running tests in isolated directories, utilizing `monkeypatch` to manipulate environment variables related to path configurations.\n\n2.3 There is a method `CwdSnapshot` within the file that restores the directory. However, its role seems to be to maintain the environment rather than directly address the reported path mismatch.\n\n2.4 The method `runpytest_inprocess` and related functions handle inline pytest execution, possibly influencing path resolution and command execution, though there's no explicit code here that seems to hook into changing file path resolution at error reporting.\n\n2.5 The approach taken by `monkeypatch` and `CwdSnapshot` suggest a mechanism to temporarily alter the environment for tests, potentially influencing how paths are handled during failure, yet no explicit mentions of overriding paths in error reports is observed here.\n\n2.6 This file handles test path configuration and directory manipulation that might relate indirectly to paths; however, it does not seem to directly cause or fix the issue reported.",
        "relevant": false,
        "root_cause": false,
        "relevant_files": [],
        "relevant_symbols": [],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileSymbolSearch",
      "metadata": {
        "start": "2024-08-19T12:17:58.124359",
        "usage": "226.8359661102295 ms"
      },
      "request": {
        "files": [
          {
            "file_path": "src/_pytest/terminal.py",
            "relevant_symbol_keys": [
              "TerminalReporter",
              "TerminalReporter._locationline",
              "TerminalReporter.write_fspath_result"
            ],
            "root_cause_symbol_keys": [
              "TerminalReporter._locationline"
            ]
          },
          {
            "file_path": "src/_pytest/config/__init__.py",
            "relevant_symbol_keys": [
              "Config.cwd_relative_nodeid",
              "Config"
            ],
            "root_cause_symbol_keys": []
          },
          {
            "file_path": "src/_pytest/nodes.py",
            "relevant_symbol_keys": [
              "Node.repr_failure",
              "Node._repr_failure_py",
              "get_fslocation_from_item"
            ],
            "root_cause_symbol_keys": [
              "Node.repr_failure",
              "Node._repr_failure_py",
              "get_fslocation_from_item"
            ]
          },
          {
            "file_path": "src/_pytest/monkeypatch.py",
            "relevant_symbol_keys": [
              "MonkeyPatch.chdir",
              "MonkeyPatch.undo"
            ],
            "root_cause_symbol_keys": []
          },
          {
            "file_path": "src/_pytest/pytester.py",
            "relevant_symbol_keys": [],
            "root_cause_symbol_keys": []
          }
        ],
        "with_content": true
      },
      "response": {
        "related_symbols": [
          {
            "name": "_pytest.terminal.TerminalReporter",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "class TerminalReporter:\n    def __init__(self, config: Config, file=None) -> None:\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None  # type: Optional[Session]\n        self._showfspath = None\n\n        self.stats = {}  # type: Dict[str, List[Any]]\n        self._main_color = None  # type: Optional[str]\n        self._known_types = None  # type: Optional[List]\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None  # type: Any\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()  # type: Set[str]\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None  # type: Optional[float]\n\n    @property\n    def writer(self) -> TerminalWriter:\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        return self._tw\n\n    @writer.setter\n    def writer(self, value: TerminalWriter):\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        self._tw = value\n\n    def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False\n\n    @property\n    def verbosity(self):\n        return self.config.option.verbose\n\n    @property\n    def showheader(self):\n        return self.verbosity >= 0\n\n    @property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0\n        return self._showfspath\n\n    @showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value\n\n    @property\n    def showlongtestinfo(self):\n        return self.verbosity > 0\n\n    def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars\n\n    def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, flush=True, **markup)\n\n    def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2\n\n    def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None\n\n    def write(self, content: str, *, flush: bool = False, **markup: bool) -> None:\n        self._tw.write(content, flush=flush, **markup)\n\n    def flush(self) -> None:\n        self._tw.flush()\n\n    def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)\n\n    def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)\n\n    def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)\n\n    def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)\n\n    def line(self, msg, **kw):\n        self._tw.line(msg, **kw)\n\n    def _add_stats(self, category: str, items: List) -> None:\n        set_main_color = category not in self.stats\n        self.stats.setdefault(category, []).extend(items[:])\n        if set_main_color:\n            self._set_main_color()\n\n    def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1\n\n    def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        self._add_stats(\"warnings\", [warning_report])\n\n    def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)\n\n    def pytest_deselected(self, items):\n        self._add_stats(\"deselected\", items)\n\n    def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n            self.flush()\n        elif self.showfspath:\n            self.write_fspath_result(nodeid, \"\")\n            self.flush()\n\n    def pytest_runtest_logreport(self, report: TestReport) -> None:\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self._add_stats(category, [rep])\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2\n        self.flush()\n\n    @property\n    def _is_last_item(self):\n        return len(self._progress_nodeids_reported) == self._session.testscollected\n\n    def pytest_runtest_logfinish(self, nodeid):\n        assert self._session\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n\n            if self._is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                main_color, _ = self._get_main_color()\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", **{main_color: True})\n\n    def _get_progress_information_message(self) -> str:\n        assert self._session\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                return \" [{:3d}%]\".format(\n                    len(self._progress_nodeids_reported) * 100 // collected\n                )\n            return \" [100%]\"\n\n    def _write_progress_information_filling_space(self):\n        color, _ = self._get_main_color()\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), flush=True, **{color: True})\n\n    @property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        return self._tw.width_of_current_line\n\n    def pytest_collection(self) -> None:\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", flush=True, bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", flush=True, bold=True)\n\n    def pytest_collectreport(self, report: CollectReport) -> None:\n        if report.failed:\n            self._add_stats(\"error\", [report])\n        elif report.skipped:\n            self._add_stats(\"skipped\", [report])\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()\n\n    def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d error%s\" % (errors, \"s\" if errors != 1 else \"\")\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)\n\n    @pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session: Session) -> None:\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n        if pypy_version_info:\n            verinfo = \".\".join(map(str, pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)\n\n    def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)\n\n    def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result\n\n    def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if session.items:\n                if self.config.option.verbose > -1:\n                    self._tw.line(\"\")\n                self._printcollecteditems(session.items)\n\n            failed = self.stats.get(\"failed\")\n            if failed:\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in failed:\n                    rep.toterminal(self._tw)\n\n    def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}  # type: Dict[str, int]\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    try:\n                        obj = col.obj  # type: ignore\n                    except AttributeError:\n                        continue\n                    doc = inspect.getdoc(obj)\n                    if doc:\n                        for line in doc.splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line))\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, session: Session, exitstatus: ExitCode):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if session.shouldfail:\n            self.write_sep(\"!\", session.shouldfail, red=True)\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        elif session.shouldstop:\n            self.write_sep(\"!\", session.shouldstop, red=True)\n        self.summary_stats()\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()\n\n    def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)\n\n    def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()\n\n    def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )\n\n    def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \"\n\n    def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?\n\n    def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"\n\n    #\n    # summaries for sessionfinish\n    #\n    def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values\n\n    def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\n                \"warnings\"\n            )  # type: Optional[List[WarningReport]]\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = (\n                order_preserving_dict()\n            )  # type: Dict[str, List[WarningReport]]\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            def collapsed_location_report(reports: List[WarningReport]):\n                locations = []\n                for w in reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        locations.append(location)\n\n                if len(locations) < 10:\n                    return \"\\n\".join(map(str, locations))\n\n                counts_by_filename = order_preserving_dict()  # type: Dict[str, int]\n                for loc in locations:\n                    key = str(loc).split(\"::\", 1)[0]\n                    counts_by_filename[key] = counts_by_filename.get(key, 0) + 1\n                return \"\\n\".join(\n                    \"{}: {} warning{}\".format(k, v, \"s\" if v > 1 else \"\")\n                    for k, v in counts_by_filename.items()\n                )\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, message_reports in reports_grouped_by_message.items():\n                maybe_location = collapsed_location_report(message_reports)\n                if maybe_location:\n                    self._tw.line(maybe_location)\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")\n\n    def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)\n\n    def _get_teardown_reports(self, nodeid: str) -> List[TestReport]:\n        return [\n            report\n            for report in self.getreports(\"\")\n            if report.when == \"teardown\" and report.nodeid == nodeid\n        ]\n\n    def _handle_teardown_sections(self, nodeid: str) -> None:\n        for report in self._get_teardown_reports(nodeid):\n            self.print_teardown_sections(report)\n\n    def print_teardown_sections(self, rep: TestReport) -> None:\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)\n\n    def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)\n\n    def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)\n\n    def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)\n\n    def summary_stats(self):\n        if self.verbosity < -1:\n            return\n\n        session_duration = time.time() - self._sessionstarttime\n        (parts, main_color) = self.build_summary_stats_line()\n        line_parts = []\n\n        display_sep = self.verbosity >= 0\n        if display_sep:\n            fullwidth = self._tw.fullwidth\n        for text, markup in parts:\n            with_markup = self._tw.markup(text, **markup)\n            if display_sep:\n                fullwidth += len(with_markup) - len(text)\n            line_parts.append(with_markup)\n        msg = \", \".join(line_parts)\n\n        main_markup = {main_color: True}\n        duration = \" in {}\".format(format_session_duration(session_duration))\n        duration_with_markup = self._tw.markup(duration, **main_markup)\n        if display_sep:\n            fullwidth += len(duration_with_markup) - len(duration)\n        msg += duration_with_markup\n\n        if display_sep:\n            markup_for_end_sep = self._tw.markup(\"\", **main_markup)\n            if markup_for_end_sep.endswith(\"\\x1b[0m\"):\n                markup_for_end_sep = markup_for_end_sep[:-4]\n            fullwidth += len(markup_for_end_sep)\n            msg += markup_for_end_sep\n\n        if display_sep:\n            self.write_sep(\"=\", msg, fullwidth=fullwidth, **main_markup)\n        else:\n            self.write_line(msg, **main_markup)\n\n    def short_test_summary(self) -> None:\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines: List[str]) -> None:\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self._tw.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines: List[str]) -> None:\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines: List[str]) -> None:\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines: List[str]) -> None:\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(self.startdir, skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }  # type: Mapping[str, Callable[[List[str]], None]]\n\n        lines = []  # type: List[str]\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:\n                self.write_line(line)\n\n    def _get_main_color(self) -> Tuple[str, List[str]]:\n        if self._main_color is None or self._known_types is None or self._is_last_item:\n            self._set_main_color()\n            assert self._main_color\n            assert self._known_types\n        return self._main_color, self._known_types\n\n    def _determine_main_color(self, unknown_type_seen: bool) -> str:\n        stats = self.stats\n        if \"failed\" in stats or \"error\" in stats:\n            main_color = \"red\"\n        elif \"warnings\" in stats or \"xpassed\" in stats or unknown_type_seen:\n            main_color = \"yellow\"\n        elif \"passed\" in stats or not self._is_last_item:\n            main_color = \"green\"\n        else:\n            main_color = \"yellow\"\n        return main_color\n\n    def _set_main_color(self) -> None:\n        unknown_types = []  # type: List[str]\n        for found_type in self.stats.keys():\n            if found_type:  # setup/teardown reports have an empty key, ignore them\n                if found_type not in KNOWN_TYPES and found_type not in unknown_types:\n                    unknown_types.append(found_type)\n        self._known_types = list(KNOWN_TYPES) + unknown_types\n        self._main_color = self._determine_main_color(bool(unknown_types))\n\n    def build_summary_stats_line(self) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:\n        main_color, known_types = self._get_main_color()\n\n        parts = []\n        for key in known_types:\n            reports = self.stats.get(key, None)\n            if reports:\n                count = sum(\n                    1 for rep in reports if getattr(rep, \"count_towards_summary\", True)\n                )\n                color = _color_for_type.get(key, _color_for_type_default)\n                markup = {color: True, \"bold\": color == main_color}\n                parts.append((\"%d %s\" % _make_plural(count, key), markup))\n\n        if not parts:\n            parts = [(\"no tests ran\", {_color_for_type_default: True})]\n\n        return parts, main_color",
            "start_line": 261,
            "start_column": 7463,
            "end_line": 0,
            "end_column": 40474,
            "start_byte": 7463,
            "end_byte": 0
          },
          {
            "name": "_pytest.terminal.TerminalReporter.__init__",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def __init__(self, config: Config, file=None) -> None:\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None  # type: Optional[Session]\n        self._showfspath = None\n\n        self.stats = {}  # type: Dict[str, List[Any]]\n        self._main_color = None  # type: Optional[str]\n        self._known_types = None  # type: Optional[List]\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None  # type: Any\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()  # type: Set[str]\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None  # type: Optional[float]",
            "start_line": 262,
            "start_column": 7491,
            "end_line": 4,
            "end_column": 8496,
            "start_byte": 7491,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.writer",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def writer(self) -> TerminalWriter:\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        return self._tw",
            "start_line": 286,
            "start_column": 8502,
            "end_line": 4,
            "end_column": 8634,
            "start_byte": 8502,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.writer",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@writer.setter\n    def writer(self, value: TerminalWriter):\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        self._tw = value",
            "start_line": 291,
            "start_column": 8640,
            "end_line": 4,
            "end_column": 8783,
            "start_byte": 8640,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._determine_show_progress_info",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False",
            "start_line": 296,
            "start_column": 8789,
            "end_line": 4,
            "end_column": 9372,
            "start_byte": 8789,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.verbosity",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def verbosity(self):\n        return self.config.option.verbose",
            "start_line": 309,
            "start_column": 9378,
            "end_line": 4,
            "end_column": 9454,
            "start_byte": 9378,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.showheader",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def showheader(self):\n        return self.verbosity >= 0",
            "start_line": 313,
            "start_column": 9460,
            "end_line": 4,
            "end_column": 9530,
            "start_byte": 9460,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.showfspath",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0\n        return self._showfspath",
            "start_line": 317,
            "start_column": 9536,
            "end_line": 4,
            "end_column": 9679,
            "start_byte": 9536,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.showfspath",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value",
            "start_line": 323,
            "start_column": 9685,
            "end_line": 4,
            "end_column": 9769,
            "start_byte": 9685,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.showlongtestinfo",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def showlongtestinfo(self):\n        return self.verbosity > 0",
            "start_line": 327,
            "start_column": 9775,
            "end_line": 4,
            "end_column": 9850,
            "start_byte": 9775,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.hasopt",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars",
            "start_line": 331,
            "start_column": 9856,
            "end_line": 4,
            "end_column": 9983,
            "start_byte": 9856,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.write_fspath_result",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, flush=True, **markup)",
            "start_line": 335,
            "start_column": 9989,
            "end_line": 4,
            "end_column": 10686,
            "start_byte": 9989,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.write_ensure_prefix",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2",
            "start_line": 348,
            "start_column": 10692,
            "end_line": 4,
            "end_column": 10992,
            "start_byte": 10692,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.ensure_newline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None",
            "start_line": 357,
            "start_column": 10998,
            "end_line": 4,
            "end_column": 11120,
            "start_byte": 10998,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.write",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write(self, content: str, *, flush: bool = False, **markup: bool) -> None:\n        self._tw.write(content, flush=flush, **markup)",
            "start_line": 362,
            "start_column": 11126,
            "end_line": 4,
            "end_column": 11259,
            "start_byte": 11126,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.flush",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def flush(self) -> None:\n        self._tw.flush()",
            "start_line": 365,
            "start_column": 11265,
            "end_line": 4,
            "end_column": 11314,
            "start_byte": 11265,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.write_line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)",
            "start_line": 368,
            "start_column": 11320,
            "end_line": 4,
            "end_column": 11510,
            "start_byte": 11320,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.rewrite",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)",
            "start_line": 374,
            "start_column": 11516,
            "end_line": 4,
            "end_column": 12134,
            "start_byte": 11516,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.write_sep",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)",
            "start_line": 392,
            "start_column": 12140,
            "end_line": 4,
            "end_column": 12260,
            "start_byte": 12140,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.section",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)",
            "start_line": 396,
            "start_column": 12266,
            "end_line": 4,
            "end_column": 12345,
            "start_byte": 12266,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def line(self, msg, **kw):\n        self._tw.line(msg, **kw)",
            "start_line": 399,
            "start_column": 12351,
            "end_line": 4,
            "end_column": 12410,
            "start_byte": 12351,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._add_stats",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _add_stats(self, category: str, items: List) -> None:\n        set_main_color = category not in self.stats\n        self.stats.setdefault(category, []).extend(items[:])\n        if set_main_color:\n            self._set_main_color()",
            "start_line": 402,
            "start_column": 12416,
            "end_line": 4,
            "end_column": 12648,
            "start_byte": 12416,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_internalerror",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1",
            "start_line": 408,
            "start_column": 12654,
            "end_line": 4,
            "end_column": 12811,
            "start_byte": 12654,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_warning_captured",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        self._add_stats(\"warnings\", [warning_report])",
            "start_line": 413,
            "start_column": 12817,
            "end_line": 4,
            "end_column": 13350,
            "start_byte": 12817,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_plugin_registered",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)",
            "start_line": 426,
            "start_column": 13356,
            "end_line": 4,
            "end_column": 13731,
            "start_byte": 13356,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_deselected",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_deselected(self, items):\n        self._add_stats(\"deselected\", items)",
            "start_line": 434,
            "start_column": 13737,
            "end_line": 4,
            "end_column": 13817,
            "start_byte": 13737,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logstart",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n            self.flush()\n        elif self.showfspath:\n            self.write_fspath_result(nodeid, \"\")\n            self.flush()",
            "start_line": 437,
            "start_column": 13823,
            "end_line": 4,
            "end_column": 14241,
            "start_byte": 13823,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logreport",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_runtest_logreport(self, report: TestReport) -> None:\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self._add_stats(category, [rep])\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2\n        self.flush()",
            "start_line": 448,
            "start_column": 14247,
            "end_line": 4,
            "end_column": 16159,
            "start_byte": 14247,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._is_last_item",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def _is_last_item(self):\n        return len(self._progress_nodeids_reported) == self._session.testscollected",
            "start_line": 497,
            "start_column": 16165,
            "end_line": 4,
            "end_column": 16287,
            "start_byte": 16165,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logfinish",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_runtest_logfinish(self, nodeid):\n        assert self._session\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n\n            if self._is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                main_color, _ = self._get_main_color()\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", **{main_color: True})",
            "start_line": 501,
            "start_column": 16293,
            "end_line": 4,
            "end_column": 17210,
            "start_byte": 16293,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._get_progress_information_message",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _get_progress_information_message(self) -> str:\n        assert self._session\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                return \" [{:3d}%]\".format(\n                    len(self._progress_nodeids_reported) * 100 // collected\n                )\n            return \" [100%]\"",
            "start_line": 522,
            "start_column": 17216,
            "end_line": 4,
            "end_column": 17957,
            "start_byte": 17216,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._write_progress_information_filling_space",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _write_progress_information_filling_space(self):\n        color, _ = self._get_main_color()\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), flush=True, **{color: True})",
            "start_line": 539,
            "start_column": 17963,
            "end_line": 4,
            "end_column": 18259,
            "start_byte": 17963,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._width_of_current_line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        return self._tw.width_of_current_line",
            "start_line": 546,
            "start_column": 18265,
            "end_line": 4,
            "end_column": 18465,
            "start_byte": 18265,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_collection",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_collection(self) -> None:\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", flush=True, bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", flush=True, bold=True)",
            "start_line": 551,
            "start_column": 18471,
            "end_line": 4,
            "end_column": 18821,
            "start_byte": 18471,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_collectreport",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_collectreport(self, report: CollectReport) -> None:\n        if report.failed:\n            self._add_stats(\"error\", [report])\n        elif report.skipped:\n            self._add_stats(\"skipped\", [report])\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()",
            "start_line": 559,
            "start_column": 18827,
            "end_line": 4,
            "end_column": 19212,
            "start_byte": 18827,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.report_collect",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d error%s\" % (errors, \"s\" if errors != 1 else \"\")\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)",
            "start_line": 569,
            "start_column": 19218,
            "end_line": 4,
            "end_column": 20633,
            "start_byte": 19218,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_sessionstart",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session: Session) -> None:\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n        if pypy_version_info:\n            verinfo = \".\".join(map(str, pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)",
            "start_line": 609,
            "start_column": 20639,
            "end_line": 4,
            "end_column": 21805,
            "start_byte": 20639,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._write_report_lines_from_hooks",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)",
            "start_line": 637,
            "start_column": 21811,
            "end_line": 4,
            "end_column": 21954,
            "start_byte": 21811,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_report_header",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result",
            "start_line": 642,
            "start_column": 21960,
            "end_line": 4,
            "end_column": 22615,
            "start_byte": 21960,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_collection_finish",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if session.items:\n                if self.config.option.verbose > -1:\n                    self._tw.line(\"\")\n                self._printcollecteditems(session.items)\n\n            failed = self.stats.get(\"failed\")\n            if failed:\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in failed:\n                    rep.toterminal(self._tw)",
            "start_line": 659,
            "start_column": 22621,
            "end_line": 4,
            "end_column": 23336,
            "start_byte": 22621,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._printcollecteditems",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}  # type: Dict[str, int]\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    try:\n                        obj = col.obj  # type: ignore\n                    except AttributeError:\n                        continue\n                    doc = inspect.getdoc(obj)\n                    if doc:\n                        for line in doc.splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line))",
            "start_line": 679,
            "start_column": 23342,
            "end_line": 4,
            "end_column": 25064,
            "start_byte": 23342,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_sessionfinish",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, session: Session, exitstatus: ExitCode):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if session.shouldfail:\n            self.write_sep(\"!\", session.shouldfail, red=True)\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        elif session.shouldstop:\n            self.write_sep(\"!\", session.shouldstop, red=True)\n        self.summary_stats()",
            "start_line": 719,
            "start_column": 25070,
            "end_line": 4,
            "end_column": 26017,
            "start_byte": 25070,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_terminal_summary",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()",
            "start_line": 744,
            "start_column": 26023,
            "end_line": 4,
            "end_column": 26366,
            "start_byte": 26023,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_keyboard_interrupt",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)",
            "start_line": 755,
            "start_column": 26372,
            "end_line": 4,
            "end_column": 26487,
            "start_byte": 26372,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_unconfigure",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()",
            "start_line": 758,
            "start_column": 26493,
            "end_line": 4,
            "end_column": 26620,
            "start_byte": 26493,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._report_keyboardinterrupt",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )",
            "start_line": 762,
            "start_column": 26626,
            "end_line": 4,
            "end_column": 27154,
            "start_byte": 26626,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._getfailureheadline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?",
            "start_line": 798,
            "start_column": 27988,
            "end_line": 4,
            "end_column": 28146,
            "start_byte": 27988,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._getcrashline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"",
            "start_line": 804,
            "start_column": 28152,
            "end_line": 4,
            "end_column": 28396,
            "start_byte": 28152,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.getreports",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values",
            "start_line": 816,
            "start_column": 28448,
            "end_line": 4,
            "end_column": 28637,
            "start_byte": 28448,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.summary_warnings",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\n                \"warnings\"\n            )  # type: Optional[List[WarningReport]]\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = (\n                order_preserving_dict()\n            )  # type: Dict[str, List[WarningReport]]\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            def collapsed_location_report(reports: List[WarningReport]):\n                locations = []\n                for w in reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        locations.append(location)\n\n                if len(locations) < 10:\n                    return \"\\n\".join(map(str, locations))\n\n                counts_by_filename = order_preserving_dict()  # type: Dict[str, int]\n                for loc in locations:\n                    key = str(loc).split(\"::\", 1)[0]\n                    counts_by_filename[key] = counts_by_filename.get(key, 0) + 1\n                return \"\\n\".join(\n                    \"{}: {} warning{}\".format(k, v, \"s\" if v > 1 else \"\")\n                    for k, v in counts_by_filename.items()\n                )\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, message_reports in reports_grouped_by_message.items():\n                maybe_location = collapsed_location_report(message_reports)\n                if maybe_location:\n                    self._tw.line(maybe_location)\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")",
            "start_line": 823,
            "start_column": 28643,
            "end_line": 4,
            "end_column": 31098,
            "start_byte": 28643,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.summary_passes",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)",
            "start_line": 880,
            "start_column": 31104,
            "end_line": 4,
            "end_column": 31684,
            "start_byte": 31104,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._get_teardown_reports",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _get_teardown_reports(self, nodeid: str) -> List[TestReport]:\n        return [\n            report\n            for report in self.getreports(\"\")\n            if report.when == \"teardown\" and report.nodeid == nodeid\n        ]",
            "start_line": 894,
            "start_column": 31690,
            "end_line": 4,
            "end_column": 31916,
            "start_byte": 31690,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._handle_teardown_sections",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _handle_teardown_sections(self, nodeid: str) -> None:\n        for report in self._get_teardown_reports(nodeid):\n            self.print_teardown_sections(report)",
            "start_line": 901,
            "start_column": 31922,
            "end_line": 4,
            "end_column": 32086,
            "start_byte": 31922,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.print_teardown_sections",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def print_teardown_sections(self, rep: TestReport) -> None:\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)",
            "start_line": 905,
            "start_column": 32092,
            "end_line": 4,
            "end_column": 32598,
            "start_byte": 32092,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.summary_failures",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)",
            "start_line": 918,
            "start_column": 32604,
            "end_line": 4,
            "end_column": 33288,
            "start_byte": 32604,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.summary_errors",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)",
            "start_line": 935,
            "start_column": 33294,
            "end_line": 4,
            "end_column": 33890,
            "start_byte": 33294,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._outrep_summary",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)",
            "start_line": 950,
            "start_column": 33896,
            "end_line": 4,
            "end_column": 34353,
            "start_byte": 33896,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.summary_stats",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_stats(self):\n        if self.verbosity < -1:\n            return\n\n        session_duration = time.time() - self._sessionstarttime\n        (parts, main_color) = self.build_summary_stats_line()\n        line_parts = []\n\n        display_sep = self.verbosity >= 0\n        if display_sep:\n            fullwidth = self._tw.fullwidth\n        for text, markup in parts:\n            with_markup = self._tw.markup(text, **markup)\n            if display_sep:\n                fullwidth += len(with_markup) - len(text)\n            line_parts.append(with_markup)\n        msg = \", \".join(line_parts)\n\n        main_markup = {main_color: True}\n        duration = \" in {}\".format(format_session_duration(session_duration))\n        duration_with_markup = self._tw.markup(duration, **main_markup)\n        if display_sep:\n            fullwidth += len(duration_with_markup) - len(duration)\n        msg += duration_with_markup\n\n        if display_sep:\n            markup_for_end_sep = self._tw.markup(\"\", **main_markup)\n            if markup_for_end_sep.endswith(\"\\x1b[0m\"):\n                markup_for_end_sep = markup_for_end_sep[:-4]\n            fullwidth += len(markup_for_end_sep)\n            msg += markup_for_end_sep\n\n        if display_sep:\n            self.write_sep(\"=\", msg, fullwidth=fullwidth, **main_markup)\n        else:\n            self.write_line(msg, **main_markup)",
            "start_line": 963,
            "start_column": 34359,
            "end_line": 4,
            "end_column": 35728,
            "start_byte": 34359,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.short_test_summary",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def short_test_summary(self) -> None:\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines: List[str]) -> None:\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self._tw.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines: List[str]) -> None:\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines: List[str]) -> None:\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines: List[str]) -> None:\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(self.startdir, skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }  # type: Mapping[str, Callable[[List[str]], None]]\n\n        lines = []  # type: List[str]\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:\n                self.write_line(line)",
            "start_line": 1000,
            "start_column": 35734,
            "end_line": 4,
            "end_column": 38473,
            "start_byte": 35734,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._get_main_color",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _get_main_color(self) -> Tuple[str, List[str]]:\n        if self._main_color is None or self._known_types is None or self._is_last_item:\n            self._set_main_color()\n            assert self._main_color\n            assert self._known_types\n        return self._main_color, self._known_types",
            "start_line": 1069,
            "start_column": 38479,
            "end_line": 4,
            "end_column": 38777,
            "start_byte": 38479,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._determine_main_color",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _determine_main_color(self, unknown_type_seen: bool) -> str:\n        stats = self.stats\n        if \"failed\" in stats or \"error\" in stats:\n            main_color = \"red\"\n        elif \"warnings\" in stats or \"xpassed\" in stats or unknown_type_seen:\n            main_color = \"yellow\"\n        elif \"passed\" in stats or not self._is_last_item:\n            main_color = \"green\"\n        else:\n            main_color = \"yellow\"\n        return main_color",
            "start_line": 1076,
            "start_column": 38783,
            "end_line": 4,
            "end_column": 39231,
            "start_byte": 38783,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._set_main_color",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _set_main_color(self) -> None:\n        unknown_types = []  # type: List[str]\n        for found_type in self.stats.keys():\n            if found_type:  # setup/teardown reports have an empty key, ignore them\n                if found_type not in KNOWN_TYPES and found_type not in unknown_types:\n                    unknown_types.append(found_type)\n        self._known_types = list(KNOWN_TYPES) + unknown_types\n        self._main_color = self._determine_main_color(bool(unknown_types))",
            "start_line": 1088,
            "start_column": 39237,
            "end_line": 4,
            "end_column": 39722,
            "start_byte": 39237,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.build_summary_stats_line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def build_summary_stats_line(self) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:\n        main_color, known_types = self._get_main_color()\n\n        parts = []\n        for key in known_types:\n            reports = self.stats.get(key, None)\n            if reports:\n                count = sum(\n                    1 for rep in reports if getattr(rep, \"count_towards_summary\", True)\n                )\n                color = _color_for_type.get(key, _color_for_type_default)\n                markup = {color: True, \"bold\": color == main_color}\n                parts.append((\"%d %s\" % _make_plural(count, key), markup))\n\n        if not parts:\n            parts = [(\"no tests ran\", {_color_for_type_default: True})]\n\n        return parts, main_color",
            "start_line": 1097,
            "start_column": 39728,
            "end_line": 4,
            "end_column": 40474,
            "start_byte": 39728,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "class Config:\n    \"\"\"\n    Access to configuration values, pluginmanager and plugin hooks.\n\n    :param PytestPluginManager pluginmanager:\n\n    :param InvocationParams invocation_params:\n        Object containing the parameters regarding the ``pytest.main``\n        invocation.\n    \"\"\"\n\n    @attr.s(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during ``pytest.main()``\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args = attr.ib(converter=tuple)\n        \"\"\"tuple of command-line arguments as passed to ``pytest.main()``.\"\"\"\n        plugins = attr.ib()\n        \"\"\"list of extra plugins, might be `None`.\"\"\"\n        dir = attr.ib(type=Path)\n        \"\"\"directory where ``pytest.main()`` was invoked from.\"\"\"\n\n    def __init__(\n        self,\n        pluginmanager: PytestPluginManager,\n        *,\n        invocation_params: Optional[InvocationParams] = None\n    ) -> None:\n        from .argparsing import Parser, FILE_OR_DIR\n\n        if invocation_params is None:\n            invocation_params = self.InvocationParams(\n                args=(), plugins=None, dir=Path().resolve()\n            )\n\n        self.option = argparse.Namespace()\n        \"\"\"access to command line option as attributes.\n\n          :type: argparse.Namespace\"\"\"\n\n        self.invocation_params = invocation_params\n\n        _a = FILE_OR_DIR\n        self._parser = Parser(\n            usage=\"%(prog)s [options] [{}] [{}] [...]\".format(_a, _a),\n            processopt=self._processopt,\n        )\n        self.pluginmanager = pluginmanager\n        \"\"\"the plugin manager handles plugin registration and hook invocation.\n\n          :type: PytestPluginManager\"\"\"\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook = self.pluginmanager.hook\n        self._inicache = {}  # type: Dict[str, Any]\n        self._override_ini = ()  # type: Sequence[str]\n        self._opt2dest = {}  # type: Dict[str, str]\n        self._cleanup = []  # type: List[Callable[[], None]]\n        # A place where plugins can store information on the config for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n\n        if TYPE_CHECKING:\n            from _pytest.cacheprovider import Cache\n\n            self.cache = None  # type: Optional[Cache]\n\n    @property\n    def invocation_dir(self):\n        \"\"\"Backward compatibility\"\"\"\n        return py.path.local(str(self.invocation_params.dir))\n\n    def add_cleanup(self, func):\n        \"\"\" Add a function to be called when the config object gets out of\n        use (usually coninciding with pytest_unconfigure).\"\"\"\n        self._cleanup.append(func)\n\n    def _do_configure(self):\n        assert not self._configured\n        self._configured = True\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"default\")\n            self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\n\n    def _ensure_unconfigure(self):\n        if self._configured:\n            self._configured = False\n            self.hook.pytest_unconfigure(config=self)\n            self.hook.pytest_configure._call_history = []\n        while self._cleanup:\n            fin = self._cleanup.pop()\n            fin()\n\n    def get_terminal_writer(self):\n        return self.pluginmanager.get_plugin(\"terminalreporter\")._tw\n\n    def pytest_cmdline_parse(self, pluginmanager, args):\n        try:\n            self.parse(args)\n        except UsageError:\n\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"version\", False) or \"--version\" in args:\n                from _pytest.helpconfig import showversion\n\n                showversion(self)\n            elif (\n                getattr(self.option, \"help\", False) or \"--help\" in args or \"-h\" in args\n            ):\n                self._parser._getparser().print_help()\n                sys.stdout.write(\n                    \"\\nNOTE: displaying only minimal help due to UsageError.\\n\\n\"\n                )\n\n            raise\n\n        return self\n\n    def notify_exception(self, excinfo, option=None):\n        if option and getattr(option, \"fulltrace\", False):\n            style = \"long\"\n        else:\n            style = \"native\"\n        excrepr = excinfo.getrepr(\n            funcargs=True, showlocals=getattr(option, \"showlocals\", False), style=style\n        )\n        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\n        if not any(res):\n            for line in str(excrepr).split(\"\\n\"):\n                sys.stderr.write(\"INTERNALERROR> %s\\n\" % line)\n                sys.stderr.flush()\n\n    def cwd_relative_nodeid(self, nodeid):\n        # nodeid's are relative to the rootpath, compute relative to cwd\n        if self.invocation_dir != self.rootdir:\n            fullpath = self.rootdir.join(nodeid)\n            nodeid = self.invocation_dir.bestrelpath(fullpath)\n        return nodeid\n\n    @classmethod\n    def fromdictargs(cls, option_dict, args):\n        \"\"\" constructor usable for subprocesses. \"\"\"\n        config = get_config(args)\n        config.option.__dict__.update(option_dict)\n        config.parse(args, addopts=False)\n        for x in config.option.plugins:\n            config.pluginmanager.consider_pluginarg(x)\n        return config\n\n    def _processopt(self, opt: \"Argument\") -> None:\n        for name in opt._short_opts + opt._long_opts:\n            self._opt2dest[name] = opt.dest\n\n        if hasattr(opt, \"default\"):\n            if not hasattr(self.option, opt.dest):\n                setattr(self.option, opt.dest, opt.default)\n\n    @hookimpl(trylast=True)\n    def pytest_load_initial_conftests(self, early_config):\n        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)\n\n    def _initini(self, args: Sequence[str]) -> None:\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(\n            args, namespace=copy.copy(self.option)\n        )\n        r = determine_setup(\n            ns.inifilename,\n            ns.file_or_dir + unknown_args,\n            rootdir_cmd_arg=ns.rootdir or None,\n            config=self,\n        )\n        self.rootdir, self.inifile, self.inicfg = r\n        self._parser.extra_info[\"rootdir\"] = self.rootdir\n        self._parser.extra_info[\"inifile\"] = self.inifile\n        self._parser.addini(\"addopts\", \"extra command line options\", \"args\")\n        self._parser.addini(\"minversion\", \"minimally required pytest version\")\n        self._override_ini = ns.override_ini or ()\n\n    def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook)\n        _warn_about_missing_assertion(mode)\n\n    def _mark_plugins_for_rewrite(self, hook):\n        \"\"\"\n        Given an importhook, mark for rewrite any top-level\n        modules or packages in the distribution package for\n        all pytest plugins.\n        \"\"\"\n        self.pluginmanager.rewrite_hook = hook\n\n        if os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # We don't autoload from setuptools entry points, no need to continue.\n            return\n\n        package_files = (\n            str(file)\n            for dist in importlib_metadata.distributions()\n            if any(ep.group == \"pytest11\" for ep in dist.entry_points)\n            for file in dist.files or []\n        )\n\n        for name in _iter_rewritable_modules(package_files):\n            hook.mark_rewrite(name)\n\n    def _validate_args(self, args: List[str], via: str) -> List[str]:\n        \"\"\"Validate known args.\"\"\"\n        self._parser._config_source_hint = via  # type: ignore\n        try:\n            self._parser.parse_known_and_unknown_args(\n                args, namespace=copy.copy(self.option)\n            )\n        finally:\n            del self._parser._config_source_hint  # type: ignore\n\n        return args\n\n    def _preparse(self, args: List[str], addopts: bool = True) -> None:\n        if addopts:\n            env_addopts = os.environ.get(\"PYTEST_ADDOPTS\", \"\")\n            if len(env_addopts):\n                args[:] = (\n                    self._validate_args(shlex.split(env_addopts), \"via PYTEST_ADDOPTS\")\n                    + args\n                )\n        self._initini(args)\n        if addopts:\n            args[:] = (\n                self._validate_args(self.getini(\"addopts\"), \"via addopts config\") + args\n            )\n\n        self._checkversion()\n        self._consider_importhook(args)\n        self.pluginmanager.consider_preparse(args, exclude_only=False)\n        if not os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # Don't autoload from setuptools entry point. Only explicitly specified\n            # plugins are going to be loaded.\n            self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\n        self.pluginmanager.consider_env()\n        self.known_args_namespace = ns = self._parser.parse_known_args(\n            args, namespace=copy.copy(self.option)\n        )\n        if self.known_args_namespace.confcutdir is None and self.inifile:\n            confcutdir = py.path.local(self.inifile).dirname\n            self.known_args_namespace.confcutdir = confcutdir\n        try:\n            self.hook.pytest_load_initial_conftests(\n                early_config=self, args=args, parser=self._parser\n            )\n        except ConftestImportFailure as e:\n            if ns.help or ns.version:\n                # we don't want to prevent --help/--version to work\n                # so just let is pass and print a warning at the end\n                from _pytest.warnings import _issue_warning_captured\n\n                _issue_warning_captured(\n                    PytestConfigWarning(\n                        \"could not load initial conftests: {}\".format(e.path)\n                    ),\n                    self.hook,\n                    stacklevel=2,\n                )\n            else:\n                raise\n\n    def _checkversion(self):\n        import pytest\n\n        minver = self.inicfg.get(\"minversion\", None)\n        if minver:\n            # Imported lazily to improve start-up time.\n            from packaging.version import Version\n\n            if Version(minver) > Version(pytest.__version__):\n                raise pytest.UsageError(\n                    \"%s:%d: requires pytest-%s, actual pytest-%s'\"\n                    % (\n                        self.inicfg.config.path,\n                        self.inicfg.lineof(\"minversion\"),\n                        minver,\n                        pytest.__version__,\n                    )\n                )\n\n    def parse(self, args: List[str], addopts: bool = True) -> None:\n        # parse given cmdline arguments into this config object.\n        assert not hasattr(\n            self, \"args\"\n        ), \"can only parse cmdline args at most once per Config object\"\n        self.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=self.pluginmanager)\n        )\n        self._preparse(args, addopts=addopts)\n        # XXX deprecated hook:\n        self.hook.pytest_cmdline_preparse(config=self, args=args)\n        self._parser.after_preparse = True  # type: ignore\n        try:\n            args = self._parser.parse_setoption(\n                args, self.option, namespace=self.option\n            )\n            if not args:\n                if self.invocation_dir == self.rootdir:\n                    args = self.getini(\"testpaths\")\n                if not args:\n                    args = [str(self.invocation_dir)]\n            self.args = args\n        except PrintHelp:\n            pass\n\n    def addinivalue_line(self, name, line):\n        \"\"\" add a line to an ini-file option. The option must have been\n        declared but might not yet be set in which case the line becomes the\n        the first line in its value. \"\"\"\n        x = self.getini(name)\n        assert isinstance(x, list)\n        x.append(line)  # modifies the cached list inline\n\n    def getini(self, name: str):\n        \"\"\" return configuration value from an :ref:`ini file <inifiles>`. If the\n        specified name hasn't been registered through a prior\n        :py:func:`parser.addini <_pytest.config.argparsing.Parser.addini>`\n        call (usually from a plugin), a ValueError is raised. \"\"\"\n        try:\n            return self._inicache[name]\n        except KeyError:\n            self._inicache[name] = val = self._getini(name)\n            return val\n\n    def _getini(self, name: str) -> Any:\n        try:\n            description, type, default = self._parser._inidict[name]\n        except KeyError:\n            raise ValueError(\"unknown configuration value: {!r}\".format(name))\n        value = self._get_override_ini_value(name)\n        if value is None:\n            try:\n                value = self.inicfg[name]\n            except KeyError:\n                if default is not None:\n                    return default\n                if type is None:\n                    return \"\"\n                return []\n        if type == \"pathlist\":\n            dp = py.path.local(self.inicfg.config.path).dirpath()\n            values = []\n            for relpath in shlex.split(value):\n                values.append(dp.join(relpath, abs=True))\n            return values\n        elif type == \"args\":\n            return shlex.split(value)\n        elif type == \"linelist\":\n            return [t for t in map(lambda x: x.strip(), value.split(\"\\n\")) if t]\n        elif type == \"bool\":\n            return bool(_strtobool(value.strip()))\n        else:\n            assert type is None\n            return value\n\n    def _getconftest_pathlist(self, name, path):\n        try:\n            mod, relroots = self.pluginmanager._rget_with_confmod(name, path)\n        except KeyError:\n            return None\n        modpath = py.path.local(mod.__file__).dirpath()\n        values = []\n        for relroot in relroots:\n            if not isinstance(relroot, py.path.local):\n                relroot = relroot.replace(\"/\", py.path.local.sep)\n                relroot = modpath.join(relroot, abs=True)\n            values.append(relroot)\n        return values\n\n    def _get_override_ini_value(self, name: str) -> Optional[str]:\n        value = None\n        # override_ini is a list of \"ini=value\" options\n        # always use the last item if multiple values are set for same ini-name,\n        # e.g. -o foo=bar1 -o foo=bar2 will set foo to bar2\n        for ini_config in self._override_ini:\n            try:\n                key, user_ini_value = ini_config.split(\"=\", 1)\n            except ValueError:\n                raise UsageError(\n                    \"-o/--override-ini expects option=value style (got: {!r}).\".format(\n                        ini_config\n                    )\n                )\n            else:\n                if key == name:\n                    value = user_ini_value\n        return value\n\n    def getoption(self, name: str, default=notset, skip: bool = False):\n        \"\"\" return command line option value.\n\n        :arg name: name of the option.  You may also specify\n            the literal ``--OPT`` option instead of the \"dest\" option name.\n        :arg default: default value if no option of that name exists.\n        :arg skip: if True raise pytest.skip if option does not exists\n            or has a None value.\n        \"\"\"\n        name = self._opt2dest.get(name, name)\n        try:\n            val = getattr(self.option, name)\n            if val is None and skip:\n                raise AttributeError(name)\n            return val\n        except AttributeError:\n            if default is not notset:\n                return default\n            if skip:\n                import pytest\n\n                pytest.skip(\"no {!r} option found\".format(name))\n            raise ValueError(\"no option named {!r}\".format(name))\n\n    def getvalue(self, name, path=None):\n        \"\"\" (deprecated, use getoption()) \"\"\"\n        return self.getoption(name)\n\n    def getvalueorskip(self, name, path=None):\n        \"\"\" (deprecated, use getoption(skip=True)) \"\"\"\n        return self.getoption(name, skip=True)",
            "start_line": 756,
            "start_column": 25530,
            "end_line": 0,
            "end_column": 42793,
            "start_byte": 25530,
            "end_byte": 0
          },
          {
            "name": "_pytest.config.Config.InvocationParams",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@attr.s(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during ``pytest.main()``\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args = attr.ib(converter=tuple)\n        \"\"\"tuple of command-line arguments as passed to ``pytest.main()``.\"\"\"\n        plugins = attr.ib()\n        \"\"\"list of extra plugins, might be `None`.\"\"\"\n        dir = attr.ib(type=Path)\n        \"\"\"directory where ``pytest.main()`` was invoked from.\"\"\"",
            "start_line": 767,
            "start_column": 25819,
            "end_line": 4,
            "end_column": 26589,
            "start_byte": 25819,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.InvocationParams.args",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "args = attr.ib(converter=tuple)",
            "start_line": 783,
            "start_column": 26299,
            "end_line": 8,
            "end_column": 26330,
            "start_byte": 26299,
            "end_byte": 8
          },
          {
            "name": "_pytest.config.Config.InvocationParams.plugins",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "plugins = attr.ib()",
            "start_line": 785,
            "start_column": 26417,
            "end_line": 8,
            "end_column": 26436,
            "start_byte": 26417,
            "end_byte": 8
          },
          {
            "name": "_pytest.config.Config.InvocationParams.dir",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "dir = attr.ib(type=Path)",
            "start_line": 787,
            "start_column": 26499,
            "end_line": 8,
            "end_column": 26523,
            "start_byte": 26499,
            "end_byte": 8
          },
          {
            "name": "_pytest.config.Config.__init__",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def __init__(\n        self,\n        pluginmanager: PytestPluginManager,\n        *,\n        invocation_params: Optional[InvocationParams] = None\n    ) -> None:\n        from .argparsing import Parser, FILE_OR_DIR\n\n        if invocation_params is None:\n            invocation_params = self.InvocationParams(\n                args=(), plugins=None, dir=Path().resolve()\n            )\n\n        self.option = argparse.Namespace()\n        \"\"\"access to command line option as attributes.\n\n          :type: argparse.Namespace\"\"\"\n\n        self.invocation_params = invocation_params\n\n        _a = FILE_OR_DIR\n        self._parser = Parser(\n            usage=\"%(prog)s [options] [{}] [{}] [...]\".format(_a, _a),\n            processopt=self._processopt,\n        )\n        self.pluginmanager = pluginmanager\n        \"\"\"the plugin manager handles plugin registration and hook invocation.\n\n          :type: PytestPluginManager\"\"\"\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook = self.pluginmanager.hook\n        self._inicache = {}  # type: Dict[str, Any]\n        self._override_ini = ()  # type: Sequence[str]\n        self._opt2dest = {}  # type: Dict[str, str]\n        self._cleanup = []  # type: List[Callable[[], None]]\n        # A place where plugins can store information on the config for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n\n        if TYPE_CHECKING:\n            from _pytest.cacheprovider import Cache\n\n            self.cache = None  # type: Optional[Cache]",
            "start_line": 790,
            "start_column": 26595,
            "end_line": 4,
            "end_column": 28375,
            "start_byte": 26595,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.invocation_dir",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@property\n    def invocation_dir(self):\n        \"\"\"Backward compatibility\"\"\"\n        return py.path.local(str(self.invocation_params.dir))",
            "start_line": 840,
            "start_column": 28381,
            "end_line": 4,
            "end_column": 28519,
            "start_byte": 28381,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.add_cleanup",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def add_cleanup(self, func):\n        \"\"\" Add a function to be called when the config object gets out of\n        use (usually coninciding with pytest_unconfigure).\"\"\"\n        self._cleanup.append(func)",
            "start_line": 845,
            "start_column": 28525,
            "end_line": 4,
            "end_column": 28725,
            "start_byte": 28525,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._do_configure",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _do_configure(self):\n        assert not self._configured\n        self._configured = True\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"default\")\n            self.hook.pytest_configure.call_historic(kwargs=dict(config=self))",
            "start_line": 850,
            "start_column": 28731,
            "end_line": 4,
            "end_column": 28987,
            "start_byte": 28731,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._ensure_unconfigure",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _ensure_unconfigure(self):\n        if self._configured:\n            self._configured = False\n            self.hook.pytest_unconfigure(config=self)\n            self.hook.pytest_configure._call_history = []\n        while self._cleanup:\n            fin = self._cleanup.pop()\n            fin()",
            "start_line": 857,
            "start_column": 28993,
            "end_line": 4,
            "end_column": 29286,
            "start_byte": 28993,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.get_terminal_writer",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def get_terminal_writer(self):\n        return self.pluginmanager.get_plugin(\"terminalreporter\")._tw",
            "start_line": 866,
            "start_column": 29292,
            "end_line": 4,
            "end_column": 29391,
            "start_byte": 29292,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.pytest_cmdline_parse",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def pytest_cmdline_parse(self, pluginmanager, args):\n        try:\n            self.parse(args)\n        except UsageError:\n\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"version\", False) or \"--version\" in args:\n                from _pytest.helpconfig import showversion\n\n                showversion(self)\n            elif (\n                getattr(self.option, \"help\", False) or \"--help\" in args or \"-h\" in args\n            ):\n                self._parser._getparser().print_help()\n                sys.stdout.write(\n                    \"\\nNOTE: displaying only minimal help due to UsageError.\\n\\n\"\n                )\n\n            raise\n\n        return self",
            "start_line": 869,
            "start_column": 29397,
            "end_line": 4,
            "end_column": 30240,
            "start_byte": 29397,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.notify_exception",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def notify_exception(self, excinfo, option=None):\n        if option and getattr(option, \"fulltrace\", False):\n            style = \"long\"\n        else:\n            style = \"native\"\n        excrepr = excinfo.getrepr(\n            funcargs=True, showlocals=getattr(option, \"showlocals\", False), style=style\n        )\n        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\n        if not any(res):\n            for line in str(excrepr).split(\"\\n\"):\n                sys.stderr.write(\"INTERNALERROR> %s\\n\" % line)\n                sys.stderr.flush()",
            "start_line": 893,
            "start_column": 30246,
            "end_line": 4,
            "end_column": 30809,
            "start_byte": 30246,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.cwd_relative_nodeid",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def cwd_relative_nodeid(self, nodeid):\n        # nodeid's are relative to the rootpath, compute relative to cwd\n        if self.invocation_dir != self.rootdir:\n            fullpath = self.rootdir.join(nodeid)\n            nodeid = self.invocation_dir.bestrelpath(fullpath)\n        return nodeid",
            "start_line": 907,
            "start_column": 30815,
            "end_line": 4,
            "end_column": 31108,
            "start_byte": 30815,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.fromdictargs",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@classmethod\n    def fromdictargs(cls, option_dict, args):\n        \"\"\" constructor usable for subprocesses. \"\"\"\n        config = get_config(args)\n        config.option.__dict__.update(option_dict)\n        config.parse(args, addopts=False)\n        for x in config.option.plugins:\n            config.pluginmanager.consider_pluginarg(x)\n        return config",
            "start_line": 914,
            "start_column": 31114,
            "end_line": 4,
            "end_column": 31469,
            "start_byte": 31114,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._processopt",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _processopt(self, opt: \"Argument\") -> None:\n        for name in opt._short_opts + opt._long_opts:\n            self._opt2dest[name] = opt.dest\n\n        if hasattr(opt, \"default\"):\n            if not hasattr(self.option, opt.dest):\n                setattr(self.option, opt.dest, opt.default)",
            "start_line": 924,
            "start_column": 31475,
            "end_line": 4,
            "end_column": 31768,
            "start_byte": 31475,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.pytest_load_initial_conftests",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@hookimpl(trylast=True)\n    def pytest_load_initial_conftests(self, early_config):\n        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)",
            "start_line": 932,
            "start_column": 31774,
            "end_line": 4,
            "end_column": 31941,
            "start_byte": 31774,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._initini",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _initini(self, args: Sequence[str]) -> None:\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(\n            args, namespace=copy.copy(self.option)\n        )\n        r = determine_setup(\n            ns.inifilename,\n            ns.file_or_dir + unknown_args,\n            rootdir_cmd_arg=ns.rootdir or None,\n            config=self,\n        )\n        self.rootdir, self.inifile, self.inicfg = r\n        self._parser.extra_info[\"rootdir\"] = self.rootdir\n        self._parser.extra_info[\"inifile\"] = self.inifile\n        self._parser.addini(\"addopts\", \"extra command line options\", \"args\")\n        self._parser.addini(\"minversion\", \"minimally required pytest version\")\n        self._override_ini = ns.override_ini or ()",
            "start_line": 936,
            "start_column": 31947,
            "end_line": 4,
            "end_column": 32684,
            "start_byte": 31947,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._consider_importhook",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook)\n        _warn_about_missing_assertion(mode)",
            "start_line": 953,
            "start_column": 32690,
            "end_line": 4,
            "end_column": 33458,
            "start_byte": 32690,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._mark_plugins_for_rewrite",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _mark_plugins_for_rewrite(self, hook):\n        \"\"\"\n        Given an importhook, mark for rewrite any top-level\n        modules or packages in the distribution package for\n        all pytest plugins.\n        \"\"\"\n        self.pluginmanager.rewrite_hook = hook\n\n        if os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # We don't autoload from setuptools entry points, no need to continue.\n            return\n\n        package_files = (\n            str(file)\n            for dist in importlib_metadata.distributions()\n            if any(ep.group == \"pytest11\" for ep in dist.entry_points)\n            for file in dist.files or []\n        )\n\n        for name in _iter_rewritable_modules(package_files):\n            hook.mark_rewrite(name)",
            "start_line": 973,
            "start_column": 33464,
            "end_line": 4,
            "end_column": 34217,
            "start_byte": 33464,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._validate_args",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _validate_args(self, args: List[str], via: str) -> List[str]:\n        \"\"\"Validate known args.\"\"\"\n        self._parser._config_source_hint = via  # type: ignore\n        try:\n            self._parser.parse_known_and_unknown_args(\n                args, namespace=copy.copy(self.option)\n            )\n        finally:\n            del self._parser._config_source_hint  # type: ignore\n\n        return args",
            "start_line": 995,
            "start_column": 34223,
            "end_line": 4,
            "end_column": 34626,
            "start_byte": 34223,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._preparse",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _preparse(self, args: List[str], addopts: bool = True) -> None:\n        if addopts:\n            env_addopts = os.environ.get(\"PYTEST_ADDOPTS\", \"\")\n            if len(env_addopts):\n                args[:] = (\n                    self._validate_args(shlex.split(env_addopts), \"via PYTEST_ADDOPTS\")\n                    + args\n                )\n        self._initini(args)\n        if addopts:\n            args[:] = (\n                self._validate_args(self.getini(\"addopts\"), \"via addopts config\") + args\n            )\n\n        self._checkversion()\n        self._consider_importhook(args)\n        self.pluginmanager.consider_preparse(args, exclude_only=False)\n        if not os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # Don't autoload from setuptools entry point. Only explicitly specified\n            # plugins are going to be loaded.\n            self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\n        self.pluginmanager.consider_env()\n        self.known_args_namespace = ns = self._parser.parse_known_args(\n            args, namespace=copy.copy(self.option)\n        )\n        if self.known_args_namespace.confcutdir is None and self.inifile:\n            confcutdir = py.path.local(self.inifile).dirname\n            self.known_args_namespace.confcutdir = confcutdir\n        try:\n            self.hook.pytest_load_initial_conftests(\n                early_config=self, args=args, parser=self._parser\n            )\n        except ConftestImportFailure as e:\n            if ns.help or ns.version:\n                # we don't want to prevent --help/--version to work\n                # so just let is pass and print a warning at the end\n                from _pytest.warnings import _issue_warning_captured\n\n                _issue_warning_captured(\n                    PytestConfigWarning(\n                        \"could not load initial conftests: {}\".format(e.path)\n                    ),\n                    self.hook,\n                    stacklevel=2,\n                )\n            else:\n                raise",
            "start_line": 1007,
            "start_column": 34632,
            "end_line": 4,
            "end_column": 36670,
            "start_byte": 34632,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._checkversion",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _checkversion(self):\n        import pytest\n\n        minver = self.inicfg.get(\"minversion\", None)\n        if minver:\n            # Imported lazily to improve start-up time.\n            from packaging.version import Version\n\n            if Version(minver) > Version(pytest.__version__):\n                raise pytest.UsageError(\n                    \"%s:%d: requires pytest-%s, actual pytest-%s'\"\n                    % (\n                        self.inicfg.config.path,\n                        self.inicfg.lineof(\"minversion\"),\n                        minver,\n                        pytest.__version__,\n                    )\n                )",
            "start_line": 1055,
            "start_column": 36676,
            "end_line": 4,
            "end_column": 37319,
            "start_byte": 36676,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.parse",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def parse(self, args: List[str], addopts: bool = True) -> None:\n        # parse given cmdline arguments into this config object.\n        assert not hasattr(\n            self, \"args\"\n        ), \"can only parse cmdline args at most once per Config object\"\n        self.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=self.pluginmanager)\n        )\n        self._preparse(args, addopts=addopts)\n        # XXX deprecated hook:\n        self.hook.pytest_cmdline_preparse(config=self, args=args)\n        self._parser.after_preparse = True  # type: ignore\n        try:\n            args = self._parser.parse_setoption(\n                args, self.option, namespace=self.option\n            )\n            if not args:\n                if self.invocation_dir == self.rootdir:\n                    args = self.getini(\"testpaths\")\n                if not args:\n                    args = [str(self.invocation_dir)]\n            self.args = args\n        except PrintHelp:\n            pass",
            "start_line": 1074,
            "start_column": 37325,
            "end_line": 4,
            "end_column": 38318,
            "start_byte": 37325,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.addinivalue_line",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def addinivalue_line(self, name, line):\n        \"\"\" add a line to an ini-file option. The option must have been\n        declared but might not yet be set in which case the line becomes the\n        the first line in its value. \"\"\"\n        x = self.getini(name)\n        assert isinstance(x, list)\n        x.append(line)  # modifies the cached list inline",
            "start_line": 1099,
            "start_column": 38324,
            "end_line": 4,
            "end_column": 38676,
            "start_byte": 38324,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.getini",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getini(self, name: str):\n        \"\"\" return configuration value from an :ref:`ini file <inifiles>`. If the\n        specified name hasn't been registered through a prior\n        :py:func:`parser.addini <_pytest.config.argparsing.Parser.addini>`\n        call (usually from a plugin), a ValueError is raised. \"\"\"\n        try:\n            return self._inicache[name]\n        except KeyError:\n            self._inicache[name] = val = self._getini(name)\n            return val",
            "start_line": 1107,
            "start_column": 38682,
            "end_line": 4,
            "end_column": 39156,
            "start_byte": 38682,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._getini",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _getini(self, name: str) -> Any:\n        try:\n            description, type, default = self._parser._inidict[name]\n        except KeyError:\n            raise ValueError(\"unknown configuration value: {!r}\".format(name))\n        value = self._get_override_ini_value(name)\n        if value is None:\n            try:\n                value = self.inicfg[name]\n            except KeyError:\n                if default is not None:\n                    return default\n                if type is None:\n                    return \"\"\n                return []\n        if type == \"pathlist\":\n            dp = py.path.local(self.inicfg.config.path).dirpath()\n            values = []\n            for relpath in shlex.split(value):\n                values.append(dp.join(relpath, abs=True))\n            return values\n        elif type == \"args\":\n            return shlex.split(value)\n        elif type == \"linelist\":\n            return [t for t in map(lambda x: x.strip(), value.split(\"\\n\")) if t]\n        elif type == \"bool\":\n            return bool(_strtobool(value.strip()))\n        else:\n            assert type is None\n            return value",
            "start_line": 1118,
            "start_column": 39162,
            "end_line": 4,
            "end_column": 40297,
            "start_byte": 39162,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._getconftest_pathlist",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _getconftest_pathlist(self, name, path):\n        try:\n            mod, relroots = self.pluginmanager._rget_with_confmod(name, path)\n        except KeyError:\n            return None\n        modpath = py.path.local(mod.__file__).dirpath()\n        values = []\n        for relroot in relroots:\n            if not isinstance(relroot, py.path.local):\n                relroot = relroot.replace(\"/\", py.path.local.sep)\n                relroot = modpath.join(relroot, abs=True)\n            values.append(relroot)\n        return values",
            "start_line": 1149,
            "start_column": 40303,
            "end_line": 4,
            "end_column": 40832,
            "start_byte": 40303,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._get_override_ini_value",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _get_override_ini_value(self, name: str) -> Optional[str]:\n        value = None\n        # override_ini is a list of \"ini=value\" options\n        # always use the last item if multiple values are set for same ini-name,\n        # e.g. -o foo=bar1 -o foo=bar2 will set foo to bar2\n        for ini_config in self._override_ini:\n            try:\n                key, user_ini_value = ini_config.split(\"=\", 1)\n            except ValueError:\n                raise UsageError(\n                    \"-o/--override-ini expects option=value style (got: {!r}).\".format(\n                        ini_config\n                    )\n                )\n            else:\n                if key == name:\n                    value = user_ini_value\n        return value",
            "start_line": 1163,
            "start_column": 40838,
            "end_line": 4,
            "end_column": 41586,
            "start_byte": 40838,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.getoption",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getoption(self, name: str, default=notset, skip: bool = False):\n        \"\"\" return command line option value.\n\n        :arg name: name of the option.  You may also specify\n            the literal ``--OPT`` option instead of the \"dest\" option name.\n        :arg default: default value if no option of that name exists.\n        :arg skip: if True raise pytest.skip if option does not exists\n            or has a None value.\n        \"\"\"\n        name = self._opt2dest.get(name, name)\n        try:\n            val = getattr(self.option, name)\n            if val is None and skip:\n                raise AttributeError(name)\n            return val\n        except AttributeError:\n            if default is not notset:\n                return default\n            if skip:\n                import pytest\n\n                pytest.skip(\"no {!r} option found\".format(name))\n            raise ValueError(\"no option named {!r}\".format(name))",
            "start_line": 1182,
            "start_column": 41592,
            "end_line": 4,
            "end_column": 42519,
            "start_byte": 41592,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.getvalue",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getvalue(self, name, path=None):\n        \"\"\" (deprecated, use getoption()) \"\"\"\n        return self.getoption(name)",
            "start_line": 1206,
            "start_column": 42525,
            "end_line": 4,
            "end_column": 42643,
            "start_byte": 42525,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.getvalueorskip",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getvalueorskip(self, name, path=None):\n        \"\"\" (deprecated, use getoption(skip=True)) \"\"\"\n        return self.getoption(name, skip=True)",
            "start_line": 1210,
            "start_column": 42649,
            "end_line": 4,
            "end_column": 42793,
            "start_byte": 42649,
            "end_byte": 4
          },
          {
            "name": "_pytest.warning_types.PytestConfigWarning",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "r\n\nimport _pytest._code\nimport _pytest.deprecated\nimport _pytest.hookspec  # the extension point definitions\nfrom .excep",
            "start_line": 30,
            "start_column": 617,
            "end_line": 0,
            "end_column": 737,
            "start_byte": 617,
            "end_byte": 0
          },
          {
            "name": "_pytest.warning_types.PytestConfigWarning.__module__",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "finitions\nfrom .excep",
            "start_line": 33,
            "start_column": 716,
            "end_line": 4,
            "end_column": 737,
            "start_byte": 716,
            "end_byte": 4
          },
          {
            "name": "_pytest.monkeypatch.MonkeyPatch.chdir",
            "file_path": "src/_pytest/monkeypatch.py",
            "file_content": "def chdir(self, path):\n        \"\"\" Change the current working directory to the specified path.\n        Path can be a string or a py.path.local object.\n        \"\"\"\n        if self._cwd is None:\n            self._cwd = os.getcwd()\n        if hasattr(path, \"chdir\"):\n            path.chdir()\n        elif isinstance(path, Path):\n            # modern python uses the fspath protocol here LEGACY\n            os.chdir(str(path))\n        else:\n            os.chdir(path)",
            "start_line": 274,
            "start_column": 9526,
            "end_line": 4,
            "end_column": 9989,
            "start_byte": 9526,
            "end_byte": 4
          },
          {
            "name": "_pytest.monkeypatch.MonkeyPatch.undo",
            "file_path": "src/_pytest/monkeypatch.py",
            "file_content": "def undo(self):\n        \"\"\" Undo previous changes.  This call consumes the\n        undo stack. Calling it a second time has no effect unless\n        you do more monkeypatching after the undo call.\n\n        There is generally no need to call `undo()`, since it is\n        called automatically during tear-down.\n\n        Note that the same `monkeypatch` fixture is used across a\n        single test function invocation. If `monkeypatch` is used both by\n        the test function itself and one of the test fixtures,\n        calling `undo()` will undo all of the changes made in\n        both functions.\n        \"\"\"\n        for obj, name, value in reversed(self._setattr):\n            if value is not notset:\n                setattr(obj, name, value)\n            else:\n                delattr(obj, name)\n        self._setattr[:] = []\n        for dictionary, name, value in reversed(self._setitem):\n            if value is notset:\n                try:\n                    del dictionary[name]\n                except KeyError:\n                    pass  # was already deleted, so we have the desired state\n            else:\n                dictionary[name] = value\n        self._setitem[:] = []\n        if self._savesyspath is not None:\n            sys.path[:] = self._savesyspath\n            self._savesyspath = None\n\n        if self._cwd is not None:\n            os.chdir(self._cwd)\n            self._cwd = None",
            "start_line": 288,
            "start_column": 9995,
            "end_line": 4,
            "end_column": 11401,
            "start_byte": 9995,
            "end_byte": 4
          }
        ],
        "root_caused_symbols": [
          {
            "name": "_pytest.terminal.TerminalReporter._locationline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \"",
            "start_line": 776,
            "start_column": 27160,
            "end_line": 4,
            "end_column": 27982,
            "start_byte": 27160,
            "end_byte": 4
          },
          {
            "name": "_pytest.nodes.Node._repr_failure_py",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def _repr_failure_py(\n        self, excinfo: ExceptionInfo[BaseException], style=None,\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        if isinstance(excinfo.value, ConftestImportFailure):\n            excinfo = ExceptionInfo(excinfo.value.excinfo)\n        if isinstance(excinfo.value, fail.Exception):\n            if not excinfo.value.pytrace:\n                style = \"value\"\n        if isinstance(excinfo.value, FixtureLookupError):\n            return excinfo.value.formatrepr()\n        if self.config.getoption(\"fulltrace\", False):\n            style = \"long\"\n        else:\n            tb = _pytest._code.Traceback([excinfo.traceback[-1]])\n            self._prunetraceback(excinfo)\n            if len(excinfo.traceback) == 0:\n                excinfo.traceback = tb\n            if style == \"auto\":\n                style = \"long\"\n        # XXX should excinfo.getrepr record all data and toterminal() process it?\n        if style is None:\n            if self.config.getoption(\"tbstyle\", \"auto\") == \"short\":\n                style = \"short\"\n            else:\n                style = \"long\"\n\n        if self.config.getoption(\"verbose\", 0) > 1:\n            truncate_locals = False\n        else:\n            truncate_locals = True\n\n        try:\n            os.getcwd()\n            abspath = False\n        except OSError:\n            abspath = True\n\n        return excinfo.getrepr(\n            funcargs=True,\n            abspath=abspath,\n            showlocals=self.config.getoption(\"showlocals\", False),\n            style=style,\n            tbfilter=False,  # pruned already, or in --fulltrace mode.\n            truncate_locals=truncate_locals,\n        )",
            "start_line": 332,
            "start_column": 10806,
            "end_line": 4,
            "end_column": 12496,
            "start_byte": 10806,
            "end_byte": 4
          },
          {
            "name": "_pytest.nodes.Node.repr_failure",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def repr_failure(\n        self, excinfo, style=None\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        \"\"\"\n        Return a representation of a collection or test failure.\n\n        :param excinfo: Exception information for the failure.\n        \"\"\"\n        return self._repr_failure_py(excinfo, style)",
            "start_line": 378,
            "start_column": 12502,
            "end_line": 4,
            "end_column": 12843,
            "start_byte": 12502,
            "end_byte": 4
          },
          {
            "name": "_pytest.nodes.get_fslocation_from_item",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def get_fslocation_from_item(\n    item: \"Item\",\n) -> Tuple[Union[str, py.path.local], Optional[int]]:\n    \"\"\"Tries to extract the actual location from an item, depending on available attributes:\n\n    * \"fslocation\": a pair (path, lineno)\n    * \"obj\": a Python object that the item wraps.\n    * \"fspath\": just a path\n\n    :rtype: a tuple of (str|LocalPath, int) with filename and line number.\n    \"\"\"\n    try:\n        return item.location[:2]\n    except AttributeError:\n        pass\n    obj = getattr(item, \"obj\", None)\n    if obj is not None:\n        return getfslineno(obj)\n    return getattr(item, \"fspath\", \"unknown location\"), -1",
            "start_line": 389,
            "start_column": 12846,
            "end_line": 0,
            "end_column": 13479,
            "start_byte": 12846,
            "end_byte": 0
          }
        ]
      }
    },
    {
      "name": "SymbolsEvaluate",
      "metadata": {
        "start": "2024-08-19T12:17:58.351202",
        "usage": "12169.561862945557 ms"
      },
      "request": {
        "related_symbols": [
          {
            "name": "_pytest.terminal.TerminalReporter",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "class TerminalReporter:\n    def __init__(self, config: Config, file=None) -> None:\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None  # type: Optional[Session]\n        self._showfspath = None\n\n        self.stats = {}  # type: Dict[str, List[Any]]\n        self._main_color = None  # type: Optional[str]\n        self._known_types = None  # type: Optional[List]\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None  # type: Any\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()  # type: Set[str]\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None  # type: Optional[float]\n\n    @property\n    def writer(self) -> TerminalWriter:\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        return self._tw\n\n    @writer.setter\n    def writer(self, value: TerminalWriter):\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        self._tw = value\n\n    def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False\n\n    @property\n    def verbosity(self):\n        return self.config.option.verbose\n\n    @property\n    def showheader(self):\n        return self.verbosity >= 0\n\n    @property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0\n        return self._showfspath\n\n    @showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value\n\n    @property\n    def showlongtestinfo(self):\n        return self.verbosity > 0\n\n    def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars\n\n    def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, flush=True, **markup)\n\n    def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2\n\n    def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None\n\n    def write(self, content: str, *, flush: bool = False, **markup: bool) -> None:\n        self._tw.write(content, flush=flush, **markup)\n\n    def flush(self) -> None:\n        self._tw.flush()\n\n    def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)\n\n    def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)\n\n    def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)\n\n    def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)\n\n    def line(self, msg, **kw):\n        self._tw.line(msg, **kw)\n\n    def _add_stats(self, category: str, items: List) -> None:\n        set_main_color = category not in self.stats\n        self.stats.setdefault(category, []).extend(items[:])\n        if set_main_color:\n            self._set_main_color()\n\n    def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1\n\n    def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        self._add_stats(\"warnings\", [warning_report])\n\n    def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)\n\n    def pytest_deselected(self, items):\n        self._add_stats(\"deselected\", items)\n\n    def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n            self.flush()\n        elif self.showfspath:\n            self.write_fspath_result(nodeid, \"\")\n            self.flush()\n\n    def pytest_runtest_logreport(self, report: TestReport) -> None:\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self._add_stats(category, [rep])\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2\n        self.flush()\n\n    @property\n    def _is_last_item(self):\n        return len(self._progress_nodeids_reported) == self._session.testscollected\n\n    def pytest_runtest_logfinish(self, nodeid):\n        assert self._session\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n\n            if self._is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                main_color, _ = self._get_main_color()\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", **{main_color: True})\n\n    def _get_progress_information_message(self) -> str:\n        assert self._session\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                return \" [{:3d}%]\".format(\n                    len(self._progress_nodeids_reported) * 100 // collected\n                )\n            return \" [100%]\"\n\n    def _write_progress_information_filling_space(self):\n        color, _ = self._get_main_color()\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), flush=True, **{color: True})\n\n    @property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        return self._tw.width_of_current_line\n\n    def pytest_collection(self) -> None:\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", flush=True, bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", flush=True, bold=True)\n\n    def pytest_collectreport(self, report: CollectReport) -> None:\n        if report.failed:\n            self._add_stats(\"error\", [report])\n        elif report.skipped:\n            self._add_stats(\"skipped\", [report])\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()\n\n    def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d error%s\" % (errors, \"s\" if errors != 1 else \"\")\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)\n\n    @pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session: Session) -> None:\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n        if pypy_version_info:\n            verinfo = \".\".join(map(str, pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)\n\n    def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)\n\n    def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result\n\n    def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if session.items:\n                if self.config.option.verbose > -1:\n                    self._tw.line(\"\")\n                self._printcollecteditems(session.items)\n\n            failed = self.stats.get(\"failed\")\n            if failed:\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in failed:\n                    rep.toterminal(self._tw)\n\n    def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}  # type: Dict[str, int]\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    try:\n                        obj = col.obj  # type: ignore\n                    except AttributeError:\n                        continue\n                    doc = inspect.getdoc(obj)\n                    if doc:\n                        for line in doc.splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line))\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, session: Session, exitstatus: ExitCode):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if session.shouldfail:\n            self.write_sep(\"!\", session.shouldfail, red=True)\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        elif session.shouldstop:\n            self.write_sep(\"!\", session.shouldstop, red=True)\n        self.summary_stats()\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()\n\n    def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)\n\n    def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()\n\n    def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )\n\n    def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \"\n\n    def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?\n\n    def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"\n\n    #\n    # summaries for sessionfinish\n    #\n    def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values\n\n    def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\n                \"warnings\"\n            )  # type: Optional[List[WarningReport]]\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = (\n                order_preserving_dict()\n            )  # type: Dict[str, List[WarningReport]]\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            def collapsed_location_report(reports: List[WarningReport]):\n                locations = []\n                for w in reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        locations.append(location)\n\n                if len(locations) < 10:\n                    return \"\\n\".join(map(str, locations))\n\n                counts_by_filename = order_preserving_dict()  # type: Dict[str, int]\n                for loc in locations:\n                    key = str(loc).split(\"::\", 1)[0]\n                    counts_by_filename[key] = counts_by_filename.get(key, 0) + 1\n                return \"\\n\".join(\n                    \"{}: {} warning{}\".format(k, v, \"s\" if v > 1 else \"\")\n                    for k, v in counts_by_filename.items()\n                )\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, message_reports in reports_grouped_by_message.items():\n                maybe_location = collapsed_location_report(message_reports)\n                if maybe_location:\n                    self._tw.line(maybe_location)\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")\n\n    def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)\n\n    def _get_teardown_reports(self, nodeid: str) -> List[TestReport]:\n        return [\n            report\n            for report in self.getreports(\"\")\n            if report.when == \"teardown\" and report.nodeid == nodeid\n        ]\n\n    def _handle_teardown_sections(self, nodeid: str) -> None:\n        for report in self._get_teardown_reports(nodeid):\n            self.print_teardown_sections(report)\n\n    def print_teardown_sections(self, rep: TestReport) -> None:\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)\n\n    def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)\n\n    def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)\n\n    def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)\n\n    def summary_stats(self):\n        if self.verbosity < -1:\n            return\n\n        session_duration = time.time() - self._sessionstarttime\n        (parts, main_color) = self.build_summary_stats_line()\n        line_parts = []\n\n        display_sep = self.verbosity >= 0\n        if display_sep:\n            fullwidth = self._tw.fullwidth\n        for text, markup in parts:\n            with_markup = self._tw.markup(text, **markup)\n            if display_sep:\n                fullwidth += len(with_markup) - len(text)\n            line_parts.append(with_markup)\n        msg = \", \".join(line_parts)\n\n        main_markup = {main_color: True}\n        duration = \" in {}\".format(format_session_duration(session_duration))\n        duration_with_markup = self._tw.markup(duration, **main_markup)\n        if display_sep:\n            fullwidth += len(duration_with_markup) - len(duration)\n        msg += duration_with_markup\n\n        if display_sep:\n            markup_for_end_sep = self._tw.markup(\"\", **main_markup)\n            if markup_for_end_sep.endswith(\"\\x1b[0m\"):\n                markup_for_end_sep = markup_for_end_sep[:-4]\n            fullwidth += len(markup_for_end_sep)\n            msg += markup_for_end_sep\n\n        if display_sep:\n            self.write_sep(\"=\", msg, fullwidth=fullwidth, **main_markup)\n        else:\n            self.write_line(msg, **main_markup)\n\n    def short_test_summary(self) -> None:\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines: List[str]) -> None:\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self._tw.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines: List[str]) -> None:\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines: List[str]) -> None:\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines: List[str]) -> None:\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(self.startdir, skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }  # type: Mapping[str, Callable[[List[str]], None]]\n\n        lines = []  # type: List[str]\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:\n                self.write_line(line)\n\n    def _get_main_color(self) -> Tuple[str, List[str]]:\n        if self._main_color is None or self._known_types is None or self._is_last_item:\n            self._set_main_color()\n            assert self._main_color\n            assert self._known_types\n        return self._main_color, self._known_types\n\n    def _determine_main_color(self, unknown_type_seen: bool) -> str:\n        stats = self.stats\n        if \"failed\" in stats or \"error\" in stats:\n            main_color = \"red\"\n        elif \"warnings\" in stats or \"xpassed\" in stats or unknown_type_seen:\n            main_color = \"yellow\"\n        elif \"passed\" in stats or not self._is_last_item:\n            main_color = \"green\"\n        else:\n            main_color = \"yellow\"\n        return main_color\n\n    def _set_main_color(self) -> None:\n        unknown_types = []  # type: List[str]\n        for found_type in self.stats.keys():\n            if found_type:  # setup/teardown reports have an empty key, ignore them\n                if found_type not in KNOWN_TYPES and found_type not in unknown_types:\n                    unknown_types.append(found_type)\n        self._known_types = list(KNOWN_TYPES) + unknown_types\n        self._main_color = self._determine_main_color(bool(unknown_types))\n\n    def build_summary_stats_line(self) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:\n        main_color, known_types = self._get_main_color()\n\n        parts = []\n        for key in known_types:\n            reports = self.stats.get(key, None)\n            if reports:\n                count = sum(\n                    1 for rep in reports if getattr(rep, \"count_towards_summary\", True)\n                )\n                color = _color_for_type.get(key, _color_for_type_default)\n                markup = {color: True, \"bold\": color == main_color}\n                parts.append((\"%d %s\" % _make_plural(count, key), markup))\n\n        if not parts:\n            parts = [(\"no tests ran\", {_color_for_type_default: True})]\n\n        return parts, main_color",
            "start_line": 261,
            "start_column": 7463,
            "end_line": 0,
            "end_column": 40474,
            "start_byte": 7463,
            "end_byte": 0
          },
          {
            "name": "_pytest.terminal.TerminalReporter.__init__",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def __init__(self, config: Config, file=None) -> None:\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None  # type: Optional[Session]\n        self._showfspath = None\n\n        self.stats = {}  # type: Dict[str, List[Any]]\n        self._main_color = None  # type: Optional[str]\n        self._known_types = None  # type: Optional[List]\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None  # type: Any\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()  # type: Set[str]\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None  # type: Optional[float]",
            "start_line": 262,
            "start_column": 7491,
            "end_line": 4,
            "end_column": 8496,
            "start_byte": 7491,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.writer",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def writer(self) -> TerminalWriter:\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        return self._tw",
            "start_line": 286,
            "start_column": 8502,
            "end_line": 4,
            "end_column": 8634,
            "start_byte": 8502,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.writer",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@writer.setter\n    def writer(self, value: TerminalWriter):\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        self._tw = value",
            "start_line": 291,
            "start_column": 8640,
            "end_line": 4,
            "end_column": 8783,
            "start_byte": 8640,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._determine_show_progress_info",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False",
            "start_line": 296,
            "start_column": 8789,
            "end_line": 4,
            "end_column": 9372,
            "start_byte": 8789,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.verbosity",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def verbosity(self):\n        return self.config.option.verbose",
            "start_line": 309,
            "start_column": 9378,
            "end_line": 4,
            "end_column": 9454,
            "start_byte": 9378,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.showheader",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def showheader(self):\n        return self.verbosity >= 0",
            "start_line": 313,
            "start_column": 9460,
            "end_line": 4,
            "end_column": 9530,
            "start_byte": 9460,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.showfspath",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0\n        return self._showfspath",
            "start_line": 317,
            "start_column": 9536,
            "end_line": 4,
            "end_column": 9679,
            "start_byte": 9536,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.showfspath",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value",
            "start_line": 323,
            "start_column": 9685,
            "end_line": 4,
            "end_column": 9769,
            "start_byte": 9685,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.showlongtestinfo",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def showlongtestinfo(self):\n        return self.verbosity > 0",
            "start_line": 327,
            "start_column": 9775,
            "end_line": 4,
            "end_column": 9850,
            "start_byte": 9775,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.hasopt",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars",
            "start_line": 331,
            "start_column": 9856,
            "end_line": 4,
            "end_column": 9983,
            "start_byte": 9856,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.write_fspath_result",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, flush=True, **markup)",
            "start_line": 335,
            "start_column": 9989,
            "end_line": 4,
            "end_column": 10686,
            "start_byte": 9989,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.write_ensure_prefix",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2",
            "start_line": 348,
            "start_column": 10692,
            "end_line": 4,
            "end_column": 10992,
            "start_byte": 10692,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.ensure_newline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None",
            "start_line": 357,
            "start_column": 10998,
            "end_line": 4,
            "end_column": 11120,
            "start_byte": 10998,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.write",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write(self, content: str, *, flush: bool = False, **markup: bool) -> None:\n        self._tw.write(content, flush=flush, **markup)",
            "start_line": 362,
            "start_column": 11126,
            "end_line": 4,
            "end_column": 11259,
            "start_byte": 11126,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.flush",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def flush(self) -> None:\n        self._tw.flush()",
            "start_line": 365,
            "start_column": 11265,
            "end_line": 4,
            "end_column": 11314,
            "start_byte": 11265,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.write_line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)",
            "start_line": 368,
            "start_column": 11320,
            "end_line": 4,
            "end_column": 11510,
            "start_byte": 11320,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.rewrite",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)",
            "start_line": 374,
            "start_column": 11516,
            "end_line": 4,
            "end_column": 12134,
            "start_byte": 11516,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.write_sep",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)",
            "start_line": 392,
            "start_column": 12140,
            "end_line": 4,
            "end_column": 12260,
            "start_byte": 12140,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.section",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)",
            "start_line": 396,
            "start_column": 12266,
            "end_line": 4,
            "end_column": 12345,
            "start_byte": 12266,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def line(self, msg, **kw):\n        self._tw.line(msg, **kw)",
            "start_line": 399,
            "start_column": 12351,
            "end_line": 4,
            "end_column": 12410,
            "start_byte": 12351,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._add_stats",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _add_stats(self, category: str, items: List) -> None:\n        set_main_color = category not in self.stats\n        self.stats.setdefault(category, []).extend(items[:])\n        if set_main_color:\n            self._set_main_color()",
            "start_line": 402,
            "start_column": 12416,
            "end_line": 4,
            "end_column": 12648,
            "start_byte": 12416,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_internalerror",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1",
            "start_line": 408,
            "start_column": 12654,
            "end_line": 4,
            "end_column": 12811,
            "start_byte": 12654,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_warning_captured",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        self._add_stats(\"warnings\", [warning_report])",
            "start_line": 413,
            "start_column": 12817,
            "end_line": 4,
            "end_column": 13350,
            "start_byte": 12817,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_plugin_registered",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)",
            "start_line": 426,
            "start_column": 13356,
            "end_line": 4,
            "end_column": 13731,
            "start_byte": 13356,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_deselected",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_deselected(self, items):\n        self._add_stats(\"deselected\", items)",
            "start_line": 434,
            "start_column": 13737,
            "end_line": 4,
            "end_column": 13817,
            "start_byte": 13737,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logstart",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n            self.flush()\n        elif self.showfspath:\n            self.write_fspath_result(nodeid, \"\")\n            self.flush()",
            "start_line": 437,
            "start_column": 13823,
            "end_line": 4,
            "end_column": 14241,
            "start_byte": 13823,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logreport",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_runtest_logreport(self, report: TestReport) -> None:\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self._add_stats(category, [rep])\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2\n        self.flush()",
            "start_line": 448,
            "start_column": 14247,
            "end_line": 4,
            "end_column": 16159,
            "start_byte": 14247,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._is_last_item",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def _is_last_item(self):\n        return len(self._progress_nodeids_reported) == self._session.testscollected",
            "start_line": 497,
            "start_column": 16165,
            "end_line": 4,
            "end_column": 16287,
            "start_byte": 16165,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logfinish",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_runtest_logfinish(self, nodeid):\n        assert self._session\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n\n            if self._is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                main_color, _ = self._get_main_color()\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", **{main_color: True})",
            "start_line": 501,
            "start_column": 16293,
            "end_line": 4,
            "end_column": 17210,
            "start_byte": 16293,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._get_progress_information_message",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _get_progress_information_message(self) -> str:\n        assert self._session\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                return \" [{:3d}%]\".format(\n                    len(self._progress_nodeids_reported) * 100 // collected\n                )\n            return \" [100%]\"",
            "start_line": 522,
            "start_column": 17216,
            "end_line": 4,
            "end_column": 17957,
            "start_byte": 17216,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._write_progress_information_filling_space",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _write_progress_information_filling_space(self):\n        color, _ = self._get_main_color()\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), flush=True, **{color: True})",
            "start_line": 539,
            "start_column": 17963,
            "end_line": 4,
            "end_column": 18259,
            "start_byte": 17963,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._width_of_current_line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        return self._tw.width_of_current_line",
            "start_line": 546,
            "start_column": 18265,
            "end_line": 4,
            "end_column": 18465,
            "start_byte": 18265,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_collection",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_collection(self) -> None:\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", flush=True, bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", flush=True, bold=True)",
            "start_line": 551,
            "start_column": 18471,
            "end_line": 4,
            "end_column": 18821,
            "start_byte": 18471,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_collectreport",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_collectreport(self, report: CollectReport) -> None:\n        if report.failed:\n            self._add_stats(\"error\", [report])\n        elif report.skipped:\n            self._add_stats(\"skipped\", [report])\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()",
            "start_line": 559,
            "start_column": 18827,
            "end_line": 4,
            "end_column": 19212,
            "start_byte": 18827,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.report_collect",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d error%s\" % (errors, \"s\" if errors != 1 else \"\")\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)",
            "start_line": 569,
            "start_column": 19218,
            "end_line": 4,
            "end_column": 20633,
            "start_byte": 19218,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_sessionstart",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session: Session) -> None:\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n        if pypy_version_info:\n            verinfo = \".\".join(map(str, pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)",
            "start_line": 609,
            "start_column": 20639,
            "end_line": 4,
            "end_column": 21805,
            "start_byte": 20639,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._write_report_lines_from_hooks",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)",
            "start_line": 637,
            "start_column": 21811,
            "end_line": 4,
            "end_column": 21954,
            "start_byte": 21811,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_report_header",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result",
            "start_line": 642,
            "start_column": 21960,
            "end_line": 4,
            "end_column": 22615,
            "start_byte": 21960,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_collection_finish",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if session.items:\n                if self.config.option.verbose > -1:\n                    self._tw.line(\"\")\n                self._printcollecteditems(session.items)\n\n            failed = self.stats.get(\"failed\")\n            if failed:\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in failed:\n                    rep.toterminal(self._tw)",
            "start_line": 659,
            "start_column": 22621,
            "end_line": 4,
            "end_column": 23336,
            "start_byte": 22621,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._printcollecteditems",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}  # type: Dict[str, int]\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    try:\n                        obj = col.obj  # type: ignore\n                    except AttributeError:\n                        continue\n                    doc = inspect.getdoc(obj)\n                    if doc:\n                        for line in doc.splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line))",
            "start_line": 679,
            "start_column": 23342,
            "end_line": 4,
            "end_column": 25064,
            "start_byte": 23342,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_sessionfinish",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, session: Session, exitstatus: ExitCode):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if session.shouldfail:\n            self.write_sep(\"!\", session.shouldfail, red=True)\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        elif session.shouldstop:\n            self.write_sep(\"!\", session.shouldstop, red=True)\n        self.summary_stats()",
            "start_line": 719,
            "start_column": 25070,
            "end_line": 4,
            "end_column": 26017,
            "start_byte": 25070,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_terminal_summary",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()",
            "start_line": 744,
            "start_column": 26023,
            "end_line": 4,
            "end_column": 26366,
            "start_byte": 26023,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_keyboard_interrupt",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)",
            "start_line": 755,
            "start_column": 26372,
            "end_line": 4,
            "end_column": 26487,
            "start_byte": 26372,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.pytest_unconfigure",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()",
            "start_line": 758,
            "start_column": 26493,
            "end_line": 4,
            "end_column": 26620,
            "start_byte": 26493,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._report_keyboardinterrupt",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )",
            "start_line": 762,
            "start_column": 26626,
            "end_line": 4,
            "end_column": 27154,
            "start_byte": 26626,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._getfailureheadline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?",
            "start_line": 798,
            "start_column": 27988,
            "end_line": 4,
            "end_column": 28146,
            "start_byte": 27988,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._getcrashline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"",
            "start_line": 804,
            "start_column": 28152,
            "end_line": 4,
            "end_column": 28396,
            "start_byte": 28152,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.getreports",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values",
            "start_line": 816,
            "start_column": 28448,
            "end_line": 4,
            "end_column": 28637,
            "start_byte": 28448,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.summary_warnings",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\n                \"warnings\"\n            )  # type: Optional[List[WarningReport]]\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = (\n                order_preserving_dict()\n            )  # type: Dict[str, List[WarningReport]]\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            def collapsed_location_report(reports: List[WarningReport]):\n                locations = []\n                for w in reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        locations.append(location)\n\n                if len(locations) < 10:\n                    return \"\\n\".join(map(str, locations))\n\n                counts_by_filename = order_preserving_dict()  # type: Dict[str, int]\n                for loc in locations:\n                    key = str(loc).split(\"::\", 1)[0]\n                    counts_by_filename[key] = counts_by_filename.get(key, 0) + 1\n                return \"\\n\".join(\n                    \"{}: {} warning{}\".format(k, v, \"s\" if v > 1 else \"\")\n                    for k, v in counts_by_filename.items()\n                )\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, message_reports in reports_grouped_by_message.items():\n                maybe_location = collapsed_location_report(message_reports)\n                if maybe_location:\n                    self._tw.line(maybe_location)\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")",
            "start_line": 823,
            "start_column": 28643,
            "end_line": 4,
            "end_column": 31098,
            "start_byte": 28643,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.summary_passes",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)",
            "start_line": 880,
            "start_column": 31104,
            "end_line": 4,
            "end_column": 31684,
            "start_byte": 31104,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._get_teardown_reports",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _get_teardown_reports(self, nodeid: str) -> List[TestReport]:\n        return [\n            report\n            for report in self.getreports(\"\")\n            if report.when == \"teardown\" and report.nodeid == nodeid\n        ]",
            "start_line": 894,
            "start_column": 31690,
            "end_line": 4,
            "end_column": 31916,
            "start_byte": 31690,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._handle_teardown_sections",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _handle_teardown_sections(self, nodeid: str) -> None:\n        for report in self._get_teardown_reports(nodeid):\n            self.print_teardown_sections(report)",
            "start_line": 901,
            "start_column": 31922,
            "end_line": 4,
            "end_column": 32086,
            "start_byte": 31922,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.print_teardown_sections",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def print_teardown_sections(self, rep: TestReport) -> None:\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)",
            "start_line": 905,
            "start_column": 32092,
            "end_line": 4,
            "end_column": 32598,
            "start_byte": 32092,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.summary_failures",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)",
            "start_line": 918,
            "start_column": 32604,
            "end_line": 4,
            "end_column": 33288,
            "start_byte": 32604,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.summary_errors",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)",
            "start_line": 935,
            "start_column": 33294,
            "end_line": 4,
            "end_column": 33890,
            "start_byte": 33294,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._outrep_summary",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)",
            "start_line": 950,
            "start_column": 33896,
            "end_line": 4,
            "end_column": 34353,
            "start_byte": 33896,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.summary_stats",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_stats(self):\n        if self.verbosity < -1:\n            return\n\n        session_duration = time.time() - self._sessionstarttime\n        (parts, main_color) = self.build_summary_stats_line()\n        line_parts = []\n\n        display_sep = self.verbosity >= 0\n        if display_sep:\n            fullwidth = self._tw.fullwidth\n        for text, markup in parts:\n            with_markup = self._tw.markup(text, **markup)\n            if display_sep:\n                fullwidth += len(with_markup) - len(text)\n            line_parts.append(with_markup)\n        msg = \", \".join(line_parts)\n\n        main_markup = {main_color: True}\n        duration = \" in {}\".format(format_session_duration(session_duration))\n        duration_with_markup = self._tw.markup(duration, **main_markup)\n        if display_sep:\n            fullwidth += len(duration_with_markup) - len(duration)\n        msg += duration_with_markup\n\n        if display_sep:\n            markup_for_end_sep = self._tw.markup(\"\", **main_markup)\n            if markup_for_end_sep.endswith(\"\\x1b[0m\"):\n                markup_for_end_sep = markup_for_end_sep[:-4]\n            fullwidth += len(markup_for_end_sep)\n            msg += markup_for_end_sep\n\n        if display_sep:\n            self.write_sep(\"=\", msg, fullwidth=fullwidth, **main_markup)\n        else:\n            self.write_line(msg, **main_markup)",
            "start_line": 963,
            "start_column": 34359,
            "end_line": 4,
            "end_column": 35728,
            "start_byte": 34359,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.short_test_summary",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def short_test_summary(self) -> None:\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines: List[str]) -> None:\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self._tw.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines: List[str]) -> None:\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines: List[str]) -> None:\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines: List[str]) -> None:\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(self.startdir, skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }  # type: Mapping[str, Callable[[List[str]], None]]\n\n        lines = []  # type: List[str]\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:\n                self.write_line(line)",
            "start_line": 1000,
            "start_column": 35734,
            "end_line": 4,
            "end_column": 38473,
            "start_byte": 35734,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._get_main_color",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _get_main_color(self) -> Tuple[str, List[str]]:\n        if self._main_color is None or self._known_types is None or self._is_last_item:\n            self._set_main_color()\n            assert self._main_color\n            assert self._known_types\n        return self._main_color, self._known_types",
            "start_line": 1069,
            "start_column": 38479,
            "end_line": 4,
            "end_column": 38777,
            "start_byte": 38479,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._determine_main_color",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _determine_main_color(self, unknown_type_seen: bool) -> str:\n        stats = self.stats\n        if \"failed\" in stats or \"error\" in stats:\n            main_color = \"red\"\n        elif \"warnings\" in stats or \"xpassed\" in stats or unknown_type_seen:\n            main_color = \"yellow\"\n        elif \"passed\" in stats or not self._is_last_item:\n            main_color = \"green\"\n        else:\n            main_color = \"yellow\"\n        return main_color",
            "start_line": 1076,
            "start_column": 38783,
            "end_line": 4,
            "end_column": 39231,
            "start_byte": 38783,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter._set_main_color",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _set_main_color(self) -> None:\n        unknown_types = []  # type: List[str]\n        for found_type in self.stats.keys():\n            if found_type:  # setup/teardown reports have an empty key, ignore them\n                if found_type not in KNOWN_TYPES and found_type not in unknown_types:\n                    unknown_types.append(found_type)\n        self._known_types = list(KNOWN_TYPES) + unknown_types\n        self._main_color = self._determine_main_color(bool(unknown_types))",
            "start_line": 1088,
            "start_column": 39237,
            "end_line": 4,
            "end_column": 39722,
            "start_byte": 39237,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.TerminalReporter.build_summary_stats_line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def build_summary_stats_line(self) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:\n        main_color, known_types = self._get_main_color()\n\n        parts = []\n        for key in known_types:\n            reports = self.stats.get(key, None)\n            if reports:\n                count = sum(\n                    1 for rep in reports if getattr(rep, \"count_towards_summary\", True)\n                )\n                color = _color_for_type.get(key, _color_for_type_default)\n                markup = {color: True, \"bold\": color == main_color}\n                parts.append((\"%d %s\" % _make_plural(count, key), markup))\n\n        if not parts:\n            parts = [(\"no tests ran\", {_color_for_type_default: True})]\n\n        return parts, main_color",
            "start_line": 1097,
            "start_column": 39728,
            "end_line": 4,
            "end_column": 40474,
            "start_byte": 39728,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "class Config:\n    \"\"\"\n    Access to configuration values, pluginmanager and plugin hooks.\n\n    :param PytestPluginManager pluginmanager:\n\n    :param InvocationParams invocation_params:\n        Object containing the parameters regarding the ``pytest.main``\n        invocation.\n    \"\"\"\n\n    @attr.s(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during ``pytest.main()``\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args = attr.ib(converter=tuple)\n        \"\"\"tuple of command-line arguments as passed to ``pytest.main()``.\"\"\"\n        plugins = attr.ib()\n        \"\"\"list of extra plugins, might be `None`.\"\"\"\n        dir = attr.ib(type=Path)\n        \"\"\"directory where ``pytest.main()`` was invoked from.\"\"\"\n\n    def __init__(\n        self,\n        pluginmanager: PytestPluginManager,\n        *,\n        invocation_params: Optional[InvocationParams] = None\n    ) -> None:\n        from .argparsing import Parser, FILE_OR_DIR\n\n        if invocation_params is None:\n            invocation_params = self.InvocationParams(\n                args=(), plugins=None, dir=Path().resolve()\n            )\n\n        self.option = argparse.Namespace()\n        \"\"\"access to command line option as attributes.\n\n          :type: argparse.Namespace\"\"\"\n\n        self.invocation_params = invocation_params\n\n        _a = FILE_OR_DIR\n        self._parser = Parser(\n            usage=\"%(prog)s [options] [{}] [{}] [...]\".format(_a, _a),\n            processopt=self._processopt,\n        )\n        self.pluginmanager = pluginmanager\n        \"\"\"the plugin manager handles plugin registration and hook invocation.\n\n          :type: PytestPluginManager\"\"\"\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook = self.pluginmanager.hook\n        self._inicache = {}  # type: Dict[str, Any]\n        self._override_ini = ()  # type: Sequence[str]\n        self._opt2dest = {}  # type: Dict[str, str]\n        self._cleanup = []  # type: List[Callable[[], None]]\n        # A place where plugins can store information on the config for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n\n        if TYPE_CHECKING:\n            from _pytest.cacheprovider import Cache\n\n            self.cache = None  # type: Optional[Cache]\n\n    @property\n    def invocation_dir(self):\n        \"\"\"Backward compatibility\"\"\"\n        return py.path.local(str(self.invocation_params.dir))\n\n    def add_cleanup(self, func):\n        \"\"\" Add a function to be called when the config object gets out of\n        use (usually coninciding with pytest_unconfigure).\"\"\"\n        self._cleanup.append(func)\n\n    def _do_configure(self):\n        assert not self._configured\n        self._configured = True\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"default\")\n            self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\n\n    def _ensure_unconfigure(self):\n        if self._configured:\n            self._configured = False\n            self.hook.pytest_unconfigure(config=self)\n            self.hook.pytest_configure._call_history = []\n        while self._cleanup:\n            fin = self._cleanup.pop()\n            fin()\n\n    def get_terminal_writer(self):\n        return self.pluginmanager.get_plugin(\"terminalreporter\")._tw\n\n    def pytest_cmdline_parse(self, pluginmanager, args):\n        try:\n            self.parse(args)\n        except UsageError:\n\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"version\", False) or \"--version\" in args:\n                from _pytest.helpconfig import showversion\n\n                showversion(self)\n            elif (\n                getattr(self.option, \"help\", False) or \"--help\" in args or \"-h\" in args\n            ):\n                self._parser._getparser().print_help()\n                sys.stdout.write(\n                    \"\\nNOTE: displaying only minimal help due to UsageError.\\n\\n\"\n                )\n\n            raise\n\n        return self\n\n    def notify_exception(self, excinfo, option=None):\n        if option and getattr(option, \"fulltrace\", False):\n            style = \"long\"\n        else:\n            style = \"native\"\n        excrepr = excinfo.getrepr(\n            funcargs=True, showlocals=getattr(option, \"showlocals\", False), style=style\n        )\n        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\n        if not any(res):\n            for line in str(excrepr).split(\"\\n\"):\n                sys.stderr.write(\"INTERNALERROR> %s\\n\" % line)\n                sys.stderr.flush()\n\n    def cwd_relative_nodeid(self, nodeid):\n        # nodeid's are relative to the rootpath, compute relative to cwd\n        if self.invocation_dir != self.rootdir:\n            fullpath = self.rootdir.join(nodeid)\n            nodeid = self.invocation_dir.bestrelpath(fullpath)\n        return nodeid\n\n    @classmethod\n    def fromdictargs(cls, option_dict, args):\n        \"\"\" constructor usable for subprocesses. \"\"\"\n        config = get_config(args)\n        config.option.__dict__.update(option_dict)\n        config.parse(args, addopts=False)\n        for x in config.option.plugins:\n            config.pluginmanager.consider_pluginarg(x)\n        return config\n\n    def _processopt(self, opt: \"Argument\") -> None:\n        for name in opt._short_opts + opt._long_opts:\n            self._opt2dest[name] = opt.dest\n\n        if hasattr(opt, \"default\"):\n            if not hasattr(self.option, opt.dest):\n                setattr(self.option, opt.dest, opt.default)\n\n    @hookimpl(trylast=True)\n    def pytest_load_initial_conftests(self, early_config):\n        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)\n\n    def _initini(self, args: Sequence[str]) -> None:\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(\n            args, namespace=copy.copy(self.option)\n        )\n        r = determine_setup(\n            ns.inifilename,\n            ns.file_or_dir + unknown_args,\n            rootdir_cmd_arg=ns.rootdir or None,\n            config=self,\n        )\n        self.rootdir, self.inifile, self.inicfg = r\n        self._parser.extra_info[\"rootdir\"] = self.rootdir\n        self._parser.extra_info[\"inifile\"] = self.inifile\n        self._parser.addini(\"addopts\", \"extra command line options\", \"args\")\n        self._parser.addini(\"minversion\", \"minimally required pytest version\")\n        self._override_ini = ns.override_ini or ()\n\n    def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook)\n        _warn_about_missing_assertion(mode)\n\n    def _mark_plugins_for_rewrite(self, hook):\n        \"\"\"\n        Given an importhook, mark for rewrite any top-level\n        modules or packages in the distribution package for\n        all pytest plugins.\n        \"\"\"\n        self.pluginmanager.rewrite_hook = hook\n\n        if os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # We don't autoload from setuptools entry points, no need to continue.\n            return\n\n        package_files = (\n            str(file)\n            for dist in importlib_metadata.distributions()\n            if any(ep.group == \"pytest11\" for ep in dist.entry_points)\n            for file in dist.files or []\n        )\n\n        for name in _iter_rewritable_modules(package_files):\n            hook.mark_rewrite(name)\n\n    def _validate_args(self, args: List[str], via: str) -> List[str]:\n        \"\"\"Validate known args.\"\"\"\n        self._parser._config_source_hint = via  # type: ignore\n        try:\n            self._parser.parse_known_and_unknown_args(\n                args, namespace=copy.copy(self.option)\n            )\n        finally:\n            del self._parser._config_source_hint  # type: ignore\n\n        return args\n\n    def _preparse(self, args: List[str], addopts: bool = True) -> None:\n        if addopts:\n            env_addopts = os.environ.get(\"PYTEST_ADDOPTS\", \"\")\n            if len(env_addopts):\n                args[:] = (\n                    self._validate_args(shlex.split(env_addopts), \"via PYTEST_ADDOPTS\")\n                    + args\n                )\n        self._initini(args)\n        if addopts:\n            args[:] = (\n                self._validate_args(self.getini(\"addopts\"), \"via addopts config\") + args\n            )\n\n        self._checkversion()\n        self._consider_importhook(args)\n        self.pluginmanager.consider_preparse(args, exclude_only=False)\n        if not os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # Don't autoload from setuptools entry point. Only explicitly specified\n            # plugins are going to be loaded.\n            self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\n        self.pluginmanager.consider_env()\n        self.known_args_namespace = ns = self._parser.parse_known_args(\n            args, namespace=copy.copy(self.option)\n        )\n        if self.known_args_namespace.confcutdir is None and self.inifile:\n            confcutdir = py.path.local(self.inifile).dirname\n            self.known_args_namespace.confcutdir = confcutdir\n        try:\n            self.hook.pytest_load_initial_conftests(\n                early_config=self, args=args, parser=self._parser\n            )\n        except ConftestImportFailure as e:\n            if ns.help or ns.version:\n                # we don't want to prevent --help/--version to work\n                # so just let is pass and print a warning at the end\n                from _pytest.warnings import _issue_warning_captured\n\n                _issue_warning_captured(\n                    PytestConfigWarning(\n                        \"could not load initial conftests: {}\".format(e.path)\n                    ),\n                    self.hook,\n                    stacklevel=2,\n                )\n            else:\n                raise\n\n    def _checkversion(self):\n        import pytest\n\n        minver = self.inicfg.get(\"minversion\", None)\n        if minver:\n            # Imported lazily to improve start-up time.\n            from packaging.version import Version\n\n            if Version(minver) > Version(pytest.__version__):\n                raise pytest.UsageError(\n                    \"%s:%d: requires pytest-%s, actual pytest-%s'\"\n                    % (\n                        self.inicfg.config.path,\n                        self.inicfg.lineof(\"minversion\"),\n                        minver,\n                        pytest.__version__,\n                    )\n                )\n\n    def parse(self, args: List[str], addopts: bool = True) -> None:\n        # parse given cmdline arguments into this config object.\n        assert not hasattr(\n            self, \"args\"\n        ), \"can only parse cmdline args at most once per Config object\"\n        self.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=self.pluginmanager)\n        )\n        self._preparse(args, addopts=addopts)\n        # XXX deprecated hook:\n        self.hook.pytest_cmdline_preparse(config=self, args=args)\n        self._parser.after_preparse = True  # type: ignore\n        try:\n            args = self._parser.parse_setoption(\n                args, self.option, namespace=self.option\n            )\n            if not args:\n                if self.invocation_dir == self.rootdir:\n                    args = self.getini(\"testpaths\")\n                if not args:\n                    args = [str(self.invocation_dir)]\n            self.args = args\n        except PrintHelp:\n            pass\n\n    def addinivalue_line(self, name, line):\n        \"\"\" add a line to an ini-file option. The option must have been\n        declared but might not yet be set in which case the line becomes the\n        the first line in its value. \"\"\"\n        x = self.getini(name)\n        assert isinstance(x, list)\n        x.append(line)  # modifies the cached list inline\n\n    def getini(self, name: str):\n        \"\"\" return configuration value from an :ref:`ini file <inifiles>`. If the\n        specified name hasn't been registered through a prior\n        :py:func:`parser.addini <_pytest.config.argparsing.Parser.addini>`\n        call (usually from a plugin), a ValueError is raised. \"\"\"\n        try:\n            return self._inicache[name]\n        except KeyError:\n            self._inicache[name] = val = self._getini(name)\n            return val\n\n    def _getini(self, name: str) -> Any:\n        try:\n            description, type, default = self._parser._inidict[name]\n        except KeyError:\n            raise ValueError(\"unknown configuration value: {!r}\".format(name))\n        value = self._get_override_ini_value(name)\n        if value is None:\n            try:\n                value = self.inicfg[name]\n            except KeyError:\n                if default is not None:\n                    return default\n                if type is None:\n                    return \"\"\n                return []\n        if type == \"pathlist\":\n            dp = py.path.local(self.inicfg.config.path).dirpath()\n            values = []\n            for relpath in shlex.split(value):\n                values.append(dp.join(relpath, abs=True))\n            return values\n        elif type == \"args\":\n            return shlex.split(value)\n        elif type == \"linelist\":\n            return [t for t in map(lambda x: x.strip(), value.split(\"\\n\")) if t]\n        elif type == \"bool\":\n            return bool(_strtobool(value.strip()))\n        else:\n            assert type is None\n            return value\n\n    def _getconftest_pathlist(self, name, path):\n        try:\n            mod, relroots = self.pluginmanager._rget_with_confmod(name, path)\n        except KeyError:\n            return None\n        modpath = py.path.local(mod.__file__).dirpath()\n        values = []\n        for relroot in relroots:\n            if not isinstance(relroot, py.path.local):\n                relroot = relroot.replace(\"/\", py.path.local.sep)\n                relroot = modpath.join(relroot, abs=True)\n            values.append(relroot)\n        return values\n\n    def _get_override_ini_value(self, name: str) -> Optional[str]:\n        value = None\n        # override_ini is a list of \"ini=value\" options\n        # always use the last item if multiple values are set for same ini-name,\n        # e.g. -o foo=bar1 -o foo=bar2 will set foo to bar2\n        for ini_config in self._override_ini:\n            try:\n                key, user_ini_value = ini_config.split(\"=\", 1)\n            except ValueError:\n                raise UsageError(\n                    \"-o/--override-ini expects option=value style (got: {!r}).\".format(\n                        ini_config\n                    )\n                )\n            else:\n                if key == name:\n                    value = user_ini_value\n        return value\n\n    def getoption(self, name: str, default=notset, skip: bool = False):\n        \"\"\" return command line option value.\n\n        :arg name: name of the option.  You may also specify\n            the literal ``--OPT`` option instead of the \"dest\" option name.\n        :arg default: default value if no option of that name exists.\n        :arg skip: if True raise pytest.skip if option does not exists\n            or has a None value.\n        \"\"\"\n        name = self._opt2dest.get(name, name)\n        try:\n            val = getattr(self.option, name)\n            if val is None and skip:\n                raise AttributeError(name)\n            return val\n        except AttributeError:\n            if default is not notset:\n                return default\n            if skip:\n                import pytest\n\n                pytest.skip(\"no {!r} option found\".format(name))\n            raise ValueError(\"no option named {!r}\".format(name))\n\n    def getvalue(self, name, path=None):\n        \"\"\" (deprecated, use getoption()) \"\"\"\n        return self.getoption(name)\n\n    def getvalueorskip(self, name, path=None):\n        \"\"\" (deprecated, use getoption(skip=True)) \"\"\"\n        return self.getoption(name, skip=True)",
            "start_line": 756,
            "start_column": 25530,
            "end_line": 0,
            "end_column": 42793,
            "start_byte": 25530,
            "end_byte": 0
          },
          {
            "name": "_pytest.config.Config.InvocationParams",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@attr.s(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during ``pytest.main()``\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args = attr.ib(converter=tuple)\n        \"\"\"tuple of command-line arguments as passed to ``pytest.main()``.\"\"\"\n        plugins = attr.ib()\n        \"\"\"list of extra plugins, might be `None`.\"\"\"\n        dir = attr.ib(type=Path)\n        \"\"\"directory where ``pytest.main()`` was invoked from.\"\"\"",
            "start_line": 767,
            "start_column": 25819,
            "end_line": 4,
            "end_column": 26589,
            "start_byte": 25819,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.InvocationParams.args",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "args = attr.ib(converter=tuple)",
            "start_line": 783,
            "start_column": 26299,
            "end_line": 8,
            "end_column": 26330,
            "start_byte": 26299,
            "end_byte": 8
          },
          {
            "name": "_pytest.config.Config.InvocationParams.plugins",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "plugins = attr.ib()",
            "start_line": 785,
            "start_column": 26417,
            "end_line": 8,
            "end_column": 26436,
            "start_byte": 26417,
            "end_byte": 8
          },
          {
            "name": "_pytest.config.Config.InvocationParams.dir",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "dir = attr.ib(type=Path)",
            "start_line": 787,
            "start_column": 26499,
            "end_line": 8,
            "end_column": 26523,
            "start_byte": 26499,
            "end_byte": 8
          },
          {
            "name": "_pytest.config.Config.__init__",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def __init__(\n        self,\n        pluginmanager: PytestPluginManager,\n        *,\n        invocation_params: Optional[InvocationParams] = None\n    ) -> None:\n        from .argparsing import Parser, FILE_OR_DIR\n\n        if invocation_params is None:\n            invocation_params = self.InvocationParams(\n                args=(), plugins=None, dir=Path().resolve()\n            )\n\n        self.option = argparse.Namespace()\n        \"\"\"access to command line option as attributes.\n\n          :type: argparse.Namespace\"\"\"\n\n        self.invocation_params = invocation_params\n\n        _a = FILE_OR_DIR\n        self._parser = Parser(\n            usage=\"%(prog)s [options] [{}] [{}] [...]\".format(_a, _a),\n            processopt=self._processopt,\n        )\n        self.pluginmanager = pluginmanager\n        \"\"\"the plugin manager handles plugin registration and hook invocation.\n\n          :type: PytestPluginManager\"\"\"\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook = self.pluginmanager.hook\n        self._inicache = {}  # type: Dict[str, Any]\n        self._override_ini = ()  # type: Sequence[str]\n        self._opt2dest = {}  # type: Dict[str, str]\n        self._cleanup = []  # type: List[Callable[[], None]]\n        # A place where plugins can store information on the config for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n\n        if TYPE_CHECKING:\n            from _pytest.cacheprovider import Cache\n\n            self.cache = None  # type: Optional[Cache]",
            "start_line": 790,
            "start_column": 26595,
            "end_line": 4,
            "end_column": 28375,
            "start_byte": 26595,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.invocation_dir",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@property\n    def invocation_dir(self):\n        \"\"\"Backward compatibility\"\"\"\n        return py.path.local(str(self.invocation_params.dir))",
            "start_line": 840,
            "start_column": 28381,
            "end_line": 4,
            "end_column": 28519,
            "start_byte": 28381,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.add_cleanup",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def add_cleanup(self, func):\n        \"\"\" Add a function to be called when the config object gets out of\n        use (usually coninciding with pytest_unconfigure).\"\"\"\n        self._cleanup.append(func)",
            "start_line": 845,
            "start_column": 28525,
            "end_line": 4,
            "end_column": 28725,
            "start_byte": 28525,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._do_configure",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _do_configure(self):\n        assert not self._configured\n        self._configured = True\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"default\")\n            self.hook.pytest_configure.call_historic(kwargs=dict(config=self))",
            "start_line": 850,
            "start_column": 28731,
            "end_line": 4,
            "end_column": 28987,
            "start_byte": 28731,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._ensure_unconfigure",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _ensure_unconfigure(self):\n        if self._configured:\n            self._configured = False\n            self.hook.pytest_unconfigure(config=self)\n            self.hook.pytest_configure._call_history = []\n        while self._cleanup:\n            fin = self._cleanup.pop()\n            fin()",
            "start_line": 857,
            "start_column": 28993,
            "end_line": 4,
            "end_column": 29286,
            "start_byte": 28993,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.get_terminal_writer",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def get_terminal_writer(self):\n        return self.pluginmanager.get_plugin(\"terminalreporter\")._tw",
            "start_line": 866,
            "start_column": 29292,
            "end_line": 4,
            "end_column": 29391,
            "start_byte": 29292,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.pytest_cmdline_parse",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def pytest_cmdline_parse(self, pluginmanager, args):\n        try:\n            self.parse(args)\n        except UsageError:\n\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"version\", False) or \"--version\" in args:\n                from _pytest.helpconfig import showversion\n\n                showversion(self)\n            elif (\n                getattr(self.option, \"help\", False) or \"--help\" in args or \"-h\" in args\n            ):\n                self._parser._getparser().print_help()\n                sys.stdout.write(\n                    \"\\nNOTE: displaying only minimal help due to UsageError.\\n\\n\"\n                )\n\n            raise\n\n        return self",
            "start_line": 869,
            "start_column": 29397,
            "end_line": 4,
            "end_column": 30240,
            "start_byte": 29397,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.notify_exception",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def notify_exception(self, excinfo, option=None):\n        if option and getattr(option, \"fulltrace\", False):\n            style = \"long\"\n        else:\n            style = \"native\"\n        excrepr = excinfo.getrepr(\n            funcargs=True, showlocals=getattr(option, \"showlocals\", False), style=style\n        )\n        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\n        if not any(res):\n            for line in str(excrepr).split(\"\\n\"):\n                sys.stderr.write(\"INTERNALERROR> %s\\n\" % line)\n                sys.stderr.flush()",
            "start_line": 893,
            "start_column": 30246,
            "end_line": 4,
            "end_column": 30809,
            "start_byte": 30246,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.cwd_relative_nodeid",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def cwd_relative_nodeid(self, nodeid):\n        # nodeid's are relative to the rootpath, compute relative to cwd\n        if self.invocation_dir != self.rootdir:\n            fullpath = self.rootdir.join(nodeid)\n            nodeid = self.invocation_dir.bestrelpath(fullpath)\n        return nodeid",
            "start_line": 907,
            "start_column": 30815,
            "end_line": 4,
            "end_column": 31108,
            "start_byte": 30815,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.fromdictargs",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@classmethod\n    def fromdictargs(cls, option_dict, args):\n        \"\"\" constructor usable for subprocesses. \"\"\"\n        config = get_config(args)\n        config.option.__dict__.update(option_dict)\n        config.parse(args, addopts=False)\n        for x in config.option.plugins:\n            config.pluginmanager.consider_pluginarg(x)\n        return config",
            "start_line": 914,
            "start_column": 31114,
            "end_line": 4,
            "end_column": 31469,
            "start_byte": 31114,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._processopt",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _processopt(self, opt: \"Argument\") -> None:\n        for name in opt._short_opts + opt._long_opts:\n            self._opt2dest[name] = opt.dest\n\n        if hasattr(opt, \"default\"):\n            if not hasattr(self.option, opt.dest):\n                setattr(self.option, opt.dest, opt.default)",
            "start_line": 924,
            "start_column": 31475,
            "end_line": 4,
            "end_column": 31768,
            "start_byte": 31475,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.pytest_load_initial_conftests",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@hookimpl(trylast=True)\n    def pytest_load_initial_conftests(self, early_config):\n        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)",
            "start_line": 932,
            "start_column": 31774,
            "end_line": 4,
            "end_column": 31941,
            "start_byte": 31774,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._initini",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _initini(self, args: Sequence[str]) -> None:\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(\n            args, namespace=copy.copy(self.option)\n        )\n        r = determine_setup(\n            ns.inifilename,\n            ns.file_or_dir + unknown_args,\n            rootdir_cmd_arg=ns.rootdir or None,\n            config=self,\n        )\n        self.rootdir, self.inifile, self.inicfg = r\n        self._parser.extra_info[\"rootdir\"] = self.rootdir\n        self._parser.extra_info[\"inifile\"] = self.inifile\n        self._parser.addini(\"addopts\", \"extra command line options\", \"args\")\n        self._parser.addini(\"minversion\", \"minimally required pytest version\")\n        self._override_ini = ns.override_ini or ()",
            "start_line": 936,
            "start_column": 31947,
            "end_line": 4,
            "end_column": 32684,
            "start_byte": 31947,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._consider_importhook",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook)\n        _warn_about_missing_assertion(mode)",
            "start_line": 953,
            "start_column": 32690,
            "end_line": 4,
            "end_column": 33458,
            "start_byte": 32690,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._mark_plugins_for_rewrite",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _mark_plugins_for_rewrite(self, hook):\n        \"\"\"\n        Given an importhook, mark for rewrite any top-level\n        modules or packages in the distribution package for\n        all pytest plugins.\n        \"\"\"\n        self.pluginmanager.rewrite_hook = hook\n\n        if os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # We don't autoload from setuptools entry points, no need to continue.\n            return\n\n        package_files = (\n            str(file)\n            for dist in importlib_metadata.distributions()\n            if any(ep.group == \"pytest11\" for ep in dist.entry_points)\n            for file in dist.files or []\n        )\n\n        for name in _iter_rewritable_modules(package_files):\n            hook.mark_rewrite(name)",
            "start_line": 973,
            "start_column": 33464,
            "end_line": 4,
            "end_column": 34217,
            "start_byte": 33464,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._validate_args",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _validate_args(self, args: List[str], via: str) -> List[str]:\n        \"\"\"Validate known args.\"\"\"\n        self._parser._config_source_hint = via  # type: ignore\n        try:\n            self._parser.parse_known_and_unknown_args(\n                args, namespace=copy.copy(self.option)\n            )\n        finally:\n            del self._parser._config_source_hint  # type: ignore\n\n        return args",
            "start_line": 995,
            "start_column": 34223,
            "end_line": 4,
            "end_column": 34626,
            "start_byte": 34223,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._preparse",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _preparse(self, args: List[str], addopts: bool = True) -> None:\n        if addopts:\n            env_addopts = os.environ.get(\"PYTEST_ADDOPTS\", \"\")\n            if len(env_addopts):\n                args[:] = (\n                    self._validate_args(shlex.split(env_addopts), \"via PYTEST_ADDOPTS\")\n                    + args\n                )\n        self._initini(args)\n        if addopts:\n            args[:] = (\n                self._validate_args(self.getini(\"addopts\"), \"via addopts config\") + args\n            )\n\n        self._checkversion()\n        self._consider_importhook(args)\n        self.pluginmanager.consider_preparse(args, exclude_only=False)\n        if not os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # Don't autoload from setuptools entry point. Only explicitly specified\n            # plugins are going to be loaded.\n            self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\n        self.pluginmanager.consider_env()\n        self.known_args_namespace = ns = self._parser.parse_known_args(\n            args, namespace=copy.copy(self.option)\n        )\n        if self.known_args_namespace.confcutdir is None and self.inifile:\n            confcutdir = py.path.local(self.inifile).dirname\n            self.known_args_namespace.confcutdir = confcutdir\n        try:\n            self.hook.pytest_load_initial_conftests(\n                early_config=self, args=args, parser=self._parser\n            )\n        except ConftestImportFailure as e:\n            if ns.help or ns.version:\n                # we don't want to prevent --help/--version to work\n                # so just let is pass and print a warning at the end\n                from _pytest.warnings import _issue_warning_captured\n\n                _issue_warning_captured(\n                    PytestConfigWarning(\n                        \"could not load initial conftests: {}\".format(e.path)\n                    ),\n                    self.hook,\n                    stacklevel=2,\n                )\n            else:\n                raise",
            "start_line": 1007,
            "start_column": 34632,
            "end_line": 4,
            "end_column": 36670,
            "start_byte": 34632,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._checkversion",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _checkversion(self):\n        import pytest\n\n        minver = self.inicfg.get(\"minversion\", None)\n        if minver:\n            # Imported lazily to improve start-up time.\n            from packaging.version import Version\n\n            if Version(minver) > Version(pytest.__version__):\n                raise pytest.UsageError(\n                    \"%s:%d: requires pytest-%s, actual pytest-%s'\"\n                    % (\n                        self.inicfg.config.path,\n                        self.inicfg.lineof(\"minversion\"),\n                        minver,\n                        pytest.__version__,\n                    )\n                )",
            "start_line": 1055,
            "start_column": 36676,
            "end_line": 4,
            "end_column": 37319,
            "start_byte": 36676,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.parse",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def parse(self, args: List[str], addopts: bool = True) -> None:\n        # parse given cmdline arguments into this config object.\n        assert not hasattr(\n            self, \"args\"\n        ), \"can only parse cmdline args at most once per Config object\"\n        self.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=self.pluginmanager)\n        )\n        self._preparse(args, addopts=addopts)\n        # XXX deprecated hook:\n        self.hook.pytest_cmdline_preparse(config=self, args=args)\n        self._parser.after_preparse = True  # type: ignore\n        try:\n            args = self._parser.parse_setoption(\n                args, self.option, namespace=self.option\n            )\n            if not args:\n                if self.invocation_dir == self.rootdir:\n                    args = self.getini(\"testpaths\")\n                if not args:\n                    args = [str(self.invocation_dir)]\n            self.args = args\n        except PrintHelp:\n            pass",
            "start_line": 1074,
            "start_column": 37325,
            "end_line": 4,
            "end_column": 38318,
            "start_byte": 37325,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.addinivalue_line",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def addinivalue_line(self, name, line):\n        \"\"\" add a line to an ini-file option. The option must have been\n        declared but might not yet be set in which case the line becomes the\n        the first line in its value. \"\"\"\n        x = self.getini(name)\n        assert isinstance(x, list)\n        x.append(line)  # modifies the cached list inline",
            "start_line": 1099,
            "start_column": 38324,
            "end_line": 4,
            "end_column": 38676,
            "start_byte": 38324,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.getini",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getini(self, name: str):\n        \"\"\" return configuration value from an :ref:`ini file <inifiles>`. If the\n        specified name hasn't been registered through a prior\n        :py:func:`parser.addini <_pytest.config.argparsing.Parser.addini>`\n        call (usually from a plugin), a ValueError is raised. \"\"\"\n        try:\n            return self._inicache[name]\n        except KeyError:\n            self._inicache[name] = val = self._getini(name)\n            return val",
            "start_line": 1107,
            "start_column": 38682,
            "end_line": 4,
            "end_column": 39156,
            "start_byte": 38682,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._getini",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _getini(self, name: str) -> Any:\n        try:\n            description, type, default = self._parser._inidict[name]\n        except KeyError:\n            raise ValueError(\"unknown configuration value: {!r}\".format(name))\n        value = self._get_override_ini_value(name)\n        if value is None:\n            try:\n                value = self.inicfg[name]\n            except KeyError:\n                if default is not None:\n                    return default\n                if type is None:\n                    return \"\"\n                return []\n        if type == \"pathlist\":\n            dp = py.path.local(self.inicfg.config.path).dirpath()\n            values = []\n            for relpath in shlex.split(value):\n                values.append(dp.join(relpath, abs=True))\n            return values\n        elif type == \"args\":\n            return shlex.split(value)\n        elif type == \"linelist\":\n            return [t for t in map(lambda x: x.strip(), value.split(\"\\n\")) if t]\n        elif type == \"bool\":\n            return bool(_strtobool(value.strip()))\n        else:\n            assert type is None\n            return value",
            "start_line": 1118,
            "start_column": 39162,
            "end_line": 4,
            "end_column": 40297,
            "start_byte": 39162,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._getconftest_pathlist",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _getconftest_pathlist(self, name, path):\n        try:\n            mod, relroots = self.pluginmanager._rget_with_confmod(name, path)\n        except KeyError:\n            return None\n        modpath = py.path.local(mod.__file__).dirpath()\n        values = []\n        for relroot in relroots:\n            if not isinstance(relroot, py.path.local):\n                relroot = relroot.replace(\"/\", py.path.local.sep)\n                relroot = modpath.join(relroot, abs=True)\n            values.append(relroot)\n        return values",
            "start_line": 1149,
            "start_column": 40303,
            "end_line": 4,
            "end_column": 40832,
            "start_byte": 40303,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config._get_override_ini_value",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _get_override_ini_value(self, name: str) -> Optional[str]:\n        value = None\n        # override_ini is a list of \"ini=value\" options\n        # always use the last item if multiple values are set for same ini-name,\n        # e.g. -o foo=bar1 -o foo=bar2 will set foo to bar2\n        for ini_config in self._override_ini:\n            try:\n                key, user_ini_value = ini_config.split(\"=\", 1)\n            except ValueError:\n                raise UsageError(\n                    \"-o/--override-ini expects option=value style (got: {!r}).\".format(\n                        ini_config\n                    )\n                )\n            else:\n                if key == name:\n                    value = user_ini_value\n        return value",
            "start_line": 1163,
            "start_column": 40838,
            "end_line": 4,
            "end_column": 41586,
            "start_byte": 40838,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.getoption",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getoption(self, name: str, default=notset, skip: bool = False):\n        \"\"\" return command line option value.\n\n        :arg name: name of the option.  You may also specify\n            the literal ``--OPT`` option instead of the \"dest\" option name.\n        :arg default: default value if no option of that name exists.\n        :arg skip: if True raise pytest.skip if option does not exists\n            or has a None value.\n        \"\"\"\n        name = self._opt2dest.get(name, name)\n        try:\n            val = getattr(self.option, name)\n            if val is None and skip:\n                raise AttributeError(name)\n            return val\n        except AttributeError:\n            if default is not notset:\n                return default\n            if skip:\n                import pytest\n\n                pytest.skip(\"no {!r} option found\".format(name))\n            raise ValueError(\"no option named {!r}\".format(name))",
            "start_line": 1182,
            "start_column": 41592,
            "end_line": 4,
            "end_column": 42519,
            "start_byte": 41592,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.getvalue",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getvalue(self, name, path=None):\n        \"\"\" (deprecated, use getoption()) \"\"\"\n        return self.getoption(name)",
            "start_line": 1206,
            "start_column": 42525,
            "end_line": 4,
            "end_column": 42643,
            "start_byte": 42525,
            "end_byte": 4
          },
          {
            "name": "_pytest.config.Config.getvalueorskip",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getvalueorskip(self, name, path=None):\n        \"\"\" (deprecated, use getoption(skip=True)) \"\"\"\n        return self.getoption(name, skip=True)",
            "start_line": 1210,
            "start_column": 42649,
            "end_line": 4,
            "end_column": 42793,
            "start_byte": 42649,
            "end_byte": 4
          },
          {
            "name": "_pytest.warning_types.PytestConfigWarning",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "r\n\nimport _pytest._code\nimport _pytest.deprecated\nimport _pytest.hookspec  # the extension point definitions\nfrom .excep",
            "start_line": 30,
            "start_column": 617,
            "end_line": 0,
            "end_column": 737,
            "start_byte": 617,
            "end_byte": 0
          },
          {
            "name": "_pytest.warning_types.PytestConfigWarning.__module__",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "finitions\nfrom .excep",
            "start_line": 33,
            "start_column": 716,
            "end_line": 4,
            "end_column": 737,
            "start_byte": 716,
            "end_byte": 4
          },
          {
            "name": "_pytest.monkeypatch.MonkeyPatch.chdir",
            "file_path": "src/_pytest/monkeypatch.py",
            "file_content": "def chdir(self, path):\n        \"\"\" Change the current working directory to the specified path.\n        Path can be a string or a py.path.local object.\n        \"\"\"\n        if self._cwd is None:\n            self._cwd = os.getcwd()\n        if hasattr(path, \"chdir\"):\n            path.chdir()\n        elif isinstance(path, Path):\n            # modern python uses the fspath protocol here LEGACY\n            os.chdir(str(path))\n        else:\n            os.chdir(path)",
            "start_line": 274,
            "start_column": 9526,
            "end_line": 4,
            "end_column": 9989,
            "start_byte": 9526,
            "end_byte": 4
          },
          {
            "name": "_pytest.monkeypatch.MonkeyPatch.undo",
            "file_path": "src/_pytest/monkeypatch.py",
            "file_content": "def undo(self):\n        \"\"\" Undo previous changes.  This call consumes the\n        undo stack. Calling it a second time has no effect unless\n        you do more monkeypatching after the undo call.\n\n        There is generally no need to call `undo()`, since it is\n        called automatically during tear-down.\n\n        Note that the same `monkeypatch` fixture is used across a\n        single test function invocation. If `monkeypatch` is used both by\n        the test function itself and one of the test fixtures,\n        calling `undo()` will undo all of the changes made in\n        both functions.\n        \"\"\"\n        for obj, name, value in reversed(self._setattr):\n            if value is not notset:\n                setattr(obj, name, value)\n            else:\n                delattr(obj, name)\n        self._setattr[:] = []\n        for dictionary, name, value in reversed(self._setitem):\n            if value is notset:\n                try:\n                    del dictionary[name]\n                except KeyError:\n                    pass  # was already deleted, so we have the desired state\n            else:\n                dictionary[name] = value\n        self._setitem[:] = []\n        if self._savesyspath is not None:\n            sys.path[:] = self._savesyspath\n            self._savesyspath = None\n\n        if self._cwd is not None:\n            os.chdir(self._cwd)\n            self._cwd = None",
            "start_line": 288,
            "start_column": 9995,
            "end_line": 4,
            "end_column": 11401,
            "start_byte": 9995,
            "end_byte": 4
          }
        ],
        "root_caused_symbols": [
          {
            "name": "_pytest.terminal.TerminalReporter._locationline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \"",
            "start_line": 776,
            "start_column": 27160,
            "end_line": 4,
            "end_column": 27982,
            "start_byte": 27160,
            "end_byte": 4
          },
          {
            "name": "_pytest.nodes.Node._repr_failure_py",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def _repr_failure_py(\n        self, excinfo: ExceptionInfo[BaseException], style=None,\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        if isinstance(excinfo.value, ConftestImportFailure):\n            excinfo = ExceptionInfo(excinfo.value.excinfo)\n        if isinstance(excinfo.value, fail.Exception):\n            if not excinfo.value.pytrace:\n                style = \"value\"\n        if isinstance(excinfo.value, FixtureLookupError):\n            return excinfo.value.formatrepr()\n        if self.config.getoption(\"fulltrace\", False):\n            style = \"long\"\n        else:\n            tb = _pytest._code.Traceback([excinfo.traceback[-1]])\n            self._prunetraceback(excinfo)\n            if len(excinfo.traceback) == 0:\n                excinfo.traceback = tb\n            if style == \"auto\":\n                style = \"long\"\n        # XXX should excinfo.getrepr record all data and toterminal() process it?\n        if style is None:\n            if self.config.getoption(\"tbstyle\", \"auto\") == \"short\":\n                style = \"short\"\n            else:\n                style = \"long\"\n\n        if self.config.getoption(\"verbose\", 0) > 1:\n            truncate_locals = False\n        else:\n            truncate_locals = True\n\n        try:\n            os.getcwd()\n            abspath = False\n        except OSError:\n            abspath = True\n\n        return excinfo.getrepr(\n            funcargs=True,\n            abspath=abspath,\n            showlocals=self.config.getoption(\"showlocals\", False),\n            style=style,\n            tbfilter=False,  # pruned already, or in --fulltrace mode.\n            truncate_locals=truncate_locals,\n        )",
            "start_line": 332,
            "start_column": 10806,
            "end_line": 4,
            "end_column": 12496,
            "start_byte": 10806,
            "end_byte": 4
          },
          {
            "name": "_pytest.nodes.Node.repr_failure",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def repr_failure(\n        self, excinfo, style=None\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        \"\"\"\n        Return a representation of a collection or test failure.\n\n        :param excinfo: Exception information for the failure.\n        \"\"\"\n        return self._repr_failure_py(excinfo, style)",
            "start_line": 378,
            "start_column": 12502,
            "end_line": 4,
            "end_column": 12843,
            "start_byte": 12502,
            "end_byte": 4
          },
          {
            "name": "_pytest.nodes.get_fslocation_from_item",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def get_fslocation_from_item(\n    item: \"Item\",\n) -> Tuple[Union[str, py.path.local], Optional[int]]:\n    \"\"\"Tries to extract the actual location from an item, depending on available attributes:\n\n    * \"fslocation\": a pair (path, lineno)\n    * \"obj\": a Python object that the item wraps.\n    * \"fspath\": just a path\n\n    :rtype: a tuple of (str|LocalPath, int) with filename and line number.\n    \"\"\"\n    try:\n        return item.location[:2]\n    except AttributeError:\n        pass\n    obj = getattr(item, \"obj\", None)\n    if obj is not None:\n        return getfslineno(obj)\n    return getattr(item, \"fspath\", \"unknown location\"), -1",
            "start_line": 389,
            "start_column": 12846,
            "end_line": 0,
            "end_column": 13479,
            "start_byte": 12846,
            "end_byte": 0
          }
        ]
      },
      "response": {
        "scratch_pad": "Analyzing the reported issue:\n\n1.1 What issue is the user describing?\n- The issue is that when the working directory is changed inside a pytest fixture, the test file errors are reported with wrong paths relative to the new directory, instead of being relative to the original directory.\n\n1.2 How was this issue caused?\n- The issue arises because the fixture `private_dir` changes the working directory to a new one (`ddd`) and the error paths are not being adjusted back to the original directory before being reported.\n\n1.3 What is the expected result?\n- The expected result is for the error paths to be displayed relative to the original directory, even after the directory has been changed within the fixture.\n\n1.4 What should the expectation be?\n- The expectation should be that the paths in the test error reports are consistent with the original directory setup, regardless of any temporary directory changes performed by the test code (fixtures).\n\n1.5 How should the issue be fixed to meet the expectation?\n- The path adjustment code needs to ensure that error messages refer to paths relative to the original directory, ignoring any temporary changes made during the test.\n\n2. Evaluating given symbols:\n\n- _pytest.terminal.TerminalReporter._locationline\n  2.1 This function creates a relative line for nodeids; it uses cwd_relative_nodeid which could be involved in incorrect path handling. The cwd_relative_nodeid function needs to consider the change of directory.\n  2.2 It seems relevant to the issue because it deals with formatting the location lines of errors and other reports.\n\n- _pytest.nodes.Node._repr_failure_py\n  2.1 Involved with the representation of failures and could affect how paths are presented in tracebacks.\n  2.2 Relative to the issue if the path being used comes through this function when the exception is formatted.\n\n- _pytest.terminal.TerminalReporter\n  2.1 The class is responsible for rendering results on the terminal, including where the errors occur.\n  2.2 Relevant due to its methods that control how paths are displayed during test sessions.",
        "symbols": [
          {
            "name": "_pytest.terminal.TerminalReporter._locationline",
            "file_path": "src/_pytest/terminal.py",
            "reason": "This function is responsible for creating relative paths for node IDs and directly affects how paths are displayed. Since the incorrect path issue is related to path handling in a relative manner, this symbol is crucial to correcting the path context."
          },
          {
            "name": "_pytest.config.Config.cwd_relative_nodeid",
            "file_path": "src/_pytest/config/__init__.py",
            "reason": "This function computes paths relative to the current working directory. It needs to ensure that paths are computed relative to the original invocation directory, not the changed directory during test execution."
          }
        ],
        "more_info": [],
        "is_done": false,
        "symbols_scratch_pad": [
          "- _pytest.terminal.TerminalReporter._locationline:\n  This function relates to the construction of location lines using cwd_relative_nodeid and potentially contributes to the error in path rendering when the current directory changes.\n  - This needs to append to ensure the path correction logic correctly always computes using the original starting directory.\n\n- _pytest.nodes.Node._repr_failure_py:\n  This function formats exception information and may impact traceback location formatting. It might intersect with path handling, but is less directly responsible compared to `cwd_relative_nodeid` or `_locationline`.\n  - While related, it appears less directly change-worthy given context.\n\n- _pytest.config.Config.cwd_relative_nodeid:\n  This symbol handles path computation for node IDs based on current versus root directory. The problem seems deeply tied to this relative path context during directory changes.\n  - Needs amending to avoid re-calculating path relative to temporary working directory changes in tests."
        ]
      }
    },
    {
      "name": "SymbolSummary",
      "metadata": {
        "start": "2024-08-19T12:18:10.520845",
        "usage": "7.487773895263672 ms"
      },
      "request": {
        "symbols": {
          "related_symbols": [
            {
              "name": "_pytest.terminal.TerminalReporter",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "class TerminalReporter:\n    def __init__(self, config: Config, file=None) -> None:\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None  # type: Optional[Session]\n        self._showfspath = None\n\n        self.stats = {}  # type: Dict[str, List[Any]]\n        self._main_color = None  # type: Optional[str]\n        self._known_types = None  # type: Optional[List]\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None  # type: Any\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()  # type: Set[str]\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None  # type: Optional[float]\n\n    @property\n    def writer(self) -> TerminalWriter:\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        return self._tw\n\n    @writer.setter\n    def writer(self, value: TerminalWriter):\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        self._tw = value\n\n    def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False\n\n    @property\n    def verbosity(self):\n        return self.config.option.verbose\n\n    @property\n    def showheader(self):\n        return self.verbosity >= 0\n\n    @property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0\n        return self._showfspath\n\n    @showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value\n\n    @property\n    def showlongtestinfo(self):\n        return self.verbosity > 0\n\n    def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars\n\n    def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, flush=True, **markup)\n\n    def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2\n\n    def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None\n\n    def write(self, content: str, *, flush: bool = False, **markup: bool) -> None:\n        self._tw.write(content, flush=flush, **markup)\n\n    def flush(self) -> None:\n        self._tw.flush()\n\n    def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)\n\n    def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)\n\n    def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)\n\n    def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)\n\n    def line(self, msg, **kw):\n        self._tw.line(msg, **kw)\n\n    def _add_stats(self, category: str, items: List) -> None:\n        set_main_color = category not in self.stats\n        self.stats.setdefault(category, []).extend(items[:])\n        if set_main_color:\n            self._set_main_color()\n\n    def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1\n\n    def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        self._add_stats(\"warnings\", [warning_report])\n\n    def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)\n\n    def pytest_deselected(self, items):\n        self._add_stats(\"deselected\", items)\n\n    def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n            self.flush()\n        elif self.showfspath:\n            self.write_fspath_result(nodeid, \"\")\n            self.flush()\n\n    def pytest_runtest_logreport(self, report: TestReport) -> None:\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self._add_stats(category, [rep])\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2\n        self.flush()\n\n    @property\n    def _is_last_item(self):\n        return len(self._progress_nodeids_reported) == self._session.testscollected\n\n    def pytest_runtest_logfinish(self, nodeid):\n        assert self._session\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n\n            if self._is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                main_color, _ = self._get_main_color()\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", **{main_color: True})\n\n    def _get_progress_information_message(self) -> str:\n        assert self._session\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                return \" [{:3d}%]\".format(\n                    len(self._progress_nodeids_reported) * 100 // collected\n                )\n            return \" [100%]\"\n\n    def _write_progress_information_filling_space(self):\n        color, _ = self._get_main_color()\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), flush=True, **{color: True})\n\n    @property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        return self._tw.width_of_current_line\n\n    def pytest_collection(self) -> None:\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", flush=True, bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", flush=True, bold=True)\n\n    def pytest_collectreport(self, report: CollectReport) -> None:\n        if report.failed:\n            self._add_stats(\"error\", [report])\n        elif report.skipped:\n            self._add_stats(\"skipped\", [report])\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()\n\n    def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d error%s\" % (errors, \"s\" if errors != 1 else \"\")\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)\n\n    @pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session: Session) -> None:\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n        if pypy_version_info:\n            verinfo = \".\".join(map(str, pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)\n\n    def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)\n\n    def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result\n\n    def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if session.items:\n                if self.config.option.verbose > -1:\n                    self._tw.line(\"\")\n                self._printcollecteditems(session.items)\n\n            failed = self.stats.get(\"failed\")\n            if failed:\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in failed:\n                    rep.toterminal(self._tw)\n\n    def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}  # type: Dict[str, int]\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    try:\n                        obj = col.obj  # type: ignore\n                    except AttributeError:\n                        continue\n                    doc = inspect.getdoc(obj)\n                    if doc:\n                        for line in doc.splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line))\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, session: Session, exitstatus: ExitCode):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if session.shouldfail:\n            self.write_sep(\"!\", session.shouldfail, red=True)\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        elif session.shouldstop:\n            self.write_sep(\"!\", session.shouldstop, red=True)\n        self.summary_stats()\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()\n\n    def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)\n\n    def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()\n\n    def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )\n\n    def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \"\n\n    def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?\n\n    def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"\n\n    #\n    # summaries for sessionfinish\n    #\n    def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values\n\n    def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\n                \"warnings\"\n            )  # type: Optional[List[WarningReport]]\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = (\n                order_preserving_dict()\n            )  # type: Dict[str, List[WarningReport]]\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            def collapsed_location_report(reports: List[WarningReport]):\n                locations = []\n                for w in reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        locations.append(location)\n\n                if len(locations) < 10:\n                    return \"\\n\".join(map(str, locations))\n\n                counts_by_filename = order_preserving_dict()  # type: Dict[str, int]\n                for loc in locations:\n                    key = str(loc).split(\"::\", 1)[0]\n                    counts_by_filename[key] = counts_by_filename.get(key, 0) + 1\n                return \"\\n\".join(\n                    \"{}: {} warning{}\".format(k, v, \"s\" if v > 1 else \"\")\n                    for k, v in counts_by_filename.items()\n                )\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, message_reports in reports_grouped_by_message.items():\n                maybe_location = collapsed_location_report(message_reports)\n                if maybe_location:\n                    self._tw.line(maybe_location)\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")\n\n    def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)\n\n    def _get_teardown_reports(self, nodeid: str) -> List[TestReport]:\n        return [\n            report\n            for report in self.getreports(\"\")\n            if report.when == \"teardown\" and report.nodeid == nodeid\n        ]\n\n    def _handle_teardown_sections(self, nodeid: str) -> None:\n        for report in self._get_teardown_reports(nodeid):\n            self.print_teardown_sections(report)\n\n    def print_teardown_sections(self, rep: TestReport) -> None:\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)\n\n    def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)\n\n    def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)\n\n    def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)\n\n    def summary_stats(self):\n        if self.verbosity < -1:\n            return\n\n        session_duration = time.time() - self._sessionstarttime\n        (parts, main_color) = self.build_summary_stats_line()\n        line_parts = []\n\n        display_sep = self.verbosity >= 0\n        if display_sep:\n            fullwidth = self._tw.fullwidth\n        for text, markup in parts:\n            with_markup = self._tw.markup(text, **markup)\n            if display_sep:\n                fullwidth += len(with_markup) - len(text)\n            line_parts.append(with_markup)\n        msg = \", \".join(line_parts)\n\n        main_markup = {main_color: True}\n        duration = \" in {}\".format(format_session_duration(session_duration))\n        duration_with_markup = self._tw.markup(duration, **main_markup)\n        if display_sep:\n            fullwidth += len(duration_with_markup) - len(duration)\n        msg += duration_with_markup\n\n        if display_sep:\n            markup_for_end_sep = self._tw.markup(\"\", **main_markup)\n            if markup_for_end_sep.endswith(\"\\x1b[0m\"):\n                markup_for_end_sep = markup_for_end_sep[:-4]\n            fullwidth += len(markup_for_end_sep)\n            msg += markup_for_end_sep\n\n        if display_sep:\n            self.write_sep(\"=\", msg, fullwidth=fullwidth, **main_markup)\n        else:\n            self.write_line(msg, **main_markup)\n\n    def short_test_summary(self) -> None:\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines: List[str]) -> None:\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self._tw.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines: List[str]) -> None:\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines: List[str]) -> None:\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines: List[str]) -> None:\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(self.startdir, skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }  # type: Mapping[str, Callable[[List[str]], None]]\n\n        lines = []  # type: List[str]\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:\n                self.write_line(line)\n\n    def _get_main_color(self) -> Tuple[str, List[str]]:\n        if self._main_color is None or self._known_types is None or self._is_last_item:\n            self._set_main_color()\n            assert self._main_color\n            assert self._known_types\n        return self._main_color, self._known_types\n\n    def _determine_main_color(self, unknown_type_seen: bool) -> str:\n        stats = self.stats\n        if \"failed\" in stats or \"error\" in stats:\n            main_color = \"red\"\n        elif \"warnings\" in stats or \"xpassed\" in stats or unknown_type_seen:\n            main_color = \"yellow\"\n        elif \"passed\" in stats or not self._is_last_item:\n            main_color = \"green\"\n        else:\n            main_color = \"yellow\"\n        return main_color\n\n    def _set_main_color(self) -> None:\n        unknown_types = []  # type: List[str]\n        for found_type in self.stats.keys():\n            if found_type:  # setup/teardown reports have an empty key, ignore them\n                if found_type not in KNOWN_TYPES and found_type not in unknown_types:\n                    unknown_types.append(found_type)\n        self._known_types = list(KNOWN_TYPES) + unknown_types\n        self._main_color = self._determine_main_color(bool(unknown_types))\n\n    def build_summary_stats_line(self) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:\n        main_color, known_types = self._get_main_color()\n\n        parts = []\n        for key in known_types:\n            reports = self.stats.get(key, None)\n            if reports:\n                count = sum(\n                    1 for rep in reports if getattr(rep, \"count_towards_summary\", True)\n                )\n                color = _color_for_type.get(key, _color_for_type_default)\n                markup = {color: True, \"bold\": color == main_color}\n                parts.append((\"%d %s\" % _make_plural(count, key), markup))\n\n        if not parts:\n            parts = [(\"no tests ran\", {_color_for_type_default: True})]\n\n        return parts, main_color",
              "start_line": 261,
              "start_column": 7463,
              "end_line": 0,
              "end_column": 40474,
              "start_byte": 7463,
              "end_byte": 0
            },
            {
              "name": "_pytest.terminal.TerminalReporter.__init__",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def __init__(self, config: Config, file=None) -> None:\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None  # type: Optional[Session]\n        self._showfspath = None\n\n        self.stats = {}  # type: Dict[str, List[Any]]\n        self._main_color = None  # type: Optional[str]\n        self._known_types = None  # type: Optional[List]\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None  # type: Any\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()  # type: Set[str]\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None  # type: Optional[float]",
              "start_line": 262,
              "start_column": 7491,
              "end_line": 4,
              "end_column": 8496,
              "start_byte": 7491,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.writer",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@property\n    def writer(self) -> TerminalWriter:\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        return self._tw",
              "start_line": 286,
              "start_column": 8502,
              "end_line": 4,
              "end_column": 8634,
              "start_byte": 8502,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.writer",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@writer.setter\n    def writer(self, value: TerminalWriter):\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        self._tw = value",
              "start_line": 291,
              "start_column": 8640,
              "end_line": 4,
              "end_column": 8783,
              "start_byte": 8640,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._determine_show_progress_info",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False",
              "start_line": 296,
              "start_column": 8789,
              "end_line": 4,
              "end_column": 9372,
              "start_byte": 8789,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.verbosity",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@property\n    def verbosity(self):\n        return self.config.option.verbose",
              "start_line": 309,
              "start_column": 9378,
              "end_line": 4,
              "end_column": 9454,
              "start_byte": 9378,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.showheader",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@property\n    def showheader(self):\n        return self.verbosity >= 0",
              "start_line": 313,
              "start_column": 9460,
              "end_line": 4,
              "end_column": 9530,
              "start_byte": 9460,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.showfspath",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0\n        return self._showfspath",
              "start_line": 317,
              "start_column": 9536,
              "end_line": 4,
              "end_column": 9679,
              "start_byte": 9536,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.showfspath",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value",
              "start_line": 323,
              "start_column": 9685,
              "end_line": 4,
              "end_column": 9769,
              "start_byte": 9685,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.showlongtestinfo",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@property\n    def showlongtestinfo(self):\n        return self.verbosity > 0",
              "start_line": 327,
              "start_column": 9775,
              "end_line": 4,
              "end_column": 9850,
              "start_byte": 9775,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.hasopt",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars",
              "start_line": 331,
              "start_column": 9856,
              "end_line": 4,
              "end_column": 9983,
              "start_byte": 9856,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.write_fspath_result",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, flush=True, **markup)",
              "start_line": 335,
              "start_column": 9989,
              "end_line": 4,
              "end_column": 10686,
              "start_byte": 9989,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.write_ensure_prefix",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2",
              "start_line": 348,
              "start_column": 10692,
              "end_line": 4,
              "end_column": 10992,
              "start_byte": 10692,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.ensure_newline",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None",
              "start_line": 357,
              "start_column": 10998,
              "end_line": 4,
              "end_column": 11120,
              "start_byte": 10998,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.write",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def write(self, content: str, *, flush: bool = False, **markup: bool) -> None:\n        self._tw.write(content, flush=flush, **markup)",
              "start_line": 362,
              "start_column": 11126,
              "end_line": 4,
              "end_column": 11259,
              "start_byte": 11126,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.flush",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def flush(self) -> None:\n        self._tw.flush()",
              "start_line": 365,
              "start_column": 11265,
              "end_line": 4,
              "end_column": 11314,
              "start_byte": 11265,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.write_line",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)",
              "start_line": 368,
              "start_column": 11320,
              "end_line": 4,
              "end_column": 11510,
              "start_byte": 11320,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.rewrite",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)",
              "start_line": 374,
              "start_column": 11516,
              "end_line": 4,
              "end_column": 12134,
              "start_byte": 11516,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.write_sep",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)",
              "start_line": 392,
              "start_column": 12140,
              "end_line": 4,
              "end_column": 12260,
              "start_byte": 12140,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.section",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)",
              "start_line": 396,
              "start_column": 12266,
              "end_line": 4,
              "end_column": 12345,
              "start_byte": 12266,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.line",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def line(self, msg, **kw):\n        self._tw.line(msg, **kw)",
              "start_line": 399,
              "start_column": 12351,
              "end_line": 4,
              "end_column": 12410,
              "start_byte": 12351,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._add_stats",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _add_stats(self, category: str, items: List) -> None:\n        set_main_color = category not in self.stats\n        self.stats.setdefault(category, []).extend(items[:])\n        if set_main_color:\n            self._set_main_color()",
              "start_line": 402,
              "start_column": 12416,
              "end_line": 4,
              "end_column": 12648,
              "start_byte": 12416,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_internalerror",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1",
              "start_line": 408,
              "start_column": 12654,
              "end_line": 4,
              "end_column": 12811,
              "start_byte": 12654,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_warning_captured",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        self._add_stats(\"warnings\", [warning_report])",
              "start_line": 413,
              "start_column": 12817,
              "end_line": 4,
              "end_column": 13350,
              "start_byte": 12817,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_plugin_registered",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)",
              "start_line": 426,
              "start_column": 13356,
              "end_line": 4,
              "end_column": 13731,
              "start_byte": 13356,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_deselected",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_deselected(self, items):\n        self._add_stats(\"deselected\", items)",
              "start_line": 434,
              "start_column": 13737,
              "end_line": 4,
              "end_column": 13817,
              "start_byte": 13737,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logstart",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n            self.flush()\n        elif self.showfspath:\n            self.write_fspath_result(nodeid, \"\")\n            self.flush()",
              "start_line": 437,
              "start_column": 13823,
              "end_line": 4,
              "end_column": 14241,
              "start_byte": 13823,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logreport",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_runtest_logreport(self, report: TestReport) -> None:\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self._add_stats(category, [rep])\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2\n        self.flush()",
              "start_line": 448,
              "start_column": 14247,
              "end_line": 4,
              "end_column": 16159,
              "start_byte": 14247,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._is_last_item",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@property\n    def _is_last_item(self):\n        return len(self._progress_nodeids_reported) == self._session.testscollected",
              "start_line": 497,
              "start_column": 16165,
              "end_line": 4,
              "end_column": 16287,
              "start_byte": 16165,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logfinish",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_runtest_logfinish(self, nodeid):\n        assert self._session\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n\n            if self._is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                main_color, _ = self._get_main_color()\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", **{main_color: True})",
              "start_line": 501,
              "start_column": 16293,
              "end_line": 4,
              "end_column": 17210,
              "start_byte": 16293,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._get_progress_information_message",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _get_progress_information_message(self) -> str:\n        assert self._session\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                return \" [{:3d}%]\".format(\n                    len(self._progress_nodeids_reported) * 100 // collected\n                )\n            return \" [100%]\"",
              "start_line": 522,
              "start_column": 17216,
              "end_line": 4,
              "end_column": 17957,
              "start_byte": 17216,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._write_progress_information_filling_space",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _write_progress_information_filling_space(self):\n        color, _ = self._get_main_color()\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), flush=True, **{color: True})",
              "start_line": 539,
              "start_column": 17963,
              "end_line": 4,
              "end_column": 18259,
              "start_byte": 17963,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._width_of_current_line",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        return self._tw.width_of_current_line",
              "start_line": 546,
              "start_column": 18265,
              "end_line": 4,
              "end_column": 18465,
              "start_byte": 18265,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_collection",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_collection(self) -> None:\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", flush=True, bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", flush=True, bold=True)",
              "start_line": 551,
              "start_column": 18471,
              "end_line": 4,
              "end_column": 18821,
              "start_byte": 18471,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_collectreport",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_collectreport(self, report: CollectReport) -> None:\n        if report.failed:\n            self._add_stats(\"error\", [report])\n        elif report.skipped:\n            self._add_stats(\"skipped\", [report])\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()",
              "start_line": 559,
              "start_column": 18827,
              "end_line": 4,
              "end_column": 19212,
              "start_byte": 18827,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.report_collect",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d error%s\" % (errors, \"s\" if errors != 1 else \"\")\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)",
              "start_line": 569,
              "start_column": 19218,
              "end_line": 4,
              "end_column": 20633,
              "start_byte": 19218,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_sessionstart",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session: Session) -> None:\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n        if pypy_version_info:\n            verinfo = \".\".join(map(str, pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)",
              "start_line": 609,
              "start_column": 20639,
              "end_line": 4,
              "end_column": 21805,
              "start_byte": 20639,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._write_report_lines_from_hooks",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)",
              "start_line": 637,
              "start_column": 21811,
              "end_line": 4,
              "end_column": 21954,
              "start_byte": 21811,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_report_header",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result",
              "start_line": 642,
              "start_column": 21960,
              "end_line": 4,
              "end_column": 22615,
              "start_byte": 21960,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_collection_finish",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if session.items:\n                if self.config.option.verbose > -1:\n                    self._tw.line(\"\")\n                self._printcollecteditems(session.items)\n\n            failed = self.stats.get(\"failed\")\n            if failed:\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in failed:\n                    rep.toterminal(self._tw)",
              "start_line": 659,
              "start_column": 22621,
              "end_line": 4,
              "end_column": 23336,
              "start_byte": 22621,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._printcollecteditems",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}  # type: Dict[str, int]\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    try:\n                        obj = col.obj  # type: ignore\n                    except AttributeError:\n                        continue\n                    doc = inspect.getdoc(obj)\n                    if doc:\n                        for line in doc.splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line))",
              "start_line": 679,
              "start_column": 23342,
              "end_line": 4,
              "end_column": 25064,
              "start_byte": 23342,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_sessionfinish",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, session: Session, exitstatus: ExitCode):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if session.shouldfail:\n            self.write_sep(\"!\", session.shouldfail, red=True)\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        elif session.shouldstop:\n            self.write_sep(\"!\", session.shouldstop, red=True)\n        self.summary_stats()",
              "start_line": 719,
              "start_column": 25070,
              "end_line": 4,
              "end_column": 26017,
              "start_byte": 25070,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_terminal_summary",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()",
              "start_line": 744,
              "start_column": 26023,
              "end_line": 4,
              "end_column": 26366,
              "start_byte": 26023,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_keyboard_interrupt",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)",
              "start_line": 755,
              "start_column": 26372,
              "end_line": 4,
              "end_column": 26487,
              "start_byte": 26372,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.pytest_unconfigure",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()",
              "start_line": 758,
              "start_column": 26493,
              "end_line": 4,
              "end_column": 26620,
              "start_byte": 26493,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._report_keyboardinterrupt",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )",
              "start_line": 762,
              "start_column": 26626,
              "end_line": 4,
              "end_column": 27154,
              "start_byte": 26626,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._getfailureheadline",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?",
              "start_line": 798,
              "start_column": 27988,
              "end_line": 4,
              "end_column": 28146,
              "start_byte": 27988,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._getcrashline",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"",
              "start_line": 804,
              "start_column": 28152,
              "end_line": 4,
              "end_column": 28396,
              "start_byte": 28152,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.getreports",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values",
              "start_line": 816,
              "start_column": 28448,
              "end_line": 4,
              "end_column": 28637,
              "start_byte": 28448,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.summary_warnings",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\n                \"warnings\"\n            )  # type: Optional[List[WarningReport]]\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = (\n                order_preserving_dict()\n            )  # type: Dict[str, List[WarningReport]]\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            def collapsed_location_report(reports: List[WarningReport]):\n                locations = []\n                for w in reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        locations.append(location)\n\n                if len(locations) < 10:\n                    return \"\\n\".join(map(str, locations))\n\n                counts_by_filename = order_preserving_dict()  # type: Dict[str, int]\n                for loc in locations:\n                    key = str(loc).split(\"::\", 1)[0]\n                    counts_by_filename[key] = counts_by_filename.get(key, 0) + 1\n                return \"\\n\".join(\n                    \"{}: {} warning{}\".format(k, v, \"s\" if v > 1 else \"\")\n                    for k, v in counts_by_filename.items()\n                )\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, message_reports in reports_grouped_by_message.items():\n                maybe_location = collapsed_location_report(message_reports)\n                if maybe_location:\n                    self._tw.line(maybe_location)\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")",
              "start_line": 823,
              "start_column": 28643,
              "end_line": 4,
              "end_column": 31098,
              "start_byte": 28643,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.summary_passes",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)",
              "start_line": 880,
              "start_column": 31104,
              "end_line": 4,
              "end_column": 31684,
              "start_byte": 31104,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._get_teardown_reports",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _get_teardown_reports(self, nodeid: str) -> List[TestReport]:\n        return [\n            report\n            for report in self.getreports(\"\")\n            if report.when == \"teardown\" and report.nodeid == nodeid\n        ]",
              "start_line": 894,
              "start_column": 31690,
              "end_line": 4,
              "end_column": 31916,
              "start_byte": 31690,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._handle_teardown_sections",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _handle_teardown_sections(self, nodeid: str) -> None:\n        for report in self._get_teardown_reports(nodeid):\n            self.print_teardown_sections(report)",
              "start_line": 901,
              "start_column": 31922,
              "end_line": 4,
              "end_column": 32086,
              "start_byte": 31922,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.print_teardown_sections",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def print_teardown_sections(self, rep: TestReport) -> None:\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)",
              "start_line": 905,
              "start_column": 32092,
              "end_line": 4,
              "end_column": 32598,
              "start_byte": 32092,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.summary_failures",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)",
              "start_line": 918,
              "start_column": 32604,
              "end_line": 4,
              "end_column": 33288,
              "start_byte": 32604,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.summary_errors",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)",
              "start_line": 935,
              "start_column": 33294,
              "end_line": 4,
              "end_column": 33890,
              "start_byte": 33294,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._outrep_summary",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)",
              "start_line": 950,
              "start_column": 33896,
              "end_line": 4,
              "end_column": 34353,
              "start_byte": 33896,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.summary_stats",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def summary_stats(self):\n        if self.verbosity < -1:\n            return\n\n        session_duration = time.time() - self._sessionstarttime\n        (parts, main_color) = self.build_summary_stats_line()\n        line_parts = []\n\n        display_sep = self.verbosity >= 0\n        if display_sep:\n            fullwidth = self._tw.fullwidth\n        for text, markup in parts:\n            with_markup = self._tw.markup(text, **markup)\n            if display_sep:\n                fullwidth += len(with_markup) - len(text)\n            line_parts.append(with_markup)\n        msg = \", \".join(line_parts)\n\n        main_markup = {main_color: True}\n        duration = \" in {}\".format(format_session_duration(session_duration))\n        duration_with_markup = self._tw.markup(duration, **main_markup)\n        if display_sep:\n            fullwidth += len(duration_with_markup) - len(duration)\n        msg += duration_with_markup\n\n        if display_sep:\n            markup_for_end_sep = self._tw.markup(\"\", **main_markup)\n            if markup_for_end_sep.endswith(\"\\x1b[0m\"):\n                markup_for_end_sep = markup_for_end_sep[:-4]\n            fullwidth += len(markup_for_end_sep)\n            msg += markup_for_end_sep\n\n        if display_sep:\n            self.write_sep(\"=\", msg, fullwidth=fullwidth, **main_markup)\n        else:\n            self.write_line(msg, **main_markup)",
              "start_line": 963,
              "start_column": 34359,
              "end_line": 4,
              "end_column": 35728,
              "start_byte": 34359,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.short_test_summary",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def short_test_summary(self) -> None:\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines: List[str]) -> None:\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self._tw.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines: List[str]) -> None:\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines: List[str]) -> None:\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines: List[str]) -> None:\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(self.startdir, skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }  # type: Mapping[str, Callable[[List[str]], None]]\n\n        lines = []  # type: List[str]\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:\n                self.write_line(line)",
              "start_line": 1000,
              "start_column": 35734,
              "end_line": 4,
              "end_column": 38473,
              "start_byte": 35734,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._get_main_color",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _get_main_color(self) -> Tuple[str, List[str]]:\n        if self._main_color is None or self._known_types is None or self._is_last_item:\n            self._set_main_color()\n            assert self._main_color\n            assert self._known_types\n        return self._main_color, self._known_types",
              "start_line": 1069,
              "start_column": 38479,
              "end_line": 4,
              "end_column": 38777,
              "start_byte": 38479,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._determine_main_color",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _determine_main_color(self, unknown_type_seen: bool) -> str:\n        stats = self.stats\n        if \"failed\" in stats or \"error\" in stats:\n            main_color = \"red\"\n        elif \"warnings\" in stats or \"xpassed\" in stats or unknown_type_seen:\n            main_color = \"yellow\"\n        elif \"passed\" in stats or not self._is_last_item:\n            main_color = \"green\"\n        else:\n            main_color = \"yellow\"\n        return main_color",
              "start_line": 1076,
              "start_column": 38783,
              "end_line": 4,
              "end_column": 39231,
              "start_byte": 38783,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter._set_main_color",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _set_main_color(self) -> None:\n        unknown_types = []  # type: List[str]\n        for found_type in self.stats.keys():\n            if found_type:  # setup/teardown reports have an empty key, ignore them\n                if found_type not in KNOWN_TYPES and found_type not in unknown_types:\n                    unknown_types.append(found_type)\n        self._known_types = list(KNOWN_TYPES) + unknown_types\n        self._main_color = self._determine_main_color(bool(unknown_types))",
              "start_line": 1088,
              "start_column": 39237,
              "end_line": 4,
              "end_column": 39722,
              "start_byte": 39237,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.TerminalReporter.build_summary_stats_line",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def build_summary_stats_line(self) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:\n        main_color, known_types = self._get_main_color()\n\n        parts = []\n        for key in known_types:\n            reports = self.stats.get(key, None)\n            if reports:\n                count = sum(\n                    1 for rep in reports if getattr(rep, \"count_towards_summary\", True)\n                )\n                color = _color_for_type.get(key, _color_for_type_default)\n                markup = {color: True, \"bold\": color == main_color}\n                parts.append((\"%d %s\" % _make_plural(count, key), markup))\n\n        if not parts:\n            parts = [(\"no tests ran\", {_color_for_type_default: True})]\n\n        return parts, main_color",
              "start_line": 1097,
              "start_column": 39728,
              "end_line": 4,
              "end_column": 40474,
              "start_byte": 39728,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "class Config:\n    \"\"\"\n    Access to configuration values, pluginmanager and plugin hooks.\n\n    :param PytestPluginManager pluginmanager:\n\n    :param InvocationParams invocation_params:\n        Object containing the parameters regarding the ``pytest.main``\n        invocation.\n    \"\"\"\n\n    @attr.s(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during ``pytest.main()``\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args = attr.ib(converter=tuple)\n        \"\"\"tuple of command-line arguments as passed to ``pytest.main()``.\"\"\"\n        plugins = attr.ib()\n        \"\"\"list of extra plugins, might be `None`.\"\"\"\n        dir = attr.ib(type=Path)\n        \"\"\"directory where ``pytest.main()`` was invoked from.\"\"\"\n\n    def __init__(\n        self,\n        pluginmanager: PytestPluginManager,\n        *,\n        invocation_params: Optional[InvocationParams] = None\n    ) -> None:\n        from .argparsing import Parser, FILE_OR_DIR\n\n        if invocation_params is None:\n            invocation_params = self.InvocationParams(\n                args=(), plugins=None, dir=Path().resolve()\n            )\n\n        self.option = argparse.Namespace()\n        \"\"\"access to command line option as attributes.\n\n          :type: argparse.Namespace\"\"\"\n\n        self.invocation_params = invocation_params\n\n        _a = FILE_OR_DIR\n        self._parser = Parser(\n            usage=\"%(prog)s [options] [{}] [{}] [...]\".format(_a, _a),\n            processopt=self._processopt,\n        )\n        self.pluginmanager = pluginmanager\n        \"\"\"the plugin manager handles plugin registration and hook invocation.\n\n          :type: PytestPluginManager\"\"\"\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook = self.pluginmanager.hook\n        self._inicache = {}  # type: Dict[str, Any]\n        self._override_ini = ()  # type: Sequence[str]\n        self._opt2dest = {}  # type: Dict[str, str]\n        self._cleanup = []  # type: List[Callable[[], None]]\n        # A place where plugins can store information on the config for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n\n        if TYPE_CHECKING:\n            from _pytest.cacheprovider import Cache\n\n            self.cache = None  # type: Optional[Cache]\n\n    @property\n    def invocation_dir(self):\n        \"\"\"Backward compatibility\"\"\"\n        return py.path.local(str(self.invocation_params.dir))\n\n    def add_cleanup(self, func):\n        \"\"\" Add a function to be called when the config object gets out of\n        use (usually coninciding with pytest_unconfigure).\"\"\"\n        self._cleanup.append(func)\n\n    def _do_configure(self):\n        assert not self._configured\n        self._configured = True\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"default\")\n            self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\n\n    def _ensure_unconfigure(self):\n        if self._configured:\n            self._configured = False\n            self.hook.pytest_unconfigure(config=self)\n            self.hook.pytest_configure._call_history = []\n        while self._cleanup:\n            fin = self._cleanup.pop()\n            fin()\n\n    def get_terminal_writer(self):\n        return self.pluginmanager.get_plugin(\"terminalreporter\")._tw\n\n    def pytest_cmdline_parse(self, pluginmanager, args):\n        try:\n            self.parse(args)\n        except UsageError:\n\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"version\", False) or \"--version\" in args:\n                from _pytest.helpconfig import showversion\n\n                showversion(self)\n            elif (\n                getattr(self.option, \"help\", False) or \"--help\" in args or \"-h\" in args\n            ):\n                self._parser._getparser().print_help()\n                sys.stdout.write(\n                    \"\\nNOTE: displaying only minimal help due to UsageError.\\n\\n\"\n                )\n\n            raise\n\n        return self\n\n    def notify_exception(self, excinfo, option=None):\n        if option and getattr(option, \"fulltrace\", False):\n            style = \"long\"\n        else:\n            style = \"native\"\n        excrepr = excinfo.getrepr(\n            funcargs=True, showlocals=getattr(option, \"showlocals\", False), style=style\n        )\n        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\n        if not any(res):\n            for line in str(excrepr).split(\"\\n\"):\n                sys.stderr.write(\"INTERNALERROR> %s\\n\" % line)\n                sys.stderr.flush()\n\n    def cwd_relative_nodeid(self, nodeid):\n        # nodeid's are relative to the rootpath, compute relative to cwd\n        if self.invocation_dir != self.rootdir:\n            fullpath = self.rootdir.join(nodeid)\n            nodeid = self.invocation_dir.bestrelpath(fullpath)\n        return nodeid\n\n    @classmethod\n    def fromdictargs(cls, option_dict, args):\n        \"\"\" constructor usable for subprocesses. \"\"\"\n        config = get_config(args)\n        config.option.__dict__.update(option_dict)\n        config.parse(args, addopts=False)\n        for x in config.option.plugins:\n            config.pluginmanager.consider_pluginarg(x)\n        return config\n\n    def _processopt(self, opt: \"Argument\") -> None:\n        for name in opt._short_opts + opt._long_opts:\n            self._opt2dest[name] = opt.dest\n\n        if hasattr(opt, \"default\"):\n            if not hasattr(self.option, opt.dest):\n                setattr(self.option, opt.dest, opt.default)\n\n    @hookimpl(trylast=True)\n    def pytest_load_initial_conftests(self, early_config):\n        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)\n\n    def _initini(self, args: Sequence[str]) -> None:\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(\n            args, namespace=copy.copy(self.option)\n        )\n        r = determine_setup(\n            ns.inifilename,\n            ns.file_or_dir + unknown_args,\n            rootdir_cmd_arg=ns.rootdir or None,\n            config=self,\n        )\n        self.rootdir, self.inifile, self.inicfg = r\n        self._parser.extra_info[\"rootdir\"] = self.rootdir\n        self._parser.extra_info[\"inifile\"] = self.inifile\n        self._parser.addini(\"addopts\", \"extra command line options\", \"args\")\n        self._parser.addini(\"minversion\", \"minimally required pytest version\")\n        self._override_ini = ns.override_ini or ()\n\n    def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook)\n        _warn_about_missing_assertion(mode)\n\n    def _mark_plugins_for_rewrite(self, hook):\n        \"\"\"\n        Given an importhook, mark for rewrite any top-level\n        modules or packages in the distribution package for\n        all pytest plugins.\n        \"\"\"\n        self.pluginmanager.rewrite_hook = hook\n\n        if os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # We don't autoload from setuptools entry points, no need to continue.\n            return\n\n        package_files = (\n            str(file)\n            for dist in importlib_metadata.distributions()\n            if any(ep.group == \"pytest11\" for ep in dist.entry_points)\n            for file in dist.files or []\n        )\n\n        for name in _iter_rewritable_modules(package_files):\n            hook.mark_rewrite(name)\n\n    def _validate_args(self, args: List[str], via: str) -> List[str]:\n        \"\"\"Validate known args.\"\"\"\n        self._parser._config_source_hint = via  # type: ignore\n        try:\n            self._parser.parse_known_and_unknown_args(\n                args, namespace=copy.copy(self.option)\n            )\n        finally:\n            del self._parser._config_source_hint  # type: ignore\n\n        return args\n\n    def _preparse(self, args: List[str], addopts: bool = True) -> None:\n        if addopts:\n            env_addopts = os.environ.get(\"PYTEST_ADDOPTS\", \"\")\n            if len(env_addopts):\n                args[:] = (\n                    self._validate_args(shlex.split(env_addopts), \"via PYTEST_ADDOPTS\")\n                    + args\n                )\n        self._initini(args)\n        if addopts:\n            args[:] = (\n                self._validate_args(self.getini(\"addopts\"), \"via addopts config\") + args\n            )\n\n        self._checkversion()\n        self._consider_importhook(args)\n        self.pluginmanager.consider_preparse(args, exclude_only=False)\n        if not os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # Don't autoload from setuptools entry point. Only explicitly specified\n            # plugins are going to be loaded.\n            self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\n        self.pluginmanager.consider_env()\n        self.known_args_namespace = ns = self._parser.parse_known_args(\n            args, namespace=copy.copy(self.option)\n        )\n        if self.known_args_namespace.confcutdir is None and self.inifile:\n            confcutdir = py.path.local(self.inifile).dirname\n            self.known_args_namespace.confcutdir = confcutdir\n        try:\n            self.hook.pytest_load_initial_conftests(\n                early_config=self, args=args, parser=self._parser\n            )\n        except ConftestImportFailure as e:\n            if ns.help or ns.version:\n                # we don't want to prevent --help/--version to work\n                # so just let is pass and print a warning at the end\n                from _pytest.warnings import _issue_warning_captured\n\n                _issue_warning_captured(\n                    PytestConfigWarning(\n                        \"could not load initial conftests: {}\".format(e.path)\n                    ),\n                    self.hook,\n                    stacklevel=2,\n                )\n            else:\n                raise\n\n    def _checkversion(self):\n        import pytest\n\n        minver = self.inicfg.get(\"minversion\", None)\n        if minver:\n            # Imported lazily to improve start-up time.\n            from packaging.version import Version\n\n            if Version(minver) > Version(pytest.__version__):\n                raise pytest.UsageError(\n                    \"%s:%d: requires pytest-%s, actual pytest-%s'\"\n                    % (\n                        self.inicfg.config.path,\n                        self.inicfg.lineof(\"minversion\"),\n                        minver,\n                        pytest.__version__,\n                    )\n                )\n\n    def parse(self, args: List[str], addopts: bool = True) -> None:\n        # parse given cmdline arguments into this config object.\n        assert not hasattr(\n            self, \"args\"\n        ), \"can only parse cmdline args at most once per Config object\"\n        self.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=self.pluginmanager)\n        )\n        self._preparse(args, addopts=addopts)\n        # XXX deprecated hook:\n        self.hook.pytest_cmdline_preparse(config=self, args=args)\n        self._parser.after_preparse = True  # type: ignore\n        try:\n            args = self._parser.parse_setoption(\n                args, self.option, namespace=self.option\n            )\n            if not args:\n                if self.invocation_dir == self.rootdir:\n                    args = self.getini(\"testpaths\")\n                if not args:\n                    args = [str(self.invocation_dir)]\n            self.args = args\n        except PrintHelp:\n            pass\n\n    def addinivalue_line(self, name, line):\n        \"\"\" add a line to an ini-file option. The option must have been\n        declared but might not yet be set in which case the line becomes the\n        the first line in its value. \"\"\"\n        x = self.getini(name)\n        assert isinstance(x, list)\n        x.append(line)  # modifies the cached list inline\n\n    def getini(self, name: str):\n        \"\"\" return configuration value from an :ref:`ini file <inifiles>`. If the\n        specified name hasn't been registered through a prior\n        :py:func:`parser.addini <_pytest.config.argparsing.Parser.addini>`\n        call (usually from a plugin), a ValueError is raised. \"\"\"\n        try:\n            return self._inicache[name]\n        except KeyError:\n            self._inicache[name] = val = self._getini(name)\n            return val\n\n    def _getini(self, name: str) -> Any:\n        try:\n            description, type, default = self._parser._inidict[name]\n        except KeyError:\n            raise ValueError(\"unknown configuration value: {!r}\".format(name))\n        value = self._get_override_ini_value(name)\n        if value is None:\n            try:\n                value = self.inicfg[name]\n            except KeyError:\n                if default is not None:\n                    return default\n                if type is None:\n                    return \"\"\n                return []\n        if type == \"pathlist\":\n            dp = py.path.local(self.inicfg.config.path).dirpath()\n            values = []\n            for relpath in shlex.split(value):\n                values.append(dp.join(relpath, abs=True))\n            return values\n        elif type == \"args\":\n            return shlex.split(value)\n        elif type == \"linelist\":\n            return [t for t in map(lambda x: x.strip(), value.split(\"\\n\")) if t]\n        elif type == \"bool\":\n            return bool(_strtobool(value.strip()))\n        else:\n            assert type is None\n            return value\n\n    def _getconftest_pathlist(self, name, path):\n        try:\n            mod, relroots = self.pluginmanager._rget_with_confmod(name, path)\n        except KeyError:\n            return None\n        modpath = py.path.local(mod.__file__).dirpath()\n        values = []\n        for relroot in relroots:\n            if not isinstance(relroot, py.path.local):\n                relroot = relroot.replace(\"/\", py.path.local.sep)\n                relroot = modpath.join(relroot, abs=True)\n            values.append(relroot)\n        return values\n\n    def _get_override_ini_value(self, name: str) -> Optional[str]:\n        value = None\n        # override_ini is a list of \"ini=value\" options\n        # always use the last item if multiple values are set for same ini-name,\n        # e.g. -o foo=bar1 -o foo=bar2 will set foo to bar2\n        for ini_config in self._override_ini:\n            try:\n                key, user_ini_value = ini_config.split(\"=\", 1)\n            except ValueError:\n                raise UsageError(\n                    \"-o/--override-ini expects option=value style (got: {!r}).\".format(\n                        ini_config\n                    )\n                )\n            else:\n                if key == name:\n                    value = user_ini_value\n        return value\n\n    def getoption(self, name: str, default=notset, skip: bool = False):\n        \"\"\" return command line option value.\n\n        :arg name: name of the option.  You may also specify\n            the literal ``--OPT`` option instead of the \"dest\" option name.\n        :arg default: default value if no option of that name exists.\n        :arg skip: if True raise pytest.skip if option does not exists\n            or has a None value.\n        \"\"\"\n        name = self._opt2dest.get(name, name)\n        try:\n            val = getattr(self.option, name)\n            if val is None and skip:\n                raise AttributeError(name)\n            return val\n        except AttributeError:\n            if default is not notset:\n                return default\n            if skip:\n                import pytest\n\n                pytest.skip(\"no {!r} option found\".format(name))\n            raise ValueError(\"no option named {!r}\".format(name))\n\n    def getvalue(self, name, path=None):\n        \"\"\" (deprecated, use getoption()) \"\"\"\n        return self.getoption(name)\n\n    def getvalueorskip(self, name, path=None):\n        \"\"\" (deprecated, use getoption(skip=True)) \"\"\"\n        return self.getoption(name, skip=True)",
              "start_line": 756,
              "start_column": 25530,
              "end_line": 0,
              "end_column": 42793,
              "start_byte": 25530,
              "end_byte": 0
            },
            {
              "name": "_pytest.config.Config.InvocationParams",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "@attr.s(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during ``pytest.main()``\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args = attr.ib(converter=tuple)\n        \"\"\"tuple of command-line arguments as passed to ``pytest.main()``.\"\"\"\n        plugins = attr.ib()\n        \"\"\"list of extra plugins, might be `None`.\"\"\"\n        dir = attr.ib(type=Path)\n        \"\"\"directory where ``pytest.main()`` was invoked from.\"\"\"",
              "start_line": 767,
              "start_column": 25819,
              "end_line": 4,
              "end_column": 26589,
              "start_byte": 25819,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.InvocationParams.args",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "args = attr.ib(converter=tuple)",
              "start_line": 783,
              "start_column": 26299,
              "end_line": 8,
              "end_column": 26330,
              "start_byte": 26299,
              "end_byte": 8
            },
            {
              "name": "_pytest.config.Config.InvocationParams.plugins",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "plugins = attr.ib()",
              "start_line": 785,
              "start_column": 26417,
              "end_line": 8,
              "end_column": 26436,
              "start_byte": 26417,
              "end_byte": 8
            },
            {
              "name": "_pytest.config.Config.InvocationParams.dir",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "dir = attr.ib(type=Path)",
              "start_line": 787,
              "start_column": 26499,
              "end_line": 8,
              "end_column": 26523,
              "start_byte": 26499,
              "end_byte": 8
            },
            {
              "name": "_pytest.config.Config.__init__",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def __init__(\n        self,\n        pluginmanager: PytestPluginManager,\n        *,\n        invocation_params: Optional[InvocationParams] = None\n    ) -> None:\n        from .argparsing import Parser, FILE_OR_DIR\n\n        if invocation_params is None:\n            invocation_params = self.InvocationParams(\n                args=(), plugins=None, dir=Path().resolve()\n            )\n\n        self.option = argparse.Namespace()\n        \"\"\"access to command line option as attributes.\n\n          :type: argparse.Namespace\"\"\"\n\n        self.invocation_params = invocation_params\n\n        _a = FILE_OR_DIR\n        self._parser = Parser(\n            usage=\"%(prog)s [options] [{}] [{}] [...]\".format(_a, _a),\n            processopt=self._processopt,\n        )\n        self.pluginmanager = pluginmanager\n        \"\"\"the plugin manager handles plugin registration and hook invocation.\n\n          :type: PytestPluginManager\"\"\"\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook = self.pluginmanager.hook\n        self._inicache = {}  # type: Dict[str, Any]\n        self._override_ini = ()  # type: Sequence[str]\n        self._opt2dest = {}  # type: Dict[str, str]\n        self._cleanup = []  # type: List[Callable[[], None]]\n        # A place where plugins can store information on the config for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n\n        if TYPE_CHECKING:\n            from _pytest.cacheprovider import Cache\n\n            self.cache = None  # type: Optional[Cache]",
              "start_line": 790,
              "start_column": 26595,
              "end_line": 4,
              "end_column": 28375,
              "start_byte": 26595,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.invocation_dir",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "@property\n    def invocation_dir(self):\n        \"\"\"Backward compatibility\"\"\"\n        return py.path.local(str(self.invocation_params.dir))",
              "start_line": 840,
              "start_column": 28381,
              "end_line": 4,
              "end_column": 28519,
              "start_byte": 28381,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.add_cleanup",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def add_cleanup(self, func):\n        \"\"\" Add a function to be called when the config object gets out of\n        use (usually coninciding with pytest_unconfigure).\"\"\"\n        self._cleanup.append(func)",
              "start_line": 845,
              "start_column": 28525,
              "end_line": 4,
              "end_column": 28725,
              "start_byte": 28525,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._do_configure",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _do_configure(self):\n        assert not self._configured\n        self._configured = True\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"default\")\n            self.hook.pytest_configure.call_historic(kwargs=dict(config=self))",
              "start_line": 850,
              "start_column": 28731,
              "end_line": 4,
              "end_column": 28987,
              "start_byte": 28731,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._ensure_unconfigure",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _ensure_unconfigure(self):\n        if self._configured:\n            self._configured = False\n            self.hook.pytest_unconfigure(config=self)\n            self.hook.pytest_configure._call_history = []\n        while self._cleanup:\n            fin = self._cleanup.pop()\n            fin()",
              "start_line": 857,
              "start_column": 28993,
              "end_line": 4,
              "end_column": 29286,
              "start_byte": 28993,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.get_terminal_writer",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def get_terminal_writer(self):\n        return self.pluginmanager.get_plugin(\"terminalreporter\")._tw",
              "start_line": 866,
              "start_column": 29292,
              "end_line": 4,
              "end_column": 29391,
              "start_byte": 29292,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.pytest_cmdline_parse",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def pytest_cmdline_parse(self, pluginmanager, args):\n        try:\n            self.parse(args)\n        except UsageError:\n\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"version\", False) or \"--version\" in args:\n                from _pytest.helpconfig import showversion\n\n                showversion(self)\n            elif (\n                getattr(self.option, \"help\", False) or \"--help\" in args or \"-h\" in args\n            ):\n                self._parser._getparser().print_help()\n                sys.stdout.write(\n                    \"\\nNOTE: displaying only minimal help due to UsageError.\\n\\n\"\n                )\n\n            raise\n\n        return self",
              "start_line": 869,
              "start_column": 29397,
              "end_line": 4,
              "end_column": 30240,
              "start_byte": 29397,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.notify_exception",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def notify_exception(self, excinfo, option=None):\n        if option and getattr(option, \"fulltrace\", False):\n            style = \"long\"\n        else:\n            style = \"native\"\n        excrepr = excinfo.getrepr(\n            funcargs=True, showlocals=getattr(option, \"showlocals\", False), style=style\n        )\n        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\n        if not any(res):\n            for line in str(excrepr).split(\"\\n\"):\n                sys.stderr.write(\"INTERNALERROR> %s\\n\" % line)\n                sys.stderr.flush()",
              "start_line": 893,
              "start_column": 30246,
              "end_line": 4,
              "end_column": 30809,
              "start_byte": 30246,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.cwd_relative_nodeid",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def cwd_relative_nodeid(self, nodeid):\n        # nodeid's are relative to the rootpath, compute relative to cwd\n        if self.invocation_dir != self.rootdir:\n            fullpath = self.rootdir.join(nodeid)\n            nodeid = self.invocation_dir.bestrelpath(fullpath)\n        return nodeid",
              "start_line": 907,
              "start_column": 30815,
              "end_line": 4,
              "end_column": 31108,
              "start_byte": 30815,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.fromdictargs",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "@classmethod\n    def fromdictargs(cls, option_dict, args):\n        \"\"\" constructor usable for subprocesses. \"\"\"\n        config = get_config(args)\n        config.option.__dict__.update(option_dict)\n        config.parse(args, addopts=False)\n        for x in config.option.plugins:\n            config.pluginmanager.consider_pluginarg(x)\n        return config",
              "start_line": 914,
              "start_column": 31114,
              "end_line": 4,
              "end_column": 31469,
              "start_byte": 31114,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._processopt",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _processopt(self, opt: \"Argument\") -> None:\n        for name in opt._short_opts + opt._long_opts:\n            self._opt2dest[name] = opt.dest\n\n        if hasattr(opt, \"default\"):\n            if not hasattr(self.option, opt.dest):\n                setattr(self.option, opt.dest, opt.default)",
              "start_line": 924,
              "start_column": 31475,
              "end_line": 4,
              "end_column": 31768,
              "start_byte": 31475,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.pytest_load_initial_conftests",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "@hookimpl(trylast=True)\n    def pytest_load_initial_conftests(self, early_config):\n        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)",
              "start_line": 932,
              "start_column": 31774,
              "end_line": 4,
              "end_column": 31941,
              "start_byte": 31774,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._initini",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _initini(self, args: Sequence[str]) -> None:\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(\n            args, namespace=copy.copy(self.option)\n        )\n        r = determine_setup(\n            ns.inifilename,\n            ns.file_or_dir + unknown_args,\n            rootdir_cmd_arg=ns.rootdir or None,\n            config=self,\n        )\n        self.rootdir, self.inifile, self.inicfg = r\n        self._parser.extra_info[\"rootdir\"] = self.rootdir\n        self._parser.extra_info[\"inifile\"] = self.inifile\n        self._parser.addini(\"addopts\", \"extra command line options\", \"args\")\n        self._parser.addini(\"minversion\", \"minimally required pytest version\")\n        self._override_ini = ns.override_ini or ()",
              "start_line": 936,
              "start_column": 31947,
              "end_line": 4,
              "end_column": 32684,
              "start_byte": 31947,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._consider_importhook",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook)\n        _warn_about_missing_assertion(mode)",
              "start_line": 953,
              "start_column": 32690,
              "end_line": 4,
              "end_column": 33458,
              "start_byte": 32690,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._mark_plugins_for_rewrite",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _mark_plugins_for_rewrite(self, hook):\n        \"\"\"\n        Given an importhook, mark for rewrite any top-level\n        modules or packages in the distribution package for\n        all pytest plugins.\n        \"\"\"\n        self.pluginmanager.rewrite_hook = hook\n\n        if os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # We don't autoload from setuptools entry points, no need to continue.\n            return\n\n        package_files = (\n            str(file)\n            for dist in importlib_metadata.distributions()\n            if any(ep.group == \"pytest11\" for ep in dist.entry_points)\n            for file in dist.files or []\n        )\n\n        for name in _iter_rewritable_modules(package_files):\n            hook.mark_rewrite(name)",
              "start_line": 973,
              "start_column": 33464,
              "end_line": 4,
              "end_column": 34217,
              "start_byte": 33464,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._validate_args",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _validate_args(self, args: List[str], via: str) -> List[str]:\n        \"\"\"Validate known args.\"\"\"\n        self._parser._config_source_hint = via  # type: ignore\n        try:\n            self._parser.parse_known_and_unknown_args(\n                args, namespace=copy.copy(self.option)\n            )\n        finally:\n            del self._parser._config_source_hint  # type: ignore\n\n        return args",
              "start_line": 995,
              "start_column": 34223,
              "end_line": 4,
              "end_column": 34626,
              "start_byte": 34223,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._preparse",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _preparse(self, args: List[str], addopts: bool = True) -> None:\n        if addopts:\n            env_addopts = os.environ.get(\"PYTEST_ADDOPTS\", \"\")\n            if len(env_addopts):\n                args[:] = (\n                    self._validate_args(shlex.split(env_addopts), \"via PYTEST_ADDOPTS\")\n                    + args\n                )\n        self._initini(args)\n        if addopts:\n            args[:] = (\n                self._validate_args(self.getini(\"addopts\"), \"via addopts config\") + args\n            )\n\n        self._checkversion()\n        self._consider_importhook(args)\n        self.pluginmanager.consider_preparse(args, exclude_only=False)\n        if not os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # Don't autoload from setuptools entry point. Only explicitly specified\n            # plugins are going to be loaded.\n            self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\n        self.pluginmanager.consider_env()\n        self.known_args_namespace = ns = self._parser.parse_known_args(\n            args, namespace=copy.copy(self.option)\n        )\n        if self.known_args_namespace.confcutdir is None and self.inifile:\n            confcutdir = py.path.local(self.inifile).dirname\n            self.known_args_namespace.confcutdir = confcutdir\n        try:\n            self.hook.pytest_load_initial_conftests(\n                early_config=self, args=args, parser=self._parser\n            )\n        except ConftestImportFailure as e:\n            if ns.help or ns.version:\n                # we don't want to prevent --help/--version to work\n                # so just let is pass and print a warning at the end\n                from _pytest.warnings import _issue_warning_captured\n\n                _issue_warning_captured(\n                    PytestConfigWarning(\n                        \"could not load initial conftests: {}\".format(e.path)\n                    ),\n                    self.hook,\n                    stacklevel=2,\n                )\n            else:\n                raise",
              "start_line": 1007,
              "start_column": 34632,
              "end_line": 4,
              "end_column": 36670,
              "start_byte": 34632,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._checkversion",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _checkversion(self):\n        import pytest\n\n        minver = self.inicfg.get(\"minversion\", None)\n        if minver:\n            # Imported lazily to improve start-up time.\n            from packaging.version import Version\n\n            if Version(minver) > Version(pytest.__version__):\n                raise pytest.UsageError(\n                    \"%s:%d: requires pytest-%s, actual pytest-%s'\"\n                    % (\n                        self.inicfg.config.path,\n                        self.inicfg.lineof(\"minversion\"),\n                        minver,\n                        pytest.__version__,\n                    )\n                )",
              "start_line": 1055,
              "start_column": 36676,
              "end_line": 4,
              "end_column": 37319,
              "start_byte": 36676,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.parse",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def parse(self, args: List[str], addopts: bool = True) -> None:\n        # parse given cmdline arguments into this config object.\n        assert not hasattr(\n            self, \"args\"\n        ), \"can only parse cmdline args at most once per Config object\"\n        self.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=self.pluginmanager)\n        )\n        self._preparse(args, addopts=addopts)\n        # XXX deprecated hook:\n        self.hook.pytest_cmdline_preparse(config=self, args=args)\n        self._parser.after_preparse = True  # type: ignore\n        try:\n            args = self._parser.parse_setoption(\n                args, self.option, namespace=self.option\n            )\n            if not args:\n                if self.invocation_dir == self.rootdir:\n                    args = self.getini(\"testpaths\")\n                if not args:\n                    args = [str(self.invocation_dir)]\n            self.args = args\n        except PrintHelp:\n            pass",
              "start_line": 1074,
              "start_column": 37325,
              "end_line": 4,
              "end_column": 38318,
              "start_byte": 37325,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.addinivalue_line",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def addinivalue_line(self, name, line):\n        \"\"\" add a line to an ini-file option. The option must have been\n        declared but might not yet be set in which case the line becomes the\n        the first line in its value. \"\"\"\n        x = self.getini(name)\n        assert isinstance(x, list)\n        x.append(line)  # modifies the cached list inline",
              "start_line": 1099,
              "start_column": 38324,
              "end_line": 4,
              "end_column": 38676,
              "start_byte": 38324,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.getini",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def getini(self, name: str):\n        \"\"\" return configuration value from an :ref:`ini file <inifiles>`. If the\n        specified name hasn't been registered through a prior\n        :py:func:`parser.addini <_pytest.config.argparsing.Parser.addini>`\n        call (usually from a plugin), a ValueError is raised. \"\"\"\n        try:\n            return self._inicache[name]\n        except KeyError:\n            self._inicache[name] = val = self._getini(name)\n            return val",
              "start_line": 1107,
              "start_column": 38682,
              "end_line": 4,
              "end_column": 39156,
              "start_byte": 38682,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._getini",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _getini(self, name: str) -> Any:\n        try:\n            description, type, default = self._parser._inidict[name]\n        except KeyError:\n            raise ValueError(\"unknown configuration value: {!r}\".format(name))\n        value = self._get_override_ini_value(name)\n        if value is None:\n            try:\n                value = self.inicfg[name]\n            except KeyError:\n                if default is not None:\n                    return default\n                if type is None:\n                    return \"\"\n                return []\n        if type == \"pathlist\":\n            dp = py.path.local(self.inicfg.config.path).dirpath()\n            values = []\n            for relpath in shlex.split(value):\n                values.append(dp.join(relpath, abs=True))\n            return values\n        elif type == \"args\":\n            return shlex.split(value)\n        elif type == \"linelist\":\n            return [t for t in map(lambda x: x.strip(), value.split(\"\\n\")) if t]\n        elif type == \"bool\":\n            return bool(_strtobool(value.strip()))\n        else:\n            assert type is None\n            return value",
              "start_line": 1118,
              "start_column": 39162,
              "end_line": 4,
              "end_column": 40297,
              "start_byte": 39162,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._getconftest_pathlist",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _getconftest_pathlist(self, name, path):\n        try:\n            mod, relroots = self.pluginmanager._rget_with_confmod(name, path)\n        except KeyError:\n            return None\n        modpath = py.path.local(mod.__file__).dirpath()\n        values = []\n        for relroot in relroots:\n            if not isinstance(relroot, py.path.local):\n                relroot = relroot.replace(\"/\", py.path.local.sep)\n                relroot = modpath.join(relroot, abs=True)\n            values.append(relroot)\n        return values",
              "start_line": 1149,
              "start_column": 40303,
              "end_line": 4,
              "end_column": 40832,
              "start_byte": 40303,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config._get_override_ini_value",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def _get_override_ini_value(self, name: str) -> Optional[str]:\n        value = None\n        # override_ini is a list of \"ini=value\" options\n        # always use the last item if multiple values are set for same ini-name,\n        # e.g. -o foo=bar1 -o foo=bar2 will set foo to bar2\n        for ini_config in self._override_ini:\n            try:\n                key, user_ini_value = ini_config.split(\"=\", 1)\n            except ValueError:\n                raise UsageError(\n                    \"-o/--override-ini expects option=value style (got: {!r}).\".format(\n                        ini_config\n                    )\n                )\n            else:\n                if key == name:\n                    value = user_ini_value\n        return value",
              "start_line": 1163,
              "start_column": 40838,
              "end_line": 4,
              "end_column": 41586,
              "start_byte": 40838,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.getoption",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def getoption(self, name: str, default=notset, skip: bool = False):\n        \"\"\" return command line option value.\n\n        :arg name: name of the option.  You may also specify\n            the literal ``--OPT`` option instead of the \"dest\" option name.\n        :arg default: default value if no option of that name exists.\n        :arg skip: if True raise pytest.skip if option does not exists\n            or has a None value.\n        \"\"\"\n        name = self._opt2dest.get(name, name)\n        try:\n            val = getattr(self.option, name)\n            if val is None and skip:\n                raise AttributeError(name)\n            return val\n        except AttributeError:\n            if default is not notset:\n                return default\n            if skip:\n                import pytest\n\n                pytest.skip(\"no {!r} option found\".format(name))\n            raise ValueError(\"no option named {!r}\".format(name))",
              "start_line": 1182,
              "start_column": 41592,
              "end_line": 4,
              "end_column": 42519,
              "start_byte": 41592,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.getvalue",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def getvalue(self, name, path=None):\n        \"\"\" (deprecated, use getoption()) \"\"\"\n        return self.getoption(name)",
              "start_line": 1206,
              "start_column": 42525,
              "end_line": 4,
              "end_column": 42643,
              "start_byte": 42525,
              "end_byte": 4
            },
            {
              "name": "_pytest.config.Config.getvalueorskip",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "def getvalueorskip(self, name, path=None):\n        \"\"\" (deprecated, use getoption(skip=True)) \"\"\"\n        return self.getoption(name, skip=True)",
              "start_line": 1210,
              "start_column": 42649,
              "end_line": 4,
              "end_column": 42793,
              "start_byte": 42649,
              "end_byte": 4
            },
            {
              "name": "_pytest.warning_types.PytestConfigWarning",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "r\n\nimport _pytest._code\nimport _pytest.deprecated\nimport _pytest.hookspec  # the extension point definitions\nfrom .excep",
              "start_line": 30,
              "start_column": 617,
              "end_line": 0,
              "end_column": 737,
              "start_byte": 617,
              "end_byte": 0
            },
            {
              "name": "_pytest.warning_types.PytestConfigWarning.__module__",
              "file_path": "src/_pytest/config/__init__.py",
              "file_content": "finitions\nfrom .excep",
              "start_line": 33,
              "start_column": 716,
              "end_line": 4,
              "end_column": 737,
              "start_byte": 716,
              "end_byte": 4
            },
            {
              "name": "_pytest.monkeypatch.MonkeyPatch.chdir",
              "file_path": "src/_pytest/monkeypatch.py",
              "file_content": "def chdir(self, path):\n        \"\"\" Change the current working directory to the specified path.\n        Path can be a string or a py.path.local object.\n        \"\"\"\n        if self._cwd is None:\n            self._cwd = os.getcwd()\n        if hasattr(path, \"chdir\"):\n            path.chdir()\n        elif isinstance(path, Path):\n            # modern python uses the fspath protocol here LEGACY\n            os.chdir(str(path))\n        else:\n            os.chdir(path)",
              "start_line": 274,
              "start_column": 9526,
              "end_line": 4,
              "end_column": 9989,
              "start_byte": 9526,
              "end_byte": 4
            },
            {
              "name": "_pytest.monkeypatch.MonkeyPatch.undo",
              "file_path": "src/_pytest/monkeypatch.py",
              "file_content": "def undo(self):\n        \"\"\" Undo previous changes.  This call consumes the\n        undo stack. Calling it a second time has no effect unless\n        you do more monkeypatching after the undo call.\n\n        There is generally no need to call `undo()`, since it is\n        called automatically during tear-down.\n\n        Note that the same `monkeypatch` fixture is used across a\n        single test function invocation. If `monkeypatch` is used both by\n        the test function itself and one of the test fixtures,\n        calling `undo()` will undo all of the changes made in\n        both functions.\n        \"\"\"\n        for obj, name, value in reversed(self._setattr):\n            if value is not notset:\n                setattr(obj, name, value)\n            else:\n                delattr(obj, name)\n        self._setattr[:] = []\n        for dictionary, name, value in reversed(self._setitem):\n            if value is notset:\n                try:\n                    del dictionary[name]\n                except KeyError:\n                    pass  # was already deleted, so we have the desired state\n            else:\n                dictionary[name] = value\n        self._setitem[:] = []\n        if self._savesyspath is not None:\n            sys.path[:] = self._savesyspath\n            self._savesyspath = None\n\n        if self._cwd is not None:\n            os.chdir(self._cwd)\n            self._cwd = None",
              "start_line": 288,
              "start_column": 9995,
              "end_line": 4,
              "end_column": 11401,
              "start_byte": 9995,
              "end_byte": 4
            }
          ],
          "root_caused_symbols": [
            {
              "name": "_pytest.terminal.TerminalReporter._locationline",
              "file_path": "src/_pytest/terminal.py",
              "file_content": "def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \"",
              "start_line": 776,
              "start_column": 27160,
              "end_line": 4,
              "end_column": 27982,
              "start_byte": 27160,
              "end_byte": 4
            },
            {
              "name": "_pytest.nodes.Node._repr_failure_py",
              "file_path": "src/_pytest/nodes.py",
              "file_content": "def _repr_failure_py(\n        self, excinfo: ExceptionInfo[BaseException], style=None,\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        if isinstance(excinfo.value, ConftestImportFailure):\n            excinfo = ExceptionInfo(excinfo.value.excinfo)\n        if isinstance(excinfo.value, fail.Exception):\n            if not excinfo.value.pytrace:\n                style = \"value\"\n        if isinstance(excinfo.value, FixtureLookupError):\n            return excinfo.value.formatrepr()\n        if self.config.getoption(\"fulltrace\", False):\n            style = \"long\"\n        else:\n            tb = _pytest._code.Traceback([excinfo.traceback[-1]])\n            self._prunetraceback(excinfo)\n            if len(excinfo.traceback) == 0:\n                excinfo.traceback = tb\n            if style == \"auto\":\n                style = \"long\"\n        # XXX should excinfo.getrepr record all data and toterminal() process it?\n        if style is None:\n            if self.config.getoption(\"tbstyle\", \"auto\") == \"short\":\n                style = \"short\"\n            else:\n                style = \"long\"\n\n        if self.config.getoption(\"verbose\", 0) > 1:\n            truncate_locals = False\n        else:\n            truncate_locals = True\n\n        try:\n            os.getcwd()\n            abspath = False\n        except OSError:\n            abspath = True\n\n        return excinfo.getrepr(\n            funcargs=True,\n            abspath=abspath,\n            showlocals=self.config.getoption(\"showlocals\", False),\n            style=style,\n            tbfilter=False,  # pruned already, or in --fulltrace mode.\n            truncate_locals=truncate_locals,\n        )",
              "start_line": 332,
              "start_column": 10806,
              "end_line": 4,
              "end_column": 12496,
              "start_byte": 10806,
              "end_byte": 4
            },
            {
              "name": "_pytest.nodes.Node.repr_failure",
              "file_path": "src/_pytest/nodes.py",
              "file_content": "def repr_failure(\n        self, excinfo, style=None\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        \"\"\"\n        Return a representation of a collection or test failure.\n\n        :param excinfo: Exception information for the failure.\n        \"\"\"\n        return self._repr_failure_py(excinfo, style)",
              "start_line": 378,
              "start_column": 12502,
              "end_line": 4,
              "end_column": 12843,
              "start_byte": 12502,
              "end_byte": 4
            },
            {
              "name": "_pytest.nodes.get_fslocation_from_item",
              "file_path": "src/_pytest/nodes.py",
              "file_content": "def get_fslocation_from_item(\n    item: \"Item\",\n) -> Tuple[Union[str, py.path.local], Optional[int]]:\n    \"\"\"Tries to extract the actual location from an item, depending on available attributes:\n\n    * \"fslocation\": a pair (path, lineno)\n    * \"obj\": a Python object that the item wraps.\n    * \"fspath\": just a path\n\n    :rtype: a tuple of (str|LocalPath, int) with filename and line number.\n    \"\"\"\n    try:\n        return item.location[:2]\n    except AttributeError:\n        pass\n    obj = getattr(item, \"obj\", None)\n    if obj is not None:\n        return getfslineno(obj)\n    return getattr(item, \"fspath\", \"unknown location\"), -1",
              "start_line": 389,
              "start_column": 12846,
              "end_line": 0,
              "end_column": 13479,
              "start_byte": 12846,
              "end_byte": 0
            }
          ]
        },
        "symbols_evaluate": {
          "scratch_pad": "Analyzing the reported issue:\n\n1.1 What issue is the user describing?\n- The issue is that when the working directory is changed inside a pytest fixture, the test file errors are reported with wrong paths relative to the new directory, instead of being relative to the original directory.\n\n1.2 How was this issue caused?\n- The issue arises because the fixture `private_dir` changes the working directory to a new one (`ddd`) and the error paths are not being adjusted back to the original directory before being reported.\n\n1.3 What is the expected result?\n- The expected result is for the error paths to be displayed relative to the original directory, even after the directory has been changed within the fixture.\n\n1.4 What should the expectation be?\n- The expectation should be that the paths in the test error reports are consistent with the original directory setup, regardless of any temporary directory changes performed by the test code (fixtures).\n\n1.5 How should the issue be fixed to meet the expectation?\n- The path adjustment code needs to ensure that error messages refer to paths relative to the original directory, ignoring any temporary changes made during the test.\n\n2. Evaluating given symbols:\n\n- _pytest.terminal.TerminalReporter._locationline\n  2.1 This function creates a relative line for nodeids; it uses cwd_relative_nodeid which could be involved in incorrect path handling. The cwd_relative_nodeid function needs to consider the change of directory.\n  2.2 It seems relevant to the issue because it deals with formatting the location lines of errors and other reports.\n\n- _pytest.nodes.Node._repr_failure_py\n  2.1 Involved with the representation of failures and could affect how paths are presented in tracebacks.\n  2.2 Relative to the issue if the path being used comes through this function when the exception is formatted.\n\n- _pytest.terminal.TerminalReporter\n  2.1 The class is responsible for rendering results on the terminal, including where the errors occur.\n  2.2 Relevant due to its methods that control how paths are displayed during test sessions.",
          "symbols": [
            {
              "name": "_pytest.terminal.TerminalReporter._locationline",
              "file_path": "src/_pytest/terminal.py",
              "reason": "This function is responsible for creating relative paths for node IDs and directly affects how paths are displayed. Since the incorrect path issue is related to path handling in a relative manner, this symbol is crucial to correcting the path context."
            },
            {
              "name": "_pytest.config.Config.cwd_relative_nodeid",
              "file_path": "src/_pytest/config/__init__.py",
              "reason": "This function computes paths relative to the current working directory. It needs to ensure that paths are computed relative to the original invocation directory, not the changed directory during test execution."
            }
          ],
          "more_info": [],
          "is_done": false,
          "symbols_scratch_pad": [
            "- _pytest.terminal.TerminalReporter._locationline:\n  This function relates to the construction of location lines using cwd_relative_nodeid and potentially contributes to the error in path rendering when the current directory changes.\n  - This needs to append to ensure the path correction logic correctly always computes using the original starting directory.\n\n- _pytest.nodes.Node._repr_failure_py:\n  This function formats exception information and may impact traceback location formatting. It might intersect with path handling, but is less directly responsible compared to `cwd_relative_nodeid` or `_locationline`.\n  - While related, it appears less directly change-worthy given context.\n\n- _pytest.config.Config.cwd_relative_nodeid:\n  This symbol handles path computation for node IDs based on current versus root directory. The problem seems deeply tied to this relative path context during directory changes.\n  - Needs amending to avoid re-calculating path relative to temporary working directory changes in tests."
          ]
        }
      },
      "response": {
        "file_paths": [
          "src/_pytest/terminal.py",
          "src/_pytest/config/__init__.py"
        ],
        "symbols": [
          "_pytest.terminal.TerminalReporter._locationline",
          "_pytest.config.Config.cwd_relative_nodeid"
        ],
        "code_spans": {
          "_pytest.terminal.TerminalReporter": {
            "name": "_pytest.terminal.TerminalReporter",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "class TerminalReporter:\n    def __init__(self, config: Config, file=None) -> None:\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None  # type: Optional[Session]\n        self._showfspath = None\n\n        self.stats = {}  # type: Dict[str, List[Any]]\n        self._main_color = None  # type: Optional[str]\n        self._known_types = None  # type: Optional[List]\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None  # type: Any\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()  # type: Set[str]\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None  # type: Optional[float]\n\n    @property\n    def writer(self) -> TerminalWriter:\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        return self._tw\n\n    @writer.setter\n    def writer(self, value: TerminalWriter):\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        self._tw = value\n\n    def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False\n\n    @property\n    def verbosity(self):\n        return self.config.option.verbose\n\n    @property\n    def showheader(self):\n        return self.verbosity >= 0\n\n    @property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0\n        return self._showfspath\n\n    @showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value\n\n    @property\n    def showlongtestinfo(self):\n        return self.verbosity > 0\n\n    def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars\n\n    def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, flush=True, **markup)\n\n    def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2\n\n    def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None\n\n    def write(self, content: str, *, flush: bool = False, **markup: bool) -> None:\n        self._tw.write(content, flush=flush, **markup)\n\n    def flush(self) -> None:\n        self._tw.flush()\n\n    def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)\n\n    def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)\n\n    def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)\n\n    def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)\n\n    def line(self, msg, **kw):\n        self._tw.line(msg, **kw)\n\n    def _add_stats(self, category: str, items: List) -> None:\n        set_main_color = category not in self.stats\n        self.stats.setdefault(category, []).extend(items[:])\n        if set_main_color:\n            self._set_main_color()\n\n    def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1\n\n    def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        self._add_stats(\"warnings\", [warning_report])\n\n    def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)\n\n    def pytest_deselected(self, items):\n        self._add_stats(\"deselected\", items)\n\n    def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n            self.flush()\n        elif self.showfspath:\n            self.write_fspath_result(nodeid, \"\")\n            self.flush()\n\n    def pytest_runtest_logreport(self, report: TestReport) -> None:\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self._add_stats(category, [rep])\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2\n        self.flush()\n\n    @property\n    def _is_last_item(self):\n        return len(self._progress_nodeids_reported) == self._session.testscollected\n\n    def pytest_runtest_logfinish(self, nodeid):\n        assert self._session\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n\n            if self._is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                main_color, _ = self._get_main_color()\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", **{main_color: True})\n\n    def _get_progress_information_message(self) -> str:\n        assert self._session\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                return \" [{:3d}%]\".format(\n                    len(self._progress_nodeids_reported) * 100 // collected\n                )\n            return \" [100%]\"\n\n    def _write_progress_information_filling_space(self):\n        color, _ = self._get_main_color()\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), flush=True, **{color: True})\n\n    @property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        return self._tw.width_of_current_line\n\n    def pytest_collection(self) -> None:\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", flush=True, bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", flush=True, bold=True)\n\n    def pytest_collectreport(self, report: CollectReport) -> None:\n        if report.failed:\n            self._add_stats(\"error\", [report])\n        elif report.skipped:\n            self._add_stats(\"skipped\", [report])\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()\n\n    def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d error%s\" % (errors, \"s\" if errors != 1 else \"\")\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)\n\n    @pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session: Session) -> None:\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n        if pypy_version_info:\n            verinfo = \".\".join(map(str, pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)\n\n    def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)\n\n    def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result\n\n    def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if session.items:\n                if self.config.option.verbose > -1:\n                    self._tw.line(\"\")\n                self._printcollecteditems(session.items)\n\n            failed = self.stats.get(\"failed\")\n            if failed:\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in failed:\n                    rep.toterminal(self._tw)\n\n    def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}  # type: Dict[str, int]\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    try:\n                        obj = col.obj  # type: ignore\n                    except AttributeError:\n                        continue\n                    doc = inspect.getdoc(obj)\n                    if doc:\n                        for line in doc.splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line))\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, session: Session, exitstatus: ExitCode):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if session.shouldfail:\n            self.write_sep(\"!\", session.shouldfail, red=True)\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        elif session.shouldstop:\n            self.write_sep(\"!\", session.shouldstop, red=True)\n        self.summary_stats()\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()\n\n    def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)\n\n    def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()\n\n    def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )\n\n    def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \"\n\n    def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?\n\n    def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"\n\n    #\n    # summaries for sessionfinish\n    #\n    def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values\n\n    def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\n                \"warnings\"\n            )  # type: Optional[List[WarningReport]]\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = (\n                order_preserving_dict()\n            )  # type: Dict[str, List[WarningReport]]\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            def collapsed_location_report(reports: List[WarningReport]):\n                locations = []\n                for w in reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        locations.append(location)\n\n                if len(locations) < 10:\n                    return \"\\n\".join(map(str, locations))\n\n                counts_by_filename = order_preserving_dict()  # type: Dict[str, int]\n                for loc in locations:\n                    key = str(loc).split(\"::\", 1)[0]\n                    counts_by_filename[key] = counts_by_filename.get(key, 0) + 1\n                return \"\\n\".join(\n                    \"{}: {} warning{}\".format(k, v, \"s\" if v > 1 else \"\")\n                    for k, v in counts_by_filename.items()\n                )\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, message_reports in reports_grouped_by_message.items():\n                maybe_location = collapsed_location_report(message_reports)\n                if maybe_location:\n                    self._tw.line(maybe_location)\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")\n\n    def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)\n\n    def _get_teardown_reports(self, nodeid: str) -> List[TestReport]:\n        return [\n            report\n            for report in self.getreports(\"\")\n            if report.when == \"teardown\" and report.nodeid == nodeid\n        ]\n\n    def _handle_teardown_sections(self, nodeid: str) -> None:\n        for report in self._get_teardown_reports(nodeid):\n            self.print_teardown_sections(report)\n\n    def print_teardown_sections(self, rep: TestReport) -> None:\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)\n\n    def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)\n\n    def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)\n\n    def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)\n\n    def summary_stats(self):\n        if self.verbosity < -1:\n            return\n\n        session_duration = time.time() - self._sessionstarttime\n        (parts, main_color) = self.build_summary_stats_line()\n        line_parts = []\n\n        display_sep = self.verbosity >= 0\n        if display_sep:\n            fullwidth = self._tw.fullwidth\n        for text, markup in parts:\n            with_markup = self._tw.markup(text, **markup)\n            if display_sep:\n                fullwidth += len(with_markup) - len(text)\n            line_parts.append(with_markup)\n        msg = \", \".join(line_parts)\n\n        main_markup = {main_color: True}\n        duration = \" in {}\".format(format_session_duration(session_duration))\n        duration_with_markup = self._tw.markup(duration, **main_markup)\n        if display_sep:\n            fullwidth += len(duration_with_markup) - len(duration)\n        msg += duration_with_markup\n\n        if display_sep:\n            markup_for_end_sep = self._tw.markup(\"\", **main_markup)\n            if markup_for_end_sep.endswith(\"\\x1b[0m\"):\n                markup_for_end_sep = markup_for_end_sep[:-4]\n            fullwidth += len(markup_for_end_sep)\n            msg += markup_for_end_sep\n\n        if display_sep:\n            self.write_sep(\"=\", msg, fullwidth=fullwidth, **main_markup)\n        else:\n            self.write_line(msg, **main_markup)\n\n    def short_test_summary(self) -> None:\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines: List[str]) -> None:\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self._tw.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines: List[str]) -> None:\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines: List[str]) -> None:\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines: List[str]) -> None:\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(self.startdir, skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }  # type: Mapping[str, Callable[[List[str]], None]]\n\n        lines = []  # type: List[str]\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:\n                self.write_line(line)\n\n    def _get_main_color(self) -> Tuple[str, List[str]]:\n        if self._main_color is None or self._known_types is None or self._is_last_item:\n            self._set_main_color()\n            assert self._main_color\n            assert self._known_types\n        return self._main_color, self._known_types\n\n    def _determine_main_color(self, unknown_type_seen: bool) -> str:\n        stats = self.stats\n        if \"failed\" in stats or \"error\" in stats:\n            main_color = \"red\"\n        elif \"warnings\" in stats or \"xpassed\" in stats or unknown_type_seen:\n            main_color = \"yellow\"\n        elif \"passed\" in stats or not self._is_last_item:\n            main_color = \"green\"\n        else:\n            main_color = \"yellow\"\n        return main_color\n\n    def _set_main_color(self) -> None:\n        unknown_types = []  # type: List[str]\n        for found_type in self.stats.keys():\n            if found_type:  # setup/teardown reports have an empty key, ignore them\n                if found_type not in KNOWN_TYPES and found_type not in unknown_types:\n                    unknown_types.append(found_type)\n        self._known_types = list(KNOWN_TYPES) + unknown_types\n        self._main_color = self._determine_main_color(bool(unknown_types))\n\n    def build_summary_stats_line(self) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:\n        main_color, known_types = self._get_main_color()\n\n        parts = []\n        for key in known_types:\n            reports = self.stats.get(key, None)\n            if reports:\n                count = sum(\n                    1 for rep in reports if getattr(rep, \"count_towards_summary\", True)\n                )\n                color = _color_for_type.get(key, _color_for_type_default)\n                markup = {color: True, \"bold\": color == main_color}\n                parts.append((\"%d %s\" % _make_plural(count, key), markup))\n\n        if not parts:\n            parts = [(\"no tests ran\", {_color_for_type_default: True})]\n\n        return parts, main_color",
            "start_line": 261,
            "start_column": 7463,
            "end_line": 0,
            "end_column": 40474,
            "start_byte": 7463,
            "end_byte": 0
          },
          "_pytest.terminal.TerminalReporter.__init__": {
            "name": "_pytest.terminal.TerminalReporter.__init__",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def __init__(self, config: Config, file=None) -> None:\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None  # type: Optional[Session]\n        self._showfspath = None\n\n        self.stats = {}  # type: Dict[str, List[Any]]\n        self._main_color = None  # type: Optional[str]\n        self._known_types = None  # type: Optional[List]\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None  # type: Any\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()  # type: Set[str]\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None  # type: Optional[float]",
            "start_line": 262,
            "start_column": 7491,
            "end_line": 4,
            "end_column": 8496,
            "start_byte": 7491,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.writer": {
            "name": "_pytest.terminal.TerminalReporter.writer",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@writer.setter\n    def writer(self, value: TerminalWriter):\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        self._tw = value",
            "start_line": 291,
            "start_column": 8640,
            "end_line": 4,
            "end_column": 8783,
            "start_byte": 8640,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._determine_show_progress_info": {
            "name": "_pytest.terminal.TerminalReporter._determine_show_progress_info",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False",
            "start_line": 296,
            "start_column": 8789,
            "end_line": 4,
            "end_column": 9372,
            "start_byte": 8789,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.verbosity": {
            "name": "_pytest.terminal.TerminalReporter.verbosity",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def verbosity(self):\n        return self.config.option.verbose",
            "start_line": 309,
            "start_column": 9378,
            "end_line": 4,
            "end_column": 9454,
            "start_byte": 9378,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.showheader": {
            "name": "_pytest.terminal.TerminalReporter.showheader",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def showheader(self):\n        return self.verbosity >= 0",
            "start_line": 313,
            "start_column": 9460,
            "end_line": 4,
            "end_column": 9530,
            "start_byte": 9460,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.showfspath": {
            "name": "_pytest.terminal.TerminalReporter.showfspath",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value",
            "start_line": 323,
            "start_column": 9685,
            "end_line": 4,
            "end_column": 9769,
            "start_byte": 9685,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.showlongtestinfo": {
            "name": "_pytest.terminal.TerminalReporter.showlongtestinfo",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def showlongtestinfo(self):\n        return self.verbosity > 0",
            "start_line": 327,
            "start_column": 9775,
            "end_line": 4,
            "end_column": 9850,
            "start_byte": 9775,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.hasopt": {
            "name": "_pytest.terminal.TerminalReporter.hasopt",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars",
            "start_line": 331,
            "start_column": 9856,
            "end_line": 4,
            "end_column": 9983,
            "start_byte": 9856,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.write_fspath_result": {
            "name": "_pytest.terminal.TerminalReporter.write_fspath_result",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, flush=True, **markup)",
            "start_line": 335,
            "start_column": 9989,
            "end_line": 4,
            "end_column": 10686,
            "start_byte": 9989,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.write_ensure_prefix": {
            "name": "_pytest.terminal.TerminalReporter.write_ensure_prefix",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2",
            "start_line": 348,
            "start_column": 10692,
            "end_line": 4,
            "end_column": 10992,
            "start_byte": 10692,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.ensure_newline": {
            "name": "_pytest.terminal.TerminalReporter.ensure_newline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None",
            "start_line": 357,
            "start_column": 10998,
            "end_line": 4,
            "end_column": 11120,
            "start_byte": 10998,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.write": {
            "name": "_pytest.terminal.TerminalReporter.write",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write(self, content: str, *, flush: bool = False, **markup: bool) -> None:\n        self._tw.write(content, flush=flush, **markup)",
            "start_line": 362,
            "start_column": 11126,
            "end_line": 4,
            "end_column": 11259,
            "start_byte": 11126,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.flush": {
            "name": "_pytest.terminal.TerminalReporter.flush",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def flush(self) -> None:\n        self._tw.flush()",
            "start_line": 365,
            "start_column": 11265,
            "end_line": 4,
            "end_column": 11314,
            "start_byte": 11265,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.write_line": {
            "name": "_pytest.terminal.TerminalReporter.write_line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)",
            "start_line": 368,
            "start_column": 11320,
            "end_line": 4,
            "end_column": 11510,
            "start_byte": 11320,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.rewrite": {
            "name": "_pytest.terminal.TerminalReporter.rewrite",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)",
            "start_line": 374,
            "start_column": 11516,
            "end_line": 4,
            "end_column": 12134,
            "start_byte": 11516,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.write_sep": {
            "name": "_pytest.terminal.TerminalReporter.write_sep",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)",
            "start_line": 392,
            "start_column": 12140,
            "end_line": 4,
            "end_column": 12260,
            "start_byte": 12140,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.section": {
            "name": "_pytest.terminal.TerminalReporter.section",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)",
            "start_line": 396,
            "start_column": 12266,
            "end_line": 4,
            "end_column": 12345,
            "start_byte": 12266,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.line": {
            "name": "_pytest.terminal.TerminalReporter.line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def line(self, msg, **kw):\n        self._tw.line(msg, **kw)",
            "start_line": 399,
            "start_column": 12351,
            "end_line": 4,
            "end_column": 12410,
            "start_byte": 12351,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._add_stats": {
            "name": "_pytest.terminal.TerminalReporter._add_stats",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _add_stats(self, category: str, items: List) -> None:\n        set_main_color = category not in self.stats\n        self.stats.setdefault(category, []).extend(items[:])\n        if set_main_color:\n            self._set_main_color()",
            "start_line": 402,
            "start_column": 12416,
            "end_line": 4,
            "end_column": 12648,
            "start_byte": 12416,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_internalerror": {
            "name": "_pytest.terminal.TerminalReporter.pytest_internalerror",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1",
            "start_line": 408,
            "start_column": 12654,
            "end_line": 4,
            "end_column": 12811,
            "start_byte": 12654,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_warning_captured": {
            "name": "_pytest.terminal.TerminalReporter.pytest_warning_captured",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        self._add_stats(\"warnings\", [warning_report])",
            "start_line": 413,
            "start_column": 12817,
            "end_line": 4,
            "end_column": 13350,
            "start_byte": 12817,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_plugin_registered": {
            "name": "_pytest.terminal.TerminalReporter.pytest_plugin_registered",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)",
            "start_line": 426,
            "start_column": 13356,
            "end_line": 4,
            "end_column": 13731,
            "start_byte": 13356,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_deselected": {
            "name": "_pytest.terminal.TerminalReporter.pytest_deselected",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_deselected(self, items):\n        self._add_stats(\"deselected\", items)",
            "start_line": 434,
            "start_column": 13737,
            "end_line": 4,
            "end_column": 13817,
            "start_byte": 13737,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_runtest_logstart": {
            "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logstart",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n            self.flush()\n        elif self.showfspath:\n            self.write_fspath_result(nodeid, \"\")\n            self.flush()",
            "start_line": 437,
            "start_column": 13823,
            "end_line": 4,
            "end_column": 14241,
            "start_byte": 13823,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_runtest_logreport": {
            "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logreport",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_runtest_logreport(self, report: TestReport) -> None:\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self._add_stats(category, [rep])\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2\n        self.flush()",
            "start_line": 448,
            "start_column": 14247,
            "end_line": 4,
            "end_column": 16159,
            "start_byte": 14247,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._is_last_item": {
            "name": "_pytest.terminal.TerminalReporter._is_last_item",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def _is_last_item(self):\n        return len(self._progress_nodeids_reported) == self._session.testscollected",
            "start_line": 497,
            "start_column": 16165,
            "end_line": 4,
            "end_column": 16287,
            "start_byte": 16165,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_runtest_logfinish": {
            "name": "_pytest.terminal.TerminalReporter.pytest_runtest_logfinish",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_runtest_logfinish(self, nodeid):\n        assert self._session\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n\n            if self._is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                main_color, _ = self._get_main_color()\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", **{main_color: True})",
            "start_line": 501,
            "start_column": 16293,
            "end_line": 4,
            "end_column": 17210,
            "start_byte": 16293,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._get_progress_information_message": {
            "name": "_pytest.terminal.TerminalReporter._get_progress_information_message",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _get_progress_information_message(self) -> str:\n        assert self._session\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                return \" [{:3d}%]\".format(\n                    len(self._progress_nodeids_reported) * 100 // collected\n                )\n            return \" [100%]\"",
            "start_line": 522,
            "start_column": 17216,
            "end_line": 4,
            "end_column": 17957,
            "start_byte": 17216,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._write_progress_information_filling_space": {
            "name": "_pytest.terminal.TerminalReporter._write_progress_information_filling_space",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _write_progress_information_filling_space(self):\n        color, _ = self._get_main_color()\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), flush=True, **{color: True})",
            "start_line": 539,
            "start_column": 17963,
            "end_line": 4,
            "end_column": 18259,
            "start_byte": 17963,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._width_of_current_line": {
            "name": "_pytest.terminal.TerminalReporter._width_of_current_line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        return self._tw.width_of_current_line",
            "start_line": 546,
            "start_column": 18265,
            "end_line": 4,
            "end_column": 18465,
            "start_byte": 18265,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_collection": {
            "name": "_pytest.terminal.TerminalReporter.pytest_collection",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_collection(self) -> None:\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", flush=True, bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", flush=True, bold=True)",
            "start_line": 551,
            "start_column": 18471,
            "end_line": 4,
            "end_column": 18821,
            "start_byte": 18471,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_collectreport": {
            "name": "_pytest.terminal.TerminalReporter.pytest_collectreport",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_collectreport(self, report: CollectReport) -> None:\n        if report.failed:\n            self._add_stats(\"error\", [report])\n        elif report.skipped:\n            self._add_stats(\"skipped\", [report])\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()",
            "start_line": 559,
            "start_column": 18827,
            "end_line": 4,
            "end_column": 19212,
            "start_byte": 18827,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.report_collect": {
            "name": "_pytest.terminal.TerminalReporter.report_collect",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d error%s\" % (errors, \"s\" if errors != 1 else \"\")\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)",
            "start_line": 569,
            "start_column": 19218,
            "end_line": 4,
            "end_column": 20633,
            "start_byte": 19218,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_sessionstart": {
            "name": "_pytest.terminal.TerminalReporter.pytest_sessionstart",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session: Session) -> None:\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n        if pypy_version_info:\n            verinfo = \".\".join(map(str, pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)",
            "start_line": 609,
            "start_column": 20639,
            "end_line": 4,
            "end_column": 21805,
            "start_byte": 20639,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._write_report_lines_from_hooks": {
            "name": "_pytest.terminal.TerminalReporter._write_report_lines_from_hooks",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)",
            "start_line": 637,
            "start_column": 21811,
            "end_line": 4,
            "end_column": 21954,
            "start_byte": 21811,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_report_header": {
            "name": "_pytest.terminal.TerminalReporter.pytest_report_header",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result",
            "start_line": 642,
            "start_column": 21960,
            "end_line": 4,
            "end_column": 22615,
            "start_byte": 21960,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_collection_finish": {
            "name": "_pytest.terminal.TerminalReporter.pytest_collection_finish",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if session.items:\n                if self.config.option.verbose > -1:\n                    self._tw.line(\"\")\n                self._printcollecteditems(session.items)\n\n            failed = self.stats.get(\"failed\")\n            if failed:\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in failed:\n                    rep.toterminal(self._tw)",
            "start_line": 659,
            "start_column": 22621,
            "end_line": 4,
            "end_column": 23336,
            "start_byte": 22621,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._printcollecteditems": {
            "name": "_pytest.terminal.TerminalReporter._printcollecteditems",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}  # type: Dict[str, int]\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    try:\n                        obj = col.obj  # type: ignore\n                    except AttributeError:\n                        continue\n                    doc = inspect.getdoc(obj)\n                    if doc:\n                        for line in doc.splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line))",
            "start_line": 679,
            "start_column": 23342,
            "end_line": 4,
            "end_column": 25064,
            "start_byte": 23342,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_sessionfinish": {
            "name": "_pytest.terminal.TerminalReporter.pytest_sessionfinish",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, session: Session, exitstatus: ExitCode):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if session.shouldfail:\n            self.write_sep(\"!\", session.shouldfail, red=True)\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        elif session.shouldstop:\n            self.write_sep(\"!\", session.shouldstop, red=True)\n        self.summary_stats()",
            "start_line": 719,
            "start_column": 25070,
            "end_line": 4,
            "end_column": 26017,
            "start_byte": 25070,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_terminal_summary": {
            "name": "_pytest.terminal.TerminalReporter.pytest_terminal_summary",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()",
            "start_line": 744,
            "start_column": 26023,
            "end_line": 4,
            "end_column": 26366,
            "start_byte": 26023,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_keyboard_interrupt": {
            "name": "_pytest.terminal.TerminalReporter.pytest_keyboard_interrupt",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)",
            "start_line": 755,
            "start_column": 26372,
            "end_line": 4,
            "end_column": 26487,
            "start_byte": 26372,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.pytest_unconfigure": {
            "name": "_pytest.terminal.TerminalReporter.pytest_unconfigure",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()",
            "start_line": 758,
            "start_column": 26493,
            "end_line": 4,
            "end_column": 26620,
            "start_byte": 26493,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._report_keyboardinterrupt": {
            "name": "_pytest.terminal.TerminalReporter._report_keyboardinterrupt",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )",
            "start_line": 762,
            "start_column": 26626,
            "end_line": 4,
            "end_column": 27154,
            "start_byte": 26626,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._getfailureheadline": {
            "name": "_pytest.terminal.TerminalReporter._getfailureheadline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?",
            "start_line": 798,
            "start_column": 27988,
            "end_line": 4,
            "end_column": 28146,
            "start_byte": 27988,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._getcrashline": {
            "name": "_pytest.terminal.TerminalReporter._getcrashline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"",
            "start_line": 804,
            "start_column": 28152,
            "end_line": 4,
            "end_column": 28396,
            "start_byte": 28152,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.getreports": {
            "name": "_pytest.terminal.TerminalReporter.getreports",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values",
            "start_line": 816,
            "start_column": 28448,
            "end_line": 4,
            "end_column": 28637,
            "start_byte": 28448,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.summary_warnings": {
            "name": "_pytest.terminal.TerminalReporter.summary_warnings",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\n                \"warnings\"\n            )  # type: Optional[List[WarningReport]]\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = (\n                order_preserving_dict()\n            )  # type: Dict[str, List[WarningReport]]\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            def collapsed_location_report(reports: List[WarningReport]):\n                locations = []\n                for w in reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        locations.append(location)\n\n                if len(locations) < 10:\n                    return \"\\n\".join(map(str, locations))\n\n                counts_by_filename = order_preserving_dict()  # type: Dict[str, int]\n                for loc in locations:\n                    key = str(loc).split(\"::\", 1)[0]\n                    counts_by_filename[key] = counts_by_filename.get(key, 0) + 1\n                return \"\\n\".join(\n                    \"{}: {} warning{}\".format(k, v, \"s\" if v > 1 else \"\")\n                    for k, v in counts_by_filename.items()\n                )\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, message_reports in reports_grouped_by_message.items():\n                maybe_location = collapsed_location_report(message_reports)\n                if maybe_location:\n                    self._tw.line(maybe_location)\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")",
            "start_line": 823,
            "start_column": 28643,
            "end_line": 4,
            "end_column": 31098,
            "start_byte": 28643,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.summary_passes": {
            "name": "_pytest.terminal.TerminalReporter.summary_passes",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)",
            "start_line": 880,
            "start_column": 31104,
            "end_line": 4,
            "end_column": 31684,
            "start_byte": 31104,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._get_teardown_reports": {
            "name": "_pytest.terminal.TerminalReporter._get_teardown_reports",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _get_teardown_reports(self, nodeid: str) -> List[TestReport]:\n        return [\n            report\n            for report in self.getreports(\"\")\n            if report.when == \"teardown\" and report.nodeid == nodeid\n        ]",
            "start_line": 894,
            "start_column": 31690,
            "end_line": 4,
            "end_column": 31916,
            "start_byte": 31690,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._handle_teardown_sections": {
            "name": "_pytest.terminal.TerminalReporter._handle_teardown_sections",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _handle_teardown_sections(self, nodeid: str) -> None:\n        for report in self._get_teardown_reports(nodeid):\n            self.print_teardown_sections(report)",
            "start_line": 901,
            "start_column": 31922,
            "end_line": 4,
            "end_column": 32086,
            "start_byte": 31922,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.print_teardown_sections": {
            "name": "_pytest.terminal.TerminalReporter.print_teardown_sections",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def print_teardown_sections(self, rep: TestReport) -> None:\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)",
            "start_line": 905,
            "start_column": 32092,
            "end_line": 4,
            "end_column": 32598,
            "start_byte": 32092,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.summary_failures": {
            "name": "_pytest.terminal.TerminalReporter.summary_failures",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)",
            "start_line": 918,
            "start_column": 32604,
            "end_line": 4,
            "end_column": 33288,
            "start_byte": 32604,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.summary_errors": {
            "name": "_pytest.terminal.TerminalReporter.summary_errors",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)",
            "start_line": 935,
            "start_column": 33294,
            "end_line": 4,
            "end_column": 33890,
            "start_byte": 33294,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._outrep_summary": {
            "name": "_pytest.terminal.TerminalReporter._outrep_summary",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)",
            "start_line": 950,
            "start_column": 33896,
            "end_line": 4,
            "end_column": 34353,
            "start_byte": 33896,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.summary_stats": {
            "name": "_pytest.terminal.TerminalReporter.summary_stats",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def summary_stats(self):\n        if self.verbosity < -1:\n            return\n\n        session_duration = time.time() - self._sessionstarttime\n        (parts, main_color) = self.build_summary_stats_line()\n        line_parts = []\n\n        display_sep = self.verbosity >= 0\n        if display_sep:\n            fullwidth = self._tw.fullwidth\n        for text, markup in parts:\n            with_markup = self._tw.markup(text, **markup)\n            if display_sep:\n                fullwidth += len(with_markup) - len(text)\n            line_parts.append(with_markup)\n        msg = \", \".join(line_parts)\n\n        main_markup = {main_color: True}\n        duration = \" in {}\".format(format_session_duration(session_duration))\n        duration_with_markup = self._tw.markup(duration, **main_markup)\n        if display_sep:\n            fullwidth += len(duration_with_markup) - len(duration)\n        msg += duration_with_markup\n\n        if display_sep:\n            markup_for_end_sep = self._tw.markup(\"\", **main_markup)\n            if markup_for_end_sep.endswith(\"\\x1b[0m\"):\n                markup_for_end_sep = markup_for_end_sep[:-4]\n            fullwidth += len(markup_for_end_sep)\n            msg += markup_for_end_sep\n\n        if display_sep:\n            self.write_sep(\"=\", msg, fullwidth=fullwidth, **main_markup)\n        else:\n            self.write_line(msg, **main_markup)",
            "start_line": 963,
            "start_column": 34359,
            "end_line": 4,
            "end_column": 35728,
            "start_byte": 34359,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.short_test_summary": {
            "name": "_pytest.terminal.TerminalReporter.short_test_summary",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def short_test_summary(self) -> None:\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines: List[str]) -> None:\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self._tw.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines: List[str]) -> None:\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines: List[str]) -> None:\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines: List[str]) -> None:\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(self.startdir, skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }  # type: Mapping[str, Callable[[List[str]], None]]\n\n        lines = []  # type: List[str]\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:\n                self.write_line(line)",
            "start_line": 1000,
            "start_column": 35734,
            "end_line": 4,
            "end_column": 38473,
            "start_byte": 35734,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._get_main_color": {
            "name": "_pytest.terminal.TerminalReporter._get_main_color",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _get_main_color(self) -> Tuple[str, List[str]]:\n        if self._main_color is None or self._known_types is None or self._is_last_item:\n            self._set_main_color()\n            assert self._main_color\n            assert self._known_types\n        return self._main_color, self._known_types",
            "start_line": 1069,
            "start_column": 38479,
            "end_line": 4,
            "end_column": 38777,
            "start_byte": 38479,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._determine_main_color": {
            "name": "_pytest.terminal.TerminalReporter._determine_main_color",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _determine_main_color(self, unknown_type_seen: bool) -> str:\n        stats = self.stats\n        if \"failed\" in stats or \"error\" in stats:\n            main_color = \"red\"\n        elif \"warnings\" in stats or \"xpassed\" in stats or unknown_type_seen:\n            main_color = \"yellow\"\n        elif \"passed\" in stats or not self._is_last_item:\n            main_color = \"green\"\n        else:\n            main_color = \"yellow\"\n        return main_color",
            "start_line": 1076,
            "start_column": 38783,
            "end_line": 4,
            "end_column": 39231,
            "start_byte": 38783,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._set_main_color": {
            "name": "_pytest.terminal.TerminalReporter._set_main_color",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _set_main_color(self) -> None:\n        unknown_types = []  # type: List[str]\n        for found_type in self.stats.keys():\n            if found_type:  # setup/teardown reports have an empty key, ignore them\n                if found_type not in KNOWN_TYPES and found_type not in unknown_types:\n                    unknown_types.append(found_type)\n        self._known_types = list(KNOWN_TYPES) + unknown_types\n        self._main_color = self._determine_main_color(bool(unknown_types))",
            "start_line": 1088,
            "start_column": 39237,
            "end_line": 4,
            "end_column": 39722,
            "start_byte": 39237,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter.build_summary_stats_line": {
            "name": "_pytest.terminal.TerminalReporter.build_summary_stats_line",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def build_summary_stats_line(self) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:\n        main_color, known_types = self._get_main_color()\n\n        parts = []\n        for key in known_types:\n            reports = self.stats.get(key, None)\n            if reports:\n                count = sum(\n                    1 for rep in reports if getattr(rep, \"count_towards_summary\", True)\n                )\n                color = _color_for_type.get(key, _color_for_type_default)\n                markup = {color: True, \"bold\": color == main_color}\n                parts.append((\"%d %s\" % _make_plural(count, key), markup))\n\n        if not parts:\n            parts = [(\"no tests ran\", {_color_for_type_default: True})]\n\n        return parts, main_color",
            "start_line": 1097,
            "start_column": 39728,
            "end_line": 4,
            "end_column": 40474,
            "start_byte": 39728,
            "end_byte": 4
          },
          "_pytest.config.Config": {
            "name": "_pytest.config.Config",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "class Config:\n    \"\"\"\n    Access to configuration values, pluginmanager and plugin hooks.\n\n    :param PytestPluginManager pluginmanager:\n\n    :param InvocationParams invocation_params:\n        Object containing the parameters regarding the ``pytest.main``\n        invocation.\n    \"\"\"\n\n    @attr.s(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during ``pytest.main()``\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args = attr.ib(converter=tuple)\n        \"\"\"tuple of command-line arguments as passed to ``pytest.main()``.\"\"\"\n        plugins = attr.ib()\n        \"\"\"list of extra plugins, might be `None`.\"\"\"\n        dir = attr.ib(type=Path)\n        \"\"\"directory where ``pytest.main()`` was invoked from.\"\"\"\n\n    def __init__(\n        self,\n        pluginmanager: PytestPluginManager,\n        *,\n        invocation_params: Optional[InvocationParams] = None\n    ) -> None:\n        from .argparsing import Parser, FILE_OR_DIR\n\n        if invocation_params is None:\n            invocation_params = self.InvocationParams(\n                args=(), plugins=None, dir=Path().resolve()\n            )\n\n        self.option = argparse.Namespace()\n        \"\"\"access to command line option as attributes.\n\n          :type: argparse.Namespace\"\"\"\n\n        self.invocation_params = invocation_params\n\n        _a = FILE_OR_DIR\n        self._parser = Parser(\n            usage=\"%(prog)s [options] [{}] [{}] [...]\".format(_a, _a),\n            processopt=self._processopt,\n        )\n        self.pluginmanager = pluginmanager\n        \"\"\"the plugin manager handles plugin registration and hook invocation.\n\n          :type: PytestPluginManager\"\"\"\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook = self.pluginmanager.hook\n        self._inicache = {}  # type: Dict[str, Any]\n        self._override_ini = ()  # type: Sequence[str]\n        self._opt2dest = {}  # type: Dict[str, str]\n        self._cleanup = []  # type: List[Callable[[], None]]\n        # A place where plugins can store information on the config for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n\n        if TYPE_CHECKING:\n            from _pytest.cacheprovider import Cache\n\n            self.cache = None  # type: Optional[Cache]\n\n    @property\n    def invocation_dir(self):\n        \"\"\"Backward compatibility\"\"\"\n        return py.path.local(str(self.invocation_params.dir))\n\n    def add_cleanup(self, func):\n        \"\"\" Add a function to be called when the config object gets out of\n        use (usually coninciding with pytest_unconfigure).\"\"\"\n        self._cleanup.append(func)\n\n    def _do_configure(self):\n        assert not self._configured\n        self._configured = True\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"default\")\n            self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\n\n    def _ensure_unconfigure(self):\n        if self._configured:\n            self._configured = False\n            self.hook.pytest_unconfigure(config=self)\n            self.hook.pytest_configure._call_history = []\n        while self._cleanup:\n            fin = self._cleanup.pop()\n            fin()\n\n    def get_terminal_writer(self):\n        return self.pluginmanager.get_plugin(\"terminalreporter\")._tw\n\n    def pytest_cmdline_parse(self, pluginmanager, args):\n        try:\n            self.parse(args)\n        except UsageError:\n\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"version\", False) or \"--version\" in args:\n                from _pytest.helpconfig import showversion\n\n                showversion(self)\n            elif (\n                getattr(self.option, \"help\", False) or \"--help\" in args or \"-h\" in args\n            ):\n                self._parser._getparser().print_help()\n                sys.stdout.write(\n                    \"\\nNOTE: displaying only minimal help due to UsageError.\\n\\n\"\n                )\n\n            raise\n\n        return self\n\n    def notify_exception(self, excinfo, option=None):\n        if option and getattr(option, \"fulltrace\", False):\n            style = \"long\"\n        else:\n            style = \"native\"\n        excrepr = excinfo.getrepr(\n            funcargs=True, showlocals=getattr(option, \"showlocals\", False), style=style\n        )\n        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\n        if not any(res):\n            for line in str(excrepr).split(\"\\n\"):\n                sys.stderr.write(\"INTERNALERROR> %s\\n\" % line)\n                sys.stderr.flush()\n\n    def cwd_relative_nodeid(self, nodeid):\n        # nodeid's are relative to the rootpath, compute relative to cwd\n        if self.invocation_dir != self.rootdir:\n            fullpath = self.rootdir.join(nodeid)\n            nodeid = self.invocation_dir.bestrelpath(fullpath)\n        return nodeid\n\n    @classmethod\n    def fromdictargs(cls, option_dict, args):\n        \"\"\" constructor usable for subprocesses. \"\"\"\n        config = get_config(args)\n        config.option.__dict__.update(option_dict)\n        config.parse(args, addopts=False)\n        for x in config.option.plugins:\n            config.pluginmanager.consider_pluginarg(x)\n        return config\n\n    def _processopt(self, opt: \"Argument\") -> None:\n        for name in opt._short_opts + opt._long_opts:\n            self._opt2dest[name] = opt.dest\n\n        if hasattr(opt, \"default\"):\n            if not hasattr(self.option, opt.dest):\n                setattr(self.option, opt.dest, opt.default)\n\n    @hookimpl(trylast=True)\n    def pytest_load_initial_conftests(self, early_config):\n        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)\n\n    def _initini(self, args: Sequence[str]) -> None:\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(\n            args, namespace=copy.copy(self.option)\n        )\n        r = determine_setup(\n            ns.inifilename,\n            ns.file_or_dir + unknown_args,\n            rootdir_cmd_arg=ns.rootdir or None,\n            config=self,\n        )\n        self.rootdir, self.inifile, self.inicfg = r\n        self._parser.extra_info[\"rootdir\"] = self.rootdir\n        self._parser.extra_info[\"inifile\"] = self.inifile\n        self._parser.addini(\"addopts\", \"extra command line options\", \"args\")\n        self._parser.addini(\"minversion\", \"minimally required pytest version\")\n        self._override_ini = ns.override_ini or ()\n\n    def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook)\n        _warn_about_missing_assertion(mode)\n\n    def _mark_plugins_for_rewrite(self, hook):\n        \"\"\"\n        Given an importhook, mark for rewrite any top-level\n        modules or packages in the distribution package for\n        all pytest plugins.\n        \"\"\"\n        self.pluginmanager.rewrite_hook = hook\n\n        if os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # We don't autoload from setuptools entry points, no need to continue.\n            return\n\n        package_files = (\n            str(file)\n            for dist in importlib_metadata.distributions()\n            if any(ep.group == \"pytest11\" for ep in dist.entry_points)\n            for file in dist.files or []\n        )\n\n        for name in _iter_rewritable_modules(package_files):\n            hook.mark_rewrite(name)\n\n    def _validate_args(self, args: List[str], via: str) -> List[str]:\n        \"\"\"Validate known args.\"\"\"\n        self._parser._config_source_hint = via  # type: ignore\n        try:\n            self._parser.parse_known_and_unknown_args(\n                args, namespace=copy.copy(self.option)\n            )\n        finally:\n            del self._parser._config_source_hint  # type: ignore\n\n        return args\n\n    def _preparse(self, args: List[str], addopts: bool = True) -> None:\n        if addopts:\n            env_addopts = os.environ.get(\"PYTEST_ADDOPTS\", \"\")\n            if len(env_addopts):\n                args[:] = (\n                    self._validate_args(shlex.split(env_addopts), \"via PYTEST_ADDOPTS\")\n                    + args\n                )\n        self._initini(args)\n        if addopts:\n            args[:] = (\n                self._validate_args(self.getini(\"addopts\"), \"via addopts config\") + args\n            )\n\n        self._checkversion()\n        self._consider_importhook(args)\n        self.pluginmanager.consider_preparse(args, exclude_only=False)\n        if not os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # Don't autoload from setuptools entry point. Only explicitly specified\n            # plugins are going to be loaded.\n            self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\n        self.pluginmanager.consider_env()\n        self.known_args_namespace = ns = self._parser.parse_known_args(\n            args, namespace=copy.copy(self.option)\n        )\n        if self.known_args_namespace.confcutdir is None and self.inifile:\n            confcutdir = py.path.local(self.inifile).dirname\n            self.known_args_namespace.confcutdir = confcutdir\n        try:\n            self.hook.pytest_load_initial_conftests(\n                early_config=self, args=args, parser=self._parser\n            )\n        except ConftestImportFailure as e:\n            if ns.help or ns.version:\n                # we don't want to prevent --help/--version to work\n                # so just let is pass and print a warning at the end\n                from _pytest.warnings import _issue_warning_captured\n\n                _issue_warning_captured(\n                    PytestConfigWarning(\n                        \"could not load initial conftests: {}\".format(e.path)\n                    ),\n                    self.hook,\n                    stacklevel=2,\n                )\n            else:\n                raise\n\n    def _checkversion(self):\n        import pytest\n\n        minver = self.inicfg.get(\"minversion\", None)\n        if minver:\n            # Imported lazily to improve start-up time.\n            from packaging.version import Version\n\n            if Version(minver) > Version(pytest.__version__):\n                raise pytest.UsageError(\n                    \"%s:%d: requires pytest-%s, actual pytest-%s'\"\n                    % (\n                        self.inicfg.config.path,\n                        self.inicfg.lineof(\"minversion\"),\n                        minver,\n                        pytest.__version__,\n                    )\n                )\n\n    def parse(self, args: List[str], addopts: bool = True) -> None:\n        # parse given cmdline arguments into this config object.\n        assert not hasattr(\n            self, \"args\"\n        ), \"can only parse cmdline args at most once per Config object\"\n        self.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=self.pluginmanager)\n        )\n        self._preparse(args, addopts=addopts)\n        # XXX deprecated hook:\n        self.hook.pytest_cmdline_preparse(config=self, args=args)\n        self._parser.after_preparse = True  # type: ignore\n        try:\n            args = self._parser.parse_setoption(\n                args, self.option, namespace=self.option\n            )\n            if not args:\n                if self.invocation_dir == self.rootdir:\n                    args = self.getini(\"testpaths\")\n                if not args:\n                    args = [str(self.invocation_dir)]\n            self.args = args\n        except PrintHelp:\n            pass\n\n    def addinivalue_line(self, name, line):\n        \"\"\" add a line to an ini-file option. The option must have been\n        declared but might not yet be set in which case the line becomes the\n        the first line in its value. \"\"\"\n        x = self.getini(name)\n        assert isinstance(x, list)\n        x.append(line)  # modifies the cached list inline\n\n    def getini(self, name: str):\n        \"\"\" return configuration value from an :ref:`ini file <inifiles>`. If the\n        specified name hasn't been registered through a prior\n        :py:func:`parser.addini <_pytest.config.argparsing.Parser.addini>`\n        call (usually from a plugin), a ValueError is raised. \"\"\"\n        try:\n            return self._inicache[name]\n        except KeyError:\n            self._inicache[name] = val = self._getini(name)\n            return val\n\n    def _getini(self, name: str) -> Any:\n        try:\n            description, type, default = self._parser._inidict[name]\n        except KeyError:\n            raise ValueError(\"unknown configuration value: {!r}\".format(name))\n        value = self._get_override_ini_value(name)\n        if value is None:\n            try:\n                value = self.inicfg[name]\n            except KeyError:\n                if default is not None:\n                    return default\n                if type is None:\n                    return \"\"\n                return []\n        if type == \"pathlist\":\n            dp = py.path.local(self.inicfg.config.path).dirpath()\n            values = []\n            for relpath in shlex.split(value):\n                values.append(dp.join(relpath, abs=True))\n            return values\n        elif type == \"args\":\n            return shlex.split(value)\n        elif type == \"linelist\":\n            return [t for t in map(lambda x: x.strip(), value.split(\"\\n\")) if t]\n        elif type == \"bool\":\n            return bool(_strtobool(value.strip()))\n        else:\n            assert type is None\n            return value\n\n    def _getconftest_pathlist(self, name, path):\n        try:\n            mod, relroots = self.pluginmanager._rget_with_confmod(name, path)\n        except KeyError:\n            return None\n        modpath = py.path.local(mod.__file__).dirpath()\n        values = []\n        for relroot in relroots:\n            if not isinstance(relroot, py.path.local):\n                relroot = relroot.replace(\"/\", py.path.local.sep)\n                relroot = modpath.join(relroot, abs=True)\n            values.append(relroot)\n        return values\n\n    def _get_override_ini_value(self, name: str) -> Optional[str]:\n        value = None\n        # override_ini is a list of \"ini=value\" options\n        # always use the last item if multiple values are set for same ini-name,\n        # e.g. -o foo=bar1 -o foo=bar2 will set foo to bar2\n        for ini_config in self._override_ini:\n            try:\n                key, user_ini_value = ini_config.split(\"=\", 1)\n            except ValueError:\n                raise UsageError(\n                    \"-o/--override-ini expects option=value style (got: {!r}).\".format(\n                        ini_config\n                    )\n                )\n            else:\n                if key == name:\n                    value = user_ini_value\n        return value\n\n    def getoption(self, name: str, default=notset, skip: bool = False):\n        \"\"\" return command line option value.\n\n        :arg name: name of the option.  You may also specify\n            the literal ``--OPT`` option instead of the \"dest\" option name.\n        :arg default: default value if no option of that name exists.\n        :arg skip: if True raise pytest.skip if option does not exists\n            or has a None value.\n        \"\"\"\n        name = self._opt2dest.get(name, name)\n        try:\n            val = getattr(self.option, name)\n            if val is None and skip:\n                raise AttributeError(name)\n            return val\n        except AttributeError:\n            if default is not notset:\n                return default\n            if skip:\n                import pytest\n\n                pytest.skip(\"no {!r} option found\".format(name))\n            raise ValueError(\"no option named {!r}\".format(name))\n\n    def getvalue(self, name, path=None):\n        \"\"\" (deprecated, use getoption()) \"\"\"\n        return self.getoption(name)\n\n    def getvalueorskip(self, name, path=None):\n        \"\"\" (deprecated, use getoption(skip=True)) \"\"\"\n        return self.getoption(name, skip=True)",
            "start_line": 756,
            "start_column": 25530,
            "end_line": 0,
            "end_column": 42793,
            "start_byte": 25530,
            "end_byte": 0
          },
          "_pytest.config.Config.InvocationParams": {
            "name": "_pytest.config.Config.InvocationParams",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@attr.s(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during ``pytest.main()``\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args = attr.ib(converter=tuple)\n        \"\"\"tuple of command-line arguments as passed to ``pytest.main()``.\"\"\"\n        plugins = attr.ib()\n        \"\"\"list of extra plugins, might be `None`.\"\"\"\n        dir = attr.ib(type=Path)\n        \"\"\"directory where ``pytest.main()`` was invoked from.\"\"\"",
            "start_line": 767,
            "start_column": 25819,
            "end_line": 4,
            "end_column": 26589,
            "start_byte": 25819,
            "end_byte": 4
          },
          "_pytest.config.Config.InvocationParams.args": {
            "name": "_pytest.config.Config.InvocationParams.args",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "args = attr.ib(converter=tuple)",
            "start_line": 783,
            "start_column": 26299,
            "end_line": 8,
            "end_column": 26330,
            "start_byte": 26299,
            "end_byte": 8
          },
          "_pytest.config.Config.InvocationParams.plugins": {
            "name": "_pytest.config.Config.InvocationParams.plugins",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "plugins = attr.ib()",
            "start_line": 785,
            "start_column": 26417,
            "end_line": 8,
            "end_column": 26436,
            "start_byte": 26417,
            "end_byte": 8
          },
          "_pytest.config.Config.InvocationParams.dir": {
            "name": "_pytest.config.Config.InvocationParams.dir",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "dir = attr.ib(type=Path)",
            "start_line": 787,
            "start_column": 26499,
            "end_line": 8,
            "end_column": 26523,
            "start_byte": 26499,
            "end_byte": 8
          },
          "_pytest.config.Config.__init__": {
            "name": "_pytest.config.Config.__init__",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def __init__(\n        self,\n        pluginmanager: PytestPluginManager,\n        *,\n        invocation_params: Optional[InvocationParams] = None\n    ) -> None:\n        from .argparsing import Parser, FILE_OR_DIR\n\n        if invocation_params is None:\n            invocation_params = self.InvocationParams(\n                args=(), plugins=None, dir=Path().resolve()\n            )\n\n        self.option = argparse.Namespace()\n        \"\"\"access to command line option as attributes.\n\n          :type: argparse.Namespace\"\"\"\n\n        self.invocation_params = invocation_params\n\n        _a = FILE_OR_DIR\n        self._parser = Parser(\n            usage=\"%(prog)s [options] [{}] [{}] [...]\".format(_a, _a),\n            processopt=self._processopt,\n        )\n        self.pluginmanager = pluginmanager\n        \"\"\"the plugin manager handles plugin registration and hook invocation.\n\n          :type: PytestPluginManager\"\"\"\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook = self.pluginmanager.hook\n        self._inicache = {}  # type: Dict[str, Any]\n        self._override_ini = ()  # type: Sequence[str]\n        self._opt2dest = {}  # type: Dict[str, str]\n        self._cleanup = []  # type: List[Callable[[], None]]\n        # A place where plugins can store information on the config for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n\n        if TYPE_CHECKING:\n            from _pytest.cacheprovider import Cache\n\n            self.cache = None  # type: Optional[Cache]",
            "start_line": 790,
            "start_column": 26595,
            "end_line": 4,
            "end_column": 28375,
            "start_byte": 26595,
            "end_byte": 4
          },
          "_pytest.config.Config.invocation_dir": {
            "name": "_pytest.config.Config.invocation_dir",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@property\n    def invocation_dir(self):\n        \"\"\"Backward compatibility\"\"\"\n        return py.path.local(str(self.invocation_params.dir))",
            "start_line": 840,
            "start_column": 28381,
            "end_line": 4,
            "end_column": 28519,
            "start_byte": 28381,
            "end_byte": 4
          },
          "_pytest.config.Config.add_cleanup": {
            "name": "_pytest.config.Config.add_cleanup",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def add_cleanup(self, func):\n        \"\"\" Add a function to be called when the config object gets out of\n        use (usually coninciding with pytest_unconfigure).\"\"\"\n        self._cleanup.append(func)",
            "start_line": 845,
            "start_column": 28525,
            "end_line": 4,
            "end_column": 28725,
            "start_byte": 28525,
            "end_byte": 4
          },
          "_pytest.config.Config._do_configure": {
            "name": "_pytest.config.Config._do_configure",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _do_configure(self):\n        assert not self._configured\n        self._configured = True\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"default\")\n            self.hook.pytest_configure.call_historic(kwargs=dict(config=self))",
            "start_line": 850,
            "start_column": 28731,
            "end_line": 4,
            "end_column": 28987,
            "start_byte": 28731,
            "end_byte": 4
          },
          "_pytest.config.Config._ensure_unconfigure": {
            "name": "_pytest.config.Config._ensure_unconfigure",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _ensure_unconfigure(self):\n        if self._configured:\n            self._configured = False\n            self.hook.pytest_unconfigure(config=self)\n            self.hook.pytest_configure._call_history = []\n        while self._cleanup:\n            fin = self._cleanup.pop()\n            fin()",
            "start_line": 857,
            "start_column": 28993,
            "end_line": 4,
            "end_column": 29286,
            "start_byte": 28993,
            "end_byte": 4
          },
          "_pytest.config.Config.get_terminal_writer": {
            "name": "_pytest.config.Config.get_terminal_writer",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def get_terminal_writer(self):\n        return self.pluginmanager.get_plugin(\"terminalreporter\")._tw",
            "start_line": 866,
            "start_column": 29292,
            "end_line": 4,
            "end_column": 29391,
            "start_byte": 29292,
            "end_byte": 4
          },
          "_pytest.config.Config.pytest_cmdline_parse": {
            "name": "_pytest.config.Config.pytest_cmdline_parse",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def pytest_cmdline_parse(self, pluginmanager, args):\n        try:\n            self.parse(args)\n        except UsageError:\n\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"version\", False) or \"--version\" in args:\n                from _pytest.helpconfig import showversion\n\n                showversion(self)\n            elif (\n                getattr(self.option, \"help\", False) or \"--help\" in args or \"-h\" in args\n            ):\n                self._parser._getparser().print_help()\n                sys.stdout.write(\n                    \"\\nNOTE: displaying only minimal help due to UsageError.\\n\\n\"\n                )\n\n            raise\n\n        return self",
            "start_line": 869,
            "start_column": 29397,
            "end_line": 4,
            "end_column": 30240,
            "start_byte": 29397,
            "end_byte": 4
          },
          "_pytest.config.Config.notify_exception": {
            "name": "_pytest.config.Config.notify_exception",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def notify_exception(self, excinfo, option=None):\n        if option and getattr(option, \"fulltrace\", False):\n            style = \"long\"\n        else:\n            style = \"native\"\n        excrepr = excinfo.getrepr(\n            funcargs=True, showlocals=getattr(option, \"showlocals\", False), style=style\n        )\n        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\n        if not any(res):\n            for line in str(excrepr).split(\"\\n\"):\n                sys.stderr.write(\"INTERNALERROR> %s\\n\" % line)\n                sys.stderr.flush()",
            "start_line": 893,
            "start_column": 30246,
            "end_line": 4,
            "end_column": 30809,
            "start_byte": 30246,
            "end_byte": 4
          },
          "_pytest.config.Config.cwd_relative_nodeid": {
            "name": "_pytest.config.Config.cwd_relative_nodeid",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def cwd_relative_nodeid(self, nodeid):\n        # nodeid's are relative to the rootpath, compute relative to cwd\n        if self.invocation_dir != self.rootdir:\n            fullpath = self.rootdir.join(nodeid)\n            nodeid = self.invocation_dir.bestrelpath(fullpath)\n        return nodeid",
            "start_line": 907,
            "start_column": 30815,
            "end_line": 4,
            "end_column": 31108,
            "start_byte": 30815,
            "end_byte": 4
          },
          "_pytest.config.Config.fromdictargs": {
            "name": "_pytest.config.Config.fromdictargs",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@classmethod\n    def fromdictargs(cls, option_dict, args):\n        \"\"\" constructor usable for subprocesses. \"\"\"\n        config = get_config(args)\n        config.option.__dict__.update(option_dict)\n        config.parse(args, addopts=False)\n        for x in config.option.plugins:\n            config.pluginmanager.consider_pluginarg(x)\n        return config",
            "start_line": 914,
            "start_column": 31114,
            "end_line": 4,
            "end_column": 31469,
            "start_byte": 31114,
            "end_byte": 4
          },
          "_pytest.config.Config._processopt": {
            "name": "_pytest.config.Config._processopt",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _processopt(self, opt: \"Argument\") -> None:\n        for name in opt._short_opts + opt._long_opts:\n            self._opt2dest[name] = opt.dest\n\n        if hasattr(opt, \"default\"):\n            if not hasattr(self.option, opt.dest):\n                setattr(self.option, opt.dest, opt.default)",
            "start_line": 924,
            "start_column": 31475,
            "end_line": 4,
            "end_column": 31768,
            "start_byte": 31475,
            "end_byte": 4
          },
          "_pytest.config.Config.pytest_load_initial_conftests": {
            "name": "_pytest.config.Config.pytest_load_initial_conftests",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "@hookimpl(trylast=True)\n    def pytest_load_initial_conftests(self, early_config):\n        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)",
            "start_line": 932,
            "start_column": 31774,
            "end_line": 4,
            "end_column": 31941,
            "start_byte": 31774,
            "end_byte": 4
          },
          "_pytest.config.Config._initini": {
            "name": "_pytest.config.Config._initini",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _initini(self, args: Sequence[str]) -> None:\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(\n            args, namespace=copy.copy(self.option)\n        )\n        r = determine_setup(\n            ns.inifilename,\n            ns.file_or_dir + unknown_args,\n            rootdir_cmd_arg=ns.rootdir or None,\n            config=self,\n        )\n        self.rootdir, self.inifile, self.inicfg = r\n        self._parser.extra_info[\"rootdir\"] = self.rootdir\n        self._parser.extra_info[\"inifile\"] = self.inifile\n        self._parser.addini(\"addopts\", \"extra command line options\", \"args\")\n        self._parser.addini(\"minversion\", \"minimally required pytest version\")\n        self._override_ini = ns.override_ini or ()",
            "start_line": 936,
            "start_column": 31947,
            "end_line": 4,
            "end_column": 32684,
            "start_byte": 31947,
            "end_byte": 4
          },
          "_pytest.config.Config._consider_importhook": {
            "name": "_pytest.config.Config._consider_importhook",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook)\n        _warn_about_missing_assertion(mode)",
            "start_line": 953,
            "start_column": 32690,
            "end_line": 4,
            "end_column": 33458,
            "start_byte": 32690,
            "end_byte": 4
          },
          "_pytest.config.Config._mark_plugins_for_rewrite": {
            "name": "_pytest.config.Config._mark_plugins_for_rewrite",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _mark_plugins_for_rewrite(self, hook):\n        \"\"\"\n        Given an importhook, mark for rewrite any top-level\n        modules or packages in the distribution package for\n        all pytest plugins.\n        \"\"\"\n        self.pluginmanager.rewrite_hook = hook\n\n        if os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # We don't autoload from setuptools entry points, no need to continue.\n            return\n\n        package_files = (\n            str(file)\n            for dist in importlib_metadata.distributions()\n            if any(ep.group == \"pytest11\" for ep in dist.entry_points)\n            for file in dist.files or []\n        )\n\n        for name in _iter_rewritable_modules(package_files):\n            hook.mark_rewrite(name)",
            "start_line": 973,
            "start_column": 33464,
            "end_line": 4,
            "end_column": 34217,
            "start_byte": 33464,
            "end_byte": 4
          },
          "_pytest.config.Config._validate_args": {
            "name": "_pytest.config.Config._validate_args",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _validate_args(self, args: List[str], via: str) -> List[str]:\n        \"\"\"Validate known args.\"\"\"\n        self._parser._config_source_hint = via  # type: ignore\n        try:\n            self._parser.parse_known_and_unknown_args(\n                args, namespace=copy.copy(self.option)\n            )\n        finally:\n            del self._parser._config_source_hint  # type: ignore\n\n        return args",
            "start_line": 995,
            "start_column": 34223,
            "end_line": 4,
            "end_column": 34626,
            "start_byte": 34223,
            "end_byte": 4
          },
          "_pytest.config.Config._preparse": {
            "name": "_pytest.config.Config._preparse",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _preparse(self, args: List[str], addopts: bool = True) -> None:\n        if addopts:\n            env_addopts = os.environ.get(\"PYTEST_ADDOPTS\", \"\")\n            if len(env_addopts):\n                args[:] = (\n                    self._validate_args(shlex.split(env_addopts), \"via PYTEST_ADDOPTS\")\n                    + args\n                )\n        self._initini(args)\n        if addopts:\n            args[:] = (\n                self._validate_args(self.getini(\"addopts\"), \"via addopts config\") + args\n            )\n\n        self._checkversion()\n        self._consider_importhook(args)\n        self.pluginmanager.consider_preparse(args, exclude_only=False)\n        if not os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # Don't autoload from setuptools entry point. Only explicitly specified\n            # plugins are going to be loaded.\n            self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\n        self.pluginmanager.consider_env()\n        self.known_args_namespace = ns = self._parser.parse_known_args(\n            args, namespace=copy.copy(self.option)\n        )\n        if self.known_args_namespace.confcutdir is None and self.inifile:\n            confcutdir = py.path.local(self.inifile).dirname\n            self.known_args_namespace.confcutdir = confcutdir\n        try:\n            self.hook.pytest_load_initial_conftests(\n                early_config=self, args=args, parser=self._parser\n            )\n        except ConftestImportFailure as e:\n            if ns.help or ns.version:\n                # we don't want to prevent --help/--version to work\n                # so just let is pass and print a warning at the end\n                from _pytest.warnings import _issue_warning_captured\n\n                _issue_warning_captured(\n                    PytestConfigWarning(\n                        \"could not load initial conftests: {}\".format(e.path)\n                    ),\n                    self.hook,\n                    stacklevel=2,\n                )\n            else:\n                raise",
            "start_line": 1007,
            "start_column": 34632,
            "end_line": 4,
            "end_column": 36670,
            "start_byte": 34632,
            "end_byte": 4
          },
          "_pytest.config.Config._checkversion": {
            "name": "_pytest.config.Config._checkversion",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _checkversion(self):\n        import pytest\n\n        minver = self.inicfg.get(\"minversion\", None)\n        if minver:\n            # Imported lazily to improve start-up time.\n            from packaging.version import Version\n\n            if Version(minver) > Version(pytest.__version__):\n                raise pytest.UsageError(\n                    \"%s:%d: requires pytest-%s, actual pytest-%s'\"\n                    % (\n                        self.inicfg.config.path,\n                        self.inicfg.lineof(\"minversion\"),\n                        minver,\n                        pytest.__version__,\n                    )\n                )",
            "start_line": 1055,
            "start_column": 36676,
            "end_line": 4,
            "end_column": 37319,
            "start_byte": 36676,
            "end_byte": 4
          },
          "_pytest.config.Config.parse": {
            "name": "_pytest.config.Config.parse",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def parse(self, args: List[str], addopts: bool = True) -> None:\n        # parse given cmdline arguments into this config object.\n        assert not hasattr(\n            self, \"args\"\n        ), \"can only parse cmdline args at most once per Config object\"\n        self.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=self.pluginmanager)\n        )\n        self._preparse(args, addopts=addopts)\n        # XXX deprecated hook:\n        self.hook.pytest_cmdline_preparse(config=self, args=args)\n        self._parser.after_preparse = True  # type: ignore\n        try:\n            args = self._parser.parse_setoption(\n                args, self.option, namespace=self.option\n            )\n            if not args:\n                if self.invocation_dir == self.rootdir:\n                    args = self.getini(\"testpaths\")\n                if not args:\n                    args = [str(self.invocation_dir)]\n            self.args = args\n        except PrintHelp:\n            pass",
            "start_line": 1074,
            "start_column": 37325,
            "end_line": 4,
            "end_column": 38318,
            "start_byte": 37325,
            "end_byte": 4
          },
          "_pytest.config.Config.addinivalue_line": {
            "name": "_pytest.config.Config.addinivalue_line",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def addinivalue_line(self, name, line):\n        \"\"\" add a line to an ini-file option. The option must have been\n        declared but might not yet be set in which case the line becomes the\n        the first line in its value. \"\"\"\n        x = self.getini(name)\n        assert isinstance(x, list)\n        x.append(line)  # modifies the cached list inline",
            "start_line": 1099,
            "start_column": 38324,
            "end_line": 4,
            "end_column": 38676,
            "start_byte": 38324,
            "end_byte": 4
          },
          "_pytest.config.Config.getini": {
            "name": "_pytest.config.Config.getini",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getini(self, name: str):\n        \"\"\" return configuration value from an :ref:`ini file <inifiles>`. If the\n        specified name hasn't been registered through a prior\n        :py:func:`parser.addini <_pytest.config.argparsing.Parser.addini>`\n        call (usually from a plugin), a ValueError is raised. \"\"\"\n        try:\n            return self._inicache[name]\n        except KeyError:\n            self._inicache[name] = val = self._getini(name)\n            return val",
            "start_line": 1107,
            "start_column": 38682,
            "end_line": 4,
            "end_column": 39156,
            "start_byte": 38682,
            "end_byte": 4
          },
          "_pytest.config.Config._getini": {
            "name": "_pytest.config.Config._getini",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _getini(self, name: str) -> Any:\n        try:\n            description, type, default = self._parser._inidict[name]\n        except KeyError:\n            raise ValueError(\"unknown configuration value: {!r}\".format(name))\n        value = self._get_override_ini_value(name)\n        if value is None:\n            try:\n                value = self.inicfg[name]\n            except KeyError:\n                if default is not None:\n                    return default\n                if type is None:\n                    return \"\"\n                return []\n        if type == \"pathlist\":\n            dp = py.path.local(self.inicfg.config.path).dirpath()\n            values = []\n            for relpath in shlex.split(value):\n                values.append(dp.join(relpath, abs=True))\n            return values\n        elif type == \"args\":\n            return shlex.split(value)\n        elif type == \"linelist\":\n            return [t for t in map(lambda x: x.strip(), value.split(\"\\n\")) if t]\n        elif type == \"bool\":\n            return bool(_strtobool(value.strip()))\n        else:\n            assert type is None\n            return value",
            "start_line": 1118,
            "start_column": 39162,
            "end_line": 4,
            "end_column": 40297,
            "start_byte": 39162,
            "end_byte": 4
          },
          "_pytest.config.Config._getconftest_pathlist": {
            "name": "_pytest.config.Config._getconftest_pathlist",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _getconftest_pathlist(self, name, path):\n        try:\n            mod, relroots = self.pluginmanager._rget_with_confmod(name, path)\n        except KeyError:\n            return None\n        modpath = py.path.local(mod.__file__).dirpath()\n        values = []\n        for relroot in relroots:\n            if not isinstance(relroot, py.path.local):\n                relroot = relroot.replace(\"/\", py.path.local.sep)\n                relroot = modpath.join(relroot, abs=True)\n            values.append(relroot)\n        return values",
            "start_line": 1149,
            "start_column": 40303,
            "end_line": 4,
            "end_column": 40832,
            "start_byte": 40303,
            "end_byte": 4
          },
          "_pytest.config.Config._get_override_ini_value": {
            "name": "_pytest.config.Config._get_override_ini_value",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def _get_override_ini_value(self, name: str) -> Optional[str]:\n        value = None\n        # override_ini is a list of \"ini=value\" options\n        # always use the last item if multiple values are set for same ini-name,\n        # e.g. -o foo=bar1 -o foo=bar2 will set foo to bar2\n        for ini_config in self._override_ini:\n            try:\n                key, user_ini_value = ini_config.split(\"=\", 1)\n            except ValueError:\n                raise UsageError(\n                    \"-o/--override-ini expects option=value style (got: {!r}).\".format(\n                        ini_config\n                    )\n                )\n            else:\n                if key == name:\n                    value = user_ini_value\n        return value",
            "start_line": 1163,
            "start_column": 40838,
            "end_line": 4,
            "end_column": 41586,
            "start_byte": 40838,
            "end_byte": 4
          },
          "_pytest.config.Config.getoption": {
            "name": "_pytest.config.Config.getoption",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getoption(self, name: str, default=notset, skip: bool = False):\n        \"\"\" return command line option value.\n\n        :arg name: name of the option.  You may also specify\n            the literal ``--OPT`` option instead of the \"dest\" option name.\n        :arg default: default value if no option of that name exists.\n        :arg skip: if True raise pytest.skip if option does not exists\n            or has a None value.\n        \"\"\"\n        name = self._opt2dest.get(name, name)\n        try:\n            val = getattr(self.option, name)\n            if val is None and skip:\n                raise AttributeError(name)\n            return val\n        except AttributeError:\n            if default is not notset:\n                return default\n            if skip:\n                import pytest\n\n                pytest.skip(\"no {!r} option found\".format(name))\n            raise ValueError(\"no option named {!r}\".format(name))",
            "start_line": 1182,
            "start_column": 41592,
            "end_line": 4,
            "end_column": 42519,
            "start_byte": 41592,
            "end_byte": 4
          },
          "_pytest.config.Config.getvalue": {
            "name": "_pytest.config.Config.getvalue",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getvalue(self, name, path=None):\n        \"\"\" (deprecated, use getoption()) \"\"\"\n        return self.getoption(name)",
            "start_line": 1206,
            "start_column": 42525,
            "end_line": 4,
            "end_column": 42643,
            "start_byte": 42525,
            "end_byte": 4
          },
          "_pytest.config.Config.getvalueorskip": {
            "name": "_pytest.config.Config.getvalueorskip",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "def getvalueorskip(self, name, path=None):\n        \"\"\" (deprecated, use getoption(skip=True)) \"\"\"\n        return self.getoption(name, skip=True)",
            "start_line": 1210,
            "start_column": 42649,
            "end_line": 4,
            "end_column": 42793,
            "start_byte": 42649,
            "end_byte": 4
          },
          "_pytest.warning_types.PytestConfigWarning": {
            "name": "_pytest.warning_types.PytestConfigWarning",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "r\n\nimport _pytest._code\nimport _pytest.deprecated\nimport _pytest.hookspec  # the extension point definitions\nfrom .excep",
            "start_line": 30,
            "start_column": 617,
            "end_line": 0,
            "end_column": 737,
            "start_byte": 617,
            "end_byte": 0
          },
          "_pytest.warning_types.PytestConfigWarning.__module__": {
            "name": "_pytest.warning_types.PytestConfigWarning.__module__",
            "file_path": "src/_pytest/config/__init__.py",
            "file_content": "finitions\nfrom .excep",
            "start_line": 33,
            "start_column": 716,
            "end_line": 4,
            "end_column": 737,
            "start_byte": 716,
            "end_byte": 4
          },
          "_pytest.monkeypatch.MonkeyPatch.chdir": {
            "name": "_pytest.monkeypatch.MonkeyPatch.chdir",
            "file_path": "src/_pytest/monkeypatch.py",
            "file_content": "def chdir(self, path):\n        \"\"\" Change the current working directory to the specified path.\n        Path can be a string or a py.path.local object.\n        \"\"\"\n        if self._cwd is None:\n            self._cwd = os.getcwd()\n        if hasattr(path, \"chdir\"):\n            path.chdir()\n        elif isinstance(path, Path):\n            # modern python uses the fspath protocol here LEGACY\n            os.chdir(str(path))\n        else:\n            os.chdir(path)",
            "start_line": 274,
            "start_column": 9526,
            "end_line": 4,
            "end_column": 9989,
            "start_byte": 9526,
            "end_byte": 4
          },
          "_pytest.monkeypatch.MonkeyPatch.undo": {
            "name": "_pytest.monkeypatch.MonkeyPatch.undo",
            "file_path": "src/_pytest/monkeypatch.py",
            "file_content": "def undo(self):\n        \"\"\" Undo previous changes.  This call consumes the\n        undo stack. Calling it a second time has no effect unless\n        you do more monkeypatching after the undo call.\n\n        There is generally no need to call `undo()`, since it is\n        called automatically during tear-down.\n\n        Note that the same `monkeypatch` fixture is used across a\n        single test function invocation. If `monkeypatch` is used both by\n        the test function itself and one of the test fixtures,\n        calling `undo()` will undo all of the changes made in\n        both functions.\n        \"\"\"\n        for obj, name, value in reversed(self._setattr):\n            if value is not notset:\n                setattr(obj, name, value)\n            else:\n                delattr(obj, name)\n        self._setattr[:] = []\n        for dictionary, name, value in reversed(self._setitem):\n            if value is notset:\n                try:\n                    del dictionary[name]\n                except KeyError:\n                    pass  # was already deleted, so we have the desired state\n            else:\n                dictionary[name] = value\n        self._setitem[:] = []\n        if self._savesyspath is not None:\n            sys.path[:] = self._savesyspath\n            self._savesyspath = None\n\n        if self._cwd is not None:\n            os.chdir(self._cwd)\n            self._cwd = None",
            "start_line": 288,
            "start_column": 9995,
            "end_line": 4,
            "end_column": 11401,
            "start_byte": 9995,
            "end_byte": 4
          },
          "_pytest.terminal.TerminalReporter._locationline": {
            "name": "_pytest.terminal.TerminalReporter._locationline",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \"",
            "start_line": 776,
            "start_column": 27160,
            "end_line": 4,
            "end_column": 27982,
            "start_byte": 27160,
            "end_byte": 4
          },
          "_pytest.nodes.Node._repr_failure_py": {
            "name": "_pytest.nodes.Node._repr_failure_py",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def _repr_failure_py(\n        self, excinfo: ExceptionInfo[BaseException], style=None,\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        if isinstance(excinfo.value, ConftestImportFailure):\n            excinfo = ExceptionInfo(excinfo.value.excinfo)\n        if isinstance(excinfo.value, fail.Exception):\n            if not excinfo.value.pytrace:\n                style = \"value\"\n        if isinstance(excinfo.value, FixtureLookupError):\n            return excinfo.value.formatrepr()\n        if self.config.getoption(\"fulltrace\", False):\n            style = \"long\"\n        else:\n            tb = _pytest._code.Traceback([excinfo.traceback[-1]])\n            self._prunetraceback(excinfo)\n            if len(excinfo.traceback) == 0:\n                excinfo.traceback = tb\n            if style == \"auto\":\n                style = \"long\"\n        # XXX should excinfo.getrepr record all data and toterminal() process it?\n        if style is None:\n            if self.config.getoption(\"tbstyle\", \"auto\") == \"short\":\n                style = \"short\"\n            else:\n                style = \"long\"\n\n        if self.config.getoption(\"verbose\", 0) > 1:\n            truncate_locals = False\n        else:\n            truncate_locals = True\n\n        try:\n            os.getcwd()\n            abspath = False\n        except OSError:\n            abspath = True\n\n        return excinfo.getrepr(\n            funcargs=True,\n            abspath=abspath,\n            showlocals=self.config.getoption(\"showlocals\", False),\n            style=style,\n            tbfilter=False,  # pruned already, or in --fulltrace mode.\n            truncate_locals=truncate_locals,\n        )",
            "start_line": 332,
            "start_column": 10806,
            "end_line": 4,
            "end_column": 12496,
            "start_byte": 10806,
            "end_byte": 4
          },
          "_pytest.nodes.Node.repr_failure": {
            "name": "_pytest.nodes.Node.repr_failure",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def repr_failure(\n        self, excinfo, style=None\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        \"\"\"\n        Return a representation of a collection or test failure.\n\n        :param excinfo: Exception information for the failure.\n        \"\"\"\n        return self._repr_failure_py(excinfo, style)",
            "start_line": 378,
            "start_column": 12502,
            "end_line": 4,
            "end_column": 12843,
            "start_byte": 12502,
            "end_byte": 4
          },
          "_pytest.nodes.get_fslocation_from_item": {
            "name": "_pytest.nodes.get_fslocation_from_item",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def get_fslocation_from_item(\n    item: \"Item\",\n) -> Tuple[Union[str, py.path.local], Optional[int]]:\n    \"\"\"Tries to extract the actual location from an item, depending on available attributes:\n\n    * \"fslocation\": a pair (path, lineno)\n    * \"obj\": a Python object that the item wraps.\n    * \"fspath\": just a path\n\n    :rtype: a tuple of (str|LocalPath, int) with filename and line number.\n    \"\"\"\n    try:\n        return item.location[:2]\n    except AttributeError:\n        pass\n    obj = getattr(item, \"obj\", None)\n    if obj is not None:\n        return getfslineno(obj)\n    return getattr(item, \"fspath\", \"unknown location\"), -1",
            "start_line": 389,
            "start_column": 12846,
            "end_line": 0,
            "end_column": 13479,
            "start_byte": 12846,
            "end_byte": 0
          }
        }
      }
    }
  ]
}