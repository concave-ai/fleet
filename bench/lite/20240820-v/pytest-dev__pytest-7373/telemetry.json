{
  "total_cost": 0,
  "task_id": "pytest-dev__pytest-7373",
  "model": "gpt-4o-2024-08-06",
  "spans": [
    {
      "name": "KeywordExtract",
      "metadata": {
        "start": "2024-08-19T13:34:42.189897",
        "usage": "1266.1759853363037 ms"
      },
      "request": {
        "repo_tokens": [
          "summary_passes",
          "Cache",
          "summary_failures",
          "visit_Name",
          "fixturenames",
          "push_format_context",
          "extract_suffixes",
          "extraline",
          "processoption",
          "fnmatch_lines",
          "reprfileloc",
          "_fixturemanager",
          "LogCaptureHandler",
          "append_collect_error",
          "_read_pyc",
          "getpluginversioninfo",
          "typename",
          "cacheprovider",
          "summary_errors",
          "_plugin_nameversions",
          "ids",
          "append_collect_skipped",
          "exit",
          "traceback",
          "_consider_importhook",
          "_validate_args",
          "delattr",
          "filter_traceback_for_conftest_import_failure",
          "CallInfo",
          "write_fspath_result",
          "CLOSE_STDIN",
          "cwd_relative_nodeid",
          "mkdir",
          "getpathnode",
          "obj",
          "_parse_ini_config",
          "pytest_warning_captured",
          "_import_plugin_specs",
          "plugins",
          "_given_basetemp",
          "addSkip",
          "add_global_property",
          "store_mark",
          "resultlog",
          "OutcomeException",
          "parseconfig",
          "_format_args",
          "_ensure_basetemp",
          "_surrounding_parens_on_own_lines",
          "runpytest",
          "builtin_plugins",
          "writer",
          "DOCTEST_REPORT_CHOICE_NDIFF",
          "_getnextfixturedef",
          "_get_allow_unicode_flag",
          "check_interactive_exception",
          "id",
          "reprtraceback",
          "getitems",
          "pastebin",
          "capsys",
          "NFPlugin",
          "approx",
          "store",
          "deselect_by_keyword",
          "_early_rewrite_bailout",
          "_get_increasing_order",
          "_collect",
          "_FixtureValue",
          "safeformat",
          "_determine_show_progress_info",
          "pytest_sessionstart",
          "writeorg",
          "_translate_non_printable",
          "cleanup_numbered_dir",
          "is_rewrite_disabled",
          "_no_match_line",
          "_get_plugin_specs_as_list",
          "_rewrite_test",
          "_assertion_supported",
          "consider_module",
          "Failed",
          "V",
          "_ensure_supporting_files",
          "pathlib",
          "terminal",
          "PytestPluginManager",
          "buffer",
          "pytest_runtest_call",
          "TEST_OUTCOME",
          "_compilecounter",
          "suspend_global_capture",
          "SysCaptureBinary",
          "prepend",
          "get_lines_after",
          "pytest_internalerror",
          "pytestPDB",
          "runtest",
          "getrawcode",
          "__str__",
          "Exit",
          "getlocation",
          "UsageError",
          "SetupState",
          "RE_IMPORT_ERROR_NAME",
          "match",
          "write_ensure_prefix",
          "from_parent",
          "_check_scope",
          "pytester",
          "_inject_setup_method_fixture",
          "_is_capturing",
          "Session",
          "_write_pyc_fp",
          "activate_fixture",
          "stream",
          "setenv",
          "_F",
          "IGNORE_PAM",
          "getexplanation",
          "_esctable",
          "pytest_report_collectionfinish",
          "classnamefilter",
          "args",
          "validate_basetemp",
          "assign",
          "get_plugin_manager",
          "MultipleDoctestFailures",
          "showlongtestinfo",
          "ReprLocals",
          "_matchnodes",
          "get_location",
          "_bestrelpath_cache",
          "expr",
          "catch_log_records_key",
          "NOTSET",
          "resolve_package_path",
          "_ET",
          "excinfo",
          "_ensure_relative_to_basetemp",
          "UnitTestCase",
          "fnmatch_lines_random",
          "LsofFdLeakChecker",
          "CallSpec2",
          "_iter_rewritable_modules",
          "raises",
          "_write_progress_information_filling_space",
          "addFailure",
          "cut",
          "readlines",
          "records",
          "pytest_assertrepr_compare",
          "getcrashentry",
          "is_async_function",
          "pytest_enter_pdb",
          "collect_one_node",
          "Module",
          "consider_conftest",
          "compile",
          "_try_repr_or_str",
          "reprcrash",
          "_config_for_test",
          "notset",
          "runpython_c",
          "_CACHE_PREFIX_VALUES",
          "pytest_pycollect_makeitem",
          "from_item",
          "frame",
          "getargs",
          "pytest_collectstart",
          "_checkversion",
          "set_when",
          "FDCapture",
          "_force_symlink",
          "countoutcomes",
          "scope",
          "CaptureIO",
          "__test__",
          "compile_",
          "_LiveLoggingStreamHandler",
          "_init_runner_class",
          "LFPluginCollWrapper",
          "ApproxBase",
          "_reprcompare",
          "pytest_warning_recorded",
          "_validate_usepdb_cls",
          "pytest_collection_modifyitems",
          "DEFAULT_ABSOLUTE_TOLERANCE",
          "_is_last_item",
          "getfixturevalue",
          "_make_xunit_fixture",
          "isdatacls",
          "_get_main_color",
          "pytest_collect_directory",
          "ExceptionRepr",
          "_getconftestmodules",
          "nofuncargs",
          "re_match_lines_random",
          "_matches_prefix_or_glob_option",
          "get_common_ancestor",
          "pop_format_context",
          "_color_for_type",
          "scope2index",
          "pytest_report_teststatus",
          "ReprFailDoctest",
          "PytestCollectionWarning",
          "_write_entry_lines",
          "NodeMeta",
          "_collectfile",
          "_dump_lines",
          "fix_cache_order",
          "CollectErrorRepr",
          "_for_parametrize",
          "_try_load_conftest",
          "SysModulesSnapshot",
          "fault_handler_stderr_key",
          "SubRequest",
          "_report_to_json",
          "HelpAction",
          "type",
          "pytest_fixture_post_finalizer",
          "python",
          "stop_global_capturing",
          "ImportPathMismatchError",
          "build_summary_stats_line",
          "visit_Starred",
          "reports",
          "extract_from",
          "Expression",
          "getreports",
          "mktemp",
          "initialnames",
          "matchnodes",
          "fileno",
          "families",
          "_format_assertmsg",
          "DEFAULT_RELATIVE_TOLERANCE",
          "isdict",
          "LogCaptureFixture",
          "fail",
          "_warn_already_imported",
          "context",
          "explanation_param",
          "mkpydir",
          "AssertionRewritingHook",
          "getoption",
          "from_call",
          "MoreQuietAction",
          "find_prefixed",
          "_PytestWrapper",
          "IDENT",
          "listextrakeywords",
          "getstatement",
          "template",
          "_AnyPurePath",
          "get_records",
          "maybe_delete_a_numbered_dir",
          "_call_assertion_pass",
          "_getscopeitem",
          "popen",
          "pytest_collect_file",
          "conftest_options",
          "getfixtureclosure",
          "readline",
          "Interrupted",
          "_has_param_ids",
          "_color_for_type_default",
          "TracebackEntry",
          "lines",
          "pytest_runtest_protocol",
          "record_tuples",
          "_assert_state",
          "istrue",
          "_teardown_towards",
          "summary_warnings",
          "_seen",
          "write_captured_output",
          "location",
          "_R",
          "_cachedir",
          "_resolve_arg_value_types",
          "done",
          "post_mortem",
          "pytest_deselected",
          "_NodeType",
          "__version__",
          "_approx_scalar",
          "NodeKeywords",
          "__setitem__",
          "skip",
          "_add_simple",
          "cached_eval",
          "_is_marked_for_rewrite",
          "for_later",
          "_update_current_test_var",
          "record_xml_attribute",
          "NotSetType",
          "SysCapture",
          "resolve_from_str",
          "PytestAssertRewriteWarning",
          "print_teardown_sections",
          "append_error",
          "_truncate_explanation",
          "funcargnames",
          "_folded_skips",
          "statement",
          "USAGE_ERROR",
          "start_capturing",
          "list",
          "_report_kwargs_from_json",
          "pytest_plugin_registered",
          "line",
          "helpconfig",
          "MarkEvaluator",
          "re_match_lines",
          "_ALLOW_MARKERS",
          "_write_content",
          "close",
          "PytestConfigWarning",
          "format",
          "_do_configure",
          "get_open_files",
          "call_runtest_hook",
          "node_reporter",
          "_get_stderr_fileno",
          "COLLECT_DIRECTORY_HOOK",
          "pytest_generate_tests",
          "_py_ext_re",
          "compat",
          "_getentrysource",
          "doctest",
          "rex_outcome",
          "_tmppath_factory",
          "Function",
          "get_parametrized_fixture_keys",
          "tmpdir_factory",
          "exec_module",
          "PyobjMixin",
          "ReprExceptionInfo",
          "_getcrashline",
          "determine_setup",
          "caplog",
          "UNARY_MAP",
          "visit_Assert",
          "isparseable",
          "pytest_make_collect_report",
          "pytest_keyboard_interrupt",
          "patchsysdict",
          "syspathinsert",
          "scopes",
          "get_user",
          "parse_setoption",
          "BaseReport",
          "warning_record_to_str",
          "_getvaluepath",
          "_main",
          "simple",
          "File",
          "CwdSnapshot",
          "visit_BinOp",
          "Junit",
          "HookRecorder",
          "LineMatcher",
          "pytest_collection",
          "console_main",
          "pytest_runtestloop",
          "_show_fixtures_per_test",
          "repr_instance",
          "show_test_item",
          "get_source",
          "getsource",
          "parse_known_and_unknown_args",
          "function",
          "_get_runner",
          "cleanup_candidates",
          "makefile",
          "setitem",
          "invocation_dir",
          "ApproxScalar",
          "start",
          "MODULE_NOT_FOUND_ERROR",
          "_handle_teardown_sections",
          "evalxfail_key",
          "capture",
          "add_funcarg_pseudo_fixture_def",
          "_expecting_failure",
          "importlib",
          "_get_verbose_word",
          "_create_formatter",
          "set_session",
          "get_lock_path",
          "eval",
          "_version",
          "_start",
          "_typ_map",
          "_ensure_unconfigure",
          "__version_tuple__",
          "chdir",
          "_update_message",
          "_node_location_to_relpath",
          "runner",
          "readouterr",
          "_postmortem_traceback",
          "node",
          "_initini",
          "teardown_exact",
          "get_default_arg_names",
          "format_session_duration",
          "junitxml",
          "illegal_xml_re",
          "cls",
          "xml_key",
          "repr_args",
          "spawn",
          "ReprEntry",
          "_exec_lsof",
          "Instance",
          "__dir__",
          "ReprEntryNative",
          "keywords",
          "STRING_TYPES",
          "_report_unserialization_failure",
          "_outrep_summary",
          "dir",
          "_recursive_debug",
          "module",
          "ReprTraceback",
          "NOT",
          "source",
          "_check_if_assertion_pass_impl",
          "resolve_fixture_function",
          "_get_teardown_reports",
          "reprlocals",
          "pytest_report_from_serializable",
          "pop_outerr_to_orig",
          "_log",
          "_showfixtures_main",
          "Class",
          "async_warn_and_skip",
          "reject",
          "wrap_function_to_error_out_if_called_directly",
          "FILLFUNCARGS",
          "DEFAULT_MAX_LINES",
          "LEVELNAME_FMT_REGEX",
          "consider_preparse",
          "to_xml",
          "_pytest",
          "PytestExperimentalApiWarning",
          "__call__",
          "handler",
          "_assertion_pass",
          "_truncate_recursive_traceback",
          "_repr_style",
          "_Markable",
          "_width_of_current_line",
          "ensure_deletable",
          "applymarker",
          "_find_spec",
          "_PLUGGY_DIR",
          "_pyfuncitem",
          "USAGE_MSG",
          "python_api",
          "_compare_eq_verbose",
          "prepare",
          "_import_pdb_cls",
          "TempdirFactory",
          "formatrepr",
          "assert_contains",
          "XFailed",
          "summary_stats",
          "_callfinalizers",
          "head_line",
          "idmaker",
          "_inject_setup_class_fixture",
          "set_repr_style",
          "_parsearg",
          "_ANSI_ESCAPE_SEQ",
          "_getindent",
          "iter_markers_with_node",
          "display",
          "EOF",
          "Node",
          "_printcollecteditems",
          "pytest_runtest_logstart",
          "_get_unknown_ini_keys",
          "add_property",
          "MarkDecorator",
          "maybe_wrap_pytest_function_for_tracing",
          "showlocals",
          "set_fixture",
          "_sys_snapshot",
          "register_assert_rewrite",
          "warning_types",
          "faulthandler",
          "_get_assertion_exprs",
          "directory_arg",
          "Package",
          "consider_env",
          "CHECKER_CLASS",
          "get_fslocation_from_item",
          "_strtobool",
          "rewrite",
          "showheader",
          "_get_override_ini_value",
          "__repr__",
          "getini",
          "_inject_setup_function_fixture",
          "helper",
          "unset_fixture",
          "istestfunction",
          "deactivate_fixture",
          "parse",
          "_running_on_ci",
          "_basetemp",
          "FastFilesCompleter",
          "showversion",
          "gethookproxy",
          "indent",
          "__getitem__",
          "get_empty_parameterset_mark",
          "log_outcome",
          "EncodedFile",
          "ihook",
          "prune_dependency_tree",
          "_importtestmodule",
          "no_header",
          "_get_checker",
          "_match_lines_random",
          "get_optionflags",
          "LogXML",
          "Skipped",
          "_set_main_color",
          "_compare_eq_set",
          "_is_skipped",
          "_should_repr_global_name",
          "pytest_exception_interact",
          "TestReport",
          "_init_pdb",
          "MultiCapture",
          "yield_fixture",
          "_resolve_arg_ids",
          "kwargs",
          "nodeid",
          "TestCaseFunction",
          "get_exconly",
          "get_last_failed_paths",
          "_preparse",
          "_mark_plugins_for_rewrite",
          "TokenType",
          "UnformattedWarning",
          "_parse_filter",
          "visit_Compare",
          "getfslineno",
          "reorder_items",
          "message",
          "__init__",
          "_issue_warning_captured",
          "visit_UnaryOp",
          "_is_numpy_array",
          "MINUS_K_COLON",
          "normalize_mark_list",
          "CFG_PYTEST_SECTION",
          "when",
          "_yield_comparisons",
          "isatty",
          "catch_warnings_for_item",
          "OK",
          "params",
          "_check_type",
          "ApproxMapping",
          "Source",
          "pytest_addoption",
          "parse_args",
          "pytest",
          "listchain",
          "get",
          "NoCapture",
          "_prepare_content",
          "timing",
          "_validate_plugins",
          "__all__",
          "listnames",
          "_finalize",
          "duration",
          "PYC_TAIL",
          "append",
          "hasopt",
          "getstatementrange_ast",
          "assert_contains_lines",
          "fill_unfilled",
          "unexpectedsuccess_key",
          "_set_opt_strings",
          "pytest_pycollect_makemodule",
          "_genfunctions",
          "_format",
          "catch_log_handler_key",
          "Config",
          "_readline_workaround",
          "from_current",
          "bin_xml_escape",
          "tmp_path_factory",
          "clear_cache",
          "_getpytestargs",
          "get_closest_marker",
          "_warn_or_fail_if_strict",
          "NO_TESTS_COLLECTED",
          "longrepr",
          "REPORT_COLLECTING_RESOLUTION",
          "__delitem__",
          "get_real_func",
          "SysPathsSnapshot",
          "_is_mocked",
          "try_makedirs",
          "T",
          "funcargs",
          "get_log_level_for_setting",
          "RaisesContext",
          "_setupstate",
          "matchreport",
          "set_location",
          "essential_plugins",
          "parsefactories",
          "_should_rewrite",
          "ImportMode",
          "prog",
          "update_testcase_duration",
          "DEFAULT_LOG_DATE_FORMAT",
          "linecomp",
          "pytest_collectreport",
          "mark_rewrite",
          "unittest",
          "FILE_OR_DIR",
          "_pformat_dispatch",
          "_getparser",
          "_call_with_optional_argument",
          "generic_visit",
          "_get_auto_indent",
          "ParseError",
          "_getfailureheadline",
          "skipped",
          "reprentries",
          "flush",
          "CaptureResult",
          "capfdbinary",
          "abspath",
          "register_cleanup_lock_removal",
          "find_spec",
          "EMPTY_BUFFER",
          "rm_rf",
          "NODE_USE_FROM_PARENT",
          "LPAREN",
          "DOCTEST_REPORT_CHOICES",
          "addSuccess",
          "old_mark_config_key",
          "istext",
          "safe_getattr",
          "get_scope_node",
          "addError",
          "AssertionState",
          "raiseerror",
          "assertoutcome",
          "pytest_pyfunc_call",
          "ishidden",
          "_show_fixture_action",
          "NoMatch",
          "getmodulecol",
          "_getglobals",
          "_perform_collect",
          "getreportopt",
          "DummyRewriteHook",
          "_check_all_skipped",
          "cacheshow",
          "Exception",
          "pytest_configure",
          "copy_example",
          "_check_initialpaths_for_relpath",
          "_recurse",
          "WarningsRecorder",
          "xfail",
          "_getini",
          "_runtest_for",
          "symlink_or_skip",
          "FakeCollectModule",
          "logging",
          "_highlight",
          "warn",
          "_pop_and_teardown",
          "run",
          "hookspec",
          "Item",
          "report_collect",
          "spawn_pytest",
          "messages",
          "_FixtureCachedResult",
          "name2fixturedefs",
          "fslocation",
          "_state",
          "ExitCode",
          "astcache",
          "_validate_keys",
          "_FixtureFunc",
          "addoption",
          "reportinfo",
          "finish_recording",
          "repr",
          "ReprTracebackNative",
          "inline_runsource",
          "fromdictargs",
          "_get_direct_parametrize_args",
          "check_strict_xfail",
          "cmdline",
          "annotated_getattr",
          "get_unpacked_marks",
          "runpytest_inprocess",
          "capstdout",
          "_resume",
          "getfixturedefs",
          "__array_ufunc__",
          "setupplan",
          "strip",
          "makepyprojecttoml",
          "start_global_capturing",
          "pytest_leave_pdb",
          "_markers",
          "getparent",
          "_idval",
          "PYTESTER_COPY_EXAMPLE",
          "_with_exception",
          "Traceback",
          "issequence",
          "LFPluginCollSkipfiles",
          "safe_isclass",
          "deselect_by_mark",
          "get_scope_package",
          "scope2props",
          "ensure_reset_dir",
          "TerminalWriter",
          "MarkGenerator",
          "pastebinfile_key",
          "ApproxSequencelike",
          "ExceptionChainRepr",
          "exconly",
          "_assert_expr_to_lineno",
          "pytest_terminal_summary",
          "wrap_session",
          "LOGLEVEL_COLOROPTS",
          "delenv",
          "finish",
          "_in_venv",
          "collect_by_name",
          "repr_traceback",
          "getplugin",
          "showfixtures",
          "config",
          "getinicfg",
          "_get_pdb_wrapper_class",
          "add_cleanup",
          "assert_outcomes",
          "_colorama_workaround",
          "cached_result",
          "builtin",
          "warns",
          "addExpectedFailure",
          "_truncate_by_char_count",
          "record_property",
          "TimeoutExpired",
          "__enter__",
          "_idvalset",
          "_format_repr_exception",
          "newinstance",
          "getparam",
          "_PluggyPlugin",
          "PrintHelp",
          "_makepath",
          "rewrite_asserts",
          "fillfixtures",
          "INTERRUPTED",
          "visit_Call",
          "DoctestTextfile",
          "no_re_match_line",
          "showfspath",
          "WARNING_CAPTURED_HOOK",
          "recursionindex",
          "_get_number_flag",
          "_CACHE_PREFIX_DIRS",
          "consider_pluginarg",
          "_parse_parametrize_parameters",
          "make_numbered_dir",
          "deprecated_call",
          "filter",
          "_saferepr",
          "_inject_setup_teardown_fixtures",
          "version_tuple",
          "toterminal",
          "global_and_fixture_disabled",
          "repr_excinfo",
          "execute",
          "DEPRECATED_EXTERNAL_PLUGINS",
          "create_module",
          "getfirstlinesource",
          "DEFAULT_MAX_CHARS",
          "inline_genitems",
          "_WithException",
          "DontReadFromInput",
          "write",
          "BINOP_MAP",
          "addsection",
          "pytest_unconfigure",
          "_Key",
          "FixtureRequest",
          "findsource",
          "runpytest_subprocess",
          "delitem",
          "param",
          "_getlines",
          "getnode",
          "_PY_DIR",
          "with_args",
          "truncate_locals",
          "make_hook_recorder",
          "_factorytraceback",
          "Store",
          "PdbInvoke",
          "_rget_with_confmod",
          "exprinfo",
          "ensure_extended_length_path",
          "RunResult",
          "FixtureLookupError",
          "DOCTEST_REPORT_CHOICE_CDIFF",
          "TeeCaptureIO",
          "visit_Attribute",
          "_bytes_to_ascii",
          "markname",
          "_getautousenames",
          "_legal_xml_re",
          "InvocationParams",
          "skipping",
          "is_globally_capturing",
          "_non_printable_ascii_translate_table",
          "get_timeout_config_value",
          "PYTEST_TAG",
          "isnosetest",
          "no_summary",
          "find_suffixes",
          "copy",
          "pytest_addhooks",
          "_FileHandler",
          "make_properties_node",
          "CaptureFixture",
          "_py36_windowsconsoleio_workaround",
          "_code",
          "create_cleanup_lock",
          "no_fnmatch_line",
          "write_line",
          "pytest_cmdline_main",
          "teardown_all",
          "LOCK_TIMEOUT",
          "get_extended_length_path_str",
          "_result",
          "_compare_eq_cls",
          "KNOWN_TYPES",
          "sections",
          "assertstate_key",
          "repr_traceback_entry",
          "TERMINALWRITER_WRITER",
          "_write_report_lines_from_hooks",
          "isinitpath",
          "_addfinalizer",
          "fspath",
          "_fail",
          "set_level",
          "PytestArg",
          "_gethookproxy",
          "collect",
          "_validate_if_using_arg_names",
          "is_generator",
          "_names",
          "PyCollector",
          "ReprFileLocation",
          "filename_arg",
          "evaluate",
          "SEP",
          "getfuncargnames",
          "call_optional",
          "get_statement_startend2",
          "COLLECT_FAKEMODULE_ATTRIBUTES",
          "get_option_ini",
          "is_capturing",
          "FaultHandlerHooks",
          "from_item_and_call",
          "_striptext",
          "addUnexpectedSuccess",
          "resolve",
          "pytest_report_to_serializable",
          "ResultLog",
          "and_expr",
          "wrap_pytest_function_for_tracing",
          "pytest_runtest_setup",
          "isset",
          "rex_session_duration",
          "getrepr",
          "FUNCARGNAMES",
          "PytestUnhandledCoroutineWarning",
          "version",
          "reprfuncargs",
          "_getobj",
          "FixtureManager",
          "on_rm_rf_error",
          "PytestCacheWarning",
          "_compare_eq_sequence",
          "scopename2class",
          "JUNIT_XML_DEFAULT_FAMILY",
          "_NodeReporter",
          "teardown_nose",
          "finalize",
          "runpython",
          "setuponly",
          "deprecated",
          "_init_checker_class",
          "resume_global_capture",
          "scopeproperty",
          "REGEX_TYPE",
          "ensure_newline",
          "__take_sys_modules_snapshot",
          "import_plugin",
          "getcalls",
          "is_true",
          "makeini",
          "setup",
          "load_config_dict_from_file",
          "_parse_lsof_output",
          "getfixturemarker",
          "_argcomplete",
          "pytest_runtest_logfinish",
          "tmp_path",
          "addinivalue_line",
          "addfinalizer",
          "_find_parametrized_scope",
          "_ellipsize",
          "MARK_GEN",
          "write_log_entry",
          "_disable_output_capturing_for_darwin",
          "encoding",
          "setmulti2",
          "__hash__",
          "StoreKey",
          "create_terminal_writer",
          "_iter_all_modules",
          "getvalueorskip",
          "RESULT_LOG",
          "Token",
          "TYPE_CHECKING",
          "filter_traceback",
          "getfailedcollections",
          "Frame",
          "get_cache_dir",
          "for_config",
          "__attrs_post_init__",
          "resume_fixture",
          "_wrapped_pdb_cls",
          "DEFAULT_LOG_FORMAT",
          "parametrize",
          "ReprFuncArgs",
          "_compare_eq_dict",
          "teardown",
          "__ne__",
          "listoutcomes",
          "_get_report_choice",
          "ParsedCall",
          "_locationline",
          "passed",
          "MonkeyPatch",
          "register",
          "exitstatus",
          "FuncFixtureInfo",
          "AssertionRewriter",
          "tbfilter",
          "install_importhook",
          "parseconfigure",
          "_addexcinfo",
          "__array_priority__",
          "saferepr",
          "getmodpath",
          "stopTest",
          "read",
          "__next__",
          "showhelp",
          "_E",
          "runitem",
          "pytest_ignore_collect",
          "gethookrecorder",
          "verbosity",
          "wcswidth",
          "longreprtext",
          "mode",
          "append_pass",
          "is_potential_nosetest",
          "perform_collect",
          "FixtureFunctionMarker",
          "_notin_text",
          "_split_lines",
          "__contains__",
          "_prepareconfig",
          "try_cleanup",
          "mangle_test_address",
          "_format_boolop",
          "PytestDeprecationWarning",
          "not_expr",
          "pytest_cmdline_parse",
          "_assert_start_repr",
          "monkeypatch",
          "_format_action_invocation",
          "set_trace",
          "argnames",
          "_log_text",
          "CollectReport",
          "_params_converter",
          "WarningReport",
          "getimfunc",
          "add_stats",
          "FunctionDefinition",
          "_warn_about_missing_assertion",
          "genitems",
          "getworkerinfoline",
          "stop_capturing",
          "_FixtureFunction",
          "reorder_items_atscope",
          "section",
          "autouse",
          "_excinfo",
          "_param_ids_from",
          "from_exc_info",
          "parseoutcomes",
          "_get_first_non_fixture_func",
          "relline",
          "pytest_sessionfinish",
          "Mark",
          "ischildnode",
          "import_path",
          "_diff_text",
          "parse_num",
          "exec_",
          "_should_truncate_item",
          "_eval_scope_callable",
          "main",
          "setdefault",
          "fail_marker",
          "read_global_capture",
          "FDCaptureBinary",
          "get_terminal_writer",
          "handleError",
          "get_sections",
          "hasplugin",
          "_processopt",
          "pytest_doctest_prepare_content",
          "names_closure",
          "_parse_parametrize_args",
          "ApproxNumpy",
          "truncate_if_required",
          "__bool__",
          "expression",
          "_recursive_list_map",
          "style",
          "_get_pos",
          "MatcherAdapter",
          "write_sep",
          "repr_locals",
          "notify_exception",
          "DOCTEST_REPORT_CHOICE_NONE",
          "recwarn",
          "path",
          "_get_continue_on_failure",
          "__eq__",
          "scopemismatch",
          "_W",
          "resume_capturing",
          "nextitem",
          "_traceback",
          "parts",
          "INTERNAL_ERROR",
          "add_report_section",
          "getcall",
          "set_log_path",
          "README_CONTENT",
          "OR",
          "fail_fixturefunc",
          "pop",
          "_validate_ids",
          "lineno",
          "item_capture",
          "_teardown_yield_fixture",
          "_makeitem",
          "isiterable",
          "Testdir",
          "names",
          "_get_active_fixturedef",
          "__len__",
          "call_fixture_func",
          "_get_multicapture",
          "addini",
          "pytest_report_header",
          "_checkargnotcontained",
          "DoctestModule",
          "name",
          "getgroup",
          "_get_allow_bytes_flag",
          "make_numbered_dir_with_cleanup",
          "mark",
          "startTest",
          "CaptureManager",
          "suspend_fixture",
          "_HandlerType",
          "RPAREN",
          "suspend_capturing",
          "get_data",
          "add_marker",
          "_format_lines",
          "_addoption",
          "_make_plural",
          "popcall",
          "_warn_incompatibility_with_xunit2",
          "wasvalid",
          "PYC_EXT",
          "tmpdir",
          "nose",
          "tb",
          "FixtureDef",
          "write_docstring",
          "istestclass",
          "session",
          "PdbTrace",
          "_check_non_top_pytest_plugins",
          "_makefile",
          "_io",
          "_compute_fixture_value",
          "_pluginmanager",
          "_importconftest",
          "debugging",
          "PYTEST_COLLECT_MODULE",
          "DropShorterLongHelpFormatter",
          "append_failure",
          "importorskip",
          "testdir",
          "_create",
          "deindent",
          "pytest_collection_finish",
          "funcnamefilter",
          "markup",
          "pytest_load_initial_conftests",
          "undo",
          "SafeRepr",
          "pytest_cmdline_preparse",
          "_get_progress_information_message",
          "getstatementrange",
          "repr_failure",
          "default_plugins",
          "_istrue",
          "_remove_ansi_escape_sequences",
          "from_config",
          "_schedule_finalizers",
          "setattr",
          "hasinit",
          "_getconftest_pathlist",
          "hookimpl",
          "nodes",
          "_initrequest",
          "_legal_chars",
          "assert_never",
          "FixtureLookupErrorRepr",
          "check_xfail_no_run",
          "parse_hookimpl_opts",
          "_S",
          "flow_marker",
          "tracebackcutdir",
          "OptionGroup",
          "reset",
          "_testcase",
          "FSCollector",
          "LFPlugin",
          "pytest_assertion_pass",
          "MarkMatcher",
          "_repr_failure_py",
          "hasnew",
          "format_explanation",
          "_determine_main_color",
          "visit_BoolOp",
          "getitem",
          "cache_dir_from_config",
          "capstderr",
          "get_dirs_from_args",
          "_set_initial_conftests",
          "_split_explanation",
          "_suspend",
          "iter_markers",
          "pos",
          "cache_key",
          "_LiveLoggingNullHandler",
          "_get_fixturestack",
          "disabled",
          "chain",
          "_write_source",
          "skipped_by_mark_key",
          "capsysbinary",
          "syspath_prepend",
          "getfailures",
          "inline_run",
          "_report_keyboardinterrupt",
          "_compare_eq_any",
          "TerminalRepr",
          "path_matches_patterns",
          "snap",
          "_mk_tmp",
          "FormattedExcinfo",
          "record_testreport",
          "PseudoFixtureDef",
          "warnings",
          "matching_platform",
          "pytest_itemcollected",
          "stepwise",
          "record_testsuite_property",
          "TerminalReporter",
          "DOCTEST_REPORT_CHOICE_UDIFF",
          "ArgumentError",
          "_legal_ranges",
          "call_and_report",
          "_addoption_instance",
          "FIXTURE_POSITIONAL_ARGUMENTS",
          "_REPORTCHARS_DEFAULT",
          "freeze_support",
          "resultlog_key",
          "_config",
          "_get_line_with_reprcrash_message",
          "_inject_setup_module_fixture",
          "fnmatch_ex",
          "D",
          "variable",
          "get_real_method",
          "CollectError",
          "Code",
          "_to_json",
          "LoggingPlugin",
          "ColoredLevelFormatter",
          "lex",
          "Collector",
          "merge_family",
          "get_terminal_width",
          "scopenum_function",
          "suspend",
          "PercentStyleMultiline",
          "restore",
          "_opentestcase",
          "KeywordMatcher",
          "doctest_namespace",
          "sep",
          "append_skipped",
          "Scanner",
          "WarningsChecker",
          "StepwisePlugin",
          "_setup_fixtures",
          "pytest_runtest_makereport",
          "get_public_names",
          "get_config",
          "LineMatcher_fixture",
          "ParameterSet",
          "IDENT_PREFIX",
          "DoctestItem",
          "locals",
          "instance",
          "_tryconvertpyarg",
          "_log_cli_enabled",
          "catching_logs",
          "CACHEDIR_TAG_CONTENT",
          "fullwidth",
          "_get_flag_lookup",
          "resume",
          "tolerance",
          "_get_marks",
          "DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE",
          "__iter__",
          "__getattr__",
          "_enter_pdb",
          "__exit__",
          "co_equal",
          "Metafunc",
          "PytestUnknownMarkWarning",
          "BASE_TYPE",
          "set",
          "entrysep",
          "errisinstance",
          "_patch_unwrap_mock_aware",
          "invalidraise",
          "accept",
          "_getreprcrash",
          "_splitnode",
          "result",
          "pytest_runtest_logreport",
          "Parser",
          "istestfunc",
          "K",
          "outcomes",
          "iscoroutinefunction",
          "combined_with",
          "fixtures",
          "fullsource",
          "_from_json",
          "LineComp",
          "at_level",
          "__slots__",
          "assertrepr_compare",
          "show_fixtures_per_test",
          "failed",
          "EMPTY_PARAMETERSET_OPTION",
          "_call_reprcompare",
          "MyOptionParser",
          "TempPathFactory",
          "getbasetemp",
          "clear",
          "__module__",
          "should_do_markup",
          "_add_stats",
          "_teardown_with_finalization",
          "value",
          "error",
          "pytest_make_parametrize_id",
          "ApproxDecimal",
          "putaround",
          "_ascii_escaped_by_config",
          "_prunetraceback",
          "ExceptionInfo",
          "emit",
          "RUNNER_CLASS",
          "pytest_fixture_setup",
          "_match_lines",
          "count_towards_summary",
          "isattrs",
          "MINUS_K_DASH",
          "Notset",
          "token",
          "maketxtfile",
          "wcwidth",
          "parse_known_args",
          "makeconftest",
          "derive_importpath",
          "str",
          "_PYTEST_DIR",
          "num_mock_patch_args",
          "stop",
          "category",
          "runtestprotocol",
          "pytestconfig",
          "_fillfixtures",
          "fixture",
          "check_testcase_implements_trial_reporter",
          "ascii_escaped",
          "add_attribute",
          "TESTS_FAILED",
          "_visit_filter",
          "_T",
          "getvalue",
          "_get_global_properties_node",
          "width_of_current_line",
          "FSHookProxy",
          "_is_setup_py",
          "_matchfactories",
          "freeze_includes",
          "own_mark_names",
          "create_new_paste",
          "text",
          "pytest_runtest_teardown",
          "AND",
          "parse_hookspec_opts",
          "PytestWarning",
          "_trace",
          "__missing__",
          "short_test_summary",
          "_ensure_immutable_ids",
          "ConftestImportFailure",
          "locate_config",
          "get_direct_param_fixture_func",
          "_saved",
          "Argument",
          "evalcache_key",
          "capfd",
          "makedir",
          "_param_ids_generated",
          "_non_numeric_type_error",
          "cache",
          "_ensure_removed_sysmodule",
          "getfixtureinfo",
          "_check_record_param_type",
          "_in_suspended",
          "assertion",
          "AlwaysDispatchingPrettyPrinter",
          "attrs",
          "_is_doctest",
          "_compare_eq_iterable",
          "makepyfile"
        ]
      },
      "response": {
        "keywords": [
          "MarkEvaluator",
          "cached_eval",
          "skip",
          "xfail",
          "evaluate",
          "Mark",
          "cache_key",
          "py",
          "evaluate.py",
          "_istrue"
        ]
      }
    },
    {
      "name": "FilesKeywordSearch",
      "metadata": {
        "start": "2024-08-19T13:34:43.456100",
        "usage": "406.4459800720215 ms"
      },
      "request": {
        "tokens": [
          "MarkEvaluator",
          "cached_eval",
          "skip",
          "xfail",
          "evaluate",
          "Mark",
          "cache_key",
          "py",
          "evaluate.py",
          "_istrue"
        ]
      },
      "response": {
        "results": {
          "py": [
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/resultlog.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/freeze_support.py",
            "src/_pytest/_argcomplete.py",
            "src/_pytest/capture.py",
            "src/_pytest/terminal.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/monkeypatch.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/pytester.py",
            "src/_pytest/config/argparsing.py",
            "src/_pytest/reports.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/_code/source.py",
            "src/_pytest/doctest.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/main.py",
            "src/_pytest/config/findpaths.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/_io/terminalwriter.py",
            "src/_pytest/compat.py"
          ],
          "skip": [
            "src/_pytest/mark/structures.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/python.py",
            "src/_pytest/terminal.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/pytester.py",
            "src/_pytest/assertion/util.py",
            "src/_pytest/unittest.py",
            "src/_pytest/reports.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/doctest.py",
            "src/_pytest/config/exceptions.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/skipping.py",
            "src/pytest/__init__.py",
            "src/_pytest/stepwise.py"
          ],
          "Mark": [
            "src/_pytest/mark/structures.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/mark/evaluate.py",
            "src/_pytest/stepwise.py"
          ],
          "cache_key": [
            "src/_pytest/fixtures.py",
            "src/_pytest/setupplan.py"
          ],
          "xfail": [
            "src/_pytest/mark/structures.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/unittest.py",
            "src/_pytest/python.py",
            "src/_pytest/skipping.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/mark/__init__.py",
            "src/pytest/__init__.py"
          ],
          "evaluate": [
            "src/_pytest/_code/code.py",
            "src/_pytest/skipping.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/mark/expression.py"
          ],
          "MarkEvaluator": [
            "src/_pytest/skipping.py",
            "src/_pytest/mark/evaluate.py"
          ],
          "cached_eval": [
            "src/_pytest/mark/evaluate.py"
          ],
          "_istrue": [
            "src/_pytest/mark/evaluate.py"
          ]
        }
      }
    },
    {
      "name": "FilesFilter",
      "metadata": {
        "start": "2024-08-19T13:34:43.862559",
        "usage": "4683.643102645874 ms"
      },
      "request": {
        "keyword_search_results": {
          "py": [
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/resultlog.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/freeze_support.py",
            "src/_pytest/_argcomplete.py",
            "src/_pytest/capture.py",
            "src/_pytest/terminal.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/monkeypatch.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/pytester.py",
            "src/_pytest/config/argparsing.py",
            "src/_pytest/reports.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/_code/source.py",
            "src/_pytest/doctest.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/main.py",
            "src/_pytest/config/findpaths.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/_io/terminalwriter.py",
            "src/_pytest/compat.py"
          ],
          "skip": [
            "src/_pytest/mark/structures.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/python.py",
            "src/_pytest/terminal.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/pytester.py",
            "src/_pytest/assertion/util.py",
            "src/_pytest/unittest.py",
            "src/_pytest/reports.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/doctest.py",
            "src/_pytest/config/exceptions.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/skipping.py",
            "src/pytest/__init__.py",
            "src/_pytest/stepwise.py"
          ],
          "Mark": [
            "src/_pytest/mark/structures.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/mark/evaluate.py",
            "src/_pytest/stepwise.py"
          ],
          "cache_key": [
            "src/_pytest/fixtures.py",
            "src/_pytest/setupplan.py"
          ],
          "xfail": [
            "src/_pytest/mark/structures.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/unittest.py",
            "src/_pytest/python.py",
            "src/_pytest/skipping.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/mark/__init__.py",
            "src/pytest/__init__.py"
          ],
          "evaluate": [
            "src/_pytest/_code/code.py",
            "src/_pytest/skipping.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/mark/expression.py"
          ],
          "MarkEvaluator": [
            "src/_pytest/skipping.py",
            "src/_pytest/mark/evaluate.py"
          ],
          "cached_eval": [
            "src/_pytest/mark/evaluate.py"
          ],
          "_istrue": [
            "src/_pytest/mark/evaluate.py"
          ]
        }
      },
      "response": {
        "scratch_pad": "The issue involves incorrect caching in pytest's skipif/xfail condition evaluation which is related to the function `cached_eval` located in `_pytest/mark/evaluate.py`. We are tasked with removing the caching mechanism and potentially inlining `cached_eval` into `MarkEvaluator._istrue` to correct the behavior. \n\nBased on the keyword search results:\n\n1. **cached_eval** and **_istrue**:\n   - Both `cached_eval` and `_istrue` are specifically mentioned in the file `src/_pytest/mark/evaluate.py`, which makes it directly relevant to the issue since it indicates where the cache mechanism is implemented.\n   \n2. **MarkEvaluator**:\n   - The keyword `MarkEvaluator` points to `src/_pytest/mark/evaluate.py` as well, further confirming its relevance since the issue suggests refactoring this specific part of the code.\n\n3. **evaluate**:\n   - While there are other files associated with the evaluate keyword (like `src/_pytest/skipping.py`), the context of evaluation in relation to caching points to `src/_pytest/mark/evaluate.py`.\n\nThus, `src/_pytest/mark/evaluate.py` is the primary file involved in this issue.",
        "file_paths": [
          "src/_pytest/mark/evaluate.py"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T13:34:48.546217",
        "usage": "6373.589992523193 ms"
      },
      "request": {
        "file_path": "src/_pytest/mark/evaluate.py"
      },
      "response": {
        "scratch_pad": "Issue Analysis:\n1. The issue is about incorrect caching of the evaluation of skipif/xfail markers in pytest, particularly when the condition is provided as a string.\n2. Users expect that when they run tests with different conditions for skipping, each should be evaluated with the appropriate context or global variable state. However, currently, both tests are either skipped or not based on the caching mechanism, which doesn't account for the individual context of each test file.\n3. The caching mechanism in place is using only the string as the caching key and not considering the different global contexts (`globals()`) each test might have.\n4. The root cause of the issue is identified in the caching mechanism employed in the `cached_eval` function, which neglects the variability introduced by different global contexts.\n5. A proposed solution is to remove or alter the caching mechanism to account for the different global contexts or inline `cached_eval` into `MarkEvaluator._istrue()` to prevent such caching from occurring.\n\nFile Evaluation:\n- The file contains the `cached_eval` function, which is indeed caching the evaluation by using only the string as a key.\n- `MarkEvaluator._istrue()` is the method where `cached_eval()` is used to evaluate the condition, this is precisely where the caching issue manifests.\n\nAfter reviewing the issue and the content of file, `cached_eval` function and `MarkEvaluator._istrue()` method are directly relevant to the reported issue because it involves the caching mechanism that makes the skip condition evaluation incorrect under different contexts.",
        "relevant": true,
        "root_cause": true,
        "relevant_files": [],
        "relevant_symbols": [
          "cached_eval",
          "MarkEvaluator._istrue"
        ],
        "root_cause_symbols": [
          "cached_eval",
          "MarkEvaluator._istrue"
        ]
      }
    },
    {
      "name": "FileSymbolSearch",
      "metadata": {
        "start": "2024-08-19T13:34:54.919830",
        "usage": "48.68888854980469 ms"
      },
      "request": {
        "files": [
          {
            "file_path": "src/_pytest/mark/evaluate.py",
            "relevant_symbol_keys": [
              "cached_eval",
              "MarkEvaluator._istrue"
            ],
            "root_cause_symbol_keys": [
              "cached_eval",
              "MarkEvaluator._istrue"
            ]
          }
        ],
        "with_content": true
      },
      "response": {
        "related_symbols": [],
        "root_caused_symbols": [
          {
            "name": "_pytest.mark.cached_eval",
            "file_path": "src/_pytest/mark/evaluate.py",
            "file_content": "def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n    default = {}  # type: Dict[str, object]\n    evalcache = config._store.setdefault(evalcache_key, default)\n    try:\n        return evalcache[expr]\n    except KeyError:\n        import _pytest._code\n\n        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n        evalcache[expr] = x = eval(exprcode, d)\n        return x",
            "start_line": 20,
            "start_column": 394,
            "end_line": 0,
            "end_column": 791,
            "start_byte": 394,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkEvaluator._istrue",
            "file_path": "src/_pytest/mark/evaluate.py",
            "file_content": "def _istrue(self) -> bool:\n        if hasattr(self, \"result\"):\n            result = getattr(self, \"result\")  # type: bool\n            return result\n        self._marks = self._get_marks()\n\n        if self._marks:\n            self.result = False\n            for mark in self._marks:\n                self._mark = mark\n                if \"condition\" not in mark.kwargs:\n                    args = mark.args\n                else:\n                    args = (mark.kwargs[\"condition\"],)\n\n                for expr in args:\n                    self.expr = expr\n                    if isinstance(expr, str):\n                        d = self._getglobals()\n                        result = cached_eval(self.item.config, expr, d)\n                    else:\n                        if \"reason\" not in mark.kwargs:\n                            # XXX better be checked at collection time\n                            msg = (\n                                \"you need to specify reason=STRING \"\n                                \"when using booleans as conditions.\"\n                            )\n                            fail(msg)\n                        result = bool(expr)\n                    if result:\n                        self.result = True\n                        self.reason = mark.kwargs.get(\"reason\", None)\n                        self.expr = expr\n                        return self.result\n\n                if not args:\n                    self.result = True\n                    self.reason = mark.kwargs.get(\"reason\", None)\n                    return self.result\n        return False",
            "start_line": 81,
            "start_column": 2564,
            "end_line": 4,
            "end_column": 4143,
            "start_byte": 2564,
            "end_byte": 4
          }
        ]
      }
    },
    {
      "name": "SymbolsEvaluate",
      "metadata": {
        "start": "2024-08-19T13:34:54.968533",
        "usage": "6083.78005027771 ms"
      },
      "request": {
        "related_symbols": [],
        "root_caused_symbols": [
          {
            "name": "_pytest.mark.cached_eval",
            "file_path": "src/_pytest/mark/evaluate.py",
            "file_content": "def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n    default = {}  # type: Dict[str, object]\n    evalcache = config._store.setdefault(evalcache_key, default)\n    try:\n        return evalcache[expr]\n    except KeyError:\n        import _pytest._code\n\n        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n        evalcache[expr] = x = eval(exprcode, d)\n        return x",
            "start_line": 20,
            "start_column": 394,
            "end_line": 0,
            "end_column": 791,
            "start_byte": 394,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkEvaluator._istrue",
            "file_path": "src/_pytest/mark/evaluate.py",
            "file_content": "def _istrue(self) -> bool:\n        if hasattr(self, \"result\"):\n            result = getattr(self, \"result\")  # type: bool\n            return result\n        self._marks = self._get_marks()\n\n        if self._marks:\n            self.result = False\n            for mark in self._marks:\n                self._mark = mark\n                if \"condition\" not in mark.kwargs:\n                    args = mark.args\n                else:\n                    args = (mark.kwargs[\"condition\"],)\n\n                for expr in args:\n                    self.expr = expr\n                    if isinstance(expr, str):\n                        d = self._getglobals()\n                        result = cached_eval(self.item.config, expr, d)\n                    else:\n                        if \"reason\" not in mark.kwargs:\n                            # XXX better be checked at collection time\n                            msg = (\n                                \"you need to specify reason=STRING \"\n                                \"when using booleans as conditions.\"\n                            )\n                            fail(msg)\n                        result = bool(expr)\n                    if result:\n                        self.result = True\n                        self.reason = mark.kwargs.get(\"reason\", None)\n                        self.expr = expr\n                        return self.result\n\n                if not args:\n                    self.result = True\n                    self.reason = mark.kwargs.get(\"reason\", None)\n                    return self.result\n        return False",
            "start_line": 81,
            "start_column": 2564,
            "end_line": 4,
            "end_column": 4143,
            "start_byte": 2564,
            "end_byte": 4
          }
        ]
      },
      "response": {
        "scratch_pad": "The reported issue here is about the incorrect behavior of pytest when using the `@pytest.mark.skipif` decorator. The problem arises because of how pytest caches the evaluation of the skip condition. In this issue, pytest incorrectly caches string expressions based solely on their string content, without considering the different execution contexts (global variables) of each test. This results in incorrect skipping behavior, as seen when running tests from different modules.\n\nTo fix this issue, the caching mechanism needs to be altered or removed. The evaluation should depend not only on the expression but also on the context (globals) in which it is evaluated, preventing shared caching entries that are inappropriate.\n\nThe suggested resolution is to remove the caching entirely and inline the `cached_eval` function into the `MarkEvaluator._istrue` method.\n\nNow, let's analyze the provided symbols to determine what changes are necessary:",
        "symbols": [
          {
            "name": "_pytest.mark.cached_eval",
            "file_path": "src/_pytest/mark/evaluate.py",
            "reason": "This function uses a caching mechanism for evaluating the skip/xfail expressions which doesn't account for the globals specific to each test item. As per the issue, the caching should be removed or modified to consider the item's globals. The simplest approach indicated is the removal of caching."
          },
          {
            "name": "_pytest.mark.MarkEvaluator._istrue",
            "file_path": "src/_pytest/mark/evaluate.py",
            "reason": "This method is responsible for evaluating the expressions provided in the marks like skipif/xfail. It currently uses `cached_eval`, which is causing the incorrect caching behavior, necessitating a change. The method should be modified to directly evaluate the expression using eval, passing the current globals, instead of using cached_eval."
          }
        ],
        "more_info": [],
        "is_done": true,
        "symbols_scratch_pad": [
          "The `cached_eval` function currently caches evaluations of expressions based solely on the expression string. This needs to be changed because it does not account for the context-specific globals which are essential for correct expression evaluation in conditional skipping/xfailing.",
          "The `_istrue` method depends on `cached_eval` to determine if a mark condition (expression) is true or not. This dependency on cached_eval is the root cause of the problem, as it leads to incorrect caching results. It needs to perform the evaluation directly based on the expression and the current global context."
        ]
      }
    },
    {
      "name": "SymbolSummary",
      "metadata": {
        "start": "2024-08-19T13:35:01.052335",
        "usage": "0.8111000061035156 ms"
      },
      "request": {
        "symbols": {
          "related_symbols": [],
          "root_caused_symbols": [
            {
              "name": "_pytest.mark.cached_eval",
              "file_path": "src/_pytest/mark/evaluate.py",
              "file_content": "def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n    default = {}  # type: Dict[str, object]\n    evalcache = config._store.setdefault(evalcache_key, default)\n    try:\n        return evalcache[expr]\n    except KeyError:\n        import _pytest._code\n\n        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n        evalcache[expr] = x = eval(exprcode, d)\n        return x",
              "start_line": 20,
              "start_column": 394,
              "end_line": 0,
              "end_column": 791,
              "start_byte": 394,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkEvaluator._istrue",
              "file_path": "src/_pytest/mark/evaluate.py",
              "file_content": "def _istrue(self) -> bool:\n        if hasattr(self, \"result\"):\n            result = getattr(self, \"result\")  # type: bool\n            return result\n        self._marks = self._get_marks()\n\n        if self._marks:\n            self.result = False\n            for mark in self._marks:\n                self._mark = mark\n                if \"condition\" not in mark.kwargs:\n                    args = mark.args\n                else:\n                    args = (mark.kwargs[\"condition\"],)\n\n                for expr in args:\n                    self.expr = expr\n                    if isinstance(expr, str):\n                        d = self._getglobals()\n                        result = cached_eval(self.item.config, expr, d)\n                    else:\n                        if \"reason\" not in mark.kwargs:\n                            # XXX better be checked at collection time\n                            msg = (\n                                \"you need to specify reason=STRING \"\n                                \"when using booleans as conditions.\"\n                            )\n                            fail(msg)\n                        result = bool(expr)\n                    if result:\n                        self.result = True\n                        self.reason = mark.kwargs.get(\"reason\", None)\n                        self.expr = expr\n                        return self.result\n\n                if not args:\n                    self.result = True\n                    self.reason = mark.kwargs.get(\"reason\", None)\n                    return self.result\n        return False",
              "start_line": 81,
              "start_column": 2564,
              "end_line": 4,
              "end_column": 4143,
              "start_byte": 2564,
              "end_byte": 4
            }
          ]
        },
        "symbols_evaluate": {
          "scratch_pad": "The reported issue here is about the incorrect behavior of pytest when using the `@pytest.mark.skipif` decorator. The problem arises because of how pytest caches the evaluation of the skip condition. In this issue, pytest incorrectly caches string expressions based solely on their string content, without considering the different execution contexts (global variables) of each test. This results in incorrect skipping behavior, as seen when running tests from different modules.\n\nTo fix this issue, the caching mechanism needs to be altered or removed. The evaluation should depend not only on the expression but also on the context (globals) in which it is evaluated, preventing shared caching entries that are inappropriate.\n\nThe suggested resolution is to remove the caching entirely and inline the `cached_eval` function into the `MarkEvaluator._istrue` method.\n\nNow, let's analyze the provided symbols to determine what changes are necessary:",
          "symbols": [
            {
              "name": "_pytest.mark.cached_eval",
              "file_path": "src/_pytest/mark/evaluate.py",
              "reason": "This function uses a caching mechanism for evaluating the skip/xfail expressions which doesn't account for the globals specific to each test item. As per the issue, the caching should be removed or modified to consider the item's globals. The simplest approach indicated is the removal of caching."
            },
            {
              "name": "_pytest.mark.MarkEvaluator._istrue",
              "file_path": "src/_pytest/mark/evaluate.py",
              "reason": "This method is responsible for evaluating the expressions provided in the marks like skipif/xfail. It currently uses `cached_eval`, which is causing the incorrect caching behavior, necessitating a change. The method should be modified to directly evaluate the expression using eval, passing the current globals, instead of using cached_eval."
            }
          ],
          "more_info": [],
          "is_done": true,
          "symbols_scratch_pad": [
            "The `cached_eval` function currently caches evaluations of expressions based solely on the expression string. This needs to be changed because it does not account for the context-specific globals which are essential for correct expression evaluation in conditional skipping/xfailing.",
            "The `_istrue` method depends on `cached_eval` to determine if a mark condition (expression) is true or not. This dependency on cached_eval is the root cause of the problem, as it leads to incorrect caching results. It needs to perform the evaluation directly based on the expression and the current global context."
          ]
        }
      },
      "response": {
        "file_paths": [
          "src/_pytest/mark/evaluate.py"
        ],
        "symbols": [
          "_pytest.mark.cached_eval",
          "_pytest.mark.MarkEvaluator._istrue"
        ],
        "code_spans": {
          "_pytest.mark.cached_eval": {
            "name": "_pytest.mark.cached_eval",
            "file_path": "src/_pytest/mark/evaluate.py",
            "file_content": "def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n    default = {}  # type: Dict[str, object]\n    evalcache = config._store.setdefault(evalcache_key, default)\n    try:\n        return evalcache[expr]\n    except KeyError:\n        import _pytest._code\n\n        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n        evalcache[expr] = x = eval(exprcode, d)\n        return x",
            "start_line": 20,
            "start_column": 394,
            "end_line": 0,
            "end_column": 791,
            "start_byte": 394,
            "end_byte": 0
          },
          "_pytest.mark.MarkEvaluator._istrue": {
            "name": "_pytest.mark.MarkEvaluator._istrue",
            "file_path": "src/_pytest/mark/evaluate.py",
            "file_content": "def _istrue(self) -> bool:\n        if hasattr(self, \"result\"):\n            result = getattr(self, \"result\")  # type: bool\n            return result\n        self._marks = self._get_marks()\n\n        if self._marks:\n            self.result = False\n            for mark in self._marks:\n                self._mark = mark\n                if \"condition\" not in mark.kwargs:\n                    args = mark.args\n                else:\n                    args = (mark.kwargs[\"condition\"],)\n\n                for expr in args:\n                    self.expr = expr\n                    if isinstance(expr, str):\n                        d = self._getglobals()\n                        result = cached_eval(self.item.config, expr, d)\n                    else:\n                        if \"reason\" not in mark.kwargs:\n                            # XXX better be checked at collection time\n                            msg = (\n                                \"you need to specify reason=STRING \"\n                                \"when using booleans as conditions.\"\n                            )\n                            fail(msg)\n                        result = bool(expr)\n                    if result:\n                        self.result = True\n                        self.reason = mark.kwargs.get(\"reason\", None)\n                        self.expr = expr\n                        return self.result\n\n                if not args:\n                    self.result = True\n                    self.reason = mark.kwargs.get(\"reason\", None)\n                    return self.result\n        return False",
            "start_line": 81,
            "start_column": 2564,
            "end_line": 4,
            "end_column": 4143,
            "start_byte": 2564,
            "end_byte": 4
          }
        }
      }
    }
  ]
}