{
  "total_cost": 0,
  "task_id": "pytest-dev__pytest-7490",
  "model": "gpt-4o-2024-08-06",
  "spans": [
    {
      "name": "KeywordExtract",
      "metadata": {
        "start": "2024-08-19T13:34:51.281686",
        "usage": "1112.569808959961 ms"
      },
      "request": {
        "repo_tokens": [
          "summary_passes",
          "Cache",
          "summary_failures",
          "visit_Name",
          "fixturenames",
          "push_format_context",
          "extract_suffixes",
          "extraline",
          "processoption",
          "fnmatch_lines",
          "reprfileloc",
          "_fixturemanager",
          "LogCaptureHandler",
          "append_collect_error",
          "_read_pyc",
          "getpluginversioninfo",
          "typename",
          "cacheprovider",
          "summary_errors",
          "_plugin_nameversions",
          "ids",
          "append_collect_skipped",
          "exit",
          "traceback",
          "_consider_importhook",
          "_validate_args",
          "delattr",
          "filter_traceback_for_conftest_import_failure",
          "CallInfo",
          "write_fspath_result",
          "CLOSE_STDIN",
          "cwd_relative_nodeid",
          "mkdir",
          "getpathnode",
          "obj",
          "_parse_ini_config",
          "pytest_warning_captured",
          "_import_plugin_specs",
          "plugins",
          "_given_basetemp",
          "addSkip",
          "add_global_property",
          "store_mark",
          "resultlog",
          "OutcomeException",
          "parseconfig",
          "_format_args",
          "_ensure_basetemp",
          "_surrounding_parens_on_own_lines",
          "runpytest",
          "builtin_plugins",
          "writer",
          "DOCTEST_REPORT_CHOICE_NDIFF",
          "_getnextfixturedef",
          "_get_allow_unicode_flag",
          "check_interactive_exception",
          "id",
          "reprtraceback",
          "getitems",
          "pastebin",
          "capsys",
          "evaluate_skip_marks",
          "NFPlugin",
          "approx",
          "store",
          "deselect_by_keyword",
          "_early_rewrite_bailout",
          "_get_increasing_order",
          "_collect",
          "_FixtureValue",
          "safeformat",
          "_determine_show_progress_info",
          "pytest_sessionstart",
          "writeorg",
          "_translate_non_printable",
          "cleanup_numbered_dir",
          "is_rewrite_disabled",
          "_no_match_line",
          "_get_plugin_specs_as_list",
          "_rewrite_test",
          "_assertion_supported",
          "consider_module",
          "Failed",
          "V",
          "_ensure_supporting_files",
          "pathlib",
          "terminal",
          "PytestPluginManager",
          "buffer",
          "pytest_runtest_call",
          "TEST_OUTCOME",
          "suspend_global_capture",
          "SysCaptureBinary",
          "prepend",
          "get_lines_after",
          "pytest_internalerror",
          "pytestPDB",
          "runtest",
          "getrawcode",
          "__str__",
          "Exit",
          "getlocation",
          "UsageError",
          "SetupState",
          "RE_IMPORT_ERROR_NAME",
          "match",
          "Xfail",
          "write_ensure_prefix",
          "from_parent",
          "_check_scope",
          "pytester",
          "_inject_setup_method_fixture",
          "_is_capturing",
          "Session",
          "_write_pyc_fp",
          "activate_fixture",
          "stream",
          "setenv",
          "_F",
          "IGNORE_PAM",
          "_esctable",
          "pytest_report_collectionfinish",
          "classnamefilter",
          "args",
          "validate_basetemp",
          "reason",
          "assign",
          "get_plugin_manager",
          "MultipleDoctestFailures",
          "showlongtestinfo",
          "ReprLocals",
          "_matchnodes",
          "get_location",
          "_bestrelpath_cache",
          "expr",
          "NOTSET",
          "resolve_package_path",
          "_ET",
          "excinfo",
          "_ensure_relative_to_basetemp",
          "UnitTestCase",
          "fnmatch_lines_random",
          "LsofFdLeakChecker",
          "CallSpec2",
          "_iter_rewritable_modules",
          "raises",
          "_write_progress_information_filling_space",
          "addFailure",
          "cut",
          "readlines",
          "records",
          "pytest_assertrepr_compare",
          "getcrashentry",
          "is_async_function",
          "pytest_enter_pdb",
          "collect_one_node",
          "Module",
          "consider_conftest",
          "compile",
          "_try_repr_or_str",
          "reprcrash",
          "_config_for_test",
          "notset",
          "runpython_c",
          "_CACHE_PREFIX_VALUES",
          "pytest_pycollect_makeitem",
          "from_item",
          "frame",
          "getargs",
          "pytest_collectstart",
          "_checkversion",
          "set_when",
          "FDCapture",
          "_force_symlink",
          "countoutcomes",
          "scope",
          "CaptureIO",
          "__test__",
          "_LiveLoggingStreamHandler",
          "xfailed_key",
          "_init_runner_class",
          "LFPluginCollWrapper",
          "ApproxBase",
          "_reprcompare",
          "pytest_warning_recorded",
          "_validate_usepdb_cls",
          "pytest_collection_modifyitems",
          "DEFAULT_ABSOLUTE_TOLERANCE",
          "_is_last_item",
          "getfixturevalue",
          "_make_xunit_fixture",
          "isdatacls",
          "_get_main_color",
          "pytest_collect_directory",
          "ExceptionRepr",
          "_getconftestmodules",
          "nofuncargs",
          "re_match_lines_random",
          "_matches_prefix_or_glob_option",
          "get_common_ancestor",
          "pop_format_context",
          "_color_for_type",
          "scope2index",
          "pytest_report_teststatus",
          "ReprFailDoctest",
          "PytestCollectionWarning",
          "_write_entry_lines",
          "NodeMeta",
          "_collectfile",
          "_dump_lines",
          "fix_cache_order",
          "CollectErrorRepr",
          "_for_parametrize",
          "_try_load_conftest",
          "SysModulesSnapshot",
          "fault_handler_stderr_key",
          "SubRequest",
          "_report_to_json",
          "HelpAction",
          "type",
          "pytest_fixture_post_finalizer",
          "python",
          "stop_global_capturing",
          "ImportPathMismatchError",
          "build_summary_stats_line",
          "visit_Starred",
          "reports",
          "extract_from",
          "Expression",
          "getreports",
          "mktemp",
          "initialnames",
          "matchnodes",
          "fileno",
          "families",
          "_format_assertmsg",
          "DEFAULT_RELATIVE_TOLERANCE",
          "isdict",
          "LogCaptureFixture",
          "fail",
          "_warn_already_imported",
          "context",
          "explanation_param",
          "mkpydir",
          "AssertionRewritingHook",
          "getoption",
          "from_call",
          "MoreQuietAction",
          "find_prefixed",
          "_PytestWrapper",
          "IDENT",
          "listextrakeywords",
          "getstatement",
          "template",
          "_AnyPurePath",
          "get_records",
          "maybe_delete_a_numbered_dir",
          "_call_assertion_pass",
          "_getscopeitem",
          "popen",
          "pytest_collect_file",
          "conftest_options",
          "getfixtureclosure",
          "evaluate_xfail_marks",
          "readline",
          "Interrupted",
          "_has_param_ids",
          "_color_for_type_default",
          "TracebackEntry",
          "lines",
          "pytest_runtest_protocol",
          "record_tuples",
          "_assert_state",
          "_teardown_towards",
          "summary_warnings",
          "_seen",
          "write_captured_output",
          "location",
          "_R",
          "_cachedir",
          "_resolve_arg_value_types",
          "done",
          "post_mortem",
          "pytest_deselected",
          "_NodeType",
          "__version__",
          "_approx_scalar",
          "NodeKeywords",
          "__setitem__",
          "skip",
          "_add_simple",
          "_is_marked_for_rewrite",
          "for_later",
          "_update_current_test_var",
          "record_xml_attribute",
          "NotSetType",
          "SysCapture",
          "resolve_from_str",
          "PytestAssertRewriteWarning",
          "print_teardown_sections",
          "append_error",
          "_truncate_explanation",
          "funcargnames",
          "_folded_skips",
          "statement",
          "USAGE_ERROR",
          "Skip",
          "start_capturing",
          "list",
          "_report_kwargs_from_json",
          "pytest_plugin_registered",
          "line",
          "helpconfig",
          "re_match_lines",
          "_ALLOW_MARKERS",
          "_write_content",
          "close",
          "PytestConfigWarning",
          "format",
          "_do_configure",
          "get_open_files",
          "call_runtest_hook",
          "node_reporter",
          "_get_stderr_fileno",
          "COLLECT_DIRECTORY_HOOK",
          "pytest_generate_tests",
          "_py_ext_re",
          "compat",
          "_getentrysource",
          "doctest",
          "rex_outcome",
          "_tmppath_factory",
          "Function",
          "get_parametrized_fixture_keys",
          "tmpdir_factory",
          "exec_module",
          "PyobjMixin",
          "ReprExceptionInfo",
          "_getcrashline",
          "determine_setup",
          "caplog",
          "UNARY_MAP",
          "visit_Assert",
          "pytest_make_collect_report",
          "pytest_keyboard_interrupt",
          "patchsysdict",
          "syspathinsert",
          "scopes",
          "get_user",
          "parse_setoption",
          "BaseReport",
          "warning_record_to_str",
          "_getvaluepath",
          "_main",
          "simple",
          "File",
          "CwdSnapshot",
          "visit_BinOp",
          "Junit",
          "HookRecorder",
          "LineMatcher",
          "pytest_collection",
          "console_main",
          "pytest_runtestloop",
          "_show_fixtures_per_test",
          "repr_instance",
          "show_test_item",
          "get_source",
          "getsource",
          "parse_known_and_unknown_args",
          "function",
          "_get_runner",
          "cleanup_candidates",
          "makefile",
          "setitem",
          "invocation_dir",
          "ApproxScalar",
          "start",
          "MODULE_NOT_FOUND_ERROR",
          "_handle_teardown_sections",
          "_expecting_failure",
          "capture",
          "add_funcarg_pseudo_fixture_def",
          "importlib",
          "_get_verbose_word",
          "_create_formatter",
          "set_session",
          "get_lock_path",
          "eval",
          "_version",
          "_start",
          "_typ_map",
          "_ensure_unconfigure",
          "__version_tuple__",
          "chdir",
          "_update_message",
          "_node_location_to_relpath",
          "runner",
          "readouterr",
          "_postmortem_traceback",
          "node",
          "_initini",
          "teardown_exact",
          "get_default_arg_names",
          "format_session_duration",
          "junitxml",
          "illegal_xml_re",
          "cls",
          "xml_key",
          "repr_args",
          "spawn",
          "ReprEntry",
          "Instance",
          "__dir__",
          "ReprEntryNative",
          "keywords",
          "STRING_TYPES",
          "_report_unserialization_failure",
          "_outrep_summary",
          "dir",
          "_recursive_debug",
          "module",
          "ReprTraceback",
          "NOT",
          "source",
          "_check_if_assertion_pass_impl",
          "resolve_fixture_function",
          "_get_teardown_reports",
          "reprlocals",
          "pytest_report_from_serializable",
          "pop_outerr_to_orig",
          "_log",
          "_showfixtures_main",
          "Class",
          "async_warn_and_skip",
          "reject",
          "wrap_function_to_error_out_if_called_directly",
          "FILLFUNCARGS",
          "DEFAULT_MAX_LINES",
          "LEVELNAME_FMT_REGEX",
          "consider_preparse",
          "to_xml",
          "_pytest",
          "PytestExperimentalApiWarning",
          "__call__",
          "handler",
          "_assertion_pass",
          "_truncate_recursive_traceback",
          "_repr_style",
          "_Markable",
          "_width_of_current_line",
          "ensure_deletable",
          "applymarker",
          "_find_spec",
          "_PLUGGY_DIR",
          "_pyfuncitem",
          "USAGE_MSG",
          "python_api",
          "_compare_eq_verbose",
          "prepare",
          "_import_pdb_cls",
          "TempdirFactory",
          "formatrepr",
          "assert_contains",
          "XFailed",
          "summary_stats",
          "_callfinalizers",
          "head_line",
          "idmaker",
          "_inject_setup_class_fixture",
          "set_repr_style",
          "_parsearg",
          "_ANSI_ESCAPE_SEQ",
          "_getindent",
          "iter_markers_with_node",
          "display",
          "EOF",
          "Node",
          "_printcollecteditems",
          "pytest_runtest_logstart",
          "_get_unknown_ini_keys",
          "add_property",
          "MarkDecorator",
          "maybe_wrap_pytest_function_for_tracing",
          "showlocals",
          "set_fixture",
          "_sys_snapshot",
          "register_assert_rewrite",
          "warning_types",
          "faulthandler",
          "_get_assertion_exprs",
          "directory_arg",
          "Package",
          "consider_env",
          "CHECKER_CLASS",
          "get_fslocation_from_item",
          "_strtobool",
          "rewrite",
          "showheader",
          "_get_override_ini_value",
          "__repr__",
          "getini",
          "_inject_setup_function_fixture",
          "helper",
          "unset_fixture",
          "istestfunction",
          "deactivate_fixture",
          "parse",
          "_running_on_ci",
          "_basetemp",
          "FastFilesCompleter",
          "showversion",
          "gethookproxy",
          "indent",
          "__getitem__",
          "get_empty_parameterset_mark",
          "log_outcome",
          "EncodedFile",
          "ihook",
          "prune_dependency_tree",
          "_importtestmodule",
          "no_header",
          "_get_checker",
          "_match_lines_random",
          "get_optionflags",
          "LogXML",
          "Skipped",
          "_set_main_color",
          "_compare_eq_set",
          "_is_skipped",
          "_should_repr_global_name",
          "pytest_exception_interact",
          "TestReport",
          "_init_pdb",
          "MultiCapture",
          "yield_fixture",
          "_resolve_arg_ids",
          "kwargs",
          "nodeid",
          "TestCaseFunction",
          "get_exconly",
          "get_last_failed_paths",
          "_preparse",
          "_mark_plugins_for_rewrite",
          "TokenType",
          "UnformattedWarning",
          "_parse_filter",
          "visit_Compare",
          "getfslineno",
          "reorder_items",
          "message",
          "__init__",
          "_issue_warning_captured",
          "visit_UnaryOp",
          "_is_numpy_array",
          "MINUS_K_COLON",
          "normalize_mark_list",
          "CFG_PYTEST_SECTION",
          "when",
          "_yield_comparisons",
          "isatty",
          "catch_warnings_for_item",
          "OK",
          "params",
          "_check_type",
          "ApproxMapping",
          "Source",
          "pytest_addoption",
          "parse_args",
          "pytest",
          "listchain",
          "get",
          "NoCapture",
          "_prepare_content",
          "timing",
          "_validate_plugins",
          "__all__",
          "listnames",
          "_finalize",
          "duration",
          "PYC_TAIL",
          "append",
          "hasopt",
          "getstatementrange_ast",
          "assert_contains_lines",
          "fill_unfilled",
          "unexpectedsuccess_key",
          "_set_opt_strings",
          "pytest_pycollect_makemodule",
          "_genfunctions",
          "_format",
          "Config",
          "_readline_workaround",
          "from_current",
          "bin_xml_escape",
          "tmp_path_factory",
          "clear_cache",
          "_getpytestargs",
          "get_closest_marker",
          "_warn_or_fail_if_strict",
          "NO_TESTS_COLLECTED",
          "longrepr",
          "REPORT_COLLECTING_RESOLUTION",
          "__delitem__",
          "get_real_func",
          "SysPathsSnapshot",
          "_is_mocked",
          "try_makedirs",
          "T",
          "funcargs",
          "get_log_level_for_setting",
          "RaisesContext",
          "_setupstate",
          "matchreport",
          "set_location",
          "essential_plugins",
          "parsefactories",
          "_should_rewrite",
          "ImportMode",
          "prog",
          "update_testcase_duration",
          "DEFAULT_LOG_DATE_FORMAT",
          "linecomp",
          "pytest_collectreport",
          "mark_rewrite",
          "unittest",
          "FILE_OR_DIR",
          "_pformat_dispatch",
          "_getparser",
          "_call_with_optional_argument",
          "generic_visit",
          "_get_auto_indent",
          "ParseError",
          "_getfailureheadline",
          "skipped",
          "reprentries",
          "flush",
          "CaptureResult",
          "capfdbinary",
          "abspath",
          "register_cleanup_lock_removal",
          "find_spec",
          "EMPTY_BUFFER",
          "rm_rf",
          "NODE_USE_FROM_PARENT",
          "LPAREN",
          "DOCTEST_REPORT_CHOICES",
          "addSuccess",
          "old_mark_config_key",
          "istext",
          "safe_getattr",
          "get_scope_node",
          "addError",
          "AssertionState",
          "raiseerror",
          "assertoutcome",
          "pytest_pyfunc_call",
          "ishidden",
          "_show_fixture_action",
          "NoMatch",
          "getmodulecol",
          "_perform_collect",
          "getreportopt",
          "DummyRewriteHook",
          "_check_all_skipped",
          "cacheshow",
          "Exception",
          "pytest_configure",
          "copy_example",
          "_check_initialpaths_for_relpath",
          "_recurse",
          "WarningsRecorder",
          "xfail",
          "_getini",
          "_runtest_for",
          "symlink_or_skip",
          "FakeCollectModule",
          "logging",
          "_highlight",
          "warn",
          "_pop_and_teardown",
          "run",
          "hookspec",
          "Item",
          "report_collect",
          "spawn_pytest",
          "messages",
          "_FixtureCachedResult",
          "name2fixturedefs",
          "fslocation",
          "_state",
          "ExitCode",
          "astcache",
          "_validate_keys",
          "_FixtureFunc",
          "addoption",
          "reportinfo",
          "finish_recording",
          "repr",
          "ReprTracebackNative",
          "inline_runsource",
          "fromdictargs",
          "_get_direct_parametrize_args",
          "cmdline",
          "annotated_getattr",
          "get_unpacked_marks",
          "runpytest_inprocess",
          "capstdout",
          "_resume",
          "getfixturedefs",
          "__array_ufunc__",
          "setupplan",
          "strip",
          "makepyprojecttoml",
          "start_global_capturing",
          "pytest_leave_pdb",
          "_markers",
          "getparent",
          "_idval",
          "PYTESTER_COPY_EXAMPLE",
          "_with_exception",
          "Traceback",
          "issequence",
          "LFPluginCollSkipfiles",
          "safe_isclass",
          "deselect_by_mark",
          "get_scope_package",
          "scope2props",
          "ensure_reset_dir",
          "TerminalWriter",
          "MarkGenerator",
          "pastebinfile_key",
          "ApproxSequencelike",
          "ExceptionChainRepr",
          "exconly",
          "_assert_expr_to_lineno",
          "pytest_terminal_summary",
          "wrap_session",
          "LOGLEVEL_COLOROPTS",
          "delenv",
          "finish",
          "_in_venv",
          "collect_by_name",
          "repr_traceback",
          "getplugin",
          "showfixtures",
          "config",
          "getinicfg",
          "_get_pdb_wrapper_class",
          "add_cleanup",
          "assert_outcomes",
          "_colorama_workaround",
          "cached_result",
          "builtin",
          "warns",
          "addExpectedFailure",
          "_truncate_by_char_count",
          "record_property",
          "TimeoutExpired",
          "__enter__",
          "_idvalset",
          "_format_repr_exception",
          "newinstance",
          "getparam",
          "_PluggyPlugin",
          "PrintHelp",
          "_makepath",
          "rewrite_asserts",
          "fillfixtures",
          "INTERRUPTED",
          "visit_Call",
          "DoctestTextfile",
          "no_re_match_line",
          "showfspath",
          "WARNING_CAPTURED_HOOK",
          "recursionindex",
          "_get_number_flag",
          "_CACHE_PREFIX_DIRS",
          "consider_pluginarg",
          "_parse_parametrize_parameters",
          "make_numbered_dir",
          "deprecated_call",
          "filter",
          "_saferepr",
          "_inject_setup_teardown_fixtures",
          "version_tuple",
          "toterminal",
          "global_and_fixture_disabled",
          "repr_excinfo",
          "execute",
          "DEPRECATED_EXTERNAL_PLUGINS",
          "create_module",
          "evaluate_condition",
          "getfirstlinesource",
          "DEFAULT_MAX_CHARS",
          "inline_genitems",
          "_WithException",
          "DontReadFromInput",
          "write",
          "BINOP_MAP",
          "addsection",
          "pytest_unconfigure",
          "_Key",
          "FixtureRequest",
          "findsource",
          "runpytest_subprocess",
          "delitem",
          "param",
          "_getlines",
          "getnode",
          "_PY_DIR",
          "with_args",
          "truncate_locals",
          "make_hook_recorder",
          "_factorytraceback",
          "Store",
          "PdbInvoke",
          "_rget_with_confmod",
          "exprinfo",
          "ensure_extended_length_path",
          "RunResult",
          "FixtureLookupError",
          "DOCTEST_REPORT_CHOICE_CDIFF",
          "TeeCaptureIO",
          "visit_Attribute",
          "_bytes_to_ascii",
          "markname",
          "_getautousenames",
          "_legal_xml_re",
          "InvocationParams",
          "skipping",
          "is_globally_capturing",
          "_non_printable_ascii_translate_table",
          "get_timeout_config_value",
          "PYTEST_TAG",
          "isnosetest",
          "no_summary",
          "find_suffixes",
          "copy",
          "pytest_addhooks",
          "_FileHandler",
          "make_properties_node",
          "CaptureFixture",
          "_py36_windowsconsoleio_workaround",
          "_code",
          "create_cleanup_lock",
          "no_fnmatch_line",
          "write_line",
          "pytest_cmdline_main",
          "teardown_all",
          "LOCK_TIMEOUT",
          "get_extended_length_path_str",
          "_result",
          "_compare_eq_cls",
          "KNOWN_TYPES",
          "sections",
          "assertstate_key",
          "repr_traceback_entry",
          "TERMINALWRITER_WRITER",
          "_write_report_lines_from_hooks",
          "isinitpath",
          "_addfinalizer",
          "fspath",
          "_fail",
          "set_level",
          "PytestArg",
          "_gethookproxy",
          "collect",
          "_validate_if_using_arg_names",
          "is_generator",
          "_names",
          "PyCollector",
          "ReprFileLocation",
          "filename_arg",
          "evaluate",
          "SEP",
          "getfuncargnames",
          "call_optional",
          "get_statement_startend2",
          "COLLECT_FAKEMODULE_ATTRIBUTES",
          "get_option_ini",
          "is_capturing",
          "FaultHandlerHooks",
          "from_item_and_call",
          "_striptext",
          "addUnexpectedSuccess",
          "resolve",
          "pytest_report_to_serializable",
          "ResultLog",
          "and_expr",
          "wrap_pytest_function_for_tracing",
          "pytest_runtest_setup",
          "isset",
          "rex_session_duration",
          "getrepr",
          "FUNCARGNAMES",
          "PytestUnhandledCoroutineWarning",
          "version",
          "reprfuncargs",
          "_getobj",
          "FixtureManager",
          "on_rm_rf_error",
          "PytestCacheWarning",
          "_compare_eq_sequence",
          "scopename2class",
          "JUNIT_XML_DEFAULT_FAMILY",
          "_NodeReporter",
          "teardown_nose",
          "finalize",
          "runpython",
          "setuponly",
          "deprecated",
          "_init_checker_class",
          "resume_global_capture",
          "scopeproperty",
          "REGEX_TYPE",
          "ensure_newline",
          "__take_sys_modules_snapshot",
          "import_plugin",
          "getcalls",
          "makeini",
          "setup",
          "load_config_dict_from_file",
          "strict",
          "getfixturemarker",
          "_argcomplete",
          "pytest_runtest_logfinish",
          "tmp_path",
          "addinivalue_line",
          "parse_summary_nouns",
          "addfinalizer",
          "_find_parametrized_scope",
          "_ellipsize",
          "MARK_GEN",
          "write_log_entry",
          "_disable_output_capturing_for_darwin",
          "encoding",
          "setmulti2",
          "__hash__",
          "StoreKey",
          "create_terminal_writer",
          "_iter_all_modules",
          "getvalueorskip",
          "RESULT_LOG",
          "Token",
          "TYPE_CHECKING",
          "filter_traceback",
          "getfailedcollections",
          "Frame",
          "get_cache_dir",
          "for_config",
          "__attrs_post_init__",
          "resume_fixture",
          "_wrapped_pdb_cls",
          "DEFAULT_LOG_FORMAT",
          "parametrize",
          "ReprFuncArgs",
          "_compare_eq_dict",
          "teardown",
          "__ne__",
          "listoutcomes",
          "_get_report_choice",
          "ParsedCall",
          "_locationline",
          "passed",
          "MonkeyPatch",
          "register",
          "exitstatus",
          "FuncFixtureInfo",
          "AssertionRewriter",
          "tbfilter",
          "install_importhook",
          "parseconfigure",
          "_addexcinfo",
          "__array_priority__",
          "saferepr",
          "getmodpath",
          "_args_converter",
          "stopTest",
          "read",
          "__next__",
          "showhelp",
          "_E",
          "caplog_handler_key",
          "runitem",
          "pytest_ignore_collect",
          "gethookrecorder",
          "verbosity",
          "wcswidth",
          "longreprtext",
          "mode",
          "append_pass",
          "is_potential_nosetest",
          "perform_collect",
          "FixtureFunctionMarker",
          "_notin_text",
          "_split_lines",
          "__contains__",
          "_prepareconfig",
          "try_cleanup",
          "mangle_test_address",
          "_format_boolop",
          "PytestDeprecationWarning",
          "not_expr",
          "pytest_cmdline_parse",
          "_assert_start_repr",
          "monkeypatch",
          "_format_action_invocation",
          "set_trace",
          "argnames",
          "_log_text",
          "CollectReport",
          "_params_converter",
          "WarningReport",
          "getimfunc",
          "add_stats",
          "FunctionDefinition",
          "_warn_about_missing_assertion",
          "genitems",
          "getworkerinfoline",
          "stop_capturing",
          "_FixtureFunction",
          "reorder_items_atscope",
          "section",
          "autouse",
          "_excinfo",
          "_param_ids_from",
          "from_exc_info",
          "parseoutcomes",
          "_get_first_non_fixture_func",
          "relline",
          "pytest_sessionfinish",
          "Mark",
          "ischildnode",
          "import_path",
          "_diff_text",
          "parse_num",
          "_should_truncate_item",
          "_eval_scope_callable",
          "main",
          "setdefault",
          "fail_marker",
          "read_global_capture",
          "FDCaptureBinary",
          "get_terminal_writer",
          "handleError",
          "get_sections",
          "hasplugin",
          "_processopt",
          "names_closure",
          "_parse_parametrize_args",
          "ApproxNumpy",
          "truncate_if_required",
          "expression",
          "_recursive_list_map",
          "style",
          "_get_pos",
          "MatcherAdapter",
          "write_sep",
          "repr_locals",
          "notify_exception",
          "DOCTEST_REPORT_CHOICE_NONE",
          "recwarn",
          "path",
          "_get_continue_on_failure",
          "__eq__",
          "scopemismatch",
          "_W",
          "resume_capturing",
          "nextitem",
          "_traceback",
          "parts",
          "INTERNAL_ERROR",
          "add_report_section",
          "getcall",
          "set_log_path",
          "README_CONTENT",
          "OR",
          "fail_fixturefunc",
          "pop",
          "_validate_ids",
          "lineno",
          "item_capture",
          "_teardown_yield_fixture",
          "_makeitem",
          "isiterable",
          "Testdir",
          "names",
          "_get_active_fixturedef",
          "__len__",
          "call_fixture_func",
          "_get_multicapture",
          "addini",
          "pytest_report_header",
          "_checkargnotcontained",
          "DoctestModule",
          "name",
          "getgroup",
          "_get_allow_bytes_flag",
          "make_numbered_dir_with_cleanup",
          "mark",
          "startTest",
          "CaptureManager",
          "suspend_fixture",
          "_HandlerType",
          "RPAREN",
          "suspend_capturing",
          "get_data",
          "add_marker",
          "_format_lines",
          "_addoption",
          "_make_plural",
          "popcall",
          "_warn_incompatibility_with_xunit2",
          "PYC_EXT",
          "tmpdir",
          "nose",
          "tb",
          "FixtureDef",
          "write_docstring",
          "istestclass",
          "session",
          "PdbTrace",
          "_check_non_top_pytest_plugins",
          "_makefile",
          "_io",
          "_compute_fixture_value",
          "_pluginmanager",
          "_importconftest",
          "debugging",
          "PYTEST_COLLECT_MODULE",
          "DropShorterLongHelpFormatter",
          "append_failure",
          "importorskip",
          "testdir",
          "_create",
          "deindent",
          "pytest_collection_finish",
          "funcnamefilter",
          "markup",
          "pytest_load_initial_conftests",
          "undo",
          "SafeRepr",
          "pytest_cmdline_preparse",
          "_get_progress_information_message",
          "getstatementrange",
          "repr_failure",
          "default_plugins",
          "_remove_ansi_escape_sequences",
          "from_config",
          "_schedule_finalizers",
          "setattr",
          "hasinit",
          "_getconftest_pathlist",
          "hookimpl",
          "nodes",
          "_initrequest",
          "_legal_chars",
          "assert_never",
          "FixtureLookupErrorRepr",
          "parse_hookimpl_opts",
          "_S",
          "flow_marker",
          "tracebackcutdir",
          "OptionGroup",
          "reset",
          "_testcase",
          "FSCollector",
          "LFPlugin",
          "pytest_assertion_pass",
          "MarkMatcher",
          "_repr_failure_py",
          "hasnew",
          "format_explanation",
          "_determine_main_color",
          "visit_BoolOp",
          "getitem",
          "cache_dir_from_config",
          "capstderr",
          "get_dirs_from_args",
          "_set_initial_conftests",
          "_split_explanation",
          "_suspend",
          "iter_markers",
          "pos",
          "cache_key",
          "_LiveLoggingNullHandler",
          "_get_fixturestack",
          "disabled",
          "chain",
          "_write_source",
          "skipped_by_mark_key",
          "capsysbinary",
          "syspath_prepend",
          "getfailures",
          "inline_run",
          "_report_keyboardinterrupt",
          "_compare_eq_any",
          "TerminalRepr",
          "path_matches_patterns",
          "snap",
          "_mk_tmp",
          "FormattedExcinfo",
          "record_testreport",
          "PseudoFixtureDef",
          "warnings",
          "matching_platform",
          "pytest_itemcollected",
          "stepwise",
          "record_testsuite_property",
          "TerminalReporter",
          "DOCTEST_REPORT_CHOICE_UDIFF",
          "ArgumentError",
          "_legal_ranges",
          "call_and_report",
          "_addoption_instance",
          "FIXTURE_POSITIONAL_ARGUMENTS",
          "_REPORTCHARS_DEFAULT",
          "freeze_support",
          "resultlog_key",
          "_config",
          "_get_line_with_reprcrash_message",
          "_inject_setup_module_fixture",
          "fnmatch_ex",
          "D",
          "variable",
          "get_real_method",
          "CollectError",
          "Code",
          "_to_json",
          "LoggingPlugin",
          "ColoredLevelFormatter",
          "lex",
          "Collector",
          "merge_family",
          "get_terminal_width",
          "scopenum_function",
          "suspend",
          "PercentStyleMultiline",
          "restore",
          "_opentestcase",
          "KeywordMatcher",
          "doctest_namespace",
          "sep",
          "append_skipped",
          "Scanner",
          "WarningsChecker",
          "StepwisePlugin",
          "_setup_fixtures",
          "pytest_runtest_makereport",
          "get_public_names",
          "get_config",
          "LineMatcher_fixture",
          "ParameterSet",
          "IDENT_PREFIX",
          "DoctestItem",
          "locals",
          "caplog_records_key",
          "instance",
          "_tryconvertpyarg",
          "_log_cli_enabled",
          "catching_logs",
          "CACHEDIR_TAG_CONTENT",
          "fullwidth",
          "_get_flag_lookup",
          "resume",
          "tolerance",
          "DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE",
          "__iter__",
          "__getattr__",
          "_enter_pdb",
          "__exit__",
          "co_equal",
          "Metafunc",
          "PytestUnknownMarkWarning",
          "BASE_TYPE",
          "set",
          "entrysep",
          "errisinstance",
          "_patch_unwrap_mock_aware",
          "accept",
          "_getreprcrash",
          "_splitnode",
          "result",
          "pytest_runtest_logreport",
          "Parser",
          "istestfunc",
          "K",
          "outcomes",
          "iscoroutinefunction",
          "combined_with",
          "fixtures",
          "fullsource",
          "_from_json",
          "LineComp",
          "at_level",
          "__slots__",
          "assertrepr_compare",
          "show_fixtures_per_test",
          "failed",
          "EMPTY_PARAMETERSET_OPTION",
          "_call_reprcompare",
          "MyOptionParser",
          "TempPathFactory",
          "getbasetemp",
          "clear",
          "__module__",
          "should_do_markup",
          "_add_stats",
          "_teardown_with_finalization",
          "value",
          "error",
          "pytest_make_parametrize_id",
          "ApproxDecimal",
          "_ascii_escaped_by_config",
          "_prunetraceback",
          "ExceptionInfo",
          "emit",
          "RUNNER_CLASS",
          "pytest_fixture_setup",
          "_match_lines",
          "count_towards_summary",
          "isattrs",
          "MINUS_K_DASH",
          "Notset",
          "token",
          "maketxtfile",
          "wcwidth",
          "parse_known_args",
          "makeconftest",
          "derive_importpath",
          "str",
          "_PYTEST_DIR",
          "num_mock_patch_args",
          "stop",
          "category",
          "runtestprotocol",
          "pytestconfig",
          "_fillfixtures",
          "fixture",
          "check_testcase_implements_trial_reporter",
          "ascii_escaped",
          "add_attribute",
          "TESTS_FAILED",
          "_visit_filter",
          "_T",
          "getvalue",
          "_get_global_properties_node",
          "width_of_current_line",
          "FSHookProxy",
          "_is_setup_py",
          "_matchfactories",
          "freeze_includes",
          "own_mark_names",
          "create_new_paste",
          "text",
          "pytest_runtest_teardown",
          "AND",
          "parse_hookspec_opts",
          "PytestWarning",
          "_trace",
          "__missing__",
          "short_test_summary",
          "_ensure_immutable_ids",
          "ConftestImportFailure",
          "locate_config",
          "get_direct_param_fixture_func",
          "_saved",
          "Argument",
          "capfd",
          "makedir",
          "_param_ids_generated",
          "_non_numeric_type_error",
          "cache",
          "_ensure_removed_sysmodule",
          "getfixtureinfo",
          "_check_record_param_type",
          "_in_suspended",
          "assertion",
          "AlwaysDispatchingPrettyPrinter",
          "attrs",
          "_is_doctest",
          "_compare_eq_iterable",
          "makepyfile"
        ]
      },
      "response": {
        "keywords": [
          "add_marker",
          "request",
          "xfail",
          "FixtureRequest",
          "pytest"
        ]
      }
    },
    {
      "name": "FilesKeywordSearch",
      "metadata": {
        "start": "2024-08-19T13:34:52.394279",
        "usage": "234.35211181640625 ms"
      },
      "request": {
        "tokens": [
          "add_marker",
          "request",
          "xfail",
          "FixtureRequest",
          "pytest"
        ]
      },
      "response": {
        "results": {
          "pytest": [
            "src/_pytest/mark/structures.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/logging.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/freeze_support.py",
            "src/_pytest/mark/expression.py",
            "src/_pytest/capture.py",
            "src/_pytest/terminal.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/monkeypatch.py",
            "src/_pytest/outcomes.py",
            "src/pytest/__main__.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/pytester.py",
            "src/_pytest/assertion/util.py",
            "src/_pytest/compat.py",
            "src/_pytest/timing.py",
            "src/_pytest/config/argparsing.py",
            "src/_pytest/unittest.py",
            "src/_pytest/reports.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/warnings.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/warning_types.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/mark/__init__.py",
            "src/pytest/collect.py",
            "src/_pytest/doctest.py",
            "src/_pytest/setupplan.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/config/exceptions.py",
            "src/_pytest/main.py",
            "src/_pytest/deprecated.py",
            "src/_pytest/config/findpaths.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/recwarn.py",
            "src/_pytest/python_api.py",
            "src/_pytest/debugging.py",
            "src/_pytest/runner.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/skipping.py",
            "src/pytest/__init__.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/stepwise.py"
          ],
          "FixtureRequest": [
            "src/_pytest/fixtures.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/unittest.py",
            "src/_pytest/logging.py",
            "src/_pytest/python.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/pytester.py",
            "src/_pytest/doctest.py",
            "src/_pytest/tmpdir.py"
          ],
          "xfail": [
            "src/_pytest/mark/structures.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/unittest.py",
            "src/_pytest/python.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/skipping.py",
            "src/_pytest/mark/__init__.py",
            "src/pytest/__init__.py"
          ],
          "request": [
            "src/_pytest/fixtures.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/unittest.py",
            "src/_pytest/capture.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/logging.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/python.py",
            "src/_pytest/runner.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/pytester.py",
            "src/_pytest/setupplan.py",
            "src/_pytest/tmpdir.py"
          ],
          "add_marker": [
            "src/_pytest/fixtures.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py"
          ]
        }
      }
    },
    {
      "name": "FilesFilter",
      "metadata": {
        "start": "2024-08-19T13:34:52.628659",
        "usage": "7187.932968139648 ms"
      },
      "request": {
        "keyword_search_results": {
          "pytest": [
            "src/_pytest/mark/structures.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/logging.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/freeze_support.py",
            "src/_pytest/mark/expression.py",
            "src/_pytest/capture.py",
            "src/_pytest/terminal.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/monkeypatch.py",
            "src/_pytest/outcomes.py",
            "src/pytest/__main__.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/pytester.py",
            "src/_pytest/assertion/util.py",
            "src/_pytest/compat.py",
            "src/_pytest/timing.py",
            "src/_pytest/config/argparsing.py",
            "src/_pytest/unittest.py",
            "src/_pytest/reports.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/warnings.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/warning_types.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/mark/__init__.py",
            "src/pytest/collect.py",
            "src/_pytest/doctest.py",
            "src/_pytest/setupplan.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/config/exceptions.py",
            "src/_pytest/main.py",
            "src/_pytest/deprecated.py",
            "src/_pytest/config/findpaths.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/recwarn.py",
            "src/_pytest/python_api.py",
            "src/_pytest/debugging.py",
            "src/_pytest/runner.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/skipping.py",
            "src/pytest/__init__.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/stepwise.py"
          ],
          "FixtureRequest": [
            "src/_pytest/fixtures.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/unittest.py",
            "src/_pytest/logging.py",
            "src/_pytest/python.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/pytester.py",
            "src/_pytest/doctest.py",
            "src/_pytest/tmpdir.py"
          ],
          "xfail": [
            "src/_pytest/mark/structures.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/unittest.py",
            "src/_pytest/python.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/skipping.py",
            "src/_pytest/mark/__init__.py",
            "src/pytest/__init__.py"
          ],
          "request": [
            "src/_pytest/fixtures.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/unittest.py",
            "src/_pytest/capture.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/logging.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/python.py",
            "src/_pytest/runner.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/pytester.py",
            "src/_pytest/setupplan.py",
            "src/_pytest/tmpdir.py"
          ],
          "add_marker": [
            "src/_pytest/fixtures.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py"
          ]
        }
      },
      "response": {
        "scratch_pad": "1. **Analyze the issue:**\n   - The issue is about dynamically adding an `xfail` marker to a test in pytest 6.x, which raises an AssertionError instead of marking the test as expected to fail (as it did in pytest 5.x).\n   - Key components involved: pytest's `add_marker`, `xfail`, and `request` object.\n\n2. **Identify related files:**\n   - Keywords: `pytest`, `xfail`, `add_marker`, `request`.\n   - Search results:\n     - `pytest` keyword yields many files, need to narrow down based on specific components (xfail and add_marker usage related).\n     - `xfail` keyword results:\n        - `src/_pytest/mark/structures.py`: Likely handles mark structures including xfail.\n        - `src/_pytest/skipping.py`: Skipping logic may include xfail as it bypasses normal test execution.\n     - `add_marker` keyword results:\n        - `src/_pytest/nodes.py`: Might relate to how markers are added to test nodes.\n     - `request` keyword results:\n        - `src/_pytest/fixtures.py`: Handles fixtures which integrate closely with the request object likely involving request.node.add_marker().\n\n3. **Select and sort related files by relevance to the issue:**\n   1. `src/_pytest/mark/structures.py`: Likely involves constructing xfail markers.\n   2. `src/_pytest/skipping.py`: Skipping logic could be impacted by xfail behavior.\n   3. `src/_pytest/nodes.py`: Concerned with adding markers to nodes, directly relevant to the issue of dynamic xfail addition.\n   4. `src/_pytest/fixtures.py`: Since it deals with the request object, it could impact how add_marker behaves.\n   5. `src/_pytest/mark/__init__.py`: Might contain initialization logic for marks including xfail.\n",
        "file_paths": [
          "src/_pytest/mark/structures.py",
          "src/_pytest/skipping.py",
          "src/_pytest/nodes.py",
          "src/_pytest/fixtures.py",
          "src/_pytest/mark/__init__.py"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T13:34:59.816612",
        "usage": "6949.345827102661 ms"
      },
      "request": {
        "file_path": "src/_pytest/mark/structures.py"
      },
      "response": {
        "scratch_pad": "1. Understanding the Issue:\n- The issue is about dynamically adding an xfail marker to a test via `request.node.add_marker(mark)` in pytest 6.0. Previously, in pytest 5.x, this would work as expected, treating the marked test as if it was statically marked with `xfail`. However, with pytest 6.0.0rc0, this raises an error during the test.\n- No specific reproduction steps are needed since the code snippet provides a clear usage pattern of how the xfail marker is dynamically added.\n- The issue seems to be caused by a change in behavior in pytest regarding the handling of dynamically added markers, particularly xfail.\n- The expectation is that dynamically adding an xfail marker should still cause the test to be reported as xfailed, not fail with an error.\n\n2. Evaluation of File Content:\n- The relevant part of the codebase is likely related to how pytest handles markers, particularly the xfail marker.\n- Key elements in the code include:\n  - The `MarkDecorator` and `Mark` classes. It's essential to understand how marks are created and applied.\n  - The `store_mark()` function: This function is used to apply a mark to an object.\n  - The `MarkGenerator` class contains logic for handling and validating markers.\n\n3. Decision:\n- The classes `Mark`, `MarkDecorator`, and function `store_mark()` seem to be directly related to the issue as they deal with how markers (including xfail) are applied and handled by pytest.\n- The issue might be due to a change in these components, causing the dynamic addition of markers to not behave as expected.",
        "relevant": true,
        "root_cause": true,
        "relevant_files": [],
        "relevant_symbols": [
          "Mark",
          "MarkDecorator",
          "store_mark"
        ],
        "root_cause_symbols": [
          "Mark",
          "MarkDecorator",
          "store_mark"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T13:35:06.765979",
        "usage": "7988.1463050842285 ms"
      },
      "request": {
        "file_path": "src/_pytest/skipping.py"
      },
      "response": {
        "scratch_pad": "1. Analyzing the reported issue:\n    - The issue reports a change in behavior in pytest version 6.0.0rc0 compared to 5.x when dynamically adding an `xfail` marker. In version 6, the test raises a failure instead of being marked as expected to fail (xfail).\n    \n2. Analyzing the code provided in `src/_pytest/skipping.py`:\n    - The file contains logic related to markers for skipping and xfail in pytest (`skip`, `skipif`, and `xfail`).\n    - `evaluate_xfail_marks` is used to evaluate xfail markers.\n    - `pytest_runtest_makereport` is involved in processing test results, affecting the reported outcome of a test item.\n    \n3. Matching symbols with the reported issue:\n    - The methods `evaluate_xfail_marks` and `pytest_runtest_makereport` are directly related to how xfail markers are evaluated and reported.\n    - There is also a `pytest_addoption` function that might relate to configurations affecting xfail behavior, hinting towards the `--runxfail` option.\n    \n4. Checking if these symbols align with the issue:\n    - Given that the issue focuses on the dynamic addition of xfail markers and their behavior, the logic within `pytest_runtest_makereport` that handles test outcomes seems likely to be the change causing the issue, as errors from failing tests change the outcome instead of marking it as xfail.\n    \n5. Determining root cause:\n    - The file `src/_pytest/skipping.py` is very likely the root cause of the issue because it contains the logic for handling xfail behavior, which directly aligns with the reported behavior change.\n\nConclusion: The file `/src/_pytest/skipping.py` and specifically the two symbols `evaluate_xfail_marks` and `pytest_runtest_makereport` seem like prime candidates for the root cause of the described issue.",
        "relevant": true,
        "root_cause": true,
        "relevant_files": [],
        "relevant_symbols": [
          "evaluate_xfail_marks",
          "pytest_runtest_makereport"
        ],
        "root_cause_symbols": [
          "evaluate_xfail_marks",
          "pytest_runtest_makereport"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T13:35:14.754143",
        "usage": "6858.81495475769 ms"
      },
      "request": {
        "file_path": "src/_pytest/nodes.py"
      },
      "response": {
        "scratch_pad": "1. Analyze User Instructions:\n1.1 The issue involves the change in behavior of dynamically adding xfail markers with pytest's request object in version 6.0.0rc0. Previously, it would treat the test as xfailed, but with 6.0.0rc0, it causes a failure assertion instead.\n\n1.2 The user provides a reproduce case using pytest's request.node.add_marker(mark) method to dynamically add an xfail marker.\n\n1.3 The change in behavior is likely due to modifications in how pytest handles dynamic markers within nodes or perhaps how nodes check for xfail conditions.\n\n1.4 The expectation is that tests dynamically marked with xfail should not fail the test session if the test fails. The current behavior does not meet this expectation in pytest 6.0.0rc0.\n\n1.5 A possible solution could involve ensuring that dynamic xfail markers are processed correctly, similar to static xfail markers.\n\n\n2. Make file evaluation:\n2.1 The file Content appears to be dealing with the internal handling of nodes in the pytest framework.\n2.2 Searching for relevant classes/functions...\n2.3 look for relevant symbol `add_marker` because dynamic marker adding involves node manipulation within test cases.\n\n- `add_marker` is a method within the `Node` class. This method might relate to the issue as users were adding xfail markers dynamically to nodes using this functionality.\n\n2.4 Investigate `Node` class and its methods to understand how markers are being processed. It's crucial given the issue involves dynamic marker handling.\n\n2.5 No direct interaction with test execution logic observed, but `add_marker` holds significance as it handles addition markers to nodes.\n\n2.6 This file seems related to dynamic marker processing but may refer to other components for test execution and assertion logic. Therefore, while not the root cause, it plays a role in the broader ecosystem.\n\n2.7 Suggest looking into test run and assertion modules if needed.",
        "relevant": true,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/runner.py",
          "src/_pytest/assertion.py"
        ],
        "relevant_symbols": [
          "Node.add_marker"
        ],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T13:35:21.612974",
        "usage": "9937.361717224121 ms"
      },
      "request": {
        "file_path": "src/_pytest/fixtures.py"
      },
      "response": {
        "scratch_pad": "1. Analyzing the Issue:\n1.1. The issue reported is about dynamically adding an `xfail` marker to a test using `request.node.add_marker(mark)` in Pytest 6.x. The behavior has changed from version 5.x, where it treated the test as expected to fail (xfail), whereas in 6.x it does not do so and fails the test.\n1.2. The user describes a reproducible step with a sample test case using `request.node.add_marker(mark)` to add a xfail marker, asserting 0 to force failure, and comparing the behavior of the same test in Pytest 5.x and 6.x.\n1.3. The change causing the issue is found in the handling or application of dynamically added markers in Pytest 6.x.\n1.4. The user's expectation is that dynamically added `xfail` markers should be honored the same way static xfail markers are. The issue is caused by some change in how dynamic markers are processed in version 6.x.\n1.5. A possible solution could involve adjusting how pytest processes dynamic markers to ensure the xfail marker is handled correctly even when added dynamically during test execution.\n\n2. Evaluating the File:\n2.1. Analysis of the file content, `src/_pytest/fixtures.py`, needs to align with issues relating to test markers, especially `request.node.add_marker`.\n2.2. The file focuses on fixture management, handling requests for fixtures, and setting up execution of test environments.\n2.3. The `FixtureRequest` class in the file has a `applymarker` method which utilizes `self.node.add_marker(marker)`. This is a potential point where the `xfail` marker might be interacting with Pytest's inner workings.\n2.6. Since the issue is about markers, and the symbol `applymarker()` uses the `add_marker` function, it's likely involved in the issue.\n\n3. Conclusion:\nThe file is partially relevant as it contains the method `applymarker()` which directly involves adding markers to tests. However, it may not be the complete root cause of why the behavior has changed. Further investigation on where `applymarker()` is called and how markers are processed might be needed. Adjustments might be required specifically in how pytest evaluates markers at runtime or integrates them into the testing workflow.",
        "relevant": true,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/nodes.py",
          "src/_pytest/mark.py",
          "src/_pytest/runner.py"
        ],
        "relevant_symbols": [
          "FixtureRequest.applymarker"
        ],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T13:35:31.550366",
        "usage": "8378.636121749878 ms"
      },
      "request": {
        "file_path": "src/_pytest/mark/__init__.py"
      },
      "response": {
        "scratch_pad": "1. Analyze User Instructions:\n1.1 The user is encountering an issue when dynamically adding an xfail marker to a test in pytest. Previously (in pytest 5.x), adding an xfail marker dynamically would cause a test failure to be ignored. In pytest 6.0.0rc0, attempting to dynamically add this marker results in an assertion error rather than the expected xfail behavior.\n1.2 The user provides steps to reproduce the issue: they have a test case where they dynamically add an xfail marker using the request object's add_marker method.\n1.3 It seems like something has changed in the way pytest 6.x handles dynamically added xfail markers compared to 5.x. This has led to tests which would have been marked as xfail in 5.x to now fail normally.\n1.4 The user expects that even with dynamic markings, tests should acknowledge and behave as xfail if marked. This expectation isn't being met because of the change in the internal handling of these markers between versions.\n1.5 The user's expectation is that the behavior of dynamically adding the xfail marker should remain consistent across versions, treating failures as \"expected\" rather than raising errors.\n1.6 A possible solution would be to revert to the behavior of 5.x for handling dynamic markers or explicitly document this change and provide a different method to achieve the same result if intended.\n\n2. Make file evaluation:\n2.1 The file imports multiple modules related to marking tests and has several functions related to pytest's configuration and command-line option parsing.\n2.2 While there are mentions of Mark, MarkDecorator, and how pytest operates with markers such as xfail through the context of parameters (with param function), no portion of this file explicitly deals with dynamically adding markers during test runs like in the reported issue.\n2.3 The relevant functions and classes mostly deal with managing and coordinating the application of markers and options but do not directly impact the runtime behavior of adding markers to test nodes.\n2.4 This suggests the dynamic behavior of adding markers might be handled in a different part of the codebase.\n2.5 While important for understanding the broader context of mark handling, this file doesn't address the direct runtime application of markers during test execution.\n\n3. Output Your Decision:\nThis file is related but doesn't seem to directly impact the runtime application of markers during test execution, which is where the reported issue lies.",
        "relevant": false,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/main.py",
          "src/_pytest/nodes.py",
          "src/_pytest/runner.py"
        ],
        "relevant_symbols": [],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileSymbolSearch",
      "metadata": {
        "start": "2024-08-19T13:35:39.929057",
        "usage": "219.82789039611816 ms"
      },
      "request": {
        "files": [
          {
            "file_path": "src/_pytest/mark/structures.py",
            "relevant_symbol_keys": [
              "Mark",
              "MarkDecorator",
              "store_mark"
            ],
            "root_cause_symbol_keys": [
              "Mark",
              "MarkDecorator",
              "store_mark"
            ]
          },
          {
            "file_path": "src/_pytest/skipping.py",
            "relevant_symbol_keys": [
              "evaluate_xfail_marks",
              "pytest_runtest_makereport"
            ],
            "root_cause_symbol_keys": [
              "evaluate_xfail_marks",
              "pytest_runtest_makereport"
            ]
          },
          {
            "file_path": "src/_pytest/nodes.py",
            "relevant_symbol_keys": [
              "Node.add_marker"
            ],
            "root_cause_symbol_keys": []
          },
          {
            "file_path": "src/_pytest/fixtures.py",
            "relevant_symbol_keys": [
              "FixtureRequest.applymarker"
            ],
            "root_cause_symbol_keys": []
          },
          {
            "file_path": "src/_pytest/mark/__init__.py",
            "relevant_symbol_keys": [],
            "root_cause_symbol_keys": []
          }
        ],
        "with_content": true
      },
      "response": {
        "related_symbols": [
          {
            "name": "_pytest.nodes.Node.add_marker",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def add_marker(\n        self, marker: Union[str, MarkDecorator], append: bool = True\n    ) -> None:\n        \"\"\"dynamically add a marker object to the node.\n\n        :type marker: ``str`` or ``pytest.mark.*``  object\n        :param marker:\n            ``append=True`` whether to append the marker,\n            if ``False`` insert at position ``0``.\n        \"\"\"\n        from _pytest.mark import MARK_GEN\n\n        if isinstance(marker, MarkDecorator):\n            marker_ = marker\n        elif isinstance(marker, str):\n            marker_ = getattr(MARK_GEN, marker)\n        else:\n            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n        self.keywords[marker_.name] = marker_\n        if append:\n            self.own_markers.append(marker_.mark)\n        else:\n            self.own_markers.insert(0, marker_.mark)",
            "start_line": 260,
            "start_column": 8242,
            "end_line": 4,
            "end_column": 9073,
            "start_byte": 8242,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureRequest.applymarker",
            "file_path": "src/_pytest/fixtures.py",
            "file_content": "def applymarker(self, marker) -> None:\n        \"\"\" Apply a marker to a single test function invocation.\n        This method is useful if you don't want to have a keyword/marker\n        on all function invocations.\n\n        :arg marker: a :py:class:`_pytest.mark.MarkDecorator` object\n            created by a call to ``pytest.mark.NAME(...)``.\n        \"\"\"\n        self.node.add_marker(marker)",
            "start_line": 548,
            "start_column": 21159,
            "end_line": 4,
            "end_column": 21551,
            "start_byte": 21159,
            "end_byte": 4
          }
        ],
        "root_caused_symbols": [
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1174,
            "start_column": 45925,
            "end_line": 0,
            "end_column": 47430,
            "start_byte": 45925,
            "end_byte": 0
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.scope",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1176,
            "start_column": 45979,
            "end_line": 4,
            "end_column": 46049,
            "start_byte": 45979,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.params",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1177,
            "start_column": 46054,
            "end_line": 4,
            "end_column": 46134,
            "start_byte": 46054,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.autouse",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1178,
            "start_column": 46139,
            "end_line": 4,
            "end_column": 46182,
            "start_byte": 46139,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1179,
            "start_column": 46187,
            "end_line": 4,
            "end_column": 46411,
            "start_byte": 46187,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1187,
            "start_column": 46416,
            "end_line": 4,
            "end_column": 46464,
            "start_byte": 46416,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1189,
            "start_column": 46470,
            "end_line": 4,
            "end_column": 47430,
            "start_byte": 46470,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "lf.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 214,
            "start_column": 7079,
            "end_line": 0,
            "end_column": 7525,
            "start_byte": 7079,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkMatcher.own_mark_names",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": " Mark.\n\n        Combines b",
            "start_line": 221,
            "start_column": 7251,
            "end_line": 4,
            "end_column": 7277,
            "start_byte": 7251,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.from_item",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "nding args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert s",
            "start_line": 223,
            "start_column": 7283,
            "end_line": 4,
            "end_column": 7438,
            "start_byte": 7283,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "me == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 228,
            "start_column": 7444,
            "end_line": 4,
            "end_column": 7525,
            "start_byte": 7444,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s(frozen=True)\nclass Mark:\n    #: Name of the mark.\n    name = attr.ib(type=str)\n    #: Positional arguments of the mark decorator.\n    args = attr.ib(type=Tuple[Any, ...])\n    #: Keyword arguments of the mark decorator.\n    kwargs = attr.ib(type=Mapping[str, Any])\n\n    #: Source Mark for ids with parametrize Marks.\n    _param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)\n    #: Resolved/generated ids with parametrize Marks.\n    _param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )\n\n    def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 195,
            "start_column": 6452,
            "end_line": 0,
            "end_column": 7948,
            "start_byte": 6452,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.Mark.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "name = attr.ib(type=str)",
            "start_line": 198,
            "start_column": 6514,
            "end_line": 4,
            "end_column": 6538,
            "start_byte": 6514,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "args = attr.ib(type=Tuple[Any, ...])",
            "start_line": 200,
            "start_column": 6594,
            "end_line": 4,
            "end_column": 6630,
            "start_byte": 6594,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "kwargs = attr.ib(type=Mapping[str, Any])",
            "start_line": 202,
            "start_column": 6683,
            "end_line": 4,
            "end_column": 6723,
            "start_byte": 6683,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_from",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)",
            "start_line": 205,
            "start_column": 6780,
            "end_line": 4,
            "end_column": 6854,
            "start_byte": 6780,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_generated",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )",
            "start_line": 207,
            "start_column": 6913,
            "end_line": 4,
            "end_column": 7013,
            "start_byte": 6913,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._has_param_ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4",
            "start_line": 211,
            "start_column": 7019,
            "end_line": 4,
            "end_column": 7111,
            "start_byte": 7019,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.combined_with",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 214,
            "start_column": 7117,
            "end_line": 4,
            "end_column": 7948,
            "start_byte": 7117,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark._Markable",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_Markable = TypeVar(\"_Markable\", bound=Union[Callable[..., object], type])",
            "start_line": 245,
            "start_column": 8132,
            "end_line": 0,
            "end_column": 8206,
            "start_byte": 8132,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s\nclass MarkDecorator:\n    \"\"\"A decorator for applying a mark on test functions and classes.\n\n    MarkDecorators are created with ``pytest.mark``::\n\n        mark1 = pytest.mark.NAME              # Simple MarkDecorator\n        mark2 = pytest.mark.NAME(name1=value) # Parametrized MarkDecorator\n\n    and can then be applied as decorators to test functions::\n\n        @mark2\n        def test_function():\n            pass\n\n    When a MarkDecorator is called it does the following:\n\n    1. If called with a single class as its only positional argument and no\n       additional keyword arguments, it attaches the mark to the class so it\n       gets applied automatically to all test cases found in that class.\n\n    2. If called with a single function as its only positional argument and\n       no additional keyword arguments, it attaches the mark to the function,\n       containing all the arguments already stored internally in the\n       MarkDecorator.\n\n    3. When called in any other case, it returns a new MarkDecorator instance\n       with the original MarkDecorator's content updated with the arguments\n       passed to this call.\n\n    Note: The rules above prevent MarkDecorators from storing only a single\n    function or class reference as their positional argument with no\n    additional keyword or positional arguments. You can work around this by\n    using `with_args()`.\n    \"\"\"\n\n    mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))\n\n    @property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name\n\n    @property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args\n\n    @property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs\n\n    @property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)\n\n    def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)\n\n    def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))\n\n    # Type ignored because the overloads overlap with an incompatible\n    # return type. Not much we can do about that. Thankfully mypy picks\n    # the first match so it works out even if we break the rules.\n    @overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()\n\n    @overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()\n\n    def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 248,
            "start_column": 8209,
            "end_line": 0,
            "end_column": 11549,
            "start_byte": 8209,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator.mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))",
            "start_line": 284,
            "start_column": 9608,
            "end_line": 4,
            "end_column": 9678,
            "start_byte": 9608,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name",
            "start_line": 286,
            "start_column": 9684,
            "end_line": 4,
            "end_column": 9785,
            "start_byte": 9684,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args",
            "start_line": 291,
            "start_column": 9791,
            "end_line": 4,
            "end_column": 9904,
            "start_byte": 9791,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs",
            "start_line": 296,
            "start_column": 9910,
            "end_line": 4,
            "end_column": 10031,
            "start_byte": 9910,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.markname",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)",
            "start_line": 301,
            "start_column": 10037,
            "end_line": 4,
            "end_column": 10147,
            "start_byte": 10037,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__repr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)",
            "start_line": 305,
            "start_column": 10153,
            "end_line": 4,
            "end_column": 10235,
            "start_byte": 10153,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.with_args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))",
            "start_line": 308,
            "start_column": 10241,
            "end_line": 4,
            "end_column": 10647,
            "start_byte": 10241,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()",
            "start_line": 322,
            "start_column": 10861,
            "end_line": 4,
            "end_column": 10981,
            "start_byte": 10861,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()",
            "start_line": 326,
            "start_column": 10987,
            "end_line": 4,
            "end_column": 11150,
            "start_byte": 10987,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 332,
            "start_column": 11156,
            "end_line": 4,
            "end_column": 11549,
            "start_byte": 11156,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.store_mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def store_mark(obj, mark: Mark) -> None:\n    \"\"\"Store a Mark on an object.\n\n    This is used to implement the Mark declarations/decorators correctly.\n    \"\"\"\n    assert isinstance(mark, Mark), mark\n    # Always reassign name to avoid updating pytestmark in a reference that\n    # was only borrowed.\n    obj.pytestmark = get_unpacked_marks(obj) + [mark]",
            "start_line": 369,
            "start_column": 12372,
            "end_line": 0,
            "end_column": 12724,
            "start_byte": 12372,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkGenerator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "class MarkGenerator:\n    \"\"\"Factory for :class:`MarkDecorator` objects - exposed as\n    a ``pytest.mark`` singleton instance.\n\n    Example::\n\n         import pytest\n\n         @pytest.mark.slowtest\n         def test_function():\n            pass\n\n    applies a 'slowtest' :class:`Mark` on ``test_function``.\n    \"\"\"\n\n    _config = None  # type: Optional[Config]\n    _markers = set()  # type: Set[str]\n\n    # See TYPE_CHECKING above.\n    if TYPE_CHECKING:\n        # Using casts instead of type comments intentionally - issue #7473.\n        # TODO(py36): Change to builtin annotation syntax.\n        skip = cast(_SkipMarkDecorator, None)\n        skipif = cast(_SkipifMarkDecorator, None)\n        xfail = cast(_XfailMarkDecorator, None)\n        parametrize = cast(_ParametrizeMarkDecorator, None)\n        usefixtures = cast(_UsefixturesMarkDecorator, None)\n        filterwarnings = cast(_FilterwarningsMarkDecorator, None)\n\n    def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 450,
            "start_column": 15252,
            "end_line": 0,
            "end_column": 18166,
            "start_byte": 15252,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkGenerator._config",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_config = None",
            "start_line": 465,
            "start_column": 15571,
            "end_line": 4,
            "end_column": 15585,
            "start_byte": 15571,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator._markers",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_markers = set()",
            "start_line": 466,
            "start_column": 15616,
            "end_line": 4,
            "end_column": 15632,
            "start_byte": 15616,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator.__getattr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 479,
            "start_column": 16175,
            "end_line": 4,
            "end_column": 18166,
            "start_byte": 16175,
            "end_byte": 4
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "\"values\", Sequence[Union[object, NotSetType]]),\n            (\"marks\", \"typing.Collection[Union[MarkDecorator, Mark]]\"),\n            (\"id\", Optional[str]),\n        ],\n    )\n):\n    @classmethod\n    d",
            "start_line": 77,
            "start_column": 1903,
            "end_line": 0,
            "end_column": 2100,
            "start_byte": 1903,
            "end_byte": 0
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning.__module__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "   @classmethod\n    d",
            "start_line": 83,
            "start_column": 2079,
            "end_line": 4,
            "end_column": 2100,
            "start_byte": 2079,
            "end_byte": 4
          },
          {
            "name": "_pytest.hookspec.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "",
            "start_line": 486,
            "start_column": 17380,
            "end_line": 0,
            "end_column": 17867,
            "start_byte": 17380,
            "end_byte": 0
          },
          {
            "name": "_pytest.runner.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "ort_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:\n    if hasattr(report, \"wasxfail\"):\n        if report.skipped",
            "start_line": 318,
            "start_column": 10464,
            "end_line": 0,
            "end_column": 10595,
            "start_byte": 10464,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.evaluate_xfail_marks",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None",
            "start_line": 199,
            "start_column": 6507,
            "end_line": 0,
            "end_column": 7408,
            "start_byte": 6507,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "@hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n    outcome = yield\n    rep = outcome.get_result()\n    xfailed = item._store.get(xfailed_key, None)\n    # unittest special case, see setting of unexpectedsuccess_key\n    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n        reason = item._store[unexpectedsuccess_key]\n        if reason:\n            rep.longrepr = \"Unexpected success: {}\".format(reason)\n        else:\n            rep.longrepr = \"Unexpected success\"\n        rep.outcome = \"failed\"\n    elif item.config.option.runxfail:\n        pass  # don't interfere\n    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n        assert call.excinfo.value.msg is not None\n        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n        rep.outcome = \"skipped\"\n    elif not rep.skipped and xfailed:\n        if call.excinfo:\n            raises = xfailed.raises\n            if raises is not None and not isinstance(call.excinfo.value, raises):\n                rep.outcome = \"failed\"\n            else:\n                rep.outcome = \"skipped\"\n                rep.wasxfail = xfailed.reason\n        elif call.when == \"call\":\n            if xfailed.strict:\n                rep.outcome = \"failed\"\n                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n            else:\n                rep.outcome = \"passed\"\n                rep.wasxfail = xfailed.reason\n\n    if (\n        item._store.get(skipped_by_mark_key, True)\n        and rep.skipped\n        and type(rep.longrepr) is tuple\n    ):\n        # skipped by mark.skipif; change the location of the failure\n        # to point to the item definition, otherwise it will display\n        # the location of where the skip exception was raised within pytest\n        _, _, reason = rep.longrepr\n        filename, line = item.reportinfo()[:2]\n        assert line is not None\n        rep.longrepr = str(filename), line + 1, reason",
            "start_line": 259,
            "start_column": 8490,
            "end_line": 0,
            "end_column": 10447,
            "start_byte": 8490,
            "end_byte": 0
          },
          {
            "name": "_pytest.unittest.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "urn \"xpassed\", \"X\", \"XPASS\"\n    return None\n",
            "start_line": 290,
            "start_column": 10683,
            "end_line": 0,
            "end_column": 11441,
            "start_byte": 10683,
            "end_byte": 0
          }
        ]
      }
    },
    {
      "name": "SymbolsEvaluate",
      "metadata": {
        "start": "2024-08-19T13:35:40.148892",
        "usage": "21790.255069732666 ms"
      },
      "request": {
        "related_symbols": [
          {
            "name": "_pytest.nodes.Node.add_marker",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def add_marker(\n        self, marker: Union[str, MarkDecorator], append: bool = True\n    ) -> None:\n        \"\"\"dynamically add a marker object to the node.\n\n        :type marker: ``str`` or ``pytest.mark.*``  object\n        :param marker:\n            ``append=True`` whether to append the marker,\n            if ``False`` insert at position ``0``.\n        \"\"\"\n        from _pytest.mark import MARK_GEN\n\n        if isinstance(marker, MarkDecorator):\n            marker_ = marker\n        elif isinstance(marker, str):\n            marker_ = getattr(MARK_GEN, marker)\n        else:\n            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n        self.keywords[marker_.name] = marker_\n        if append:\n            self.own_markers.append(marker_.mark)\n        else:\n            self.own_markers.insert(0, marker_.mark)",
            "start_line": 260,
            "start_column": 8242,
            "end_line": 4,
            "end_column": 9073,
            "start_byte": 8242,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureRequest.applymarker",
            "file_path": "src/_pytest/fixtures.py",
            "file_content": "def applymarker(self, marker) -> None:\n        \"\"\" Apply a marker to a single test function invocation.\n        This method is useful if you don't want to have a keyword/marker\n        on all function invocations.\n\n        :arg marker: a :py:class:`_pytest.mark.MarkDecorator` object\n            created by a call to ``pytest.mark.NAME(...)``.\n        \"\"\"\n        self.node.add_marker(marker)",
            "start_line": 548,
            "start_column": 21159,
            "end_line": 4,
            "end_column": 21551,
            "start_byte": 21159,
            "end_byte": 4
          }
        ],
        "root_caused_symbols": [
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1174,
            "start_column": 45925,
            "end_line": 0,
            "end_column": 47430,
            "start_byte": 45925,
            "end_byte": 0
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.scope",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1176,
            "start_column": 45979,
            "end_line": 4,
            "end_column": 46049,
            "start_byte": 45979,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.params",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1177,
            "start_column": 46054,
            "end_line": 4,
            "end_column": 46134,
            "start_byte": 46054,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.autouse",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1178,
            "start_column": 46139,
            "end_line": 4,
            "end_column": 46182,
            "start_byte": 46139,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1179,
            "start_column": 46187,
            "end_line": 4,
            "end_column": 46411,
            "start_byte": 46187,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1187,
            "start_column": 46416,
            "end_line": 4,
            "end_column": 46464,
            "start_byte": 46416,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1189,
            "start_column": 46470,
            "end_line": 4,
            "end_column": 47430,
            "start_byte": 46470,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "lf.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 214,
            "start_column": 7079,
            "end_line": 0,
            "end_column": 7525,
            "start_byte": 7079,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkMatcher.own_mark_names",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": " Mark.\n\n        Combines b",
            "start_line": 221,
            "start_column": 7251,
            "end_line": 4,
            "end_column": 7277,
            "start_byte": 7251,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.from_item",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "nding args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert s",
            "start_line": 223,
            "start_column": 7283,
            "end_line": 4,
            "end_column": 7438,
            "start_byte": 7283,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "me == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 228,
            "start_column": 7444,
            "end_line": 4,
            "end_column": 7525,
            "start_byte": 7444,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s(frozen=True)\nclass Mark:\n    #: Name of the mark.\n    name = attr.ib(type=str)\n    #: Positional arguments of the mark decorator.\n    args = attr.ib(type=Tuple[Any, ...])\n    #: Keyword arguments of the mark decorator.\n    kwargs = attr.ib(type=Mapping[str, Any])\n\n    #: Source Mark for ids with parametrize Marks.\n    _param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)\n    #: Resolved/generated ids with parametrize Marks.\n    _param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )\n\n    def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 195,
            "start_column": 6452,
            "end_line": 0,
            "end_column": 7948,
            "start_byte": 6452,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.Mark.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "name = attr.ib(type=str)",
            "start_line": 198,
            "start_column": 6514,
            "end_line": 4,
            "end_column": 6538,
            "start_byte": 6514,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "args = attr.ib(type=Tuple[Any, ...])",
            "start_line": 200,
            "start_column": 6594,
            "end_line": 4,
            "end_column": 6630,
            "start_byte": 6594,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "kwargs = attr.ib(type=Mapping[str, Any])",
            "start_line": 202,
            "start_column": 6683,
            "end_line": 4,
            "end_column": 6723,
            "start_byte": 6683,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_from",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)",
            "start_line": 205,
            "start_column": 6780,
            "end_line": 4,
            "end_column": 6854,
            "start_byte": 6780,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_generated",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )",
            "start_line": 207,
            "start_column": 6913,
            "end_line": 4,
            "end_column": 7013,
            "start_byte": 6913,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._has_param_ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4",
            "start_line": 211,
            "start_column": 7019,
            "end_line": 4,
            "end_column": 7111,
            "start_byte": 7019,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.combined_with",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 214,
            "start_column": 7117,
            "end_line": 4,
            "end_column": 7948,
            "start_byte": 7117,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark._Markable",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_Markable = TypeVar(\"_Markable\", bound=Union[Callable[..., object], type])",
            "start_line": 245,
            "start_column": 8132,
            "end_line": 0,
            "end_column": 8206,
            "start_byte": 8132,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s\nclass MarkDecorator:\n    \"\"\"A decorator for applying a mark on test functions and classes.\n\n    MarkDecorators are created with ``pytest.mark``::\n\n        mark1 = pytest.mark.NAME              # Simple MarkDecorator\n        mark2 = pytest.mark.NAME(name1=value) # Parametrized MarkDecorator\n\n    and can then be applied as decorators to test functions::\n\n        @mark2\n        def test_function():\n            pass\n\n    When a MarkDecorator is called it does the following:\n\n    1. If called with a single class as its only positional argument and no\n       additional keyword arguments, it attaches the mark to the class so it\n       gets applied automatically to all test cases found in that class.\n\n    2. If called with a single function as its only positional argument and\n       no additional keyword arguments, it attaches the mark to the function,\n       containing all the arguments already stored internally in the\n       MarkDecorator.\n\n    3. When called in any other case, it returns a new MarkDecorator instance\n       with the original MarkDecorator's content updated with the arguments\n       passed to this call.\n\n    Note: The rules above prevent MarkDecorators from storing only a single\n    function or class reference as their positional argument with no\n    additional keyword or positional arguments. You can work around this by\n    using `with_args()`.\n    \"\"\"\n\n    mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))\n\n    @property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name\n\n    @property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args\n\n    @property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs\n\n    @property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)\n\n    def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)\n\n    def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))\n\n    # Type ignored because the overloads overlap with an incompatible\n    # return type. Not much we can do about that. Thankfully mypy picks\n    # the first match so it works out even if we break the rules.\n    @overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()\n\n    @overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()\n\n    def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 248,
            "start_column": 8209,
            "end_line": 0,
            "end_column": 11549,
            "start_byte": 8209,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator.mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))",
            "start_line": 284,
            "start_column": 9608,
            "end_line": 4,
            "end_column": 9678,
            "start_byte": 9608,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name",
            "start_line": 286,
            "start_column": 9684,
            "end_line": 4,
            "end_column": 9785,
            "start_byte": 9684,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args",
            "start_line": 291,
            "start_column": 9791,
            "end_line": 4,
            "end_column": 9904,
            "start_byte": 9791,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs",
            "start_line": 296,
            "start_column": 9910,
            "end_line": 4,
            "end_column": 10031,
            "start_byte": 9910,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.markname",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)",
            "start_line": 301,
            "start_column": 10037,
            "end_line": 4,
            "end_column": 10147,
            "start_byte": 10037,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__repr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)",
            "start_line": 305,
            "start_column": 10153,
            "end_line": 4,
            "end_column": 10235,
            "start_byte": 10153,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.with_args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))",
            "start_line": 308,
            "start_column": 10241,
            "end_line": 4,
            "end_column": 10647,
            "start_byte": 10241,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()",
            "start_line": 322,
            "start_column": 10861,
            "end_line": 4,
            "end_column": 10981,
            "start_byte": 10861,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()",
            "start_line": 326,
            "start_column": 10987,
            "end_line": 4,
            "end_column": 11150,
            "start_byte": 10987,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 332,
            "start_column": 11156,
            "end_line": 4,
            "end_column": 11549,
            "start_byte": 11156,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.store_mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def store_mark(obj, mark: Mark) -> None:\n    \"\"\"Store a Mark on an object.\n\n    This is used to implement the Mark declarations/decorators correctly.\n    \"\"\"\n    assert isinstance(mark, Mark), mark\n    # Always reassign name to avoid updating pytestmark in a reference that\n    # was only borrowed.\n    obj.pytestmark = get_unpacked_marks(obj) + [mark]",
            "start_line": 369,
            "start_column": 12372,
            "end_line": 0,
            "end_column": 12724,
            "start_byte": 12372,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkGenerator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "class MarkGenerator:\n    \"\"\"Factory for :class:`MarkDecorator` objects - exposed as\n    a ``pytest.mark`` singleton instance.\n\n    Example::\n\n         import pytest\n\n         @pytest.mark.slowtest\n         def test_function():\n            pass\n\n    applies a 'slowtest' :class:`Mark` on ``test_function``.\n    \"\"\"\n\n    _config = None  # type: Optional[Config]\n    _markers = set()  # type: Set[str]\n\n    # See TYPE_CHECKING above.\n    if TYPE_CHECKING:\n        # Using casts instead of type comments intentionally - issue #7473.\n        # TODO(py36): Change to builtin annotation syntax.\n        skip = cast(_SkipMarkDecorator, None)\n        skipif = cast(_SkipifMarkDecorator, None)\n        xfail = cast(_XfailMarkDecorator, None)\n        parametrize = cast(_ParametrizeMarkDecorator, None)\n        usefixtures = cast(_UsefixturesMarkDecorator, None)\n        filterwarnings = cast(_FilterwarningsMarkDecorator, None)\n\n    def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 450,
            "start_column": 15252,
            "end_line": 0,
            "end_column": 18166,
            "start_byte": 15252,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkGenerator._config",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_config = None",
            "start_line": 465,
            "start_column": 15571,
            "end_line": 4,
            "end_column": 15585,
            "start_byte": 15571,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator._markers",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_markers = set()",
            "start_line": 466,
            "start_column": 15616,
            "end_line": 4,
            "end_column": 15632,
            "start_byte": 15616,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator.__getattr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 479,
            "start_column": 16175,
            "end_line": 4,
            "end_column": 18166,
            "start_byte": 16175,
            "end_byte": 4
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "\"values\", Sequence[Union[object, NotSetType]]),\n            (\"marks\", \"typing.Collection[Union[MarkDecorator, Mark]]\"),\n            (\"id\", Optional[str]),\n        ],\n    )\n):\n    @classmethod\n    d",
            "start_line": 77,
            "start_column": 1903,
            "end_line": 0,
            "end_column": 2100,
            "start_byte": 1903,
            "end_byte": 0
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning.__module__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "   @classmethod\n    d",
            "start_line": 83,
            "start_column": 2079,
            "end_line": 4,
            "end_column": 2100,
            "start_byte": 2079,
            "end_byte": 4
          },
          {
            "name": "_pytest.hookspec.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "",
            "start_line": 486,
            "start_column": 17380,
            "end_line": 0,
            "end_column": 17867,
            "start_byte": 17380,
            "end_byte": 0
          },
          {
            "name": "_pytest.runner.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "ort_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:\n    if hasattr(report, \"wasxfail\"):\n        if report.skipped",
            "start_line": 318,
            "start_column": 10464,
            "end_line": 0,
            "end_column": 10595,
            "start_byte": 10464,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.evaluate_xfail_marks",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None",
            "start_line": 199,
            "start_column": 6507,
            "end_line": 0,
            "end_column": 7408,
            "start_byte": 6507,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "@hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n    outcome = yield\n    rep = outcome.get_result()\n    xfailed = item._store.get(xfailed_key, None)\n    # unittest special case, see setting of unexpectedsuccess_key\n    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n        reason = item._store[unexpectedsuccess_key]\n        if reason:\n            rep.longrepr = \"Unexpected success: {}\".format(reason)\n        else:\n            rep.longrepr = \"Unexpected success\"\n        rep.outcome = \"failed\"\n    elif item.config.option.runxfail:\n        pass  # don't interfere\n    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n        assert call.excinfo.value.msg is not None\n        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n        rep.outcome = \"skipped\"\n    elif not rep.skipped and xfailed:\n        if call.excinfo:\n            raises = xfailed.raises\n            if raises is not None and not isinstance(call.excinfo.value, raises):\n                rep.outcome = \"failed\"\n            else:\n                rep.outcome = \"skipped\"\n                rep.wasxfail = xfailed.reason\n        elif call.when == \"call\":\n            if xfailed.strict:\n                rep.outcome = \"failed\"\n                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n            else:\n                rep.outcome = \"passed\"\n                rep.wasxfail = xfailed.reason\n\n    if (\n        item._store.get(skipped_by_mark_key, True)\n        and rep.skipped\n        and type(rep.longrepr) is tuple\n    ):\n        # skipped by mark.skipif; change the location of the failure\n        # to point to the item definition, otherwise it will display\n        # the location of where the skip exception was raised within pytest\n        _, _, reason = rep.longrepr\n        filename, line = item.reportinfo()[:2]\n        assert line is not None\n        rep.longrepr = str(filename), line + 1, reason",
            "start_line": 259,
            "start_column": 8490,
            "end_line": 0,
            "end_column": 10447,
            "start_byte": 8490,
            "end_byte": 0
          },
          {
            "name": "_pytest.unittest.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "urn \"xpassed\", \"X\", \"XPASS\"\n    return None\n",
            "start_line": 290,
            "start_column": 10683,
            "end_line": 0,
            "end_column": 11441,
            "start_byte": 10683,
            "end_byte": 0
          }
        ]
      },
      "response": {
        "scratch_pad": "1. Analyze User Instructions:\n   1.1 The issue is that the pytest 6.0.0rc0 raises an error for tests dynamically marked as xfail, which did not happen in pytest 5.x.\n   1.2 The issue is likely caused by a change in how pytest handles markers added dynamically to tests, particularly xfail markers.\n   1.3 The tests should behave like they did in 5.x where the xfail marker would cause the test to be marked as expected to fail without raising.\n   1.4 The expectation is that dynamically adding an xfail marker would mark the test as expected to fail without causing it to actually fail unexpectedly.\n   1.5 The issue should be fixed by ensuring that dynamically added xfail markers are properly recognized in pytest 6 and don't result in unexpected test failures.\n\n2. Make the evaluate:\n   2.1 Analyze each symbol provided.\n   2.2 The symbols related to \"_pytest.mark\" seem relevant because xfail is a kind of mark applied to tests, and the issue concerns the handling of such marks.\n   2.3 Relevance should be determined by whether the symbols impact or provide functionality related to test marking, particularly xfail markers.",
        "symbols": [
          {
            "name": "_pytest.nodes.Node.add_marker",
            "file_path": "src/_pytest/nodes.py",
            "reason": "The reported issue is about the add_marker method dynamically marking tests, which is causing unexpected behavior in pytest 6 relative to pytest 5."
          }
        ],
        "more_info": [],
        "is_done": true,
        "symbols_scratch_pad": [
          "_pytest.fixtures.FixtureFunctionMarker: This symbol relates to fixture handling and marking within pytest fixtures, which might not directly address the issue of dynamic markers on tests for xfail.",
          "_pytest.fixtures.FixtureFunctionMarker.scope: This symbol handles scoping within fixture function markers, which likely does not pertain to the current issue.",
          "_pytest.fixtures.FixtureFunctionMarker.params: This likely involves parameters within a fixture context, probably not relevant to marking test failures like xfail.",
          "_pytest.fixtures.FixtureFunctionMarker.autouse: Autouse fixtures automatically apply to tests, but aren't related to test mark behavior directly for xfail.",
          "_pytest.fixtures.FixtureFunctionMarker.ids: IDs in fixture contexts might not influence add_marker behavior related to xfail.",
          "_pytest.fixtures.FixtureFunctionMarker.name: The name property for fixtures, not immediately relevant to dynamic test markings.",
          "_pytest.fixtures.FixtureFunctionMarker.__call__: This symbol shows how fixtures can be called/used, not directly evident to xfail marker handling.",
          "_pytest.mark.MarkMatcher: MarkMatcher likely involves comparing or resolving marks, potentially relevant to handling xfail, but not directly the cause identified.",
          "_pytest.mark.MarkMatcher.own_mark_names: Deals with mark names, possibly relevant for checking against xfail behavior for markers.",
          "_pytest.mark.MarkMatcher.from_item: Converts from item to mark matcher, converts context but not directly involving incorrect behavior itself.",
          "_pytest.mark.MarkMatcher.__call__: Calling context for MarkMatcher, not directly involved reported xfail behavior.",
          "_pytest.mark.Mark: Defines a Mark object; relevant as xfail uses marks.",
          "_pytest.mark.Mark.name: Names a given mark, possible relevance to xfail naming but not behavioral.",
          "_pytest.mark.Mark.args: Arguments within a Mark object, somewhat related to xfail params, incomplete relevance.",
          "_pytest.mark.Mark.kwargs: Keyword arguments in Marks may impact xfail specifics like 'strict','reason', but not directly behavioral source.",
          "_pytest.mark.Mark._param_ids_from: Attribute tracking param source IDs, perhaps useful if parametrize affects xfail, but not direct cause.",
          "_pytest.mark.Mark._param_ids_generated: Tracks generated IDs, relevant for parametrize, non-crucial for this issue.",
          "_pytest.mark.Mark._has_param_ids: Checks param IDs, potentially influental if parametrize is interacting badly with xfail behavior.",
          "_pytest.mark.Mark.combined_with: This combines marks, relevant if multiple marks like xfail impacts result, pointer to interaction more than fault.",
          "_pytest.mark._Markable: Type var for Mark usage context, aids understanding but not directly solving the issue.",
          "_pytest.mark.MarkDecorator: Handles application of marks like xfail to tests, important but known as part of mechanism not source of bug.",
          "_pytest.mark.MarkDecorator.mark: References a Mark object within MarkDecorator, significant for usage not error.",
          "_pytest.mark.MarkDecorator.name: Returns mark's name used in decorator, foundational but not broken behavior.",
          "_pytest.mark.MarkDecorator.args: Arguments in decorator, similar param control but not core to failure of xfail.",
          "_pytest.mark.MarkDecorator.kwargs: Keyword args for MarkDecorator, possible xfail specifics but generally a stable attribute.",
          "_pytest.mark.MarkDecorator.markname: Backward compatibility property for mark naming, helpful context for naming conflicts not error tracking.",
          "_pytest.mark.MarkDecorator.__repr__: Repr of decorator to convey useful debugging info, not core error.",
          "_pytest.mark.MarkDecorator.with_args: Adds extra args to decorator, relevant for modifying xs if failing here.",
          "_pytest.mark.MarkDecorator.__call__: Calls an instance of decorator, allows setattr form, crucial in applying marks but usage context.",
          "_pytest.mark.store_mark: Storing marks on an object is fundamental to applying them, if this had errors, highly likely reason for breakage.",
          "_pytest.mark.MarkGenerator: Constructs MarkDecorator instances, relevant for initial creation but not xfail runtime variance issue.",
          "_pytest.mark.MarkGenerator._config: Contains config information; might alter with config policies/issues but does not generate bug directly.",
          "_pytest.mark.MarkGenerator._markers: Holds known markers within generator; possible relevance if note in control, completeness not precisely pinpointed.",
          "_pytest.mark.MarkGenerator.__getattr__: Returns MarkDecorator on mark name reference, factory to get Marks, relevant for creation more than use.",
          "_pytest.warning_types.PytestUnknownMarkWarning: Warns unknown markers, might produce error message, -> PC not facility end root cause.",
          "_pytest.warning_types.PytestUnknownMarkWarning.__module__: Module tracking for warning context; not exposing bug directly, trackable component.",
          "_pytest.hookspec.pytest_runtest_makereport: Hookspec guides how to report runs of tests, possible outcome expressor but no root issue.",
          "_pytest.runner.pytest_runtest_makereport: Reports tests with optional xpass/or xfail statuses, relevant dynamic error outcome.",
          "_pytest.skipping.evaluate_xfail_marks: Evaluates xfail marking conditions about implications, conditional result determination.",
          "_pytest.skipping.pytest_runtest_makereport: Handles xfail skip conditions including unexpected results therefore potential correlator.",
          "_pytest.unittest.pytest_runtest_makereport: Reports unittest results in a specific fashion, doesn't directly cross into xfail.",
          "_pytest.nodes.Node.add_marker: Directly matches the issue statement, since it\u2019s about applying marks to expressions dynamically.",
          "_pytest.fixtures.FixtureRequest.applymarker: Uses node.add_marker by extension in fixtures, not wrong relevancy but not nucleus of global context."
        ]
      }
    },
    {
      "name": "SymbolSummary",
      "metadata": {
        "start": "2024-08-19T13:36:01.939191",
        "usage": "3.5009384155273438 ms"
      },
      "request": {
        "symbols": {
          "related_symbols": [
            {
              "name": "_pytest.nodes.Node.add_marker",
              "file_path": "src/_pytest/nodes.py",
              "file_content": "def add_marker(\n        self, marker: Union[str, MarkDecorator], append: bool = True\n    ) -> None:\n        \"\"\"dynamically add a marker object to the node.\n\n        :type marker: ``str`` or ``pytest.mark.*``  object\n        :param marker:\n            ``append=True`` whether to append the marker,\n            if ``False`` insert at position ``0``.\n        \"\"\"\n        from _pytest.mark import MARK_GEN\n\n        if isinstance(marker, MarkDecorator):\n            marker_ = marker\n        elif isinstance(marker, str):\n            marker_ = getattr(MARK_GEN, marker)\n        else:\n            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n        self.keywords[marker_.name] = marker_\n        if append:\n            self.own_markers.append(marker_.mark)\n        else:\n            self.own_markers.insert(0, marker_.mark)",
              "start_line": 260,
              "start_column": 8242,
              "end_line": 4,
              "end_column": 9073,
              "start_byte": 8242,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureRequest.applymarker",
              "file_path": "src/_pytest/fixtures.py",
              "file_content": "def applymarker(self, marker) -> None:\n        \"\"\" Apply a marker to a single test function invocation.\n        This method is useful if you don't want to have a keyword/marker\n        on all function invocations.\n\n        :arg marker: a :py:class:`_pytest.mark.MarkDecorator` object\n            created by a call to ``pytest.mark.NAME(...)``.\n        \"\"\"\n        self.node.add_marker(marker)",
              "start_line": 548,
              "start_column": 21159,
              "end_line": 4,
              "end_column": 21551,
              "start_byte": 21159,
              "end_byte": 4
            }
          ],
          "root_caused_symbols": [
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1174,
              "start_column": 45925,
              "end_line": 0,
              "end_column": 47430,
              "start_byte": 45925,
              "end_byte": 0
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.scope",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1176,
              "start_column": 45979,
              "end_line": 4,
              "end_column": 46049,
              "start_byte": 45979,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.params",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1177,
              "start_column": 46054,
              "end_line": 4,
              "end_column": 46134,
              "start_byte": 46054,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.autouse",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1178,
              "start_column": 46139,
              "end_line": 4,
              "end_column": 46182,
              "start_byte": 46139,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.ids",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1179,
              "start_column": 46187,
              "end_line": 4,
              "end_column": 46411,
              "start_byte": 46187,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.name",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1187,
              "start_column": 46416,
              "end_line": 4,
              "end_column": 46464,
              "start_byte": 46416,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.__call__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1189,
              "start_column": 46470,
              "end_line": 4,
              "end_column": 47430,
              "start_byte": 46470,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkMatcher",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "lf.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
              "start_line": 214,
              "start_column": 7079,
              "end_line": 0,
              "end_column": 7525,
              "start_byte": 7079,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkMatcher.own_mark_names",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": " Mark.\n\n        Combines b",
              "start_line": 221,
              "start_column": 7251,
              "end_line": 4,
              "end_column": 7277,
              "start_byte": 7251,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkMatcher.from_item",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "nding args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert s",
              "start_line": 223,
              "start_column": 7283,
              "end_line": 4,
              "end_column": 7438,
              "start_byte": 7283,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkMatcher.__call__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "me == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
              "start_line": 228,
              "start_column": 7444,
              "end_line": 4,
              "end_column": 7525,
              "start_byte": 7444,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@attr.s(frozen=True)\nclass Mark:\n    #: Name of the mark.\n    name = attr.ib(type=str)\n    #: Positional arguments of the mark decorator.\n    args = attr.ib(type=Tuple[Any, ...])\n    #: Keyword arguments of the mark decorator.\n    kwargs = attr.ib(type=Mapping[str, Any])\n\n    #: Source Mark for ids with parametrize Marks.\n    _param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)\n    #: Resolved/generated ids with parametrize Marks.\n    _param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )\n\n    def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
              "start_line": 195,
              "start_column": 6452,
              "end_line": 0,
              "end_column": 7948,
              "start_byte": 6452,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.Mark.name",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "name = attr.ib(type=str)",
              "start_line": 198,
              "start_column": 6514,
              "end_line": 4,
              "end_column": 6538,
              "start_byte": 6514,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark.args",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "args = attr.ib(type=Tuple[Any, ...])",
              "start_line": 200,
              "start_column": 6594,
              "end_line": 4,
              "end_column": 6630,
              "start_byte": 6594,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark.kwargs",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "kwargs = attr.ib(type=Mapping[str, Any])",
              "start_line": 202,
              "start_column": 6683,
              "end_line": 4,
              "end_column": 6723,
              "start_byte": 6683,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark._param_ids_from",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "_param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)",
              "start_line": 205,
              "start_column": 6780,
              "end_line": 4,
              "end_column": 6854,
              "start_byte": 6780,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark._param_ids_generated",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "_param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )",
              "start_line": 207,
              "start_column": 6913,
              "end_line": 4,
              "end_column": 7013,
              "start_byte": 6913,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark._has_param_ids",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4",
              "start_line": 211,
              "start_column": 7019,
              "end_line": 4,
              "end_column": 7111,
              "start_byte": 7019,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark.combined_with",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
              "start_line": 214,
              "start_column": 7117,
              "end_line": 4,
              "end_column": 7948,
              "start_byte": 7117,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark._Markable",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "_Markable = TypeVar(\"_Markable\", bound=Union[Callable[..., object], type])",
              "start_line": 245,
              "start_column": 8132,
              "end_line": 0,
              "end_column": 8206,
              "start_byte": 8132,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkDecorator",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@attr.s\nclass MarkDecorator:\n    \"\"\"A decorator for applying a mark on test functions and classes.\n\n    MarkDecorators are created with ``pytest.mark``::\n\n        mark1 = pytest.mark.NAME              # Simple MarkDecorator\n        mark2 = pytest.mark.NAME(name1=value) # Parametrized MarkDecorator\n\n    and can then be applied as decorators to test functions::\n\n        @mark2\n        def test_function():\n            pass\n\n    When a MarkDecorator is called it does the following:\n\n    1. If called with a single class as its only positional argument and no\n       additional keyword arguments, it attaches the mark to the class so it\n       gets applied automatically to all test cases found in that class.\n\n    2. If called with a single function as its only positional argument and\n       no additional keyword arguments, it attaches the mark to the function,\n       containing all the arguments already stored internally in the\n       MarkDecorator.\n\n    3. When called in any other case, it returns a new MarkDecorator instance\n       with the original MarkDecorator's content updated with the arguments\n       passed to this call.\n\n    Note: The rules above prevent MarkDecorators from storing only a single\n    function or class reference as their positional argument with no\n    additional keyword or positional arguments. You can work around this by\n    using `with_args()`.\n    \"\"\"\n\n    mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))\n\n    @property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name\n\n    @property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args\n\n    @property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs\n\n    @property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)\n\n    def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)\n\n    def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))\n\n    # Type ignored because the overloads overlap with an incompatible\n    # return type. Not much we can do about that. Thankfully mypy picks\n    # the first match so it works out even if we break the rules.\n    @overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()\n\n    @overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()\n\n    def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
              "start_line": 248,
              "start_column": 8209,
              "end_line": 0,
              "end_column": 11549,
              "start_byte": 8209,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkDecorator.mark",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))",
              "start_line": 284,
              "start_column": 9608,
              "end_line": 4,
              "end_column": 9678,
              "start_byte": 9608,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.name",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name",
              "start_line": 286,
              "start_column": 9684,
              "end_line": 4,
              "end_column": 9785,
              "start_byte": 9684,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.args",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args",
              "start_line": 291,
              "start_column": 9791,
              "end_line": 4,
              "end_column": 9904,
              "start_byte": 9791,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.kwargs",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs",
              "start_line": 296,
              "start_column": 9910,
              "end_line": 4,
              "end_column": 10031,
              "start_byte": 9910,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.markname",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)",
              "start_line": 301,
              "start_column": 10037,
              "end_line": 4,
              "end_column": 10147,
              "start_byte": 10037,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__repr__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)",
              "start_line": 305,
              "start_column": 10153,
              "end_line": 4,
              "end_column": 10235,
              "start_byte": 10153,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.with_args",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))",
              "start_line": 308,
              "start_column": 10241,
              "end_line": 4,
              "end_column": 10647,
              "start_byte": 10241,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__call__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()",
              "start_line": 322,
              "start_column": 10861,
              "end_line": 4,
              "end_column": 10981,
              "start_byte": 10861,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__call__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()",
              "start_line": 326,
              "start_column": 10987,
              "end_line": 4,
              "end_column": 11150,
              "start_byte": 10987,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__call__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
              "start_line": 332,
              "start_column": 11156,
              "end_line": 4,
              "end_column": 11549,
              "start_byte": 11156,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.store_mark",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def store_mark(obj, mark: Mark) -> None:\n    \"\"\"Store a Mark on an object.\n\n    This is used to implement the Mark declarations/decorators correctly.\n    \"\"\"\n    assert isinstance(mark, Mark), mark\n    # Always reassign name to avoid updating pytestmark in a reference that\n    # was only borrowed.\n    obj.pytestmark = get_unpacked_marks(obj) + [mark]",
              "start_line": 369,
              "start_column": 12372,
              "end_line": 0,
              "end_column": 12724,
              "start_byte": 12372,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkGenerator",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "class MarkGenerator:\n    \"\"\"Factory for :class:`MarkDecorator` objects - exposed as\n    a ``pytest.mark`` singleton instance.\n\n    Example::\n\n         import pytest\n\n         @pytest.mark.slowtest\n         def test_function():\n            pass\n\n    applies a 'slowtest' :class:`Mark` on ``test_function``.\n    \"\"\"\n\n    _config = None  # type: Optional[Config]\n    _markers = set()  # type: Set[str]\n\n    # See TYPE_CHECKING above.\n    if TYPE_CHECKING:\n        # Using casts instead of type comments intentionally - issue #7473.\n        # TODO(py36): Change to builtin annotation syntax.\n        skip = cast(_SkipMarkDecorator, None)\n        skipif = cast(_SkipifMarkDecorator, None)\n        xfail = cast(_XfailMarkDecorator, None)\n        parametrize = cast(_ParametrizeMarkDecorator, None)\n        usefixtures = cast(_UsefixturesMarkDecorator, None)\n        filterwarnings = cast(_FilterwarningsMarkDecorator, None)\n\n    def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
              "start_line": 450,
              "start_column": 15252,
              "end_line": 0,
              "end_column": 18166,
              "start_byte": 15252,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkGenerator._config",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "_config = None",
              "start_line": 465,
              "start_column": 15571,
              "end_line": 4,
              "end_column": 15585,
              "start_byte": 15571,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkGenerator._markers",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "_markers = set()",
              "start_line": 466,
              "start_column": 15616,
              "end_line": 4,
              "end_column": 15632,
              "start_byte": 15616,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkGenerator.__getattr__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
              "start_line": 479,
              "start_column": 16175,
              "end_line": 4,
              "end_column": 18166,
              "start_byte": 16175,
              "end_byte": 4
            },
            {
              "name": "_pytest.warning_types.PytestUnknownMarkWarning",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "\"values\", Sequence[Union[object, NotSetType]]),\n            (\"marks\", \"typing.Collection[Union[MarkDecorator, Mark]]\"),\n            (\"id\", Optional[str]),\n        ],\n    )\n):\n    @classmethod\n    d",
              "start_line": 77,
              "start_column": 1903,
              "end_line": 0,
              "end_column": 2100,
              "start_byte": 1903,
              "end_byte": 0
            },
            {
              "name": "_pytest.warning_types.PytestUnknownMarkWarning.__module__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "   @classmethod\n    d",
              "start_line": 83,
              "start_column": 2079,
              "end_line": 4,
              "end_column": 2100,
              "start_byte": 2079,
              "end_byte": 4
            },
            {
              "name": "_pytest.hookspec.pytest_runtest_makereport",
              "file_path": "src/_pytest/skipping.py",
              "file_content": "",
              "start_line": 486,
              "start_column": 17380,
              "end_line": 0,
              "end_column": 17867,
              "start_byte": 17380,
              "end_byte": 0
            },
            {
              "name": "_pytest.runner.pytest_runtest_makereport",
              "file_path": "src/_pytest/skipping.py",
              "file_content": "ort_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:\n    if hasattr(report, \"wasxfail\"):\n        if report.skipped",
              "start_line": 318,
              "start_column": 10464,
              "end_line": 0,
              "end_column": 10595,
              "start_byte": 10464,
              "end_byte": 0
            },
            {
              "name": "_pytest.skipping.evaluate_xfail_marks",
              "file_path": "src/_pytest/skipping.py",
              "file_content": "def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None",
              "start_line": 199,
              "start_column": 6507,
              "end_line": 0,
              "end_column": 7408,
              "start_byte": 6507,
              "end_byte": 0
            },
            {
              "name": "_pytest.skipping.pytest_runtest_makereport",
              "file_path": "src/_pytest/skipping.py",
              "file_content": "@hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n    outcome = yield\n    rep = outcome.get_result()\n    xfailed = item._store.get(xfailed_key, None)\n    # unittest special case, see setting of unexpectedsuccess_key\n    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n        reason = item._store[unexpectedsuccess_key]\n        if reason:\n            rep.longrepr = \"Unexpected success: {}\".format(reason)\n        else:\n            rep.longrepr = \"Unexpected success\"\n        rep.outcome = \"failed\"\n    elif item.config.option.runxfail:\n        pass  # don't interfere\n    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n        assert call.excinfo.value.msg is not None\n        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n        rep.outcome = \"skipped\"\n    elif not rep.skipped and xfailed:\n        if call.excinfo:\n            raises = xfailed.raises\n            if raises is not None and not isinstance(call.excinfo.value, raises):\n                rep.outcome = \"failed\"\n            else:\n                rep.outcome = \"skipped\"\n                rep.wasxfail = xfailed.reason\n        elif call.when == \"call\":\n            if xfailed.strict:\n                rep.outcome = \"failed\"\n                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n            else:\n                rep.outcome = \"passed\"\n                rep.wasxfail = xfailed.reason\n\n    if (\n        item._store.get(skipped_by_mark_key, True)\n        and rep.skipped\n        and type(rep.longrepr) is tuple\n    ):\n        # skipped by mark.skipif; change the location of the failure\n        # to point to the item definition, otherwise it will display\n        # the location of where the skip exception was raised within pytest\n        _, _, reason = rep.longrepr\n        filename, line = item.reportinfo()[:2]\n        assert line is not None\n        rep.longrepr = str(filename), line + 1, reason",
              "start_line": 259,
              "start_column": 8490,
              "end_line": 0,
              "end_column": 10447,
              "start_byte": 8490,
              "end_byte": 0
            },
            {
              "name": "_pytest.unittest.pytest_runtest_makereport",
              "file_path": "src/_pytest/skipping.py",
              "file_content": "urn \"xpassed\", \"X\", \"XPASS\"\n    return None\n",
              "start_line": 290,
              "start_column": 10683,
              "end_line": 0,
              "end_column": 11441,
              "start_byte": 10683,
              "end_byte": 0
            }
          ]
        },
        "symbols_evaluate": {
          "scratch_pad": "1. Analyze User Instructions:\n   1.1 The issue is that the pytest 6.0.0rc0 raises an error for tests dynamically marked as xfail, which did not happen in pytest 5.x.\n   1.2 The issue is likely caused by a change in how pytest handles markers added dynamically to tests, particularly xfail markers.\n   1.3 The tests should behave like they did in 5.x where the xfail marker would cause the test to be marked as expected to fail without raising.\n   1.4 The expectation is that dynamically adding an xfail marker would mark the test as expected to fail without causing it to actually fail unexpectedly.\n   1.5 The issue should be fixed by ensuring that dynamically added xfail markers are properly recognized in pytest 6 and don't result in unexpected test failures.\n\n2. Make the evaluate:\n   2.1 Analyze each symbol provided.\n   2.2 The symbols related to \"_pytest.mark\" seem relevant because xfail is a kind of mark applied to tests, and the issue concerns the handling of such marks.\n   2.3 Relevance should be determined by whether the symbols impact or provide functionality related to test marking, particularly xfail markers.",
          "symbols": [
            {
              "name": "_pytest.nodes.Node.add_marker",
              "file_path": "src/_pytest/nodes.py",
              "reason": "The reported issue is about the add_marker method dynamically marking tests, which is causing unexpected behavior in pytest 6 relative to pytest 5."
            }
          ],
          "more_info": [],
          "is_done": true,
          "symbols_scratch_pad": [
            "_pytest.fixtures.FixtureFunctionMarker: This symbol relates to fixture handling and marking within pytest fixtures, which might not directly address the issue of dynamic markers on tests for xfail.",
            "_pytest.fixtures.FixtureFunctionMarker.scope: This symbol handles scoping within fixture function markers, which likely does not pertain to the current issue.",
            "_pytest.fixtures.FixtureFunctionMarker.params: This likely involves parameters within a fixture context, probably not relevant to marking test failures like xfail.",
            "_pytest.fixtures.FixtureFunctionMarker.autouse: Autouse fixtures automatically apply to tests, but aren't related to test mark behavior directly for xfail.",
            "_pytest.fixtures.FixtureFunctionMarker.ids: IDs in fixture contexts might not influence add_marker behavior related to xfail.",
            "_pytest.fixtures.FixtureFunctionMarker.name: The name property for fixtures, not immediately relevant to dynamic test markings.",
            "_pytest.fixtures.FixtureFunctionMarker.__call__: This symbol shows how fixtures can be called/used, not directly evident to xfail marker handling.",
            "_pytest.mark.MarkMatcher: MarkMatcher likely involves comparing or resolving marks, potentially relevant to handling xfail, but not directly the cause identified.",
            "_pytest.mark.MarkMatcher.own_mark_names: Deals with mark names, possibly relevant for checking against xfail behavior for markers.",
            "_pytest.mark.MarkMatcher.from_item: Converts from item to mark matcher, converts context but not directly involving incorrect behavior itself.",
            "_pytest.mark.MarkMatcher.__call__: Calling context for MarkMatcher, not directly involved reported xfail behavior.",
            "_pytest.mark.Mark: Defines a Mark object; relevant as xfail uses marks.",
            "_pytest.mark.Mark.name: Names a given mark, possible relevance to xfail naming but not behavioral.",
            "_pytest.mark.Mark.args: Arguments within a Mark object, somewhat related to xfail params, incomplete relevance.",
            "_pytest.mark.Mark.kwargs: Keyword arguments in Marks may impact xfail specifics like 'strict','reason', but not directly behavioral source.",
            "_pytest.mark.Mark._param_ids_from: Attribute tracking param source IDs, perhaps useful if parametrize affects xfail, but not direct cause.",
            "_pytest.mark.Mark._param_ids_generated: Tracks generated IDs, relevant for parametrize, non-crucial for this issue.",
            "_pytest.mark.Mark._has_param_ids: Checks param IDs, potentially influental if parametrize is interacting badly with xfail behavior.",
            "_pytest.mark.Mark.combined_with: This combines marks, relevant if multiple marks like xfail impacts result, pointer to interaction more than fault.",
            "_pytest.mark._Markable: Type var for Mark usage context, aids understanding but not directly solving the issue.",
            "_pytest.mark.MarkDecorator: Handles application of marks like xfail to tests, important but known as part of mechanism not source of bug.",
            "_pytest.mark.MarkDecorator.mark: References a Mark object within MarkDecorator, significant for usage not error.",
            "_pytest.mark.MarkDecorator.name: Returns mark's name used in decorator, foundational but not broken behavior.",
            "_pytest.mark.MarkDecorator.args: Arguments in decorator, similar param control but not core to failure of xfail.",
            "_pytest.mark.MarkDecorator.kwargs: Keyword args for MarkDecorator, possible xfail specifics but generally a stable attribute.",
            "_pytest.mark.MarkDecorator.markname: Backward compatibility property for mark naming, helpful context for naming conflicts not error tracking.",
            "_pytest.mark.MarkDecorator.__repr__: Repr of decorator to convey useful debugging info, not core error.",
            "_pytest.mark.MarkDecorator.with_args: Adds extra args to decorator, relevant for modifying xs if failing here.",
            "_pytest.mark.MarkDecorator.__call__: Calls an instance of decorator, allows setattr form, crucial in applying marks but usage context.",
            "_pytest.mark.store_mark: Storing marks on an object is fundamental to applying them, if this had errors, highly likely reason for breakage.",
            "_pytest.mark.MarkGenerator: Constructs MarkDecorator instances, relevant for initial creation but not xfail runtime variance issue.",
            "_pytest.mark.MarkGenerator._config: Contains config information; might alter with config policies/issues but does not generate bug directly.",
            "_pytest.mark.MarkGenerator._markers: Holds known markers within generator; possible relevance if note in control, completeness not precisely pinpointed.",
            "_pytest.mark.MarkGenerator.__getattr__: Returns MarkDecorator on mark name reference, factory to get Marks, relevant for creation more than use.",
            "_pytest.warning_types.PytestUnknownMarkWarning: Warns unknown markers, might produce error message, -> PC not facility end root cause.",
            "_pytest.warning_types.PytestUnknownMarkWarning.__module__: Module tracking for warning context; not exposing bug directly, trackable component.",
            "_pytest.hookspec.pytest_runtest_makereport: Hookspec guides how to report runs of tests, possible outcome expressor but no root issue.",
            "_pytest.runner.pytest_runtest_makereport: Reports tests with optional xpass/or xfail statuses, relevant dynamic error outcome.",
            "_pytest.skipping.evaluate_xfail_marks: Evaluates xfail marking conditions about implications, conditional result determination.",
            "_pytest.skipping.pytest_runtest_makereport: Handles xfail skip conditions including unexpected results therefore potential correlator.",
            "_pytest.unittest.pytest_runtest_makereport: Reports unittest results in a specific fashion, doesn't directly cross into xfail.",
            "_pytest.nodes.Node.add_marker: Directly matches the issue statement, since it\u2019s about applying marks to expressions dynamically.",
            "_pytest.fixtures.FixtureRequest.applymarker: Uses node.add_marker by extension in fixtures, not wrong relevancy but not nucleus of global context."
          ]
        }
      },
      "response": {
        "file_paths": [
          "src/_pytest/nodes.py"
        ],
        "symbols": [
          "_pytest.nodes.Node.add_marker"
        ],
        "code_spans": {
          "_pytest.nodes.Node.add_marker": {
            "name": "_pytest.nodes.Node.add_marker",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def add_marker(\n        self, marker: Union[str, MarkDecorator], append: bool = True\n    ) -> None:\n        \"\"\"dynamically add a marker object to the node.\n\n        :type marker: ``str`` or ``pytest.mark.*``  object\n        :param marker:\n            ``append=True`` whether to append the marker,\n            if ``False`` insert at position ``0``.\n        \"\"\"\n        from _pytest.mark import MARK_GEN\n\n        if isinstance(marker, MarkDecorator):\n            marker_ = marker\n        elif isinstance(marker, str):\n            marker_ = getattr(MARK_GEN, marker)\n        else:\n            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n        self.keywords[marker_.name] = marker_\n        if append:\n            self.own_markers.append(marker_.mark)\n        else:\n            self.own_markers.insert(0, marker_.mark)",
            "start_line": 260,
            "start_column": 8242,
            "end_line": 4,
            "end_column": 9073,
            "start_byte": 8242,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureRequest.applymarker": {
            "name": "_pytest.fixtures.FixtureRequest.applymarker",
            "file_path": "src/_pytest/fixtures.py",
            "file_content": "def applymarker(self, marker) -> None:\n        \"\"\" Apply a marker to a single test function invocation.\n        This method is useful if you don't want to have a keyword/marker\n        on all function invocations.\n\n        :arg marker: a :py:class:`_pytest.mark.MarkDecorator` object\n            created by a call to ``pytest.mark.NAME(...)``.\n        \"\"\"\n        self.node.add_marker(marker)",
            "start_line": 548,
            "start_column": 21159,
            "end_line": 4,
            "end_column": 21551,
            "start_byte": 21159,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker": {
            "name": "_pytest.fixtures.FixtureFunctionMarker",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1174,
            "start_column": 45925,
            "end_line": 0,
            "end_column": 47430,
            "start_byte": 45925,
            "end_byte": 0
          },
          "_pytest.fixtures.FixtureFunctionMarker.scope": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.scope",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1176,
            "start_column": 45979,
            "end_line": 4,
            "end_column": 46049,
            "start_byte": 45979,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker.params": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.params",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1177,
            "start_column": 46054,
            "end_line": 4,
            "end_column": 46134,
            "start_byte": 46054,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker.autouse": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.autouse",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1178,
            "start_column": 46139,
            "end_line": 4,
            "end_column": 46182,
            "start_byte": 46139,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker.ids": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1179,
            "start_column": 46187,
            "end_line": 4,
            "end_column": 46411,
            "start_byte": 46187,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker.name": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1187,
            "start_column": 46416,
            "end_line": 4,
            "end_column": 46464,
            "start_byte": 46416,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker.__call__": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1189,
            "start_column": 46470,
            "end_line": 4,
            "end_column": 47430,
            "start_byte": 46470,
            "end_byte": 4
          },
          "_pytest.mark.MarkMatcher": {
            "name": "_pytest.mark.MarkMatcher",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "lf.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 214,
            "start_column": 7079,
            "end_line": 0,
            "end_column": 7525,
            "start_byte": 7079,
            "end_byte": 0
          },
          "_pytest.mark.MarkMatcher.own_mark_names": {
            "name": "_pytest.mark.MarkMatcher.own_mark_names",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": " Mark.\n\n        Combines b",
            "start_line": 221,
            "start_column": 7251,
            "end_line": 4,
            "end_column": 7277,
            "start_byte": 7251,
            "end_byte": 4
          },
          "_pytest.mark.MarkMatcher.from_item": {
            "name": "_pytest.mark.MarkMatcher.from_item",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "nding args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert s",
            "start_line": 223,
            "start_column": 7283,
            "end_line": 4,
            "end_column": 7438,
            "start_byte": 7283,
            "end_byte": 4
          },
          "_pytest.mark.MarkMatcher.__call__": {
            "name": "_pytest.mark.MarkMatcher.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "me == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 228,
            "start_column": 7444,
            "end_line": 4,
            "end_column": 7525,
            "start_byte": 7444,
            "end_byte": 4
          },
          "_pytest.mark.Mark": {
            "name": "_pytest.mark.Mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s(frozen=True)\nclass Mark:\n    #: Name of the mark.\n    name = attr.ib(type=str)\n    #: Positional arguments of the mark decorator.\n    args = attr.ib(type=Tuple[Any, ...])\n    #: Keyword arguments of the mark decorator.\n    kwargs = attr.ib(type=Mapping[str, Any])\n\n    #: Source Mark for ids with parametrize Marks.\n    _param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)\n    #: Resolved/generated ids with parametrize Marks.\n    _param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )\n\n    def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 195,
            "start_column": 6452,
            "end_line": 0,
            "end_column": 7948,
            "start_byte": 6452,
            "end_byte": 0
          },
          "_pytest.mark.Mark.name": {
            "name": "_pytest.mark.Mark.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "name = attr.ib(type=str)",
            "start_line": 198,
            "start_column": 6514,
            "end_line": 4,
            "end_column": 6538,
            "start_byte": 6514,
            "end_byte": 4
          },
          "_pytest.mark.Mark.args": {
            "name": "_pytest.mark.Mark.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "args = attr.ib(type=Tuple[Any, ...])",
            "start_line": 200,
            "start_column": 6594,
            "end_line": 4,
            "end_column": 6630,
            "start_byte": 6594,
            "end_byte": 4
          },
          "_pytest.mark.Mark.kwargs": {
            "name": "_pytest.mark.Mark.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "kwargs = attr.ib(type=Mapping[str, Any])",
            "start_line": 202,
            "start_column": 6683,
            "end_line": 4,
            "end_column": 6723,
            "start_byte": 6683,
            "end_byte": 4
          },
          "_pytest.mark.Mark._param_ids_from": {
            "name": "_pytest.mark.Mark._param_ids_from",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)",
            "start_line": 205,
            "start_column": 6780,
            "end_line": 4,
            "end_column": 6854,
            "start_byte": 6780,
            "end_byte": 4
          },
          "_pytest.mark.Mark._param_ids_generated": {
            "name": "_pytest.mark.Mark._param_ids_generated",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )",
            "start_line": 207,
            "start_column": 6913,
            "end_line": 4,
            "end_column": 7013,
            "start_byte": 6913,
            "end_byte": 4
          },
          "_pytest.mark.Mark._has_param_ids": {
            "name": "_pytest.mark.Mark._has_param_ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4",
            "start_line": 211,
            "start_column": 7019,
            "end_line": 4,
            "end_column": 7111,
            "start_byte": 7019,
            "end_byte": 4
          },
          "_pytest.mark.Mark.combined_with": {
            "name": "_pytest.mark.Mark.combined_with",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 214,
            "start_column": 7117,
            "end_line": 4,
            "end_column": 7948,
            "start_byte": 7117,
            "end_byte": 4
          },
          "_pytest.mark._Markable": {
            "name": "_pytest.mark._Markable",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_Markable = TypeVar(\"_Markable\", bound=Union[Callable[..., object], type])",
            "start_line": 245,
            "start_column": 8132,
            "end_line": 0,
            "end_column": 8206,
            "start_byte": 8132,
            "end_byte": 0
          },
          "_pytest.mark.MarkDecorator": {
            "name": "_pytest.mark.MarkDecorator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s\nclass MarkDecorator:\n    \"\"\"A decorator for applying a mark on test functions and classes.\n\n    MarkDecorators are created with ``pytest.mark``::\n\n        mark1 = pytest.mark.NAME              # Simple MarkDecorator\n        mark2 = pytest.mark.NAME(name1=value) # Parametrized MarkDecorator\n\n    and can then be applied as decorators to test functions::\n\n        @mark2\n        def test_function():\n            pass\n\n    When a MarkDecorator is called it does the following:\n\n    1. If called with a single class as its only positional argument and no\n       additional keyword arguments, it attaches the mark to the class so it\n       gets applied automatically to all test cases found in that class.\n\n    2. If called with a single function as its only positional argument and\n       no additional keyword arguments, it attaches the mark to the function,\n       containing all the arguments already stored internally in the\n       MarkDecorator.\n\n    3. When called in any other case, it returns a new MarkDecorator instance\n       with the original MarkDecorator's content updated with the arguments\n       passed to this call.\n\n    Note: The rules above prevent MarkDecorators from storing only a single\n    function or class reference as their positional argument with no\n    additional keyword or positional arguments. You can work around this by\n    using `with_args()`.\n    \"\"\"\n\n    mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))\n\n    @property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name\n\n    @property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args\n\n    @property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs\n\n    @property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)\n\n    def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)\n\n    def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))\n\n    # Type ignored because the overloads overlap with an incompatible\n    # return type. Not much we can do about that. Thankfully mypy picks\n    # the first match so it works out even if we break the rules.\n    @overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()\n\n    @overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()\n\n    def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 248,
            "start_column": 8209,
            "end_line": 0,
            "end_column": 11549,
            "start_byte": 8209,
            "end_byte": 0
          },
          "_pytest.mark.MarkDecorator.mark": {
            "name": "_pytest.mark.MarkDecorator.mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))",
            "start_line": 284,
            "start_column": 9608,
            "end_line": 4,
            "end_column": 9678,
            "start_byte": 9608,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.name": {
            "name": "_pytest.mark.MarkDecorator.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name",
            "start_line": 286,
            "start_column": 9684,
            "end_line": 4,
            "end_column": 9785,
            "start_byte": 9684,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.args": {
            "name": "_pytest.mark.MarkDecorator.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args",
            "start_line": 291,
            "start_column": 9791,
            "end_line": 4,
            "end_column": 9904,
            "start_byte": 9791,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.kwargs": {
            "name": "_pytest.mark.MarkDecorator.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs",
            "start_line": 296,
            "start_column": 9910,
            "end_line": 4,
            "end_column": 10031,
            "start_byte": 9910,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.markname": {
            "name": "_pytest.mark.MarkDecorator.markname",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)",
            "start_line": 301,
            "start_column": 10037,
            "end_line": 4,
            "end_column": 10147,
            "start_byte": 10037,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.__repr__": {
            "name": "_pytest.mark.MarkDecorator.__repr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)",
            "start_line": 305,
            "start_column": 10153,
            "end_line": 4,
            "end_column": 10235,
            "start_byte": 10153,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.with_args": {
            "name": "_pytest.mark.MarkDecorator.with_args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))",
            "start_line": 308,
            "start_column": 10241,
            "end_line": 4,
            "end_column": 10647,
            "start_byte": 10241,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.__call__": {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 332,
            "start_column": 11156,
            "end_line": 4,
            "end_column": 11549,
            "start_byte": 11156,
            "end_byte": 4
          },
          "_pytest.mark.store_mark": {
            "name": "_pytest.mark.store_mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def store_mark(obj, mark: Mark) -> None:\n    \"\"\"Store a Mark on an object.\n\n    This is used to implement the Mark declarations/decorators correctly.\n    \"\"\"\n    assert isinstance(mark, Mark), mark\n    # Always reassign name to avoid updating pytestmark in a reference that\n    # was only borrowed.\n    obj.pytestmark = get_unpacked_marks(obj) + [mark]",
            "start_line": 369,
            "start_column": 12372,
            "end_line": 0,
            "end_column": 12724,
            "start_byte": 12372,
            "end_byte": 0
          },
          "_pytest.mark.MarkGenerator": {
            "name": "_pytest.mark.MarkGenerator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "class MarkGenerator:\n    \"\"\"Factory for :class:`MarkDecorator` objects - exposed as\n    a ``pytest.mark`` singleton instance.\n\n    Example::\n\n         import pytest\n\n         @pytest.mark.slowtest\n         def test_function():\n            pass\n\n    applies a 'slowtest' :class:`Mark` on ``test_function``.\n    \"\"\"\n\n    _config = None  # type: Optional[Config]\n    _markers = set()  # type: Set[str]\n\n    # See TYPE_CHECKING above.\n    if TYPE_CHECKING:\n        # Using casts instead of type comments intentionally - issue #7473.\n        # TODO(py36): Change to builtin annotation syntax.\n        skip = cast(_SkipMarkDecorator, None)\n        skipif = cast(_SkipifMarkDecorator, None)\n        xfail = cast(_XfailMarkDecorator, None)\n        parametrize = cast(_ParametrizeMarkDecorator, None)\n        usefixtures = cast(_UsefixturesMarkDecorator, None)\n        filterwarnings = cast(_FilterwarningsMarkDecorator, None)\n\n    def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 450,
            "start_column": 15252,
            "end_line": 0,
            "end_column": 18166,
            "start_byte": 15252,
            "end_byte": 0
          },
          "_pytest.mark.MarkGenerator._config": {
            "name": "_pytest.mark.MarkGenerator._config",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_config = None",
            "start_line": 465,
            "start_column": 15571,
            "end_line": 4,
            "end_column": 15585,
            "start_byte": 15571,
            "end_byte": 4
          },
          "_pytest.mark.MarkGenerator._markers": {
            "name": "_pytest.mark.MarkGenerator._markers",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_markers = set()",
            "start_line": 466,
            "start_column": 15616,
            "end_line": 4,
            "end_column": 15632,
            "start_byte": 15616,
            "end_byte": 4
          },
          "_pytest.mark.MarkGenerator.__getattr__": {
            "name": "_pytest.mark.MarkGenerator.__getattr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 479,
            "start_column": 16175,
            "end_line": 4,
            "end_column": 18166,
            "start_byte": 16175,
            "end_byte": 4
          },
          "_pytest.warning_types.PytestUnknownMarkWarning": {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "\"values\", Sequence[Union[object, NotSetType]]),\n            (\"marks\", \"typing.Collection[Union[MarkDecorator, Mark]]\"),\n            (\"id\", Optional[str]),\n        ],\n    )\n):\n    @classmethod\n    d",
            "start_line": 77,
            "start_column": 1903,
            "end_line": 0,
            "end_column": 2100,
            "start_byte": 1903,
            "end_byte": 0
          },
          "_pytest.warning_types.PytestUnknownMarkWarning.__module__": {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning.__module__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "   @classmethod\n    d",
            "start_line": 83,
            "start_column": 2079,
            "end_line": 4,
            "end_column": 2100,
            "start_byte": 2079,
            "end_byte": 4
          },
          "_pytest.hookspec.pytest_runtest_makereport": {
            "name": "_pytest.hookspec.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "",
            "start_line": 486,
            "start_column": 17380,
            "end_line": 0,
            "end_column": 17867,
            "start_byte": 17380,
            "end_byte": 0
          },
          "_pytest.runner.pytest_runtest_makereport": {
            "name": "_pytest.runner.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "ort_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:\n    if hasattr(report, \"wasxfail\"):\n        if report.skipped",
            "start_line": 318,
            "start_column": 10464,
            "end_line": 0,
            "end_column": 10595,
            "start_byte": 10464,
            "end_byte": 0
          },
          "_pytest.skipping.evaluate_xfail_marks": {
            "name": "_pytest.skipping.evaluate_xfail_marks",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None",
            "start_line": 199,
            "start_column": 6507,
            "end_line": 0,
            "end_column": 7408,
            "start_byte": 6507,
            "end_byte": 0
          },
          "_pytest.skipping.pytest_runtest_makereport": {
            "name": "_pytest.skipping.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "@hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n    outcome = yield\n    rep = outcome.get_result()\n    xfailed = item._store.get(xfailed_key, None)\n    # unittest special case, see setting of unexpectedsuccess_key\n    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n        reason = item._store[unexpectedsuccess_key]\n        if reason:\n            rep.longrepr = \"Unexpected success: {}\".format(reason)\n        else:\n            rep.longrepr = \"Unexpected success\"\n        rep.outcome = \"failed\"\n    elif item.config.option.runxfail:\n        pass  # don't interfere\n    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n        assert call.excinfo.value.msg is not None\n        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n        rep.outcome = \"skipped\"\n    elif not rep.skipped and xfailed:\n        if call.excinfo:\n            raises = xfailed.raises\n            if raises is not None and not isinstance(call.excinfo.value, raises):\n                rep.outcome = \"failed\"\n            else:\n                rep.outcome = \"skipped\"\n                rep.wasxfail = xfailed.reason\n        elif call.when == \"call\":\n            if xfailed.strict:\n                rep.outcome = \"failed\"\n                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n            else:\n                rep.outcome = \"passed\"\n                rep.wasxfail = xfailed.reason\n\n    if (\n        item._store.get(skipped_by_mark_key, True)\n        and rep.skipped\n        and type(rep.longrepr) is tuple\n    ):\n        # skipped by mark.skipif; change the location of the failure\n        # to point to the item definition, otherwise it will display\n        # the location of where the skip exception was raised within pytest\n        _, _, reason = rep.longrepr\n        filename, line = item.reportinfo()[:2]\n        assert line is not None\n        rep.longrepr = str(filename), line + 1, reason",
            "start_line": 259,
            "start_column": 8490,
            "end_line": 0,
            "end_column": 10447,
            "start_byte": 8490,
            "end_byte": 0
          },
          "_pytest.unittest.pytest_runtest_makereport": {
            "name": "_pytest.unittest.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "urn \"xpassed\", \"X\", \"XPASS\"\n    return None\n",
            "start_line": 290,
            "start_column": 10683,
            "end_line": 0,
            "end_column": 11441,
            "start_byte": 10683,
            "end_byte": 0
          }
        }
      }
    }
  ]
}