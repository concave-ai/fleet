{
  "total_cost": 0,
  "task_id": "pytest-dev__pytest-5103",
  "model": "gpt-4o-2024-08-06",
  "spans": [
    {
      "name": "KeywordExtract",
      "metadata": {
        "start": "2024-08-19T13:33:50.665084",
        "usage": "3711.498975753784 ms"
      },
      "request": {
        "repo_tokens": [
          "summary_passes",
          "Cache",
          "summary_failures",
          "visit_Name",
          "fixturenames",
          "push_format_context",
          "extract_suffixes",
          "processoption",
          "fnmatch_lines",
          "LogCaptureHandler",
          "append_collect_error",
          "_read_pyc",
          "getpluginversioninfo",
          "typename",
          "cacheprovider",
          "find",
          "summary_errors",
          "_plugin_nameversions",
          "ids",
          "append_collect_skipped",
          "exit",
          "traceback",
          "_consider_importhook",
          "_validate_args",
          "delattr",
          "PYTEST_WARNS_UNKNOWN_KWARGS",
          "CallInfo",
          "write_fspath_result",
          "CLOSE_STDIN",
          "cwd_relative_nodeid",
          "mkdir",
          "getpathnode",
          "obj",
          "pytest_warning_captured",
          "FunctionMixin",
          "_import_plugin_specs",
          "_given_basetemp",
          "YIELD_TESTS",
          "addSkip",
          "last_failed_paths",
          "add_global_property",
          "store_mark",
          "resultlog",
          "OutcomeException",
          "parseconfig",
          "_format_args",
          "_ensure_basetemp",
          "runpytest",
          "builtin_plugins",
          "DOCTEST_REPORT_CHOICE_NDIFF",
          "getlocals",
          "_getnextfixturedef",
          "_get_allow_unicode_flag",
          "check_interactive_exception",
          "id",
          "getitems",
          "pastebin",
          "capsys",
          "NFPlugin",
          "approx",
          "RN",
          "deselect_by_keyword",
          "_early_rewrite_bailout",
          "_get_increasing_order",
          "_collect",
          "safeformat",
          "_determine_show_progress_info",
          "__unicode__",
          "pytest_sessionstart",
          "writeorg",
          "_translate_non_printable",
          "cleanup_numbered_dir",
          "is_rewrite_disabled",
          "_get_plugin_specs_as_list",
          "_rewrite_test",
          "_assertion_supported",
          "consider_module",
          "Failed",
          "_ensure_supporting_files",
          "pathlib",
          "terminal",
          "PytestPluginManager",
          "buffer",
          "pytest_runtest_call",
          "TEST_OUTCOME",
          "_compilecounter",
          "suspend_global_capture",
          "SysCaptureBinary",
          "get_lines_after",
          "pytest_internalerror",
          "pytestPDB",
          "runtest",
          "getrawcode",
          "__str__",
          "Exit",
          "getlocation",
          "UsageError",
          "SetupState",
          "_ensure_only_one_capture_fixture",
          "RE_IMPORT_ERROR_NAME",
          "match",
          "write_ensure_prefix",
          "_check_scope",
          "pytester",
          "_inject_setup_method_fixture",
          "EXIT_NOTESTSCOLLECTED",
          "_is_capturing",
          "Session",
          "activate_fixture",
          "setenv",
          "IGNORE_PAM",
          "getexplanation",
          "_call_and_format_exception",
          "pytest_report_collectionfinish",
          "classnamefilter",
          "args",
          "assign",
          "get_plugin_manager",
          "MultipleDoctestFailures",
          "showlongtestinfo",
          "ReprLocals",
          "is_package",
          "_matchnodes",
          "get_location",
          "_bestrelpath_cache",
          "NOTSET",
          "excinfo",
          "UnitTestCase",
          "fnmatch_lines_random",
          "LsofFdLeakChecker",
          "CallSpec2",
          "_iter_rewritable_modules",
          "raises",
          "_write_progress_information_filling_space",
          "addFailure",
          "cut",
          "readlines",
          "records",
          "pytest_assertrepr_compare",
          "getcrashentry",
          "_runtest_for_main",
          "pytest_enter_pdb",
          "collect_one_node",
          "Module",
          "consider_conftest",
          "compile",
          "_config_for_test",
          "notset",
          "runpython_c",
          "pytest_pycollect_makeitem",
          "from_item",
          "frame",
          "getargs",
          "pytest_collectstart",
          "_checkversion",
          "set_when",
          "FDCapture",
          "_force_symlink",
          "countoutcomes",
          "scope",
          "__test__",
          "compile_",
          "_LiveLoggingStreamHandler",
          "_init_runner_class",
          "ApproxBase",
          "_reprcompare",
          "_validate_usepdb_cls",
          "pytest_collection_modifyitems",
          "_fix_spoof_python2",
          "DEFAULT_ABSOLUTE_TOLERANCE",
          "getfixturevalue",
          "_make_xunit_fixture",
          "isdatacls",
          "PY36",
          "pytest_collect_directory",
          "ExceptionRepr",
          "_getconftestmodules",
          "nofuncargs",
          "re_match_lines_random",
          "_matches_prefix_or_glob_option",
          "get_common_ancestor",
          "pop_format_context",
          "scope2index",
          "pytest_report_teststatus",
          "ReprFailDoctest",
          "PytestCollectionWarning",
          "NodeMarkers",
          "_collectfile",
          "_dump_lines",
          "fix_cache_order",
          "CollectErrorRepr",
          "_for_parametrize",
          "_try_load_conftest",
          "SysModulesSnapshot",
          "rmtree",
          "_format_final_exc_line",
          "SubRequest",
          "HelpAction",
          "type",
          "pytest_fixture_post_finalizer",
          "python",
          "stop_global_capturing",
          "build_summary_stats_line",
          "visit_Starred",
          "reports",
          "extract_from",
          "mktemp",
          "getreports",
          "initialnames",
          "matchnodes",
          "fileno",
          "families",
          "_format_assertmsg",
          "DEFAULT_RELATIVE_TOLERANCE",
          "isdict",
          "LogCaptureFixture",
          "fail",
          "_warn_already_imported",
          "context",
          "explanation_param",
          "mkpydir",
          "AssertionRewritingHook",
          "getoption",
          "from_call",
          "MoreQuietAction",
          "find_prefixed",
          "out",
          "_PytestWrapper",
          "listextrakeywords",
          "RemovedInPytest4Warning",
          "getstatement",
          "template",
          "N",
          "pytest_logwarning",
          "get_records",
          "maybe_delete_a_numbered_dir",
          "_getscopeitem",
          "popen",
          "pytest_collect_file",
          "conftest_options",
          "EXIT_OK",
          "getfixtureclosure",
          "readline",
          "Interrupted",
          "TracebackEntry",
          "pytest_runtest_protocol",
          "record_tuples",
          "istrue",
          "_teardown_towards",
          "summary_warnings",
          "_seen",
          "write_captured_output",
          "location",
          "_cachedir",
          "_resolve_arg_value_types",
          "done",
          "MarkMapping",
          "post_mortem",
          "pytest_deselected",
          "__version__",
          "_approx_scalar",
          "NodeKeywords",
          "__setitem__",
          "skip",
          "_add_simple",
          "cached_eval",
          "_is_marked_for_rewrite",
          "for_later",
          "_update_current_test_var",
          "record_xml_attribute",
          "SysCapture",
          "resolve_from_str",
          "PytestAssertRewriteWarning",
          "print_teardown_sections",
          "append_error",
          "_truncate_explanation",
          "writelines",
          "funcargnames",
          "_folded_skips",
          "statement",
          "start_capturing",
          "list",
          "pytest_plugin_registered",
          "line",
          "helpconfig",
          "MarkEvaluator",
          "re_match_lines",
          "_ALLOW_MARKERS",
          "close",
          "PytestConfigWarning",
          "format",
          "_do_configure",
          "get_open_files",
          "call_runtest_hook",
          "node_reporter",
          "pytest_generate_tests",
          "_py_ext_re",
          "compat",
          "_getentrysource",
          "doctest",
          "rex_outcome",
          "_tmppath_factory",
          "Function",
          "get_parametrized_fixture_keys",
          "tmpdir_factory",
          "PyobjMixin",
          "_getcrashline",
          "ReprExceptionInfo",
          "determine_setup",
          "caplog",
          "visit_Assert",
          "pytest_make_collect_report",
          "isparseable",
          "pytest_keyboard_interrupt",
          "getfuncargvalue",
          "patchsysdict",
          "syspathinsert",
          "scopes",
          "get_user",
          "parse_setoption",
          "BaseReport",
          "warning_record_to_str",
          "_getvaluepath",
          "_main",
          "simple",
          "File",
          "CwdSnapshot",
          "visit_BinOp",
          "Junit",
          "HookRecorder",
          "LineMatcher",
          "pytest_collection",
          "_setoption",
          "pytest_runtestloop",
          "_show_fixtures_per_test",
          "repr_instance",
          "show_test_item",
          "get_source",
          "getsource",
          "parse_known_and_unknown_args",
          "function",
          "_get_runner",
          "cleanup_candidates",
          "makefile",
          "setitem",
          "ApproxScalar",
          "start",
          "MODULE_NOT_FOUND_ERROR",
          "capture",
          "add_funcarg_pseudo_fixture_def",
          "_get_verbose_word",
          "set_session",
          "get_lock_path",
          "eval",
          "_version",
          "_start",
          "_typ_map",
          "_ensure_unconfigure",
          "__version_tuple__",
          "_import_pdbcls",
          "chdir",
          "_node_location_to_relpath",
          "runner",
          "readouterr",
          "_postmortem_traceback",
          "node",
          "_initini",
          "teardown_exact",
          "get_default_arg_names",
          "junitxml",
          "illegal_xml_re",
          "cls",
          "repr_args",
          "spawn",
          "ReprEntry",
          "_exec_lsof",
          "Instance",
          "ReprEntryNative",
          "keywords",
          "_report_unserialization_failure",
          "_outrep_summary",
          "_recursive_debug",
          "module",
          "ReprTraceback",
          "source",
          "resolve_fixture_function",
          "PyobjContext",
          "winpymap",
          "pytest_report_from_serializable",
          "pop_outerr_to_orig",
          "_log",
          "_showfixtures_main",
          "Class",
          "wrap_function_to_error_out_if_called_directly",
          "visit_Call_legacy",
          "DEFAULT_MAX_LINES",
          "LEVELNAME_FMT_REGEX",
          "consider_preparse",
          "to_xml",
          "_pytest",
          "PytestExperimentalApiWarning",
          "__call__",
          "__nonzero__",
          "handler",
          "_truncate_recursive_traceback",
          "_repr_style",
          "update",
          "_width_of_current_line",
          "ensure_deletable",
          "applymarker",
          "_PLUGGY_DIR",
          "_pyfuncitem",
          "USAGE_MSG",
          "python_api",
          "repr_unicode",
          "_compare_eq_verbose",
          "prepare",
          "TempdirFactory",
          "EXIT_INTERNALERROR",
          "formatrepr",
          "assert_contains",
          "XFailed",
          "summary_stats",
          "_callfinalizers",
          "errors",
          "head_line",
          "idmaker",
          "_inject_setup_class_fixture",
          "set_repr_style",
          "_parsearg",
          "_getindent",
          "iter_markers_with_node",
          "display",
          "_callhelper",
          "Node",
          "_printcollecteditems",
          "pytest_runtest_logstart",
          "add_property",
          "MarkDecorator",
          "NoneType",
          "showlocals",
          "_sys_snapshot",
          "register_assert_rewrite",
          "warning_types",
          "directory_arg",
          "Package",
          "consider_env",
          "WARNS_EXEC",
          "get_fslocation_from_item",
          "_strtobool",
          "rewrite",
          "showheader",
          "_get_override_ini_value",
          "__repr__",
          "getini",
          "_inject_setup_function_fixture",
          "helper",
          "istestfunction",
          "deactivate_fixture",
          "parse",
          "_running_on_ci",
          "_basetemp",
          "FastFilesCompleter",
          "showversion",
          "gethookproxy",
          "indent",
          "__getitem__",
          "visit_Call_35",
          "get_empty_parameterset_mark",
          "log_outcome",
          "EncodedFile",
          "ihook",
          "_PY3",
          "prune_dependency_tree",
          "_importtestmodule",
          "_get_checker",
          "warn_about_none_ast",
          "_match_lines_random",
          "get_optionflags",
          "LogXML",
          "Skipped",
          "_compare_eq_set",
          "_some_str",
          "_should_repr_global_name",
          "pytest_exception_interact",
          "TestReport",
          "_init_pdb",
          "_ConfigDeprecated",
          "MultiCapture",
          "yield_fixture",
          "_resolve_arg_ids",
          "kwargs",
          "nodeid",
          "TestCaseFunction",
          "get_exconly",
          "_preparse",
          "_mark_plugins_for_rewrite",
          "UnformattedWarning",
          "visit_Compare",
          "getfslineno",
          "reorder_items",
          "message",
          "__init__",
          "_issue_warning_captured",
          "visit_UnaryOp",
          "_is_numpy_array",
          "normalize_mark_list",
          "CFG_PYTEST_SECTION",
          "when",
          "_yield_comparisons",
          "_install_capture_fixture_on_item",
          "isatty",
          "catch_warnings_for_item",
          "params",
          "_check_type",
          "ApproxMapping",
          "Source",
          "pytest_addoption",
          "parse_args",
          "listchain",
          "get",
          "NoCapture",
          "PYTEST_PARAM_UNKNOWN_KWARGS",
          "__all__",
          "listnames",
          "_finalize",
          "safe_text_dupfile",
          "cookie_re",
          "PYC_TAIL",
          "append",
          "hasopt",
          "getstatementrange_ast",
          "assert_contains_lines",
          "_set_opt_strings",
          "pytest_pycollect_makemodule",
          "_genfunctions",
          "Config",
          "_readline_workaround",
          "pyobj_property",
          "from_current",
          "bin_xml_escape",
          "tmp_path_factory",
          "_getpytestargs",
          "get_closest_marker",
          "isclass",
          "REPORT_COLLECTING_RESOLUTION",
          "__delitem__",
          "get_real_func",
          "SysPathsSnapshot",
          "_write_pyc",
          "_is_mocked",
          "_get_xunit_setup_teardown",
          "funcargs",
          "RaisesContext",
          "matchreport",
          "set_location",
          "essential_plugins",
          "parsefactories",
          "_should_rewrite",
          "prog",
          "update_testcase_duration",
          "DEFAULT_LOG_DATE_FORMAT",
          "linecomp",
          "pytest_collectreport",
          "mark_rewrite",
          "unittest",
          "FILE_OR_DIR",
          "_getparser",
          "_call_with_optional_argument",
          "generic_visit",
          "_getfailureheadline",
          "skipped",
          "CaptureResult",
          "capfdbinary",
          "abspath",
          "register_cleanup_lock_removal",
          "isfunction",
          "EMPTY_BUFFER",
          "pytest_itemstart",
          "FIXTURE_FUNCTION_CALL",
          "DOCTEST_REPORT_CHOICES",
          "addSuccess",
          "istext",
          "safe_getattr",
          "get_scope_node",
          "addError",
          "AssertionState",
          "raiseerror",
          "assertoutcome",
          "pytest_pyfunc_call",
          "ishidden",
          "_show_fixture_action",
          "NoMatch",
          "getmodulecol",
          "_getglobals",
          "_perform_collect",
          "getreportopt",
          "DummyRewriteHook",
          "_check_all_skipped",
          "cacheshow",
          "format_exception_only",
          "load_module",
          "pytest_configure",
          "copy_example",
          "find_module",
          "_check_initialpaths_for_relpath",
          "_recurse",
          "WarningsRecorder",
          "xfail",
          "_getini",
          "_runtest_for",
          "logging",
          "_pop_and_teardown",
          "warn",
          "_PY2",
          "run",
          "hookspec",
          "Item",
          "report_collect",
          "spawn_pytest",
          "messages",
          "setall",
          "name2fixturedefs",
          "fslocation",
          "_state",
          "astcache",
          "addoption",
          "reportinfo",
          "finish_recording",
          "repr",
          "ReprTracebackNative",
          "inline_runsource",
          "fromdictargs",
          "check_strict_xfail",
          "cmdline",
          "unary_map",
          "annotated_getattr",
          "get_unpacked_marks",
          "runpytest_inprocess",
          "capstdout",
          "_resume",
          "getfixturedefs",
          "__array_ufunc__",
          "setupplan",
          "strip",
          "start_global_capturing",
          "PYTEST_ENSURETEMP",
          "pytest_leave_pdb",
          "_markers",
          "_warn_if_env_name_is_not_str",
          "getparent",
          "_imp_find_module",
          "_idval",
          "PYTESTER_COPY_EXAMPLE",
          "FIXTURE_NAMED_REQUEST",
          "Traceback",
          "issequence",
          "safe_isclass",
          "deselect_by_mark",
          "get_scope_package",
          "GETFUNCARGVALUE",
          "scope2props",
          "_fix_unittest_skip_decorator",
          "ensure_reset_dir",
          "MarkGenerator",
          "ApproxSequencelike",
          "ExceptionChainRepr",
          "exconly",
          "SHOW_PYTEST_WARNINGS_ARG",
          "pytest_terminal_summary",
          "wrap_session",
          "_find_last_non_hidden_frame",
          "LOGLEVEL_COLOROPTS",
          "delenv",
          "finish",
          "_in_venv",
          "collect_by_name",
          "repr_traceback",
          "getplugin",
          "showfixtures",
          "config",
          "getinicfg",
          "binop_map",
          "add_cleanup",
          "assert_outcomes",
          "_colorama_workaround",
          "cached_result",
          "builtin",
          "warns",
          "addExpectedFailure",
          "_truncate_by_char_count",
          "record_property",
          "TimeoutExpired",
          "__enter__",
          "_idvalset",
          "newinstance",
          "_register_with_pkg_resources",
          "getparam",
          "PrintHelp",
          "_makepath",
          "rewrite_asserts",
          "ensuretemp",
          "fillfixtures",
          "DoctestTextfile",
          "showfspath",
          "recursionindex",
          "consider_pluginarg",
          "make_numbered_dir",
          "deprecated_call",
          "filter",
          "_saferepr",
          "_inject_setup_teardown_fixtures",
          "version_tuple",
          "defaultfuncargprefixmarker",
          "toterminal",
          "global_and_fixture_disabled",
          "repr_excinfo",
          "execute",
          "getfirstlinesource",
          "DEFAULT_MAX_CHARS",
          "inline_genitems",
          "DontReadFromInput",
          "write",
          "addsection",
          "pytest_unconfigure",
          "FixtureRequest",
          "findsource",
          "runpytest_subprocess",
          "delitem",
          "param",
          "_getlines",
          "getnode",
          "_PY_DIR",
          "with_args",
          "truncate_locals",
          "make_hook_recorder",
          "_factorytraceback",
          "PdbInvoke",
          "_rget_with_confmod",
          "exprinfo",
          "_test_pytest_function",
          "RunResult",
          "FixtureLookupError",
          "DOCTEST_REPORT_CHOICE_CDIFF",
          "visit_Attribute",
          "markname",
          "_getautousenames",
          "getdecoded",
          "_legal_xml_re",
          "skipping",
          "is_globally_capturing",
          "_non_printable_ascii_translate_table",
          "_attempt_to_close_capture_file",
          "isnosetest",
          "find_suffixes",
          "copy",
          "pytest_addhooks",
          "make_properties_node",
          "CaptureFixture",
          "_py36_windowsconsoleio_workaround",
          "_code",
          "create_cleanup_lock",
          "write_line",
          "pytest_cmdline_main",
          "teardown_all",
          "LOCK_TIMEOUT",
          "raise_on_kwargs",
          "_result",
          "_compare_eq_cls",
          "repr_traceback_entry",
          "_write_report_lines_from_hooks",
          "isinitpath",
          "_addfinalizer",
          "fspath",
          "set_level",
          "PytestArg",
          "collect",
          "_validate_if_using_arg_names",
          "is_generator",
          "PyCollector",
          "ReprFileLocation",
          "filename_arg",
          "SEP",
          "getfuncargnames",
          "call_optional",
          "get_statement_startend2",
          "COLLECT_FAKEMODULE_ATTRIBUTES",
          "get_option_ini",
          "is_capturing",
          "from_item_and_call",
          "_striptext",
          "addUnexpectedSuccess",
          "resolve",
          "pytest_report_to_serializable",
          "ResultLog",
          "_pdb_cls",
          "_cmp_raises_type_error",
          "pytest_runtest_setup",
          "isset",
          "getrepr",
          "_is_unittest_unexpected_success_a_failure",
          "PytestUnhandledCoroutineWarning",
          "version",
          "_getobj",
          "FixtureManager",
          "PytestCacheWarning",
          "_compare_eq_sequence",
          "scopename2class",
          "RAISES_EXEC",
          "_NodeReporter",
          "teardown_nose",
          "finalize",
          "runpython",
          "setuponly",
          "deprecated",
          "resume_global_capture",
          "scopeproperty",
          "REGEX_TYPE",
          "ensure_newline",
          "__take_sys_modules_snapshot",
          "import_plugin",
          "getcalls",
          "is_true",
          "makeini",
          "setup",
          "_parse_lsof_output",
          "getfixturemarker",
          "_argcomplete",
          "pytest_runtest_logfinish",
          "tmp_path",
          "addinivalue_line",
          "addfinalizer",
          "_find_parametrized_scope",
          "MARK_GEN",
          "write_log_entry",
          "_disable_output_capturing_for_darwin",
          "encoding",
          "setmulti2",
          "__hash__",
          "create_terminal_writer",
          "_iter_all_modules",
          "getvalueorskip",
          "RESULT_LOG",
          "TYPE_CHECKING",
          "filter_traceback",
          "getfailedcollections",
          "Frame",
          "for_config",
          "resume_fixture",
          "DEFAULT_LOG_FORMAT",
          "parametrize",
          "ReprFuncArgs",
          "_compare_eq_dict",
          "teardown",
          "__ne__",
          "EXIT_TESTSFAILED",
          "listoutcomes",
          "_get_report_choice",
          "ParsedCall",
          "_locationline",
          "passed",
          "MonkeyPatch",
          "register",
          "FuncFixtureInfo",
          "AssertionRewriter",
          "tbfilter",
          "install_importhook",
          "parseconfigure",
          "_addexcinfo",
          "__array_priority__",
          "saferepr",
          "getmodpath",
          "stopTest",
          "read",
          "__next__",
          "showhelp",
          "getcfg",
          "runitem",
          "pytest_ignore_collect",
          "FuncargnamesCompatAttr",
          "gethookrecorder",
          "verbosity",
          "longreprtext",
          "mode",
          "append_pass",
          "is_potential_nosetest",
          "perform_collect",
          "FixtureFunctionMarker",
          "_notin_text",
          "capture_fixtures",
          "_prepareconfig",
          "try_cleanup",
          "mangle_test_address",
          "PYTEST_LOGWARNING",
          "_format_boolop",
          "PytestDeprecationWarning",
          "pytest_cmdline_parse",
          "_assert_start_repr",
          "monkeypatch",
          "_format_action_invocation",
          "set_trace",
          "argnames",
          "_log_text",
          "CollectReport",
          "WarningReport",
          "getimfunc",
          "add_stats",
          "FunctionDefinition",
          "_warn_about_missing_assertion",
          "genitems",
          "stop_capturing",
          "reorder_items_atscope",
          "section",
          "autouse",
          "_excinfo",
          "parseoutcomes",
          "matchmark",
          "_handle_skip",
          "relline",
          "pytest_sessionfinish",
          "Mark",
          "ischildnode",
          "_diff_text",
          "parse_num",
          "exec_",
          "_should_truncate_item",
          "main",
          "matchkeyword",
          "fail_marker",
          "read_global_capture",
          "FDCaptureBinary",
          "get_terminal_writer",
          "get_sections",
          "hasplugin",
          "_processopt",
          "pytest_doctest_prepare_content",
          "names_closure",
          "ApproxNumpy",
          "truncate_if_required",
          "__bool__",
          "_recursive_list_map",
          "style",
          "_get_pos",
          "write_sep",
          "repr_locals",
          "notify_exception",
          "DOCTEST_REPORT_CHOICE_NONE",
          "recwarn",
          "path",
          "_get_continue_on_failure",
          "__eq__",
          "scopemismatch",
          "resume_capturing",
          "nextitem",
          "_traceback",
          "parts",
          "add_report_section",
          "getcall",
          "set_log_path",
          "Entry",
          "README_CONTENT",
          "fail_fixturefunc",
          "pop",
          "item_capture",
          "_teardown_yield_fixture",
          "_makeitem",
          "isiterable",
          "Testdir",
          "names",
          "_get_active_fixturedef",
          "__len__",
          "call_fixture_func",
          "addini",
          "pytest_report_header",
          "_checkargnotcontained",
          "DoctestModule",
          "name",
          "getgroup",
          "_get_allow_bytes_flag",
          "make_numbered_dir_with_cleanup",
          "alias",
          "mark",
          "startTest",
          "CaptureManager",
          "suspend_fixture",
          "dummy_context_manager",
          "suspend_capturing",
          "get_data",
          "add_marker",
          "_format_lines",
          "_addoption",
          "popcall",
          "_warn_incompatibility_with_xunit2",
          "wasvalid",
          "PYC_EXT",
          "tmpdir",
          "nose",
          "_patched_find_module",
          "tb",
          "FixtureDef",
          "write_docstring",
          "istestclass",
          "session",
          "PdbTrace",
          "_makefile",
          "_io",
          "_compute_fixture_value",
          "_pluginmanager",
          "_importconftest",
          "debugging",
          "DropShorterLongHelpFormatter",
          "append_failure",
          "exc_clear",
          "importorskip",
          "testdir",
          "getslaveinfoline",
          "RAISES_MESSAGE_PARAMETER",
          "deindent",
          "_setup_cli_logging",
          "pytest_collection_finish",
          "funcnamefilter",
          "pytest_load_initial_conftests",
          "undo",
          "SafeRepr",
          "pytest_cmdline_preparse",
          "_get_progress_information_message",
          "getstatementrange",
          "repr_failure",
          "default_plugins",
          "_setup_collect_fakemodule",
          "_istrue",
          "from_config",
          "_schedule_finalizers",
          "setattr",
          "hasinit",
          "_getconftest_pathlist",
          "hookimpl",
          "nodes",
          "_initrequest",
          "_legal_chars",
          "FixtureLookupErrorRepr",
          "ASCII_IS_DEFAULT_ENCODING",
          "check_xfail_no_run",
          "parse_hookimpl_opts",
          "flow_marker",
          "tracebackcutdir",
          "OptionGroup",
          "reset",
          "_testcase",
          "FSCollector",
          "LFPlugin",
          "_repr_failure_py",
          "hasnew",
          "own_markers",
          "format_explanation",
          "visit_BoolOp",
          "getitem",
          "cache_dir_from_config",
          "BOM_UTF8",
          "capstderr",
          "get_dirs_from_args",
          "_set_initial_conftests",
          "_split_explanation",
          "_suspend",
          "iter_markers",
          "_get_fixturestack",
          "disabled",
          "addhooks",
          "chain",
          "capsysbinary",
          "syspath_prepend",
          "getfailures",
          "inline_run",
          "_report_keyboardinterrupt",
          "TerminalRepr",
          "path_matches_patterns",
          "snap",
          "_mk_tmp",
          "FormattedExcinfo",
          "record_testreport",
          "warnings",
          "PseudoFixtureDef",
          "EXIT_INTERRUPTED",
          "matching_platform",
          "pytest_itemcollected",
          "stepwise",
          "record_testsuite_property",
          "TerminalReporter",
          "DOCTEST_REPORT_CHOICE_UDIFF",
          "ArgumentError",
          "_legal_ranges",
          "call_and_report",
          "_addoption_instance",
          "freeze_support",
          "KeywordMapping",
          "_config",
          "_get_line_with_reprcrash_message",
          "_inject_setup_module_fixture",
          "fnmatch_ex",
          "variable",
          "PY35",
          "get_real_method",
          "CollectError",
          "Code",
          "_to_json",
          "LoggingPlugin",
          "ColoredLevelFormatter",
          "Collector",
          "merge_family",
          "_getcapture",
          "scopenum_function",
          "__setattr__",
          "PYTEST_CONFIG_GLOBAL",
          "suspend",
          "restore",
          "_opentestcase",
          "doctest_namespace",
          "append_skipped",
          "WarningsChecker",
          "StepwisePlugin",
          "get_actual_log_level",
          "_setup_fixtures",
          "pytest_runtest_makereport",
          "get_public_names",
          "get_config",
          "LineMatcher_fixture",
          "ParameterSet",
          "DoctestItem",
          "EXIT_USAGEERROR",
          "locals",
          "_get_non_fixture_func",
          "instance",
          "_tryconvertpyarg",
          "_log_cli_enabled",
          "catching_logs",
          "CACHEDIR_TAG_CONTENT",
          "_get_flag_lookup",
          "resume",
          "tolerance",
          "_get_marks",
          "DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE",
          "__iter__",
          "__getattr__",
          "_enter_pdb",
          "__exit__",
          "co_equal",
          "Metafunc",
          "PytestUnknownMarkWarning",
          "BASE_TYPE",
          "set",
          "entrysep",
          "errisinstance",
          "_patch_unwrap_mock_aware",
          "invalidraise",
          "setns",
          "_getreprcrash",
          "_splitnode",
          "result",
          "pytest_runtest_logreport",
          "Parser",
          "istestfunc",
          "outcomes",
          "iscoroutinefunction",
          "combined_with",
          "fixtures",
          "fullsource",
          "_from_json",
          "get_skip_exceptions",
          "LineComp",
          "at_level",
          "assertrepr_compare",
          "show_fixtures_per_test",
          "failed",
          "EMPTY_PARAMETERSET_OPTION",
          "_call_reprcompare",
          "MyOptionParser",
          "TempPathFactory",
          "getbasetemp",
          "clear",
          "__module__",
          "_teardown_with_finalization",
          "value",
          "error",
          "pytest_make_parametrize_id",
          "ApproxDecimal",
          "putaround",
          "PYTEST_PLUGINS_FROM_NON_TOP_LEVEL_CONFTEST",
          "_ascii_escaped_by_config",
          "_prunetraceback",
          "ExceptionInfo",
          "emit",
          "RUNNER_CLASS",
          "pytest_fixture_setup",
          "_match_lines",
          "count_towards_summary",
          "isattrs",
          "Notset",
          "maketxtfile",
          "parse_known_args",
          "makeconftest",
          "derive_importpath",
          "str",
          "_PYTEST_DIR",
          "num_mock_patch_args",
          "stop",
          "exists",
          "runtestprotocol",
          "category",
          "pytestconfig",
          "_fillfixtures",
          "fixture",
          "check_testcase_implements_trial_reporter",
          "add_attribute",
          "getvalue",
          "_get_global_properties_node",
          "ecu",
          "FSHookProxy",
          "_is_setup_py",
          "_matchfactories",
          "freeze_includes",
          "own_mark_names",
          "create_new_paste",
          "text",
          "pytest_runtest_teardown",
          "parse_hookspec_opts",
          "PytestWarning",
          "_trace",
          "__missing__",
          "short_test_summary",
          "_ensure_immutable_ids",
          "ConftestImportFailure",
          "get_direct_param_fixture_func",
          "_saved",
          "Argument",
          "capfd",
          "makedir",
          "_non_numeric_type_error",
          "cache",
          "_ensure_removed_sysmodule",
          "getfixtureinfo",
          "_check_record_param_type",
          "assertion",
          "attrs",
          "_is_doctest",
          "_compare_eq_iterable",
          "python_keywords_allowed_list",
          "makepyfile"
        ]
      },
      "response": {
        "keywords": [
          "AssertionRewriter",
          "rewrite_asserts",
          "assertrepr_compare",
          "pytest_assertrepr_compare",
          "ReprFailDoctest",
          "AssertionState",
          "assertoutcome",
          "AssertionError",
          "assertoutcomes",
          "assert_contains"
        ]
      }
    },
    {
      "name": "FilesKeywordSearch",
      "metadata": {
        "start": "2024-08-19T13:33:54.376598",
        "usage": "256.7727565765381 ms"
      },
      "request": {
        "tokens": [
          "AssertionRewriter",
          "rewrite_asserts",
          "assertrepr_compare",
          "pytest_assertrepr_compare",
          "ReprFailDoctest",
          "AssertionState",
          "assertoutcome",
          "AssertionError",
          "assertoutcomes",
          "assert_contains"
        ]
      },
      "response": {
        "results": {
          "AssertionError": [
            "src/_pytest/config/__init__.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/recwarn.py",
            "src/_pytest/_code/code.py"
          ],
          "assertrepr_compare": [
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/assertion/util.py"
          ],
          "ReprFailDoctest": [
            "src/_pytest/doctest.py"
          ],
          "assert_contains": [
            "src/_pytest/pytester.py"
          ],
          "assertoutcome": [
            "src/_pytest/pytester.py"
          ],
          "pytest_assertrepr_compare": [
            "src/_pytest/hookspec.py",
            "src/_pytest/assertion/__init__.py"
          ],
          "AssertionState": [
            "src/_pytest/assertion/__init__.py"
          ],
          "AssertionRewriter": [
            "src/_pytest/assertion/rewrite.py"
          ],
          "rewrite_asserts": [
            "src/_pytest/assertion/rewrite.py"
          ]
        }
      }
    },
    {
      "name": "FilesFilter",
      "metadata": {
        "start": "2024-08-19T13:33:54.633384",
        "usage": "5850.1129150390625 ms"
      },
      "request": {
        "keyword_search_results": {
          "AssertionError": [
            "src/_pytest/config/__init__.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/recwarn.py",
            "src/_pytest/_code/code.py"
          ],
          "assertrepr_compare": [
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/assertion/util.py"
          ],
          "ReprFailDoctest": [
            "src/_pytest/doctest.py"
          ],
          "assert_contains": [
            "src/_pytest/pytester.py"
          ],
          "assertoutcome": [
            "src/_pytest/pytester.py"
          ],
          "pytest_assertrepr_compare": [
            "src/_pytest/hookspec.py",
            "src/_pytest/assertion/__init__.py"
          ],
          "AssertionState": [
            "src/_pytest/assertion/__init__.py"
          ],
          "AssertionRewriter": [
            "src/_pytest/assertion/rewrite.py"
          ],
          "rewrite_asserts": [
            "src/_pytest/assertion/rewrite.py"
          ]
        }
      },
      "response": {
        "scratch_pad": "The problem revolves around improving error messages by rewriting assertions that use the `all` and `any` functions. The goal is to transform these assertions to provide more detailed error reports, similar to those obtained when using a `for` loop.\n\nIn the context of pytest, assertions and their rewriting would be a part of the assertion mechanism. `AssertionRewriter` and `rewrite_asserts` are both keywords that suggest file locations where assertions are manipulated for error reporting purposes.\n\nThe most relevant files would likely involve mechanisms that enhance or modify assertion behavior, specifically related to expression rewriting. The presence of `AssertionRewriter` and `rewrite_asserts` in `src/_pytest/assertion/rewrite.py` suggests it plays a significant role in transforming or rewriting assertions. Thus, this file is highly likely related to implementing a feature to unroll iterables for better report messages in assertions involving `all` and `any`.\n\nAdditionally, `src/_pytest/assertion/util.py` and `src/_pytest/assertion/__init__.py` are important, as they include `assertrepr_compare` and other assertion-related keywords that might influence how comparisons and assertions are displayed.\n\nTherefore, the files associated with assertion manipulation and utilities are:\n1. `src/_pytest/assertion/rewrite.py` - Likely the main file responsible for rewriting assertions, which can be modified to implement the proposed feature.\n2. `src/_pytest/assertion/util.py` - Could contain utilities or helper functions for comparing or presenting assertion results.\n3. `src/_pytest/assertion/__init__.py` - Might have some setup or glue code that brings together assertion features.\n\nThe other files such as those in `config` or `recwarn` aren't directly related to this issue as they don't involve assertion rewriting or presentation.",
        "file_paths": [
          "src/_pytest/assertion/rewrite.py",
          "src/_pytest/assertion/util.py",
          "src/_pytest/assertion/__init__.py"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T13:34:00.483507",
        "usage": "17431.73098564148 ms"
      },
      "request": {
        "file_path": "src/_pytest/assertion/rewrite.py"
      },
      "response": {
        "scratch_pad": "1. **Reported Issue Analysis**:\n  - The user is having difficulty with the error messaging when using the `all` and `any` functions within pytest assertions. The error message is not informative as it only states that the assertion has failed with the specific generator or list comprehension.\n  - The meaningful error is provided only if assertions are unrolled and explicitly asserted one by one, as in a for loop.\n  - Currently, using `all` or `any` produces a less informative message, particularly if it fails.\n  - The user suggests enhancing the assertion rewriter in pytest to \"unroll\" assertions using `all` or `any` functions into individual checks to improve error reporting.\n\n2. **File Evaluation**:\n  - The file `rewrite.py` handles the assertion rewriting mechanism in pytest. One of the key classes here is `AssertionRewriter` which is responsible for taking an AST (Abstract Syntax Tree) module and rewriting assertions to improve error output.\n  - The `visit_Assert` function is a prime candidate for this feature. It currently rewrites assertions to improve detail but may not handle iterator-based assertions like `all` or `any` effectively.\n  - Before getting into `visit_Assert`, invoking methods such as `rewrite_asserts` or `run` will be critical since they orchestrate the overall rewriting and visiting of assertions in AST nodes.\n  - The `_rewrite_test` function rewrites the tests when they're parsed and identifies how they're recompiled into code objects.\n  - Key methods inside `AssertionRewriter` like `visit_BoolOp` and others relating to visiting AST nodes could incorporate the change: specifically unraveling expressions containing `all` or `any` calls to assert each element individually.\n\n3. **Conclusion**:\n  - The code within this file is relevant to addressing the user's issue because it deals with improving assertion error messages, which is directly what the user is asking for.\n  - While the file is likely not the root cause of confusing messages, it is the solution point where messages can be improved.\n  - Enhancements here can potentially transform `all(X)` or `any(X)` calls to iterate and assert more expressively per item, thus diagnosing which exact piece failed, providing meaningful error output.",
        "relevant": true,
        "root_cause": false,
        "relevant_files": [],
        "relevant_symbols": [
          "AssertionRewriter.run",
          "AssertionRewriter.visit_Assert"
        ],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T13:34:17.915295",
        "usage": "10234.394311904907 ms"
      },
      "request": {
        "file_path": "src/_pytest/assertion/util.py"
      },
      "response": {
        "scratch_pad": "1. Analyze User Instructions:\n1.1. The user is frustrated with the generic failure messages when using Python's `all` or `any` functions in assertions while testing. These functions don't provide detailed failures like a typical for-loop assertion would.\n1.2. The user has included sample code reproducing the issue with `all`/`any` compared to `for` loops. When `all` or `any` are used, if the assertion fails, it simply returns a generic Failure message, not detailing what part of the data caused the failure.\n1.3. This issue is caused because `all` and `any` return boolean values directly based on the iterable, not allowing pytest to access the internal details of the iteration.\n1.4. The user's expectation is for assertion rewriters in pytest to \"unroll\" these iterators, so assertions on iterations using `all`/`any` provide detailed failure messages without needing to manually write verbose for loops.\n1.5. The issue is rooted in pytest's handling of `all` and `any` usage as whole blackbox expressions. An enhancement would involve intercepting these for detailed failure reports, similarly to how pytest handles normal comparison assertions.\n\n2. File Evaluation:\n2.1. The file `src/_pytest/assertion/util.py` contains utilities related to assertion debugging and specific handling of comparisons (`assertrepr_compare`).\n2.2. The file does have content dealing with expanding iterable objects (`issequence`, `isiterable`) and comparing sequences, sets, dicts, etc.\n2.3. Functions like `assertrepr_compare` and utilities like `_compare_eq_*` methods are relevant as they handle detailed assertion representations and comparisons. They work with elements like sequences and might connect to extending `all` and `any` representations.\n2.4. Symbols related to improving the detailed assertion reports include the `assertrepr_compare` function and related iterable comparison methods.\n2.5. The file seems relevant as it contains logic for creating detailed assertion reports and comparisons but doesn't directly address unrolling iterators like `all`/`any`.\n\n2.6. To address the issue with `all`/`any`, a relevant section for processing iterators is required, which might involve expanding their logic within `assertrepr_compare` function or surrounding policies.\n\n3. Conclusion:\n3.1. While this file is highly relevant, additional changes in assertion rewriting or hooks into the iterative processes over `all`/`any` might be necessary. Additional files likely help in pytest's internals regarding expression rewriting for assertions.",
        "relevant": true,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/assertion/rewrite.py",
          "src/_pytest/_code/code.py",
          "src/_pytest/mark/evaluate.py"
        ],
        "relevant_symbols": [
          "assertrepr_compare",
          "issequence",
          "isiterable",
          "_compare_eq_iterable",
          "_compare_eq_sequence",
          "_split_explanation",
          "_format_lines"
        ],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-19T13:34:28.149719",
        "usage": "9917.580127716064 ms"
      },
      "request": {
        "file_path": "src/_pytest/assertion/__init__.py"
      },
      "response": {
        "scratch_pad": "1. Analyzing the User's Issue Description: \n   1.1. The user is describing an issue with assertion failures when using Python's built-in `all()` and `any()` functions. Specifically, the error messages generated when assertions fail do not provide enough information to diagnose which element in the iterable caused the failure.\n   1.2. The user mentions different ways they tried to assert conditions across an iterable: using a generator expression, a list comprehension, and a for loop. The for loop provides a more useful error message but is less concise.\n   1.3. The root cause is likely due to how `all()` and `any()` work\u2014they do not provide detailed failure context since they return a boolean after evaluating the entire iterable.\n   1.4. The user expects a more detailed failure report, similar to what happens in a for loop where the exact element causing an assertion failure is shown.\n   1.5. A possible solution is to modify or create a custom assertion function that mimics `all()` or `any()` but provides more informative error messages by unrolling the iterations and checking each element.\n\n2. Evaluating the Provided File:\n   2.1 The file `src/_pytest/assertion/__init__.py` appears to deal with assertion mechanism setup and may not directly influence how `all()` or `any()` failure messages are generated.\n   2.2 Key areas like `pytest_addoption`, `register_assert_rewrite`, `AssertionState`, and related functions deal with assertion rewriting and not directly with modifying how assertions are reported.\n   2.3 The functions seem related to configuring pytest's behavior, particularly regarding how assertions are checked and reported.\n   2.4 No function specifically handles the unrolling of iterables inside assertions or providing detailed feedback on `all()` or `any()` calls.\n   2.5 The closest related area might be the configuration of custom assertion hooks in `pytest_runtest_setup`. However, this is likely too high-level to affect individual `all()` or `any()` calls directly.",
        "relevant": false,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/assertion/rewrite.py",
          "src/_pytest/assertion/util.py"
        ],
        "relevant_symbols": [],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileSymbolSearch",
      "metadata": {
        "start": "2024-08-19T13:34:38.067332",
        "usage": "210.7710838317871 ms"
      },
      "request": {
        "files": [
          {
            "file_path": "src/_pytest/assertion/rewrite.py",
            "relevant_symbol_keys": [
              "AssertionRewriter.run",
              "AssertionRewriter.visit_Assert"
            ],
            "root_cause_symbol_keys": []
          },
          {
            "file_path": "src/_pytest/assertion/util.py",
            "relevant_symbol_keys": [
              "assertrepr_compare",
              "issequence",
              "isiterable",
              "_compare_eq_iterable",
              "_compare_eq_sequence",
              "_split_explanation",
              "_format_lines"
            ],
            "root_cause_symbol_keys": []
          },
          {
            "file_path": "src/_pytest/assertion/__init__.py",
            "relevant_symbol_keys": [],
            "root_cause_symbol_keys": []
          }
        ],
        "with_content": true
      },
      "response": {
        "related_symbols": [
          {
            "name": "_pytest.assertion.AssertionRewriter.run",
            "file_path": "src/_pytest/assertion/rewrite.py",
            "file_content": "def run(self, mod):\n        \"\"\"Find all assert statements in *mod* and rewrite them.\"\"\"\n        if not mod.body:\n            # Nothing to do.\n            return\n        # Insert some special imports at the top of the module but after any\n        # docstrings and __future__ imports.\n        aliases = [\n            ast.alias(six.moves.builtins.__name__, \"@py_builtins\"),\n            ast.alias(\"_pytest.assertion.rewrite\", \"@pytest_ar\"),\n        ]\n        doc = getattr(mod, \"docstring\", None)\n        expect_docstring = doc is None\n        if doc is not None and self.is_rewrite_disabled(doc):\n            return\n        pos = 0\n        lineno = 1\n        for item in mod.body:\n            if (\n                expect_docstring\n                and isinstance(item, ast.Expr)\n                and isinstance(item.value, ast.Str)\n            ):\n                doc = item.value.s\n                if self.is_rewrite_disabled(doc):\n                    return\n                expect_docstring = False\n            elif (\n                not isinstance(item, ast.ImportFrom)\n                or item.level > 0\n                or item.module != \"__future__\"\n            ):\n                lineno = item.lineno\n                break\n            pos += 1\n        else:\n            lineno = item.lineno\n        imports = [\n            ast.Import([alias], lineno=lineno, col_offset=0) for alias in aliases\n        ]\n        mod.body[pos:pos] = imports\n        # Collect asserts.\n        nodes = [mod]\n        while nodes:\n            node = nodes.pop()\n            for name, field in ast.iter_fields(node):\n                if isinstance(field, list):\n                    new = []\n                    for i, child in enumerate(field):\n                        if isinstance(child, ast.Assert):\n                            # Transform assert.\n                            new.extend(self.visit(child))\n                        else:\n                            new.append(child)\n                            if isinstance(child, ast.AST):\n                                nodes.append(child)\n                    setattr(node, name, new)\n                elif (\n                    isinstance(field, ast.AST)\n                    # Don't recurse into expressions as they can't contain\n                    # asserts.\n                    and not isinstance(field, ast.expr)\n                ):\n                    nodes.append(field)",
            "start_line": 664,
            "start_column": 24108,
            "end_line": 4,
            "end_column": 26514,
            "start_byte": 24108,
            "end_byte": 4
          },
          {
            "name": "_pytest.assertion.AssertionRewriter.visit_Assert",
            "file_path": "src/_pytest/assertion/rewrite.py",
            "file_content": "def visit_Assert(self, assert_):\n        \"\"\"Return the AST statements to replace the ast.Assert instance.\n\n        This rewrites the test of an assertion to provide\n        intermediate values and replace it with an if statement which\n        raises an assertion error with a detailed explanation in case\n        the expression is false.\n\n        \"\"\"\n        if isinstance(assert_.test, ast.Tuple) and len(assert_.test.elts) >= 1:\n            from _pytest.warning_types import PytestAssertRewriteWarning\n            import warnings\n\n            warnings.warn_explicit(\n                PytestAssertRewriteWarning(\n                    \"assertion is always true, perhaps remove parentheses?\"\n                ),\n                category=None,\n                filename=str(self.module_path),\n                lineno=assert_.lineno,\n            )\n\n        self.statements = []\n        self.variables = []\n        self.variable_counter = itertools.count()\n        self.stack = []\n        self.on_failure = []\n        self.push_format_context()\n        # Rewrite assert into a bunch of statements.\n        top_condition, explanation = self.visit(assert_.test)\n        # If in a test module, check if directly asserting None, in order to warn [Issue #3191]\n        if self.module_path is not None:\n            self.statements.append(\n                self.warn_about_none_ast(\n                    top_condition, module_path=self.module_path, lineno=assert_.lineno\n                )\n            )\n        # Create failure message.\n        body = self.on_failure\n        negation = ast.UnaryOp(ast.Not(), top_condition)\n        self.statements.append(ast.If(negation, body, []))\n        if assert_.msg:\n            assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n            explanation = \"\\n>assert \" + explanation\n        else:\n            assertmsg = ast.Str(\"\")\n            explanation = \"assert \" + explanation\n        template = ast.BinOp(assertmsg, ast.Add(), ast.Str(explanation))\n        msg = self.pop_format_context(template)\n        fmt = self.helper(\"_format_explanation\", msg)\n        err_name = ast.Name(\"AssertionError\", ast.Load())\n        exc = ast_Call(err_name, [fmt], [])\n        if sys.version_info[0] >= 3:\n            raise_ = ast.Raise(exc, None)\n        else:\n            raise_ = ast.Raise(exc, None, None)\n        body.append(raise_)\n        # Clear temporary variables by setting them to None.\n        if self.variables:\n            variables = [ast.Name(name, ast.Store()) for name in self.variables]\n            clear = ast.Assign(variables, _NameConstant(None))\n            self.statements.append(clear)\n        # Fix line numbers.\n        for stmt in self.statements:\n            set_location(stmt, assert_.lineno, assert_.col_offset)\n        return self.statements",
            "start_line": 813,
            "start_column": 29854,
            "end_line": 4,
            "end_column": 32649,
            "start_byte": 29854,
            "end_byte": 4
          },
          {
            "name": "_pytest.assertion.pytest_assertrepr_compare",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "n is not None:\n                        explanation.",
            "start_line": 154,
            "start_column": 5119,
            "end_line": 0,
            "end_column": 5170,
            "start_byte": 5119,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion._split_explanation",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _split_explanation(explanation):\n    \"\"\"Return a list of individual lines in the explanation\n\n    This will return a list of lines split on '\\n{', '\\n}' and '\\n~'.\n    Any other newlines will be escaped and appear in the line as the\n    literal '\\n' characters.\n    \"\"\"\n    raw_lines = (explanation or u\"\").split(\"\\n\")\n    lines = [raw_lines[0]]\n    for values in raw_lines[1:]:\n        if values and values[0] in [\"{\", \"}\", \"~\", \">\"]:\n            lines.append(values)\n        else:\n            lines[-1] += \"\\\\n\" + values\n    return lines",
            "start_line": 46,
            "start_column": 1358,
            "end_line": 0,
            "end_column": 1901,
            "start_byte": 1358,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion._format_lines",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _format_lines(lines):\n    \"\"\"Format the individual lines\n\n    This will replace the '{', '}' and '~' characters of our mini\n    formatting language with the proper 'where ...', 'and ...' and ' +\n    ...' text, taking care of indentation along the way.\n\n    Return a list of formatted lines.\n    \"\"\"\n    result = lines[:1]\n    stack = [0]\n    stackcnt = [0]\n    for line in lines[1:]:\n        if line.startswith(\"{\"):\n            if stackcnt[-1]:\n                s = u\"and   \"\n            else:\n                s = u\"where \"\n            stack.append(len(result))\n            stackcnt[-1] += 1\n            stackcnt.append(0)\n            result.append(u\" +\" + u\"  \" * (len(stack) - 1) + s + line[1:])\n        elif line.startswith(\"}\"):\n            stack.pop()\n            stackcnt.pop()\n            result[stack[-1]] += line[1:]\n        else:\n            assert line[0] in [\"~\", \">\"]\n            stack[-1] += 1\n            indent = len(stack) if line.startswith(\"~\") else len(stack) - 1\n            result.append(u\"  \" * indent + line[1:])\n    assert len(stack) == 1\n    return result",
            "start_line": 63,
            "start_column": 1904,
            "end_line": 0,
            "end_column": 2989,
            "start_byte": 1904,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion.issequence",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def issequence(x):\n    return isinstance(x, Sequence) and not isinstance(x, basestring)",
            "start_line": 105,
            "start_column": 3098,
            "end_line": 0,
            "end_column": 3185,
            "start_byte": 3098,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion.isiterable",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def isiterable(obj):\n    try:\n        iter(obj)\n        return not istext(obj)\n    except TypeError:\n        return False",
            "start_line": 129,
            "start_column": 3518,
            "end_line": 0,
            "end_column": 3639,
            "start_byte": 3518,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion.assertrepr_compare",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def assertrepr_compare(config, op, left, right):\n    \"\"\"Return specialised explanations for some operators/operands\"\"\"\n    width = 80 - 15 - len(op) - 2  # 15 chars indentation, 1 space around op\n    left_repr = saferepr(left, maxsize=int(width // 2))\n    right_repr = saferepr(right, maxsize=width - len(left_repr))\n\n    summary = u\"%s %s %s\" % (ecu(left_repr), op, ecu(right_repr))\n\n    verbose = config.getoption(\"verbose\")\n    explanation = None\n    try:\n        if op == \"==\":\n            if istext(left) and istext(right):\n                explanation = _diff_text(left, right, verbose)\n            else:\n                if issequence(left) and issequence(right):\n                    explanation = _compare_eq_sequence(left, right, verbose)\n                elif isset(left) and isset(right):\n                    explanation = _compare_eq_set(left, right, verbose)\n                elif isdict(left) and isdict(right):\n                    explanation = _compare_eq_dict(left, right, verbose)\n                elif type(left) == type(right) and (isdatacls(left) or isattrs(left)):\n                    type_fn = (isdatacls, isattrs)\n                    explanation = _compare_eq_cls(left, right, verbose, type_fn)\n                elif verbose > 0:\n                    explanation = _compare_eq_verbose(left, right)\n                if isiterable(left) and isiterable(right):\n                    expl = _compare_eq_iterable(left, right, verbose)\n                    if explanation is not None:\n                        explanation.extend(expl)\n                    else:\n                        explanation = expl\n        elif op == \"not in\":\n            if istext(left) and istext(right):\n                explanation = _notin_text(left, right, verbose)\n    except outcomes.Exit:\n        raise\n    except Exception:\n        explanation = [\n            u\"(pytest_assertion plugin: representation of details failed.  \"\n            u\"Probably an object has a faulty __repr__.)\",\n            six.text_type(_pytest._code.ExceptionInfo.from_current()),\n        ]\n\n    if not explanation:\n        return None\n\n    return [summary] + explanation",
            "start_line": 137,
            "start_column": 3642,
            "end_line": 0,
            "end_column": 5775,
            "start_byte": 3642,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion._compare_eq_iterable",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _compare_eq_iterable(left, right, verbose=0):\n    if not verbose:\n        return [u\"Use -v to get the full diff\"]\n    # dynamic import to speedup pytest\n    import difflib\n\n    try:\n        left_formatting = pprint.pformat(left).splitlines()\n        right_formatting = pprint.pformat(right).splitlines()\n        explanation = [u\"Full diff:\"]\n    except Exception:\n        # hack: PrettyPrinter.pformat() in python 2 fails when formatting items that can't be sorted(), ie, calling\n        # sorted() on a list would raise. See issue #718.\n        # As a workaround, the full diff is generated by using the repr() string of each item of each container.\n        left_formatting = sorted(repr(x) for x in left)\n        right_formatting = sorted(repr(x) for x in right)\n        explanation = [u\"Full diff (fallback to calling repr on each item):\"]\n    explanation.extend(\n        line.strip() for line in difflib.ndiff(left_formatting, right_formatting)\n    )\n    return explanation",
            "start_line": 262,
            "start_column": 8366,
            "end_line": 0,
            "end_column": 9347,
            "start_byte": 8366,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion._compare_eq_sequence",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _compare_eq_sequence(left, right, verbose=0):\n    explanation = []\n    len_left = len(left)\n    len_right = len(right)\n    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            explanation += [u\"At index %s diff: %r != %r\" % (i, left[i], right[i])]\n            break\n    len_diff = len_left - len_right\n\n    if len_diff:\n        if len_diff > 0:\n            dir_with_more = \"Left\"\n            extra = saferepr(left[len_right])\n        else:\n            len_diff = 0 - len_diff\n            dir_with_more = \"Right\"\n            extra = saferepr(right[len_left])\n\n        if len_diff == 1:\n            explanation += [u\"%s contains one more item: %s\" % (dir_with_more, extra)]\n        else:\n            explanation += [\n                u\"%s contains %d more items, first extra item: %s\"\n                % (dir_with_more, len_diff, extra)\n            ]\n    return explanation",
            "start_line": 285,
            "start_column": 9350,
            "end_line": 0,
            "end_column": 10256,
            "start_byte": 9350,
            "end_byte": 0
          },
          {
            "name": "_pytest.hookspec.pytest_assertrepr_compare",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "",
            "start_line": 475,
            "start_column": 15508,
            "end_line": 0,
            "end_column": 16001,
            "start_byte": 15508,
            "end_byte": 0
          }
        ],
        "root_caused_symbols": []
      }
    },
    {
      "name": "SymbolsEvaluate",
      "metadata": {
        "start": "2024-08-19T13:34:38.278110",
        "usage": "11189.71300125122 ms"
      },
      "request": {
        "related_symbols": [
          {
            "name": "_pytest.assertion.AssertionRewriter.run",
            "file_path": "src/_pytest/assertion/rewrite.py",
            "file_content": "def run(self, mod):\n        \"\"\"Find all assert statements in *mod* and rewrite them.\"\"\"\n        if not mod.body:\n            # Nothing to do.\n            return\n        # Insert some special imports at the top of the module but after any\n        # docstrings and __future__ imports.\n        aliases = [\n            ast.alias(six.moves.builtins.__name__, \"@py_builtins\"),\n            ast.alias(\"_pytest.assertion.rewrite\", \"@pytest_ar\"),\n        ]\n        doc = getattr(mod, \"docstring\", None)\n        expect_docstring = doc is None\n        if doc is not None and self.is_rewrite_disabled(doc):\n            return\n        pos = 0\n        lineno = 1\n        for item in mod.body:\n            if (\n                expect_docstring\n                and isinstance(item, ast.Expr)\n                and isinstance(item.value, ast.Str)\n            ):\n                doc = item.value.s\n                if self.is_rewrite_disabled(doc):\n                    return\n                expect_docstring = False\n            elif (\n                not isinstance(item, ast.ImportFrom)\n                or item.level > 0\n                or item.module != \"__future__\"\n            ):\n                lineno = item.lineno\n                break\n            pos += 1\n        else:\n            lineno = item.lineno\n        imports = [\n            ast.Import([alias], lineno=lineno, col_offset=0) for alias in aliases\n        ]\n        mod.body[pos:pos] = imports\n        # Collect asserts.\n        nodes = [mod]\n        while nodes:\n            node = nodes.pop()\n            for name, field in ast.iter_fields(node):\n                if isinstance(field, list):\n                    new = []\n                    for i, child in enumerate(field):\n                        if isinstance(child, ast.Assert):\n                            # Transform assert.\n                            new.extend(self.visit(child))\n                        else:\n                            new.append(child)\n                            if isinstance(child, ast.AST):\n                                nodes.append(child)\n                    setattr(node, name, new)\n                elif (\n                    isinstance(field, ast.AST)\n                    # Don't recurse into expressions as they can't contain\n                    # asserts.\n                    and not isinstance(field, ast.expr)\n                ):\n                    nodes.append(field)",
            "start_line": 664,
            "start_column": 24108,
            "end_line": 4,
            "end_column": 26514,
            "start_byte": 24108,
            "end_byte": 4
          },
          {
            "name": "_pytest.assertion.AssertionRewriter.visit_Assert",
            "file_path": "src/_pytest/assertion/rewrite.py",
            "file_content": "def visit_Assert(self, assert_):\n        \"\"\"Return the AST statements to replace the ast.Assert instance.\n\n        This rewrites the test of an assertion to provide\n        intermediate values and replace it with an if statement which\n        raises an assertion error with a detailed explanation in case\n        the expression is false.\n\n        \"\"\"\n        if isinstance(assert_.test, ast.Tuple) and len(assert_.test.elts) >= 1:\n            from _pytest.warning_types import PytestAssertRewriteWarning\n            import warnings\n\n            warnings.warn_explicit(\n                PytestAssertRewriteWarning(\n                    \"assertion is always true, perhaps remove parentheses?\"\n                ),\n                category=None,\n                filename=str(self.module_path),\n                lineno=assert_.lineno,\n            )\n\n        self.statements = []\n        self.variables = []\n        self.variable_counter = itertools.count()\n        self.stack = []\n        self.on_failure = []\n        self.push_format_context()\n        # Rewrite assert into a bunch of statements.\n        top_condition, explanation = self.visit(assert_.test)\n        # If in a test module, check if directly asserting None, in order to warn [Issue #3191]\n        if self.module_path is not None:\n            self.statements.append(\n                self.warn_about_none_ast(\n                    top_condition, module_path=self.module_path, lineno=assert_.lineno\n                )\n            )\n        # Create failure message.\n        body = self.on_failure\n        negation = ast.UnaryOp(ast.Not(), top_condition)\n        self.statements.append(ast.If(negation, body, []))\n        if assert_.msg:\n            assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n            explanation = \"\\n>assert \" + explanation\n        else:\n            assertmsg = ast.Str(\"\")\n            explanation = \"assert \" + explanation\n        template = ast.BinOp(assertmsg, ast.Add(), ast.Str(explanation))\n        msg = self.pop_format_context(template)\n        fmt = self.helper(\"_format_explanation\", msg)\n        err_name = ast.Name(\"AssertionError\", ast.Load())\n        exc = ast_Call(err_name, [fmt], [])\n        if sys.version_info[0] >= 3:\n            raise_ = ast.Raise(exc, None)\n        else:\n            raise_ = ast.Raise(exc, None, None)\n        body.append(raise_)\n        # Clear temporary variables by setting them to None.\n        if self.variables:\n            variables = [ast.Name(name, ast.Store()) for name in self.variables]\n            clear = ast.Assign(variables, _NameConstant(None))\n            self.statements.append(clear)\n        # Fix line numbers.\n        for stmt in self.statements:\n            set_location(stmt, assert_.lineno, assert_.col_offset)\n        return self.statements",
            "start_line": 813,
            "start_column": 29854,
            "end_line": 4,
            "end_column": 32649,
            "start_byte": 29854,
            "end_byte": 4
          },
          {
            "name": "_pytest.assertion.pytest_assertrepr_compare",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "n is not None:\n                        explanation.",
            "start_line": 154,
            "start_column": 5119,
            "end_line": 0,
            "end_column": 5170,
            "start_byte": 5119,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion._split_explanation",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _split_explanation(explanation):\n    \"\"\"Return a list of individual lines in the explanation\n\n    This will return a list of lines split on '\\n{', '\\n}' and '\\n~'.\n    Any other newlines will be escaped and appear in the line as the\n    literal '\\n' characters.\n    \"\"\"\n    raw_lines = (explanation or u\"\").split(\"\\n\")\n    lines = [raw_lines[0]]\n    for values in raw_lines[1:]:\n        if values and values[0] in [\"{\", \"}\", \"~\", \">\"]:\n            lines.append(values)\n        else:\n            lines[-1] += \"\\\\n\" + values\n    return lines",
            "start_line": 46,
            "start_column": 1358,
            "end_line": 0,
            "end_column": 1901,
            "start_byte": 1358,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion._format_lines",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _format_lines(lines):\n    \"\"\"Format the individual lines\n\n    This will replace the '{', '}' and '~' characters of our mini\n    formatting language with the proper 'where ...', 'and ...' and ' +\n    ...' text, taking care of indentation along the way.\n\n    Return a list of formatted lines.\n    \"\"\"\n    result = lines[:1]\n    stack = [0]\n    stackcnt = [0]\n    for line in lines[1:]:\n        if line.startswith(\"{\"):\n            if stackcnt[-1]:\n                s = u\"and   \"\n            else:\n                s = u\"where \"\n            stack.append(len(result))\n            stackcnt[-1] += 1\n            stackcnt.append(0)\n            result.append(u\" +\" + u\"  \" * (len(stack) - 1) + s + line[1:])\n        elif line.startswith(\"}\"):\n            stack.pop()\n            stackcnt.pop()\n            result[stack[-1]] += line[1:]\n        else:\n            assert line[0] in [\"~\", \">\"]\n            stack[-1] += 1\n            indent = len(stack) if line.startswith(\"~\") else len(stack) - 1\n            result.append(u\"  \" * indent + line[1:])\n    assert len(stack) == 1\n    return result",
            "start_line": 63,
            "start_column": 1904,
            "end_line": 0,
            "end_column": 2989,
            "start_byte": 1904,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion.issequence",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def issequence(x):\n    return isinstance(x, Sequence) and not isinstance(x, basestring)",
            "start_line": 105,
            "start_column": 3098,
            "end_line": 0,
            "end_column": 3185,
            "start_byte": 3098,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion.isiterable",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def isiterable(obj):\n    try:\n        iter(obj)\n        return not istext(obj)\n    except TypeError:\n        return False",
            "start_line": 129,
            "start_column": 3518,
            "end_line": 0,
            "end_column": 3639,
            "start_byte": 3518,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion.assertrepr_compare",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def assertrepr_compare(config, op, left, right):\n    \"\"\"Return specialised explanations for some operators/operands\"\"\"\n    width = 80 - 15 - len(op) - 2  # 15 chars indentation, 1 space around op\n    left_repr = saferepr(left, maxsize=int(width // 2))\n    right_repr = saferepr(right, maxsize=width - len(left_repr))\n\n    summary = u\"%s %s %s\" % (ecu(left_repr), op, ecu(right_repr))\n\n    verbose = config.getoption(\"verbose\")\n    explanation = None\n    try:\n        if op == \"==\":\n            if istext(left) and istext(right):\n                explanation = _diff_text(left, right, verbose)\n            else:\n                if issequence(left) and issequence(right):\n                    explanation = _compare_eq_sequence(left, right, verbose)\n                elif isset(left) and isset(right):\n                    explanation = _compare_eq_set(left, right, verbose)\n                elif isdict(left) and isdict(right):\n                    explanation = _compare_eq_dict(left, right, verbose)\n                elif type(left) == type(right) and (isdatacls(left) or isattrs(left)):\n                    type_fn = (isdatacls, isattrs)\n                    explanation = _compare_eq_cls(left, right, verbose, type_fn)\n                elif verbose > 0:\n                    explanation = _compare_eq_verbose(left, right)\n                if isiterable(left) and isiterable(right):\n                    expl = _compare_eq_iterable(left, right, verbose)\n                    if explanation is not None:\n                        explanation.extend(expl)\n                    else:\n                        explanation = expl\n        elif op == \"not in\":\n            if istext(left) and istext(right):\n                explanation = _notin_text(left, right, verbose)\n    except outcomes.Exit:\n        raise\n    except Exception:\n        explanation = [\n            u\"(pytest_assertion plugin: representation of details failed.  \"\n            u\"Probably an object has a faulty __repr__.)\",\n            six.text_type(_pytest._code.ExceptionInfo.from_current()),\n        ]\n\n    if not explanation:\n        return None\n\n    return [summary] + explanation",
            "start_line": 137,
            "start_column": 3642,
            "end_line": 0,
            "end_column": 5775,
            "start_byte": 3642,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion._compare_eq_iterable",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _compare_eq_iterable(left, right, verbose=0):\n    if not verbose:\n        return [u\"Use -v to get the full diff\"]\n    # dynamic import to speedup pytest\n    import difflib\n\n    try:\n        left_formatting = pprint.pformat(left).splitlines()\n        right_formatting = pprint.pformat(right).splitlines()\n        explanation = [u\"Full diff:\"]\n    except Exception:\n        # hack: PrettyPrinter.pformat() in python 2 fails when formatting items that can't be sorted(), ie, calling\n        # sorted() on a list would raise. See issue #718.\n        # As a workaround, the full diff is generated by using the repr() string of each item of each container.\n        left_formatting = sorted(repr(x) for x in left)\n        right_formatting = sorted(repr(x) for x in right)\n        explanation = [u\"Full diff (fallback to calling repr on each item):\"]\n    explanation.extend(\n        line.strip() for line in difflib.ndiff(left_formatting, right_formatting)\n    )\n    return explanation",
            "start_line": 262,
            "start_column": 8366,
            "end_line": 0,
            "end_column": 9347,
            "start_byte": 8366,
            "end_byte": 0
          },
          {
            "name": "_pytest.assertion._compare_eq_sequence",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _compare_eq_sequence(left, right, verbose=0):\n    explanation = []\n    len_left = len(left)\n    len_right = len(right)\n    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            explanation += [u\"At index %s diff: %r != %r\" % (i, left[i], right[i])]\n            break\n    len_diff = len_left - len_right\n\n    if len_diff:\n        if len_diff > 0:\n            dir_with_more = \"Left\"\n            extra = saferepr(left[len_right])\n        else:\n            len_diff = 0 - len_diff\n            dir_with_more = \"Right\"\n            extra = saferepr(right[len_left])\n\n        if len_diff == 1:\n            explanation += [u\"%s contains one more item: %s\" % (dir_with_more, extra)]\n        else:\n            explanation += [\n                u\"%s contains %d more items, first extra item: %s\"\n                % (dir_with_more, len_diff, extra)\n            ]\n    return explanation",
            "start_line": 285,
            "start_column": 9350,
            "end_line": 0,
            "end_column": 10256,
            "start_byte": 9350,
            "end_byte": 0
          },
          {
            "name": "_pytest.hookspec.pytest_assertrepr_compare",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "",
            "start_line": 475,
            "start_column": 15508,
            "end_line": 0,
            "end_column": 16001,
            "start_byte": 15508,
            "end_byte": 0
          }
        ],
        "root_caused_symbols": []
      },
      "response": {
        "scratch_pad": "1. Analyze User Instructions:\n1.1 The user wants better error reporting when using `all` and `any` in assertions. The default behavior doesn't provide useful messages.\n1.2 The issue arises because `all` and `any` return a single boolean result, which doesn't convey which specific item in the iterable caused the assertion to fail.\n1.3 The expected result is for assertion failures to identify which element(s) caused the failure, similar to individual assertions in a loop.\n1.4 If not provided, the expectation should be for detailed failure reports identifying exact elements causing failure.\n1.5 The issue could be resolved by modifying the assertion rewriter to 'unroll' iterables used in `all`/`any` into individual assertions for each element.\n\n2. Make the evaluate:\n2.1 Analyze `_pytest.assertion.AssertionRewriter.run`:\n   - This function collects and modifies AST nodes to change assert statements.\n   - It doesn't directly handle `all`/`any`, but it outlines what the rewriter is doing overall.\n\n2.2 Analyze `_pytest.assertion.AssertionRewriter.visit_Assert`:\n   - This function likely handles individual assertions and could be adapted to unroll iterables.\n   - Adding logic here to convert `all`/`any` constructs into individual assertions seems appropriate.\n\n2.3 Analyze `_pytest.assertion.pytest_assertrepr_compare`:\n   - This function customizes comparison messages, but not specifically for unrolling iterables.\n\n2.4 Analyze `_pytest.assertion._split_explanation` etc.:\n   - Functions for formatting and splitting explanations, not directly relevant to unrolling iterables.\n\nEvaluating potential code changes:\n1. `_pytest.assertion.AssertionRewriter.visit_Assert`\n   - Critically important as it already transforms asserts; can be modified to handle `all`/`any`.\n\n2. `_pytest.assertion.AssertionRewriter.run`\n   - May need only minor adjustments or none.\n\n3. Other symbols analyzed are not directly relevant to the specific solution of 'unrolling' iterables for `all`/`any`.",
        "symbols": [
          {
            "name": "_pytest.assertion.AssertionRewriter.visit_Assert",
            "file_path": "src/_pytest/assertion/rewrite.py",
            "reason": "This function should transform asserts involving `all` or `any` to unroll iterables into individual assertions."
          }
        ],
        "more_info": [],
        "is_done": true,
        "symbols_scratch_pad": [
          "Analyzing `_pytest.assertion.AssertionRewriter.run`: The function rewrites assert statements but doesn't handle `all`/`any` directly. Unrolling logic would likely be added elsewhere.",
          "The `visit_Assert` function is where assert transformations occur. Logic to unroll iterables in `all`/`any` should be added here, requiring examination and modification of assert test expressions.",
          "The `pytest_assertrepr_compare` function customizes message comparisons and isn't directly related to unrolling iterable assertions.",
          "The `_split_explanation` function involves formatting and explanation splitting, not directly relevant to unrolling.",
          "The `_format_lines` function handles formatting lines in explanations, unrelated to unrolling iterables.",
          "The `issequence` function checks if an object is a sequence; doesn't relate to unrolling `all`/`any`.",
          "The `isiterable` function determines if an object is iterable; might be part of a type check but not a direct change.",
          "The function `assertrepr_compare` generates custom explanations but isn't specific to unrolling changes.",
          "The `_compare_eq_iterable` function deals with iterable equality but not relevant to unrolling `all`/`any`.",
          "The `_compare_eq_sequence` function compares sequence equality but not related to unrolling."
        ]
      }
    },
    {
      "name": "SymbolSummary",
      "metadata": {
        "start": "2024-08-19T13:34:49.467842",
        "usage": "1.4178752899169922 ms"
      },
      "request": {
        "symbols": {
          "related_symbols": [
            {
              "name": "_pytest.assertion.AssertionRewriter.run",
              "file_path": "src/_pytest/assertion/rewrite.py",
              "file_content": "def run(self, mod):\n        \"\"\"Find all assert statements in *mod* and rewrite them.\"\"\"\n        if not mod.body:\n            # Nothing to do.\n            return\n        # Insert some special imports at the top of the module but after any\n        # docstrings and __future__ imports.\n        aliases = [\n            ast.alias(six.moves.builtins.__name__, \"@py_builtins\"),\n            ast.alias(\"_pytest.assertion.rewrite\", \"@pytest_ar\"),\n        ]\n        doc = getattr(mod, \"docstring\", None)\n        expect_docstring = doc is None\n        if doc is not None and self.is_rewrite_disabled(doc):\n            return\n        pos = 0\n        lineno = 1\n        for item in mod.body:\n            if (\n                expect_docstring\n                and isinstance(item, ast.Expr)\n                and isinstance(item.value, ast.Str)\n            ):\n                doc = item.value.s\n                if self.is_rewrite_disabled(doc):\n                    return\n                expect_docstring = False\n            elif (\n                not isinstance(item, ast.ImportFrom)\n                or item.level > 0\n                or item.module != \"__future__\"\n            ):\n                lineno = item.lineno\n                break\n            pos += 1\n        else:\n            lineno = item.lineno\n        imports = [\n            ast.Import([alias], lineno=lineno, col_offset=0) for alias in aliases\n        ]\n        mod.body[pos:pos] = imports\n        # Collect asserts.\n        nodes = [mod]\n        while nodes:\n            node = nodes.pop()\n            for name, field in ast.iter_fields(node):\n                if isinstance(field, list):\n                    new = []\n                    for i, child in enumerate(field):\n                        if isinstance(child, ast.Assert):\n                            # Transform assert.\n                            new.extend(self.visit(child))\n                        else:\n                            new.append(child)\n                            if isinstance(child, ast.AST):\n                                nodes.append(child)\n                    setattr(node, name, new)\n                elif (\n                    isinstance(field, ast.AST)\n                    # Don't recurse into expressions as they can't contain\n                    # asserts.\n                    and not isinstance(field, ast.expr)\n                ):\n                    nodes.append(field)",
              "start_line": 664,
              "start_column": 24108,
              "end_line": 4,
              "end_column": 26514,
              "start_byte": 24108,
              "end_byte": 4
            },
            {
              "name": "_pytest.assertion.AssertionRewriter.visit_Assert",
              "file_path": "src/_pytest/assertion/rewrite.py",
              "file_content": "def visit_Assert(self, assert_):\n        \"\"\"Return the AST statements to replace the ast.Assert instance.\n\n        This rewrites the test of an assertion to provide\n        intermediate values and replace it with an if statement which\n        raises an assertion error with a detailed explanation in case\n        the expression is false.\n\n        \"\"\"\n        if isinstance(assert_.test, ast.Tuple) and len(assert_.test.elts) >= 1:\n            from _pytest.warning_types import PytestAssertRewriteWarning\n            import warnings\n\n            warnings.warn_explicit(\n                PytestAssertRewriteWarning(\n                    \"assertion is always true, perhaps remove parentheses?\"\n                ),\n                category=None,\n                filename=str(self.module_path),\n                lineno=assert_.lineno,\n            )\n\n        self.statements = []\n        self.variables = []\n        self.variable_counter = itertools.count()\n        self.stack = []\n        self.on_failure = []\n        self.push_format_context()\n        # Rewrite assert into a bunch of statements.\n        top_condition, explanation = self.visit(assert_.test)\n        # If in a test module, check if directly asserting None, in order to warn [Issue #3191]\n        if self.module_path is not None:\n            self.statements.append(\n                self.warn_about_none_ast(\n                    top_condition, module_path=self.module_path, lineno=assert_.lineno\n                )\n            )\n        # Create failure message.\n        body = self.on_failure\n        negation = ast.UnaryOp(ast.Not(), top_condition)\n        self.statements.append(ast.If(negation, body, []))\n        if assert_.msg:\n            assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n            explanation = \"\\n>assert \" + explanation\n        else:\n            assertmsg = ast.Str(\"\")\n            explanation = \"assert \" + explanation\n        template = ast.BinOp(assertmsg, ast.Add(), ast.Str(explanation))\n        msg = self.pop_format_context(template)\n        fmt = self.helper(\"_format_explanation\", msg)\n        err_name = ast.Name(\"AssertionError\", ast.Load())\n        exc = ast_Call(err_name, [fmt], [])\n        if sys.version_info[0] >= 3:\n            raise_ = ast.Raise(exc, None)\n        else:\n            raise_ = ast.Raise(exc, None, None)\n        body.append(raise_)\n        # Clear temporary variables by setting them to None.\n        if self.variables:\n            variables = [ast.Name(name, ast.Store()) for name in self.variables]\n            clear = ast.Assign(variables, _NameConstant(None))\n            self.statements.append(clear)\n        # Fix line numbers.\n        for stmt in self.statements:\n            set_location(stmt, assert_.lineno, assert_.col_offset)\n        return self.statements",
              "start_line": 813,
              "start_column": 29854,
              "end_line": 4,
              "end_column": 32649,
              "start_byte": 29854,
              "end_byte": 4
            },
            {
              "name": "_pytest.assertion.pytest_assertrepr_compare",
              "file_path": "src/_pytest/assertion/util.py",
              "file_content": "n is not None:\n                        explanation.",
              "start_line": 154,
              "start_column": 5119,
              "end_line": 0,
              "end_column": 5170,
              "start_byte": 5119,
              "end_byte": 0
            },
            {
              "name": "_pytest.assertion._split_explanation",
              "file_path": "src/_pytest/assertion/util.py",
              "file_content": "def _split_explanation(explanation):\n    \"\"\"Return a list of individual lines in the explanation\n\n    This will return a list of lines split on '\\n{', '\\n}' and '\\n~'.\n    Any other newlines will be escaped and appear in the line as the\n    literal '\\n' characters.\n    \"\"\"\n    raw_lines = (explanation or u\"\").split(\"\\n\")\n    lines = [raw_lines[0]]\n    for values in raw_lines[1:]:\n        if values and values[0] in [\"{\", \"}\", \"~\", \">\"]:\n            lines.append(values)\n        else:\n            lines[-1] += \"\\\\n\" + values\n    return lines",
              "start_line": 46,
              "start_column": 1358,
              "end_line": 0,
              "end_column": 1901,
              "start_byte": 1358,
              "end_byte": 0
            },
            {
              "name": "_pytest.assertion._format_lines",
              "file_path": "src/_pytest/assertion/util.py",
              "file_content": "def _format_lines(lines):\n    \"\"\"Format the individual lines\n\n    This will replace the '{', '}' and '~' characters of our mini\n    formatting language with the proper 'where ...', 'and ...' and ' +\n    ...' text, taking care of indentation along the way.\n\n    Return a list of formatted lines.\n    \"\"\"\n    result = lines[:1]\n    stack = [0]\n    stackcnt = [0]\n    for line in lines[1:]:\n        if line.startswith(\"{\"):\n            if stackcnt[-1]:\n                s = u\"and   \"\n            else:\n                s = u\"where \"\n            stack.append(len(result))\n            stackcnt[-1] += 1\n            stackcnt.append(0)\n            result.append(u\" +\" + u\"  \" * (len(stack) - 1) + s + line[1:])\n        elif line.startswith(\"}\"):\n            stack.pop()\n            stackcnt.pop()\n            result[stack[-1]] += line[1:]\n        else:\n            assert line[0] in [\"~\", \">\"]\n            stack[-1] += 1\n            indent = len(stack) if line.startswith(\"~\") else len(stack) - 1\n            result.append(u\"  \" * indent + line[1:])\n    assert len(stack) == 1\n    return result",
              "start_line": 63,
              "start_column": 1904,
              "end_line": 0,
              "end_column": 2989,
              "start_byte": 1904,
              "end_byte": 0
            },
            {
              "name": "_pytest.assertion.issequence",
              "file_path": "src/_pytest/assertion/util.py",
              "file_content": "def issequence(x):\n    return isinstance(x, Sequence) and not isinstance(x, basestring)",
              "start_line": 105,
              "start_column": 3098,
              "end_line": 0,
              "end_column": 3185,
              "start_byte": 3098,
              "end_byte": 0
            },
            {
              "name": "_pytest.assertion.isiterable",
              "file_path": "src/_pytest/assertion/util.py",
              "file_content": "def isiterable(obj):\n    try:\n        iter(obj)\n        return not istext(obj)\n    except TypeError:\n        return False",
              "start_line": 129,
              "start_column": 3518,
              "end_line": 0,
              "end_column": 3639,
              "start_byte": 3518,
              "end_byte": 0
            },
            {
              "name": "_pytest.assertion.assertrepr_compare",
              "file_path": "src/_pytest/assertion/util.py",
              "file_content": "def assertrepr_compare(config, op, left, right):\n    \"\"\"Return specialised explanations for some operators/operands\"\"\"\n    width = 80 - 15 - len(op) - 2  # 15 chars indentation, 1 space around op\n    left_repr = saferepr(left, maxsize=int(width // 2))\n    right_repr = saferepr(right, maxsize=width - len(left_repr))\n\n    summary = u\"%s %s %s\" % (ecu(left_repr), op, ecu(right_repr))\n\n    verbose = config.getoption(\"verbose\")\n    explanation = None\n    try:\n        if op == \"==\":\n            if istext(left) and istext(right):\n                explanation = _diff_text(left, right, verbose)\n            else:\n                if issequence(left) and issequence(right):\n                    explanation = _compare_eq_sequence(left, right, verbose)\n                elif isset(left) and isset(right):\n                    explanation = _compare_eq_set(left, right, verbose)\n                elif isdict(left) and isdict(right):\n                    explanation = _compare_eq_dict(left, right, verbose)\n                elif type(left) == type(right) and (isdatacls(left) or isattrs(left)):\n                    type_fn = (isdatacls, isattrs)\n                    explanation = _compare_eq_cls(left, right, verbose, type_fn)\n                elif verbose > 0:\n                    explanation = _compare_eq_verbose(left, right)\n                if isiterable(left) and isiterable(right):\n                    expl = _compare_eq_iterable(left, right, verbose)\n                    if explanation is not None:\n                        explanation.extend(expl)\n                    else:\n                        explanation = expl\n        elif op == \"not in\":\n            if istext(left) and istext(right):\n                explanation = _notin_text(left, right, verbose)\n    except outcomes.Exit:\n        raise\n    except Exception:\n        explanation = [\n            u\"(pytest_assertion plugin: representation of details failed.  \"\n            u\"Probably an object has a faulty __repr__.)\",\n            six.text_type(_pytest._code.ExceptionInfo.from_current()),\n        ]\n\n    if not explanation:\n        return None\n\n    return [summary] + explanation",
              "start_line": 137,
              "start_column": 3642,
              "end_line": 0,
              "end_column": 5775,
              "start_byte": 3642,
              "end_byte": 0
            },
            {
              "name": "_pytest.assertion._compare_eq_iterable",
              "file_path": "src/_pytest/assertion/util.py",
              "file_content": "def _compare_eq_iterable(left, right, verbose=0):\n    if not verbose:\n        return [u\"Use -v to get the full diff\"]\n    # dynamic import to speedup pytest\n    import difflib\n\n    try:\n        left_formatting = pprint.pformat(left).splitlines()\n        right_formatting = pprint.pformat(right).splitlines()\n        explanation = [u\"Full diff:\"]\n    except Exception:\n        # hack: PrettyPrinter.pformat() in python 2 fails when formatting items that can't be sorted(), ie, calling\n        # sorted() on a list would raise. See issue #718.\n        # As a workaround, the full diff is generated by using the repr() string of each item of each container.\n        left_formatting = sorted(repr(x) for x in left)\n        right_formatting = sorted(repr(x) for x in right)\n        explanation = [u\"Full diff (fallback to calling repr on each item):\"]\n    explanation.extend(\n        line.strip() for line in difflib.ndiff(left_formatting, right_formatting)\n    )\n    return explanation",
              "start_line": 262,
              "start_column": 8366,
              "end_line": 0,
              "end_column": 9347,
              "start_byte": 8366,
              "end_byte": 0
            },
            {
              "name": "_pytest.assertion._compare_eq_sequence",
              "file_path": "src/_pytest/assertion/util.py",
              "file_content": "def _compare_eq_sequence(left, right, verbose=0):\n    explanation = []\n    len_left = len(left)\n    len_right = len(right)\n    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            explanation += [u\"At index %s diff: %r != %r\" % (i, left[i], right[i])]\n            break\n    len_diff = len_left - len_right\n\n    if len_diff:\n        if len_diff > 0:\n            dir_with_more = \"Left\"\n            extra = saferepr(left[len_right])\n        else:\n            len_diff = 0 - len_diff\n            dir_with_more = \"Right\"\n            extra = saferepr(right[len_left])\n\n        if len_diff == 1:\n            explanation += [u\"%s contains one more item: %s\" % (dir_with_more, extra)]\n        else:\n            explanation += [\n                u\"%s contains %d more items, first extra item: %s\"\n                % (dir_with_more, len_diff, extra)\n            ]\n    return explanation",
              "start_line": 285,
              "start_column": 9350,
              "end_line": 0,
              "end_column": 10256,
              "start_byte": 9350,
              "end_byte": 0
            },
            {
              "name": "_pytest.hookspec.pytest_assertrepr_compare",
              "file_path": "src/_pytest/assertion/util.py",
              "file_content": "",
              "start_line": 475,
              "start_column": 15508,
              "end_line": 0,
              "end_column": 16001,
              "start_byte": 15508,
              "end_byte": 0
            }
          ],
          "root_caused_symbols": []
        },
        "symbols_evaluate": {
          "scratch_pad": "1. Analyze User Instructions:\n1.1 The user wants better error reporting when using `all` and `any` in assertions. The default behavior doesn't provide useful messages.\n1.2 The issue arises because `all` and `any` return a single boolean result, which doesn't convey which specific item in the iterable caused the assertion to fail.\n1.3 The expected result is for assertion failures to identify which element(s) caused the failure, similar to individual assertions in a loop.\n1.4 If not provided, the expectation should be for detailed failure reports identifying exact elements causing failure.\n1.5 The issue could be resolved by modifying the assertion rewriter to 'unroll' iterables used in `all`/`any` into individual assertions for each element.\n\n2. Make the evaluate:\n2.1 Analyze `_pytest.assertion.AssertionRewriter.run`:\n   - This function collects and modifies AST nodes to change assert statements.\n   - It doesn't directly handle `all`/`any`, but it outlines what the rewriter is doing overall.\n\n2.2 Analyze `_pytest.assertion.AssertionRewriter.visit_Assert`:\n   - This function likely handles individual assertions and could be adapted to unroll iterables.\n   - Adding logic here to convert `all`/`any` constructs into individual assertions seems appropriate.\n\n2.3 Analyze `_pytest.assertion.pytest_assertrepr_compare`:\n   - This function customizes comparison messages, but not specifically for unrolling iterables.\n\n2.4 Analyze `_pytest.assertion._split_explanation` etc.:\n   - Functions for formatting and splitting explanations, not directly relevant to unrolling iterables.\n\nEvaluating potential code changes:\n1. `_pytest.assertion.AssertionRewriter.visit_Assert`\n   - Critically important as it already transforms asserts; can be modified to handle `all`/`any`.\n\n2. `_pytest.assertion.AssertionRewriter.run`\n   - May need only minor adjustments or none.\n\n3. Other symbols analyzed are not directly relevant to the specific solution of 'unrolling' iterables for `all`/`any`.",
          "symbols": [
            {
              "name": "_pytest.assertion.AssertionRewriter.visit_Assert",
              "file_path": "src/_pytest/assertion/rewrite.py",
              "reason": "This function should transform asserts involving `all` or `any` to unroll iterables into individual assertions."
            }
          ],
          "more_info": [],
          "is_done": true,
          "symbols_scratch_pad": [
            "Analyzing `_pytest.assertion.AssertionRewriter.run`: The function rewrites assert statements but doesn't handle `all`/`any` directly. Unrolling logic would likely be added elsewhere.",
            "The `visit_Assert` function is where assert transformations occur. Logic to unroll iterables in `all`/`any` should be added here, requiring examination and modification of assert test expressions.",
            "The `pytest_assertrepr_compare` function customizes message comparisons and isn't directly related to unrolling iterable assertions.",
            "The `_split_explanation` function involves formatting and explanation splitting, not directly relevant to unrolling.",
            "The `_format_lines` function handles formatting lines in explanations, unrelated to unrolling iterables.",
            "The `issequence` function checks if an object is a sequence; doesn't relate to unrolling `all`/`any`.",
            "The `isiterable` function determines if an object is iterable; might be part of a type check but not a direct change.",
            "The function `assertrepr_compare` generates custom explanations but isn't specific to unrolling changes.",
            "The `_compare_eq_iterable` function deals with iterable equality but not relevant to unrolling `all`/`any`.",
            "The `_compare_eq_sequence` function compares sequence equality but not related to unrolling."
          ]
        }
      },
      "response": {
        "file_paths": [
          "src/_pytest/assertion/rewrite.py"
        ],
        "symbols": [
          "_pytest.assertion.AssertionRewriter.visit_Assert"
        ],
        "code_spans": {
          "_pytest.assertion.AssertionRewriter.run": {
            "name": "_pytest.assertion.AssertionRewriter.run",
            "file_path": "src/_pytest/assertion/rewrite.py",
            "file_content": "def run(self, mod):\n        \"\"\"Find all assert statements in *mod* and rewrite them.\"\"\"\n        if not mod.body:\n            # Nothing to do.\n            return\n        # Insert some special imports at the top of the module but after any\n        # docstrings and __future__ imports.\n        aliases = [\n            ast.alias(six.moves.builtins.__name__, \"@py_builtins\"),\n            ast.alias(\"_pytest.assertion.rewrite\", \"@pytest_ar\"),\n        ]\n        doc = getattr(mod, \"docstring\", None)\n        expect_docstring = doc is None\n        if doc is not None and self.is_rewrite_disabled(doc):\n            return\n        pos = 0\n        lineno = 1\n        for item in mod.body:\n            if (\n                expect_docstring\n                and isinstance(item, ast.Expr)\n                and isinstance(item.value, ast.Str)\n            ):\n                doc = item.value.s\n                if self.is_rewrite_disabled(doc):\n                    return\n                expect_docstring = False\n            elif (\n                not isinstance(item, ast.ImportFrom)\n                or item.level > 0\n                or item.module != \"__future__\"\n            ):\n                lineno = item.lineno\n                break\n            pos += 1\n        else:\n            lineno = item.lineno\n        imports = [\n            ast.Import([alias], lineno=lineno, col_offset=0) for alias in aliases\n        ]\n        mod.body[pos:pos] = imports\n        # Collect asserts.\n        nodes = [mod]\n        while nodes:\n            node = nodes.pop()\n            for name, field in ast.iter_fields(node):\n                if isinstance(field, list):\n                    new = []\n                    for i, child in enumerate(field):\n                        if isinstance(child, ast.Assert):\n                            # Transform assert.\n                            new.extend(self.visit(child))\n                        else:\n                            new.append(child)\n                            if isinstance(child, ast.AST):\n                                nodes.append(child)\n                    setattr(node, name, new)\n                elif (\n                    isinstance(field, ast.AST)\n                    # Don't recurse into expressions as they can't contain\n                    # asserts.\n                    and not isinstance(field, ast.expr)\n                ):\n                    nodes.append(field)",
            "start_line": 664,
            "start_column": 24108,
            "end_line": 4,
            "end_column": 26514,
            "start_byte": 24108,
            "end_byte": 4
          },
          "_pytest.assertion.AssertionRewriter.visit_Assert": {
            "name": "_pytest.assertion.AssertionRewriter.visit_Assert",
            "file_path": "src/_pytest/assertion/rewrite.py",
            "file_content": "def visit_Assert(self, assert_):\n        \"\"\"Return the AST statements to replace the ast.Assert instance.\n\n        This rewrites the test of an assertion to provide\n        intermediate values and replace it with an if statement which\n        raises an assertion error with a detailed explanation in case\n        the expression is false.\n\n        \"\"\"\n        if isinstance(assert_.test, ast.Tuple) and len(assert_.test.elts) >= 1:\n            from _pytest.warning_types import PytestAssertRewriteWarning\n            import warnings\n\n            warnings.warn_explicit(\n                PytestAssertRewriteWarning(\n                    \"assertion is always true, perhaps remove parentheses?\"\n                ),\n                category=None,\n                filename=str(self.module_path),\n                lineno=assert_.lineno,\n            )\n\n        self.statements = []\n        self.variables = []\n        self.variable_counter = itertools.count()\n        self.stack = []\n        self.on_failure = []\n        self.push_format_context()\n        # Rewrite assert into a bunch of statements.\n        top_condition, explanation = self.visit(assert_.test)\n        # If in a test module, check if directly asserting None, in order to warn [Issue #3191]\n        if self.module_path is not None:\n            self.statements.append(\n                self.warn_about_none_ast(\n                    top_condition, module_path=self.module_path, lineno=assert_.lineno\n                )\n            )\n        # Create failure message.\n        body = self.on_failure\n        negation = ast.UnaryOp(ast.Not(), top_condition)\n        self.statements.append(ast.If(negation, body, []))\n        if assert_.msg:\n            assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n            explanation = \"\\n>assert \" + explanation\n        else:\n            assertmsg = ast.Str(\"\")\n            explanation = \"assert \" + explanation\n        template = ast.BinOp(assertmsg, ast.Add(), ast.Str(explanation))\n        msg = self.pop_format_context(template)\n        fmt = self.helper(\"_format_explanation\", msg)\n        err_name = ast.Name(\"AssertionError\", ast.Load())\n        exc = ast_Call(err_name, [fmt], [])\n        if sys.version_info[0] >= 3:\n            raise_ = ast.Raise(exc, None)\n        else:\n            raise_ = ast.Raise(exc, None, None)\n        body.append(raise_)\n        # Clear temporary variables by setting them to None.\n        if self.variables:\n            variables = [ast.Name(name, ast.Store()) for name in self.variables]\n            clear = ast.Assign(variables, _NameConstant(None))\n            self.statements.append(clear)\n        # Fix line numbers.\n        for stmt in self.statements:\n            set_location(stmt, assert_.lineno, assert_.col_offset)\n        return self.statements",
            "start_line": 813,
            "start_column": 29854,
            "end_line": 4,
            "end_column": 32649,
            "start_byte": 29854,
            "end_byte": 4
          },
          "_pytest.assertion.pytest_assertrepr_compare": {
            "name": "_pytest.assertion.pytest_assertrepr_compare",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "n is not None:\n                        explanation.",
            "start_line": 154,
            "start_column": 5119,
            "end_line": 0,
            "end_column": 5170,
            "start_byte": 5119,
            "end_byte": 0
          },
          "_pytest.assertion._split_explanation": {
            "name": "_pytest.assertion._split_explanation",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _split_explanation(explanation):\n    \"\"\"Return a list of individual lines in the explanation\n\n    This will return a list of lines split on '\\n{', '\\n}' and '\\n~'.\n    Any other newlines will be escaped and appear in the line as the\n    literal '\\n' characters.\n    \"\"\"\n    raw_lines = (explanation or u\"\").split(\"\\n\")\n    lines = [raw_lines[0]]\n    for values in raw_lines[1:]:\n        if values and values[0] in [\"{\", \"}\", \"~\", \">\"]:\n            lines.append(values)\n        else:\n            lines[-1] += \"\\\\n\" + values\n    return lines",
            "start_line": 46,
            "start_column": 1358,
            "end_line": 0,
            "end_column": 1901,
            "start_byte": 1358,
            "end_byte": 0
          },
          "_pytest.assertion._format_lines": {
            "name": "_pytest.assertion._format_lines",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _format_lines(lines):\n    \"\"\"Format the individual lines\n\n    This will replace the '{', '}' and '~' characters of our mini\n    formatting language with the proper 'where ...', 'and ...' and ' +\n    ...' text, taking care of indentation along the way.\n\n    Return a list of formatted lines.\n    \"\"\"\n    result = lines[:1]\n    stack = [0]\n    stackcnt = [0]\n    for line in lines[1:]:\n        if line.startswith(\"{\"):\n            if stackcnt[-1]:\n                s = u\"and   \"\n            else:\n                s = u\"where \"\n            stack.append(len(result))\n            stackcnt[-1] += 1\n            stackcnt.append(0)\n            result.append(u\" +\" + u\"  \" * (len(stack) - 1) + s + line[1:])\n        elif line.startswith(\"}\"):\n            stack.pop()\n            stackcnt.pop()\n            result[stack[-1]] += line[1:]\n        else:\n            assert line[0] in [\"~\", \">\"]\n            stack[-1] += 1\n            indent = len(stack) if line.startswith(\"~\") else len(stack) - 1\n            result.append(u\"  \" * indent + line[1:])\n    assert len(stack) == 1\n    return result",
            "start_line": 63,
            "start_column": 1904,
            "end_line": 0,
            "end_column": 2989,
            "start_byte": 1904,
            "end_byte": 0
          },
          "_pytest.assertion.issequence": {
            "name": "_pytest.assertion.issequence",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def issequence(x):\n    return isinstance(x, Sequence) and not isinstance(x, basestring)",
            "start_line": 105,
            "start_column": 3098,
            "end_line": 0,
            "end_column": 3185,
            "start_byte": 3098,
            "end_byte": 0
          },
          "_pytest.assertion.isiterable": {
            "name": "_pytest.assertion.isiterable",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def isiterable(obj):\n    try:\n        iter(obj)\n        return not istext(obj)\n    except TypeError:\n        return False",
            "start_line": 129,
            "start_column": 3518,
            "end_line": 0,
            "end_column": 3639,
            "start_byte": 3518,
            "end_byte": 0
          },
          "_pytest.assertion.assertrepr_compare": {
            "name": "_pytest.assertion.assertrepr_compare",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def assertrepr_compare(config, op, left, right):\n    \"\"\"Return specialised explanations for some operators/operands\"\"\"\n    width = 80 - 15 - len(op) - 2  # 15 chars indentation, 1 space around op\n    left_repr = saferepr(left, maxsize=int(width // 2))\n    right_repr = saferepr(right, maxsize=width - len(left_repr))\n\n    summary = u\"%s %s %s\" % (ecu(left_repr), op, ecu(right_repr))\n\n    verbose = config.getoption(\"verbose\")\n    explanation = None\n    try:\n        if op == \"==\":\n            if istext(left) and istext(right):\n                explanation = _diff_text(left, right, verbose)\n            else:\n                if issequence(left) and issequence(right):\n                    explanation = _compare_eq_sequence(left, right, verbose)\n                elif isset(left) and isset(right):\n                    explanation = _compare_eq_set(left, right, verbose)\n                elif isdict(left) and isdict(right):\n                    explanation = _compare_eq_dict(left, right, verbose)\n                elif type(left) == type(right) and (isdatacls(left) or isattrs(left)):\n                    type_fn = (isdatacls, isattrs)\n                    explanation = _compare_eq_cls(left, right, verbose, type_fn)\n                elif verbose > 0:\n                    explanation = _compare_eq_verbose(left, right)\n                if isiterable(left) and isiterable(right):\n                    expl = _compare_eq_iterable(left, right, verbose)\n                    if explanation is not None:\n                        explanation.extend(expl)\n                    else:\n                        explanation = expl\n        elif op == \"not in\":\n            if istext(left) and istext(right):\n                explanation = _notin_text(left, right, verbose)\n    except outcomes.Exit:\n        raise\n    except Exception:\n        explanation = [\n            u\"(pytest_assertion plugin: representation of details failed.  \"\n            u\"Probably an object has a faulty __repr__.)\",\n            six.text_type(_pytest._code.ExceptionInfo.from_current()),\n        ]\n\n    if not explanation:\n        return None\n\n    return [summary] + explanation",
            "start_line": 137,
            "start_column": 3642,
            "end_line": 0,
            "end_column": 5775,
            "start_byte": 3642,
            "end_byte": 0
          },
          "_pytest.assertion._compare_eq_iterable": {
            "name": "_pytest.assertion._compare_eq_iterable",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _compare_eq_iterable(left, right, verbose=0):\n    if not verbose:\n        return [u\"Use -v to get the full diff\"]\n    # dynamic import to speedup pytest\n    import difflib\n\n    try:\n        left_formatting = pprint.pformat(left).splitlines()\n        right_formatting = pprint.pformat(right).splitlines()\n        explanation = [u\"Full diff:\"]\n    except Exception:\n        # hack: PrettyPrinter.pformat() in python 2 fails when formatting items that can't be sorted(), ie, calling\n        # sorted() on a list would raise. See issue #718.\n        # As a workaround, the full diff is generated by using the repr() string of each item of each container.\n        left_formatting = sorted(repr(x) for x in left)\n        right_formatting = sorted(repr(x) for x in right)\n        explanation = [u\"Full diff (fallback to calling repr on each item):\"]\n    explanation.extend(\n        line.strip() for line in difflib.ndiff(left_formatting, right_formatting)\n    )\n    return explanation",
            "start_line": 262,
            "start_column": 8366,
            "end_line": 0,
            "end_column": 9347,
            "start_byte": 8366,
            "end_byte": 0
          },
          "_pytest.assertion._compare_eq_sequence": {
            "name": "_pytest.assertion._compare_eq_sequence",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "def _compare_eq_sequence(left, right, verbose=0):\n    explanation = []\n    len_left = len(left)\n    len_right = len(right)\n    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            explanation += [u\"At index %s diff: %r != %r\" % (i, left[i], right[i])]\n            break\n    len_diff = len_left - len_right\n\n    if len_diff:\n        if len_diff > 0:\n            dir_with_more = \"Left\"\n            extra = saferepr(left[len_right])\n        else:\n            len_diff = 0 - len_diff\n            dir_with_more = \"Right\"\n            extra = saferepr(right[len_left])\n\n        if len_diff == 1:\n            explanation += [u\"%s contains one more item: %s\" % (dir_with_more, extra)]\n        else:\n            explanation += [\n                u\"%s contains %d more items, first extra item: %s\"\n                % (dir_with_more, len_diff, extra)\n            ]\n    return explanation",
            "start_line": 285,
            "start_column": 9350,
            "end_line": 0,
            "end_column": 10256,
            "start_byte": 9350,
            "end_byte": 0
          },
          "_pytest.hookspec.pytest_assertrepr_compare": {
            "name": "_pytest.hookspec.pytest_assertrepr_compare",
            "file_path": "src/_pytest/assertion/util.py",
            "file_content": "",
            "start_line": 475,
            "start_column": 15508,
            "end_line": 0,
            "end_column": 16001,
            "start_byte": 15508,
            "end_byte": 0
          }
        }
      }
    }
  ]
}