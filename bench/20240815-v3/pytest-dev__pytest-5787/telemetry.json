{
  "total_cost": 0,
  "task_id": "pytest-dev__pytest-5787",
  "model": "gpt-4o-mini",
  "spans": [
    {
      "name": "KeywordExtract",
      "metadata": {
        "start": "2024-08-15T18:44:47.527282",
        "usage": "1239.34006690979 ms"
      },
      "request": {
        "repo_tokens": [
          "23",
          "42",
          "A",
          "ABSOLUTE",
          "ALLOW",
          "ANSI",
          "ARGS",
          "ARGUMENTS",
          "ATTRIBUTES",
          "ATTRS",
          "AlwaysDispatchingPrettyPrinter",
          "AnyPurePath",
          "ApproxBase",
          "ApproxDecimal",
          "ApproxMapping",
          "ApproxNumpy",
          "ApproxScalar",
          "ApproxSequencelike",
          "Argument",
          "ArgumentError",
          "Assert",
          "AssertionRewriter",
          "AssertionRewritingHook",
          "AssertionState",
          "Attribute",
          "BASE",
          "BINOP",
          "BODY",
          "BUFFER",
          "Bar",
          "BaseReport",
          "BinOp",
          "BoolOp",
          "CACHE",
          "CACHEDIR",
          "CDIFF",
          "CFG",
          "CHARS",
          "CHECKER",
          "CHECKING",
          "CHOICE",
          "CHOICES",
          "CLASS",
          "CLOSE",
          "COLLECT",
          "COLLECTED",
          "COLLECTING",
          "COLOROPTS",
          "CONTENT",
          "COPY",
          "Cache",
          "Call",
          "CallInfo",
          "CallSpec2",
          "Capture",
          "CaptureFixture",
          "CaptureIO",
          "CaptureManager",
          "CaptureMethod",
          "CaptureResult",
          "Class",
          "Code",
          "Collect",
          "CollectError",
          "CollectErrorRepr",
          "CollectReport",
          "Collector",
          "ColoredLevelFormatter",
          "Compare",
          "Config",
          "ConftestImportFailure",
          "CwdSnapshot",
          "D",
          "DATE",
          "DEFAULT",
          "DEPRECATED",
          "DIR",
          "DIRECTORY",
          "DIRS",
          "DOCTEST",
          "DoctestItem",
          "DoctestModule",
          "DoctestTextfile",
          "DontReadFromInput",
          "DropShorterLongHelpFormatter",
          "DummyRewriteHook",
          "E",
          "EMPTY",
          "EQ",
          "ERROR",
          "ESCAPE",
          "ET",
          "EXAMPLE",
          "EXT",
          "EXTERNAL",
          "EncodedFile",
          "Exception",
          "ExceptionChainRepr",
          "ExceptionInfo",
          "ExceptionRepr",
          "Exit",
          "ExitCode",
          "F",
          "FAILED",
          "FAILURE",
          "FAKEMODULE",
          "FAMILY",
          "FDCapture",
          "FDCaptureBinary",
          "FIELD",
          "FILE",
          "FILLFUNCARGS",
          "FIRST",
          "FIXTURE",
          "FMT",
          "FORMAT",
          "FOUND",
          "FROM",
          "FSCollector",
          "FSHookProxy",
          "FUNCARGNAMES",
          "Failed",
          "FakeCollectModule",
          "FastFilesCompleter",
          "FaultHandlerHooks",
          "FixtureDef",
          "FixtureFunctionMarker",
          "FixtureLookupError",
          "FixtureLookupErrorRepr",
          "FixtureManager",
          "FixtureRequest",
          "FlaskyStyle",
          "Foo",
          "FormattedExcinfo",
          "Frame",
          "FuncFixtureInfo",
          "Function",
          "FunctionDefinition",
          "GEN",
          "HOOK",
          "HelpAction",
          "HookCaller",
          "HookRecorder",
          "IGNORE",
          "IMPORT",
          "INSTALL",
          "INTERNAL",
          "INTERRUPTED",
          "Instance",
          "Interrupted",
          "InvalidFeatureRelease",
          "InvocationParams",
          "Item",
          "JSON",
          "JUNIT",
          "Junit",
          "KNOWN",
          "KeywordMapping",
          "LEVELNAME",
          "LFPlugin",
          "LFPluginCollSkipfiles",
          "LFPluginCollWrapper",
          "LINES",
          "LOCK",
          "LOG",
          "LOGLEVEL",
          "LOGS",
          "LineComp",
          "LineMatcher",
          "LiteralsOutputChecker",
          "LiveLoggingStreamHandler",
          "LogCaptureFixture",
          "LogCaptureHandler",
          "LogXML",
          "LoggingPlugin",
          "LsofFdLeakChecker",
          "MAP",
          "MARK",
          "MARKERS",
          "MAX",
          "MODULE",
          "MSG",
          "Mark",
          "MarkDecorator",
          "MarkEvaluator",
          "MarkGenerator",
          "MarkMapping",
          "Metafunc",
          "MockAwareDocTestFinder",
          "Module",
          "MonkeyPatch",
          "MoreQuietAction",
          "MultiCapture",
          "MultipleDoctestFailures",
          "MyOptionParser",
          "NAME",
          "NDIFF",
          "NFPlugin",
          "NO",
          "NODE",
          "NONE",
          "NOT",
          "NOTSET",
          "Name",
          "NoCapture",
          "NoMatch",
          "Node",
          "NodeKeywords",
          "NodeMeta",
          "NodeReporter",
          "Notset",
          "OK",
          "ONLY",
          "OPTION",
          "OR",
          "ORDER",
          "OUTCOME",
          "OptionGroup",
          "OutcomeException",
          "PAM",
          "PARAMETERSET",
          "PARENT",
          "PLUGGY",
          "PLUGINS",
          "POSITIONAL",
          "PR",
          "PREFIX",
          "PRINT",
          "PY",
          "PYC",
          "PYTEST",
          "PYTESTER",
          "Package",
          "ParameterSet",
          "ParsedCall",
          "Parser",
          "PdbInvoke",
          "PdbTrace",
          "PercentStyleMultiline",
          "PluggyPlugin",
          "PluginManager",
          "PrintHelp",
          "PseudoFixtureDef",
          "PyCollector",
          "PyobjMixin",
          "PytestArg",
          "PytestAssertRewriteWarning",
          "PytestCacheWarning",
          "PytestCollectionWarning",
          "PytestDeprecationWarning",
          "PytestDoctestRunner",
          "PytestExperimentalApiWarning",
          "PytestPdbWrapper",
          "PytestPluginManager",
          "PytestUnhandledCoroutineWarning",
          "PytestUnknownMarkWarning",
          "PytestWrapper",
          "Python",
          "RE",
          "README",
          "REGEX",
          "RELATIVE",
          "REPORT",
          "REPORTCHARS",
          "REQUIRES",
          "RESOLUTION",
          "RESULT",
          "RUNNER",
          "RaisesContext",
          "ReprEntry",
          "ReprEntryNative",
          "ReprExceptionInfo",
          "ReprFailDoctest",
          "ReprFileLocation",
          "ReprFuncArgs",
          "ReprLocals",
          "ReprTraceback",
          "ReprTracebackNative",
          "ResultLog",
          "RunResult",
          "S",
          "SECTION",
          "SEP",
          "SEQ",
          "SKIP",
          "SLUG",
          "STDIN",
          "STRING",
          "SafeRepr",
          "Session",
          "SetupState",
          "Skipped",
          "Source",
          "Starred",
          "StepwisePlugin",
          "Store",
          "StoreKey",
          "SubRequest",
          "SysCapture",
          "SysCaptureBinary",
          "SysModulesSnapshot",
          "SysPathsSnapshot",
          "T",
          "TAG",
          "TAIL",
          "TERMINALWRITER",
          "TEST",
          "TESTS",
          "TIMEOUT",
          "TOLERANCE",
          "TUPLE",
          "TYPE",
          "TYPES",
          "TagTracer",
          "TagTracerSub",
          "TeeCaptureIO",
          "TeeSysCapture",
          "TempPathFactory",
          "TempdirFactory",
          "TerminalReporter",
          "TerminalRepr",
          "TerminalWriter",
          "TestCaseFunction",
          "TestClass",
          "TestCustomAssertMsg",
          "TestFailing",
          "TestMoreErrors",
          "TestRaises",
          "TestReport",
          "TestSpecialisedExplanations",
          "TestStateFullThing",
          "Testdir",
          "TimeoutExpired",
          "Traceback",
          "TracebackEntry",
          "TracebackStyle",
          "UDIFF",
          "UNARY",
          "USAGE",
          "USE",
          "UnaryOp",
          "UnformattedWarning",
          "UnitTestCase",
          "VALUES",
          "VERSION",
          "W",
          "WRITER",
          "WarnLogFilter",
          "WarningReport",
          "WarningsChecker",
          "WarningsRecorder",
          "WithException",
          "XFailed",
          "XML",
          "YamlFile",
          "YamlItem",
          "a",
          "a1",
          "about",
          "abs",
          "abspath",
          "action",
          "activate",
          "active",
          "actual",
          "add",
          "addError",
          "addExpectedFailure",
          "addFailure",
          "addSkip",
          "addSuccess",
          "addUnexpectedSuccess",
          "addexcinfo",
          "addfinalizer",
          "addhooks",
          "addini",
          "addinivalue",
          "addoption",
          "addopts",
          "address",
          "addsection",
          "after",
          "all",
          "allow",
          "allowance",
          "allowed",
          "already",
          "ancestor",
          "anchor",
          "and",
          "ann",
          "annotated",
          "announce",
          "anonymous",
          "anothermethod",
          "ansi",
          "api",
          "apiname",
          "app",
          "append",
          "applymarker",
          "approx",
          "arg",
          "arg2fixturedefs",
          "arg2index",
          "arg2scopenum",
          "argcomplete",
          "argkey",
          "argkeys",
          "argname",
          "argnames",
          "argparsing",
          "argpath",
          "args",
          "argument",
          "argv",
          "argvalues",
          "array",
          "as",
          "ascii",
          "assert",
          "assertion",
          "assertmsg",
          "assertoutcome",
          "assertrepr",
          "asserts",
          "assertstate",
          "assign",
          "ast",
          "astcache",
          "astnode",
          "async",
          "at",
          "atscope",
          "attr",
          "attribute",
          "attrs",
          "author",
          "auto",
          "autodoc",
          "autouse",
          "autousenames",
          "aware",
          "b",
          "background",
          "bailout",
          "base",
          "baseid",
          "basename",
          "basenames",
          "basetemp",
          "basic",
          "before",
          "bench",
          "best",
          "bestrelpath",
          "bestrelpathcache",
          "bin",
          "binop",
          "body",
          "bool",
          "boolop",
          "branch",
          "buffer",
          "build",
          "builtin",
          "by",
          "bytes",
          "c",
          "cache",
          "cache1",
          "cache2",
          "cache3",
          "cached",
          "cachedir",
          "cacheprovider",
          "cacheshow",
          "call",
          "callable",
          "callbinrepr",
          "called",
          "callfinalizers",
          "callobj",
          "calls",
          "callspec",
          "candidates",
          "capfd",
          "capfdbinary",
          "caplog",
          "capman",
          "capstderr",
          "capstdout",
          "capsys",
          "capsysbinary",
          "capture",
          "captureVars",
          "captureclass",
          "captured",
          "capturing",
          "catch",
          "catching",
          "category",
          "chain",
          "changelog",
          "char",
          "chars",
          "chdir",
          "check",
          "checkargnotcontained",
          "checked",
          "checker",
          "checkversion",
          "chmod",
          "choice",
          "ci",
          "class",
          "classnamefilter",
          "cleanup",
          "clear",
          "cli",
          "close",
          "closest",
          "closure",
          "cls",
          "cmd",
          "cmdargs",
          "cmdline",
          "cmdlineargs",
          "cnt",
          "co",
          "code",
          "codecov",
          "col",
          "colitem",
          "colitems",
          "collapsed",
          "collect",
          "collected",
          "collectfile",
          "collection",
          "collectionfinish",
          "collections",
          "collector",
          "collectors",
          "collectreport",
          "collectstart",
          "color",
          "colorama",
          "combined",
          "command",
          "comment",
          "common",
          "comp",
          "compact",
          "compare",
          "comparisons",
          "compat",
          "compile",
          "compilecounter",
          "complex",
          "compute",
          "conf",
          "confcutdir",
          "config",
          "configargs",
          "configure",
          "configured",
          "confmod",
          "conftest",
          "conftestmodule",
          "conftestpath",
          "conftestpath2mod",
          "conftests",
          "consecutive",
          "consider",
          "cont",
          "contains",
          "content",
          "contents",
          "context",
          "continue",
          "continued",
          "convert",
          "copy",
          "copyright",
          "count",
          "counter",
          "countoutcomes",
          "crash",
          "create",
          "created",
          "ctrlc",
          "cur",
          "curdir",
          "current",
          "currentfspath",
          "currentscope",
          "custom",
          "cut",
          "cwd",
          "d",
          "darwin",
          "data",
          "dataclass",
          "date",
          "deactivate",
          "dead",
          "debug",
          "debugging",
          "decorate",
          "decoratescope",
          "def",
          "default",
          "definition",
          "defs",
          "deindent",
          "delattr",
          "delenv",
          "deletable",
          "delete",
          "delitem",
          "demo",
          "dependency",
          "deprecated",
          "depth",
          "derive",
          "descr",
          "description",
          "deselect",
          "deselected",
          "deserialize",
          "dest",
          "determine",
          "dic",
          "dict",
          "diff",
          "dir",
          "direct",
          "directly",
          "directories",
          "directory",
          "dirpath",
          "dirpath2confmods",
          "dirs",
          "disable",
          "disabled",
          "dispatch",
          "display",
          "displayed",
          "do",
          "doc",
          "docstring",
          "doctest",
          "documents",
          "doesnt",
          "doit",
          "domain",
          "done",
          "dont",
          "double",
          "dtest",
          "dump",
          "dumps",
          "dupes",
          "duplicatepaths",
          "duration",
          "dynamic",
          "each",
          "early",
          "ellipsize",
          "emit",
          "emitted",
          "empty",
          "en",
          "enable",
          "enabled",
          "encoding",
          "ensure",
          "enter",
          "entered",
          "entries",
          "entry",
          "entrysep",
          "env",
          "epub",
          "eq",
          "equal",
          "err",
          "errisinstance",
          "errlines",
          "error",
          "errors",
          "errorstring",
          "escape",
          "escaped",
          "essential",
          "eval",
          "evalcache",
          "evaluate",
          "evalxfail",
          "ex",
          "exact",
          "example",
          "exc",
          "exception",
          "exceptions",
          "excinfo",
          "exclude",
          "excludepath",
          "exconly",
          "excrepr",
          "excstore",
          "exec",
          "execute",
          "exists",
          "exit",
          "exitstatus",
          "expect",
          "expected",
          "expecting",
          "expl",
          "explanation",
          "explanations",
          "explicit",
          "expls",
          "expr",
          "expression",
          "exprinfo",
          "exprs",
          "ext",
          "extensions",
          "extra",
          "extract",
          "extraline",
          "f",
          "f1",
          "f2",
          "f3",
          "factory",
          "factorytraceback",
          "fail",
          "failed",
          "fails",
          "failure",
          "failures",
          "families",
          "family",
          "fault",
          "faulthandler",
          "favicon",
          "fd",
          "file",
          "filename",
          "fileno",
          "files",
          "filescompleter",
          "fill",
          "fillfixtures",
          "filling",
          "filter",
          "fin",
          "final",
          "finalization",
          "finalize",
          "finalizer",
          "finalizers",
          "finally",
          "find",
          "findpaths",
          "findsource",
          "finish",
          "first",
          "firstlineno",
          "fix",
          "fixname",
          "fixture",
          "fixturedef",
          "fixturedefs",
          "fixturefunc",
          "fixtureinfo",
          "fixturemanager",
          "fixturename",
          "fixturenames",
          "fixtures",
          "fixturestack",
          "flag",
          "flags",
          "flask",
          "flow",
          "fmt",
          "fn",
          "fname",
          "fnline",
          "fnmatch",
          "fnpats",
          "fns",
          "folded",
          "foo",
          "for",
          "force",
          "format",
          "formatrepr",
          "formatter",
          "formatting",
          "fp",
          "frame",
          "freeze",
          "from",
          "fromdictargs",
          "fslocation",
          "fspath",
          "fullsource",
          "fun",
          "func",
          "func1",
          "funcarg",
          "funcargnames",
          "funcargs",
          "funcname",
          "funcnamefilter",
          "funcobj",
          "function",
          "g",
          "generate",
          "generated",
          "generative",
          "generator",
          "generic",
          "genframe",
          "genfunctions",
          "genitems",
          "get",
          "getargs",
          "getattr",
          "getautousenames",
          "getbasetemp",
          "getcall",
          "getcalls",
          "getcfg",
          "getconftest",
          "getconftestmodules",
          "getcrashentry",
          "getcrashline",
          "getentrysource",
          "getexplanation",
          "getfailedcollections",
          "getfailureheadline",
          "getfailures",
          "getfirstlinesource",
          "getfixtureclosure",
          "getfixturedefs",
          "getfixtureinfo",
          "getfixturemarker",
          "getfixturevalue",
          "getfslineno",
          "getfuncargnames",
          "getglobals",
          "getgroup",
          "gethookproxy",
          "gethookrecorder",
          "getimfunc",
          "getindent",
          "getini",
          "getinicfg",
          "getitem",
          "getitems",
          "getlines",
          "getlocation",
          "getmodpath",
          "getmodulecol",
          "getnextfixturedef",
          "getnode",
          "getobj",
          "getoption",
          "getparam",
          "getparent",
          "getparser",
          "getpathnode",
          "getplugin",
          "getpluginversioninfo",
          "getpytestargs",
          "getrawcode",
          "getreportopt",
          "getreports",
          "getrepr",
          "getreprcrash",
          "getscopeitem",
          "getslaveinfoline",
          "getsource",
          "getstatement",
          "getstatementrange",
          "getvalue",
          "getvalueorskip",
          "getvaluepath",
          "github",
          "given",
          "glob",
          "global",
          "globally",
          "globals",
          "globf",
          "globs",
          "got",
          "groups",
          "handle",
          "handler",
          "has",
          "hash",
          "hasinit",
          "hasmarkup",
          "hasnew",
          "hasopt",
          "hasplugin",
          "head",
          "header",
          "hello",
          "hello2",
          "hello3",
          "hello4",
          "hello5",
          "hello6",
          "hello7",
          "help",
          "helpconfig",
          "helper",
          "highlight",
          "history",
          "holder",
          "holderobjseen",
          "hook",
          "hookimpl",
          "hooks",
          "hookspec",
          "html",
          "htmlhelp",
          "i",
          "id",
          "idfn",
          "idlist",
          "idmaker",
          "ids",
          "idval",
          "idvalset",
          "idx",
          "if",
          "ignore",
          "ihook",
          "illegal",
          "immutable",
          "impl",
          "implements",
          "impls",
          "import",
          "importconftest",
          "imported",
          "importhook",
          "importorskip",
          "importpath",
          "imports",
          "importtestmodule",
          "in",
          "inamepart",
          "include",
          "includemodule",
          "includes",
          "incompatibility",
          "increasing",
          "indent",
          "indents",
          "index",
          "indices",
          "indirect",
          "info",
          "information",
          "inherit",
          "ini",
          "inicache",
          "inicfg",
          "inidict",
          "inifile",
          "ininames",
          "init",
          "initial",
          "initialnames",
          "initialpaths",
          "initini",
          "initrequest",
          "inject",
          "inline",
          "inprocess",
          "input",
          "install",
          "instance",
          "interact",
          "interactive",
          "internalerror",
          "interrupt",
          "intersphinx",
          "invalidraise",
          "invocation",
          "invoking",
          "io",
          "is",
          "isattrs",
          "isatty",
          "ischildnode",
          "isclass",
          "iscoroutinefunction",
          "isdatacls",
          "isdict",
          "ishidden",
          "isinitpath",
          "isiterable",
          "isnosetest",
          "isopen",
          "isparseable",
          "issequence",
          "isset",
          "issue",
          "issues",
          "istestclass",
          "istestfunc",
          "istestfunction",
          "istext",
          "istrue",
          "it",
          "it2",
          "item",
          "itemcollected",
          "items",
          "iter",
          "iterable",
          "jheader",
          "json",
          "junitxml",
          "k",
          "keep",
          "key",
          "keyboard",
          "keyboardinterrupt",
          "keys",
          "keyword",
          "keywordexpr",
          "keywords",
          "kind",
          "known",
          "kw",
          "kwargs",
          "kwds",
          "last",
          "lastfailed",
          "later",
          "latex",
          "least",
          "leave",
          "left",
          "legacy",
          "legal",
          "len",
          "length",
          "lettercode",
          "level",
          "levels",
          "lfplugin",
          "lib",
          "line",
          "linecomp",
          "lineno",
          "lines",
          "lines2",
          "link",
          "linkcheck",
          "links",
          "list",
          "listchain",
          "listextrakeywords",
          "listnames",
          "listoutcomes",
          "literal",
          "live",
          "load",
          "locals",
          "location",
          "locationline",
          "lock",
          "log",
          "logfile",
          "logfinish",
          "logger",
          "logging",
          "login",
          "logo",
          "logreport",
          "logs",
          "logstart",
          "long",
          "longer",
          "longrepr",
          "longreprtext",
          "lookup",
          "lsof",
          "m1",
          "main",
          "make",
          "makeconftest",
          "makedir",
          "makedirs",
          "makefile",
          "makeini",
          "makeitem",
          "makemodule",
          "makepath",
          "makepyfile",
          "makereport",
          "maketxtfile",
          "man",
          "manager",
          "mangle",
          "manyparam",
          "map",
          "mapping",
          "mark",
          "markall",
          "marked",
          "marker",
          "markers",
          "markexpr",
          "markname",
          "marks",
          "markup",
          "master",
          "match",
          "matches",
          "matchfactories",
          "matching",
          "matchkeyword",
          "matchmark",
          "matchnodes",
          "matchobj",
          "matchreport",
          "max",
          "maxsize",
          "maybe",
          "md",
          "member",
          "memo",
          "merge",
          "message",
          "messages",
          "metafunc",
          "method",
          "minversion",
          "missing",
          "mk",
          "mkdir",
          "mkpydir",
          "mkrel",
          "mktemp",
          "mock",
          "mocked",
          "mod",
          "modcol",
          "mode",
          "modifyitems",
          "modname",
          "mods",
          "module",
          "modules",
          "monkeypatch",
          "mortem",
          "msg",
          "multi",
          "multicapture",
          "multiline",
          "multiple",
          "multipython",
          "must",
          "mydir",
          "mywriter",
          "name",
          "name2fixturedefs",
          "name2plugin",
          "name2pseudofixturedef",
          "names",
          "namespace",
          "nameversions",
          "nan",
          "ne",
          "needed",
          "nested",
          "new",
          "newinstance",
          "newline",
          "newscope",
          "next",
          "nextitem",
          "nicely",
          "nickname",
          "no",
          "noconftest",
          "node",
          "nodeid",
          "nodeids",
          "nodes",
          "nofuncargs",
          "non",
          "nonpython",
          "noop",
          "nop",
          "norecursepatterns",
          "normalize",
          "nose",
          "nosetest",
          "not",
          "notfound",
          "notify",
          "notin",
          "notset",
          "noun",
          "nullcontext",
          "num",
          "number",
          "numbered",
          "numcollected",
          "numeric",
          "numpy",
          "obj",
          "object",
          "objects",
          "of",
          "offset",
          "ok",
          "old",
          "on",
          "one",
          "only",
          "op",
          "open",
          "opentestcase",
          "ops",
          "opt",
          "opt2dest",
          "option",
          "optional",
          "optionflags",
          "options",
          "optname",
          "optnames",
          "optparser",
          "opts",
          "or",
          "order",
          "ordered",
          "orig",
          "original",
          "originalname",
          "other",
          "otherfunc",
          "otherlist",
          "out",
          "outcome",
          "outcomes",
          "outerr",
          "outlines",
          "output",
          "outrep",
          "overload",
          "override",
          "own",
          "owner",
          "p",
          "package",
          "pages",
          "param",
          "param1",
          "param2",
          "parameters",
          "parameterset",
          "parametersets",
          "parametrize",
          "parametrized",
          "params",
          "parens",
          "parent",
          "parentnode",
          "parse",
          "parsearg",
          "parseconfig",
          "parseconfigure",
          "parsefactories",
          "parseoutcomes",
          "parser",
          "part",
          "parts",
          "pass",
          "passed",
          "passes",
          "passing",
          "paste",
          "pastebin",
          "pastebinfile",
          "pat",
          "patch",
          "patchsysdict",
          "path",
          "pathlib",
          "pathlist",
          "pathname",
          "paths",
          "pattern",
          "patterns",
          "payload",
          "pdb",
          "per",
          "perform",
          "pformat",
          "picklefile",
          "pid",
          "pkg",
          "platform",
          "pluggy",
          "plugin",
          "pluginarg",
          "plugininfo",
          "pluginmanager",
          "plugins",
          "plural",
          "pm",
          "points",
          "pop",
          "popcall",
          "popen",
          "pos",
          "post",
          "postmortem",
          "potential",
          "pre",
          "precision",
          "prefix",
          "prefixed",
          "prefixes",
          "prepare",
          "prepareconfig",
          "preparse",
          "prepend",
          "preserve",
          "preserving",
          "previously",
          "print",
          "printable",
          "printcollecteditems",
          "priority",
          "processopt",
          "processoption",
          "prog",
          "progress",
          "project",
          "properly",
          "properties",
          "property",
          "protocol",
          "provide",
          "prune",
          "prunetraceback",
          "pseudo",
          "public",
          "publish",
          "publish-gh-release-notes",
          "publisher",
          "push",
          "putaround",
          "py",
          "py36",
          "pyargs",
          "pyc",
          "pycollect",
          "pyfunc",
          "pyfuncitem",
          "pygments",
          "pyobj",
          "pytest",
          "pytestPDB",
          "pytestconfig",
          "pytester",
          "python",
          "python1",
          "python2",
          "pythoncollection",
          "pythonlist",
          "pythonpath",
          "pytrace",
          "q",
          "quit",
          "raise",
          "raiseerror",
          "raises",
          "raising",
          "ran",
          "random",
          "ranges",
          "raw",
          "rawcode",
          "rawentry",
          "rawexcinfo",
          "re",
          "read",
          "readline",
          "readlines",
          "readouterr",
          "real",
          "reason",
          "record",
          "recorder",
          "recording",
          "records",
          "recurse",
          "recursionindex",
          "recursive",
          "recwarn",
          "regen",
          "regex",
          "regexp",
          "register",
          "registered",
          "reinterpret",
          "rel",
          "relative",
          "release",
          "release-on-comment",
          "relline",
          "relpath",
          "removal",
          "remove",
          "removed",
          "reopen",
          "reorder",
          "rep",
          "repl",
          "report",
          "reportchars",
          "reportdict",
          "reported",
          "reporter",
          "reporters",
          "reportinfo",
          "reports",
          "repr",
          "reprcompare",
          "reprcrash",
          "reprec",
          "reprentries",
          "reprfileloc",
          "reprfuncargs",
          "reprlocals",
          "reprlocation",
          "reprtraceback",
          "request",
          "requested",
          "required",
          "reraise",
          "res",
          "reset",
          "resolve",
          "restore",
          "result",
          "resultlog",
          "results",
          "resume",
          "ret",
          "returncode",
          "rewritable",
          "rewrite",
          "rewritten",
          "rex",
          "rf",
          "rget",
          "right",
          "rm",
          "role",
          "root",
          "rootdir",
          "roots",
          "rst",
          "run",
          "runitem",
          "runner",
          "running",
          "runpytest",
          "runpython",
          "runsource",
          "runtest",
          "runtestloop",
          "runtestprotocol",
          "rw",
          "s",
          "s1",
          "safe",
          "safeformat",
          "saferepr",
          "save",
          "saved",
          "savesyspath",
          "scalar",
          "schedule",
          "scope",
          "scope2index",
          "scope2props",
          "scopemismatch",
          "scopename2class",
          "scopenum",
          "scopeproperty",
          "scopes",
          "screen",
          "script",
          "scripts",
          "seconds",
          "section",
          "sections",
          "seen",
          "self",
          "sep",
          "sequence",
          "sequences",
          "serializable",
          "serialize",
          "session",
          "sessionfinish",
          "sessionstart",
          "sessionstarttime",
          "set",
          "setattr",
          "setdefault",
          "setenv",
          "setitem",
          "setmulti2",
          "setoption",
          "setting",
          "setup",
          "setup-py",
          "setuponly",
          "setupplan",
          "setupstate",
          "short",
          "shortupper",
          "should",
          "shouldfail",
          "shouldstop",
          "show",
          "showfixtures",
          "showfspath",
          "showheader",
          "showhelp",
          "showlocals",
          "showlongtestinfo",
          "shown",
          "shows",
          "showversion",
          "sidebars",
          "similar",
          "simple",
          "single",
          "skip",
          "skipped",
          "skipping",
          "skips",
          "slots",
          "slug",
          "snap",
          "snapshot",
          "some",
          "somefunc",
          "sort",
          "source",
          "sourcelink",
          "space",
          "spawn",
          "spec",
          "specifiers",
          "specs",
          "split",
          "splitnode",
          "src",
          "stack",
          "stacklevel",
          "starred",
          "start",
          "startTest",
          "startdir",
          "startend2",
          "startswith",
          "stat",
          "state",
          "statement",
          "statements",
          "stats",
          "status",
          "stderr",
          "stdin",
          "stdio",
          "stdout",
          "stepwise",
          "stmts",
          "stop",
          "stopTest",
          "stopatmodule",
          "store",
          "str",
          "stream",
          "strict",
          "string",
          "stringio",
          "strings",
          "strip",
          "striptext",
          "strtobool",
          "structures",
          "style",
          "styles",
          "subname",
          "subprocess",
          "subrequest",
          "suffix",
          "suffixes",
          "suite",
          "summary",
          "support",
          "supported",
          "supporting",
          "surrounding",
          "suspend",
          "suspended",
          "symlink",
          "sys",
          "syscapture",
          "sysmodule",
          "syspath",
          "syspathinsert",
          "t",
          "table",
          "tag",
          "tags",
          "take",
          "target",
          "targetfd",
          "tb",
          "tbfilter",
          "tblines",
          "tearDown",
          "teardown",
          "tee",
          "template",
          "templates",
          "term",
          "terminal",
          "terminalreporter",
          "terminalwriter",
          "termwidth",
          "test",
          "testcase",
          "testdir",
          "testmodule",
          "testpath",
          "testreport",
          "tests",
          "testscollected",
          "testsfailed",
          "teststatus",
          "testsuite",
          "texinfo",
          "text",
          "the",
          "theme",
          "themes",
          "time",
          "timeout",
          "title",
          "tmp",
          "tmpdir",
          "tmpfile",
          "tmppath",
          "tmproot",
          "to",
          "todo",
          "todos",
          "token",
          "tolerance",
          "top",
          "toterminal",
          "towards",
          "trace",
          "traceback",
          "tracebackcutdir",
          "tracing",
          "translate",
          "tree",
          "trial",
          "trigger",
          "true",
          "truncate",
          "try",
          "trycall",
          "tryconvertpyarg",
          "tryshort",
          "tuple",
          "tupleerror",
          "tuples",
          "tw",
          "txt",
          "typ",
          "type",
          "typename",
          "types",
          "ufunc",
          "unary",
          "unconfigure",
          "undo",
          "unexpected",
          "unexpectedsuccess",
          "unfilled",
          "unicode",
          "unittest",
          "unknown",
          "unpack",
          "unpacked",
          "unserialization",
          "unset",
          "unwanted",
          "unwrap",
          "update",
          "url",
          "usage",
          "use",
          "usepdb",
          "user",
          "using",
          "util",
          "v",
          "val",
          "validate",
          "valset",
          "valtypes",
          "value",
          "values",
          "var",
          "variable",
          "variables",
          "vars",
          "venv",
          "verbose",
          "verbosity",
          "version",
          "via",
          "visit",
          "want",
          "warn",
          "warning",
          "warnings",
          "warns",
          "wasvalid",
          "when",
          "where",
          "width",
          "windowsconsoleio",
          "with",
          "withinit",
          "wmod",
          "word",
          "workaround",
          "workers",
          "world",
          "wrap",
          "wrapped",
          "wrapper",
          "wrapping",
          "write",
          "writeorg",
          "writer",
          "writing",
          "written",
          "x",
          "xfail",
          "xfailed",
          "xml",
          "xpassed",
          "xunit",
          "xunit2",
          "y",
          "yield",
          "z1",
          "z2",
          ""
        ]
      },
      "response": {
        "keywords": [
          "chained",
          "exception",
          "ValueError",
          "longrepr",
          "traceback",
          "pytest",
          "xdist",
          "tests",
          "test_chained_exception_with_from",
          "test_chained_exception_without_from"
        ]
      }
    },
    {
      "name": "FilesKeywordSearch",
      "metadata": {
        "start": "2024-08-15T18:44:48.766645",
        "usage": "73.4410285949707 ms"
      },
      "request": {
        "tokens": [
          "chained",
          "exception",
          "ValueError",
          "longrepr",
          "traceback",
          "pytest",
          "xdist",
          "tests",
          "test_chained_exception_with_from",
          "test_chained_exception_without_from"
        ]
      },
      "response": {
        "results": {
          "xdist": [
            "src/_pytest/logging.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/reports.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/pytester.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/resultlog.py"
          ],
          "longrepr": [
            "src/_pytest/terminal.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/reports.py",
            "src/_pytest/skipping.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/runner.py",
            "src/_pytest/resultlog.py"
          ],
          "exception": [
            "src/_pytest/runner.py",
            "src/_pytest/nose.py",
            "src/_pytest/compat.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/reports.py",
            "src/_pytest/skipping.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/recwarn.py",
            "src/_pytest/python_api.py",
            "src/_pytest/_io/saferepr.py",
            "src/_pytest/unittest.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/monkeypatch.py",
            "src/_pytest/logging.py",
            "src/_pytest/pytester.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/debugging.py",
            "src/_pytest/main.py"
          ],
          "pytest": [
            "src/_pytest/warning_types.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/deprecated.py",
            "src/_pytest/runner.py",
            "src/_pytest/compat.py",
            "src/pytest.py",
            "src/_pytest/terminal.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/doctest.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/reports.py",
            "src/_pytest/skipping.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/recwarn.py",
            "src/_pytest/mark/legacy.py",
            "src/_pytest/unittest.py",
            "src/_pytest/python_api.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/monkeypatch.py",
            "src/_pytest/logging.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/config/argparsing.py",
            "src/_pytest/freeze_support.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/pytester.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/stepwise.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/assertion/util.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/debugging.py",
            "src/_pytest/config/exceptions.py",
            "src/_pytest/warnings.py",
            "src/_pytest/main.py",
            "src/_pytest/config/findpaths.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/capture.py",
            "src/_pytest/setupplan.py"
          ],
          "tests": [
            "src/_pytest/cacheprovider.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/runner.py",
            "src/_pytest/terminal.py",
            "src/_pytest/doctest.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/skipping.py",
            "src/_pytest/python_api.py",
            "src/_pytest/unittest.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/logging.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/pytester.py",
            "src/_pytest/stepwise.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/main.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/setupplan.py"
          ],
          "ValueError": [
            "src/_pytest/logging.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/debugging.py",
            "src/_pytest/main.py",
            "src/_pytest/warnings.py",
            "src/_pytest/config/argparsing.py",
            "src/_pytest/nodes.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/pytester.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/python.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/python_api.py",
            "src/_pytest/capture.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/compat.py"
          ],
          "traceback": [
            "src/_pytest/terminal.py",
            "src/_pytest/mark/evaluate.py",
            "src/_pytest/logging.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/doctest.py",
            "src/_pytest/reports.py",
            "src/_pytest/debugging.py",
            "src/_pytest/pytester.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python_api.py",
            "src/_pytest/python.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/unittest.py",
            "src/_pytest/fixtures.py"
          ],
          "chained": [
            "src/_pytest/_code/code.py"
          ]
        }
      }
    },
    {
      "name": "FilesFilter",
      "metadata": {
        "start": "2024-08-15T18:44:48.840098",
        "usage": "5945.069789886475 ms"
      },
      "request": {
        "keyword_search_results": {
          "xdist": [
            "src/_pytest/logging.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/reports.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/pytester.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/resultlog.py"
          ],
          "longrepr": [
            "src/_pytest/terminal.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/reports.py",
            "src/_pytest/skipping.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/runner.py",
            "src/_pytest/resultlog.py"
          ],
          "exception": [
            "src/_pytest/runner.py",
            "src/_pytest/nose.py",
            "src/_pytest/compat.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/reports.py",
            "src/_pytest/skipping.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/recwarn.py",
            "src/_pytest/python_api.py",
            "src/_pytest/_io/saferepr.py",
            "src/_pytest/unittest.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/monkeypatch.py",
            "src/_pytest/logging.py",
            "src/_pytest/pytester.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/debugging.py",
            "src/_pytest/main.py"
          ],
          "pytest": [
            "src/_pytest/warning_types.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/deprecated.py",
            "src/_pytest/runner.py",
            "src/_pytest/compat.py",
            "src/pytest.py",
            "src/_pytest/terminal.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/doctest.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/reports.py",
            "src/_pytest/skipping.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/recwarn.py",
            "src/_pytest/mark/legacy.py",
            "src/_pytest/unittest.py",
            "src/_pytest/python_api.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/monkeypatch.py",
            "src/_pytest/logging.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/config/argparsing.py",
            "src/_pytest/freeze_support.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/pytester.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/stepwise.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/assertion/util.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/debugging.py",
            "src/_pytest/config/exceptions.py",
            "src/_pytest/warnings.py",
            "src/_pytest/main.py",
            "src/_pytest/config/findpaths.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/capture.py",
            "src/_pytest/setupplan.py"
          ],
          "tests": [
            "src/_pytest/cacheprovider.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/runner.py",
            "src/_pytest/terminal.py",
            "src/_pytest/doctest.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/skipping.py",
            "src/_pytest/python_api.py",
            "src/_pytest/unittest.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/logging.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/pytester.py",
            "src/_pytest/stepwise.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/main.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/setupplan.py"
          ],
          "ValueError": [
            "src/_pytest/logging.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/debugging.py",
            "src/_pytest/main.py",
            "src/_pytest/warnings.py",
            "src/_pytest/config/argparsing.py",
            "src/_pytest/nodes.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/pytester.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/python.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/python_api.py",
            "src/_pytest/capture.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/compat.py"
          ],
          "traceback": [
            "src/_pytest/terminal.py",
            "src/_pytest/mark/evaluate.py",
            "src/_pytest/logging.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/doctest.py",
            "src/_pytest/reports.py",
            "src/_pytest/debugging.py",
            "src/_pytest/pytester.py",
            "src/_pytest/nodes.py",
            "src/_pytest/python_api.py",
            "src/_pytest/python.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/unittest.py",
            "src/_pytest/fixtures.py"
          ],
          "chained": [
            "src/_pytest/_code/code.py"
          ]
        }
      },
      "response": {
        "scratch_pad": "The reported issue is about the behavior of exception serialization when using xdist in pytest. In particular, it states that when tests are run with xdist, only the last exception is displayed, losing the chained exceptions that typically show the error history. The keywords related to this issue from the search results are 'xdist', 'exception', 'longrepr', and 'chained'.  \n\nFrom these keywords, we should focus on files that handle exceptions and their representations since the primary concern is how exceptions are being serialized and shown in the test output when using xdist. \n\n1. **src/_pytest/runner.py:** This file is significant because it is likely involved in executing tests and handling exceptions during their execution. It relates to the issue as it might contain code on how exceptions are reported back to the user, which seems to directly relate to the problem at hand.\n\n2. **src/_pytest/reports.py:** Reports are often generated after test execution, including how exceptions are logged or displayed, making this file relevant for how chained exceptions are serialized and presented.\n\n3. **src/_pytest/terminal.py:** This file handles terminal output, including formatted messages about test results and errors. It could involve how exceptions content are printed, notably in xdist mode.\n\n4. **src/_pytest/junitxml.py:** This file may deal with outputting results in JUnit XML format, and exceptions could be serialized in that format, which can be relevant for understanding differences in outputs with xdist.\n\n5. **src/_pytest/logging.py:** This file manages logging within pytest and may have functions that handle exception logging, possibly influencing how these exceptions appear in tests.\n\n6. **src/_pytest/_code/code.py:** It has been tagged with 'chained', indicating it might contain utility functions to deal with chained exceptions, which could be central to the problem of missing exception traces.\n\nBased on this analysis, I will list these files in order from most relevant to least relevant.",
        "file_paths": [
          "src/_pytest/runner.py",
          "src/_pytest/reports.py",
          "src/_pytest/terminal.py",
          "src/_pytest/junitxml.py",
          "src/_pytest/logging.py",
          "src/_pytest/_code/code.py"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-15T18:44:54.785186",
        "usage": "4610.128879547119 ms"
      },
      "request": {
        "file_path": "src/_pytest/runner.py"
      },
      "response": {
        "scratch_pad": "The issue describes a problem with exception serialization in pytest when running tests with xdist. It notes that while pytest normally provides detailed exception traces, running under xdist results in insufficient information being displayed, particularly in relation to chained exceptions. The primary context here revolves around how pytest handles exceptions, manages their serialization, and the reporting of failures.\n\nIn reviewing the provided code in src/_pytest/runner.py:\n- There are several functions defined that are responsible for managing the test execution process, including handling exceptions, reporting test statuses, and providing functionality regarding chained exceptions.\n- Notably, the classes and functions such as 'CallInfo', 'pytest_runtest_makereport', and 'check_interactive_exception' are closely related to how exceptions are captured and reported in pytest.\n- The 'CallInfo' class manages the result and exception information for function invocations, encapsulating logic to handle and potentially serialize exceptions.\n- The function 'pytest_runtest_call(item)' stores trace info for exceptions and raises them after potentially capturing relevant information about the execution, which is critical for understanding how exceptions are reported.\n- While the code doesn't directly show a handling issue, its structure indicates a role in how exception handling and reporting might be constructed, particularly in differing contexts like normal execution versus execution with xdist.\n\nThe way exceptions are processed here points towards potential causes or areas where the reporting might fail, significantly when running tests under different conditions (like with xdist). However, without the exact logic that decides how to serialize and format the recorded exception information into the output being displayed, it is difficult to pinpoint a root cause directly in this file without more context on how pytest integrates with xdist. That said, the relevant classes/functions can certainly be further examined in conjunction with other pytest-related files to clarify their roles. \n\nIn conclusion, this file is relevant to the exception serialization issue described in the report, as it involves handling test execution and exception information, thereby affecting how exceptions are logged and displayed.",
        "relevant": true,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/report.py",
          "src/_pytest/terminal.py",
          "src/_pytest/config.py"
        ],
        "relevant_symbols": [
          "pytest_runtest_call()",
          "check_interactive_exception()",
          "CallInfo#",
          "pytest_runtest_makereport()",
          "pytest_report_teststatus()"
        ],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-15T18:44:59.395325",
        "usage": "4091.0251140594482 ms"
      },
      "request": {
        "file_path": "src/_pytest/reports.py"
      },
      "response": {
        "scratch_pad": "The issue reported relates to exception serialization in Pytest, particularly regarding how chained exceptions are handled. The relevant code here is likely related to how exceptions are recorded and presented in the test report. The most relevant methods and classes involve 'longrepr', 'TestReport', and the 'BaseReport' class, which handles printing and creating reports of test outcomes.\n\nThe primary functions that seem to be related to exception handling and could be evaluated for further investigation are within the 'TestReport' and 'BaseReport' classes. The need for \"-- traceback representation during failures\" hints at the use of the long representation of exceptions in these classes.\n\nI need to evaluate whether these classes properly include and manage chained exceptions during serialization and if there is a part of the code that specifically addresses the issue when running tests with 'xdist'.",
        "relevant": true,
        "root_cause": true,
        "relevant_files": [],
        "relevant_symbols": [
          "BaseReport#longreprtext()",
          "BaseReport#longrepr",
          "TestReport#longrepr",
          "BaseReport#toterminal()",
          "TestReport#from_item_and_call()",
          "TestReport#_to_json()",
          "CollectReport#longrepr"
        ],
        "root_cause_symbols": [
          "BaseReport#longreprtext()",
          "TestReport#from_item_and_call()",
          "BaseReport#toterminal()"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-15T18:45:03.486362",
        "usage": "5324.605941772461 ms"
      },
      "request": {
        "file_path": "src/_pytest/terminal.py"
      },
      "response": {
        "scratch_pad": "The given file `src/_pytest/terminal.py` seems to be responsible for terminal reporting and output formatting for pytest. The issue described relates to the display of chained exceptions when tests are run with xdist, where it appears that only the last exception is shown instead of the complete chain.\\n\\nReviewing the code, it does not contain any specific handling for the serialization of chained exceptions directly. Instead, it focuses on formatting outputs related to test results and might rely on how exceptions are reported internally in pytest.\\n\\nThe relevant parts of the testing process that could affect how exceptions are displayed seem to be in the methods `pytest_runtest_logreport` and `pytest_terminal_summary`. However, there is no explicit mention in this file of handling chained exceptions well, especially when running tests with xdist.\\n\\nSince the issue specifically highlights a discrepancy occurring only with the `xdist` plugin, the root cause of the exception display issue will likely be elsewhere, though this file certainly participates in the reporting process. \n\nIn summary, while this file is part of the reporting mechanism, it does not appear to directly cause the issue but rather it's relevant to how failures are displayed. The root cause does not reside in this implementation directly. \n\nRelevant functions to look into or follow might include the ones involved with reporting outcomes (e.g., `pytest_report_teststatus()` and logging details) but they do not address the serialization of exceptions specifically.",
        "relevant": true,
        "root_cause": false,
        "relevant_files": [],
        "relevant_symbols": [
          "pytest_runtest_logreport()",
          "pytest_terminal_summary()",
          "TerminalReporter#"
        ],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-15T18:45:08.810980",
        "usage": "3483.344793319702 ms"
      },
      "request": {
        "file_path": "src/_pytest/junitxml.py"
      },
      "response": {
        "scratch_pad": "The reported issue is about chained exceptions not being serialized properly when using xdist with pytest. The provided issue description includes specific behavior of exceptions during the tests that should be detailed in the XML output. The file content includes various components of a JUnit XML reporting structure, which may be responsible for formatting or serializing reports from pytest. The functions related to writing outputs and handling exceptions are potential points of interest.\n\nKey points to consider:\n1. The file contains methods that handle the reporting of failures, which include appending failure messages and capturing outputs during test executions.\n2. The methods `append_failure`, `append_error`, and `write_captured_output` are responsible for adding failure information and logs to the report, which is fundamental for the issue cited.\n3. The absence of chaining information in the XML output could be linked to how exceptions are being captured and reported in the `pytest_runtest_logreport` and related methods.\n\nBased on the systematic analysis of the methods present in this file, it seems that the Junit XML handling here is relevant to the reported issue, specifically the methods that handle exceptions and their serialization for reports.",
        "relevant": true,
        "root_cause": false,
        "relevant_files": [],
        "relevant_symbols": [
          "LogXML#append_failure()",
          "LogXML#write_captured_output()",
          "LogXML#pytest_runtest_logreport()",
          "_NodeReporter#append()",
          "_NodeReporter#append_failure()",
          "_NodeReporter#write_captured_output()"
        ],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileSymbolSearch",
      "metadata": {
        "start": "2024-08-15T18:45:12.294352",
        "usage": "307.6212406158447 ms"
      },
      "request": {
        "files": [
          {
            "file_path": "src/_pytest/runner.py",
            "relevant_symbol_keys": [
              "pytest_runtest_call()",
              "check_interactive_exception()",
              "CallInfo#",
              "pytest_runtest_makereport()",
              "pytest_report_teststatus()"
            ],
            "root_cause_symbol_keys": []
          },
          {
            "file_path": "src/_pytest/reports.py",
            "relevant_symbol_keys": [
              "BaseReport#longreprtext()",
              "BaseReport#longrepr",
              "TestReport#longrepr",
              "BaseReport#toterminal()",
              "TestReport#from_item_and_call()",
              "TestReport#_to_json()",
              "CollectReport#longrepr"
            ],
            "root_cause_symbol_keys": [
              "BaseReport#longreprtext()",
              "TestReport#from_item_and_call()",
              "BaseReport#toterminal()"
            ]
          },
          {
            "file_path": "src/_pytest/terminal.py",
            "relevant_symbol_keys": [
              "pytest_runtest_logreport()",
              "pytest_terminal_summary()",
              "TerminalReporter#"
            ],
            "root_cause_symbol_keys": []
          },
          {
            "file_path": "src/_pytest/junitxml.py",
            "relevant_symbol_keys": [
              "LogXML#append_failure()",
              "LogXML#write_captured_output()",
              "LogXML#pytest_runtest_logreport()",
              "_NodeReporter#append()",
              "_NodeReporter#append_failure()",
              "_NodeReporter#write_captured_output()"
            ],
            "root_cause_symbol_keys": []
          }
        ],
        "with_content": true
      },
      "response": {
        "related_symbols": [
          {
            "name": "pytest_runtest_call().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "def pytest_runtest_call(item):\n    _update_current_test_var(item, \"call\")\n    sys.last_type, sys.last_value, sys.last_traceback = (None, None, None)\n    try:\n        item.runtest()\n    except Exception:\n        # Store trace info to allow postmortem debugging\n        type, value, tb = sys.exc_info()\n        tb = tb.tb_next  # Skip *this* frame\n        sys.last_type = type\n        sys.last_value = value\n        sys.last_traceback = tb\n        del type, value, tb  # Get rid of these in this frame"
          },
          {
            "name": "pytest_report_teststatus().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "def pytest_report_teststatus(report):\n    if report.when in (\"setup\", \"teardown\"):\n        if report.failed:\n            #      category, shortletter, verbose-word\n            return \"error\", \"E\", \"ERROR\"\n        elif report.skipped:\n            return \"skipped\", \"s\", \"SKIPPED\"\n        else:"
          },
          {
            "name": "check_interactive_exception().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "def check_interactive_exception(call, report):\n    return call.excinfo and not (\n        hasattr(report, \"wasxfail\")\n        or call.excinfo.errisinstance(Skipped)\n        or call.excinfo.errisinstance(bdb.BdbQuit)"
          },
          {
            "name": "CallInfo#",
            "file_path": "src/_pytest/runner.py",
            "file_content": "@attr.s(repr=False)\nclass CallInfo:\n    \"\"\" Result/Exception info a function invocation. \"\"\"\n\n    _result = attr.ib()\n    # Optional[ExceptionInfo]\n    excinfo = attr.ib()\n    start = attr.ib()\n    stop = attr.ib()\n    when = attr.ib()\n\n    @property\n    def result(self):\n        if self.excinfo is not None:\n            raise AttributeError(\"{!r} has no valid result\".format(self))\n        return self._result\n\n    @classmethod\n    def from_call(cls, func, when, reraise=None):\n        #: context of invocation: one of \"setup\", \"call\",\n        #: \"teardown\", \"memocollect\"\n        start = time()\n        excinfo = None\n        try:\n            result = func()\n        except:  # noqa\n            excinfo = ExceptionInfo.from_current()\n            if reraise is not None and excinfo.errisinstance(reraise):\n                raise\n            result = None\n        stop = time()\n        return cls(start=start, stop=stop, when=when, result=result, excinfo=excinfo)\n\n    def __repr__(self):\n        if self.excinfo is not None:\n            status = \"exception\"\n            value = self.excinfo.value\n        else:\n            # TODO: investigate unification\n            value = repr(self._result)\n            status = \"result\"\n        return \"<CallInfo when={when!r} {status}: {value}>\".format(\n            when=self.when, value=value, status=status"
          },
          {
            "name": "CallInfo#result().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "    @property\n    def result(self):\n        if self.excinfo is not None:\n            raise AttributeError(\"{!r} has no valid result\".format(self))"
          },
          {
            "name": "CallInfo#from_call().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "    @classmethod\n    def from_call(cls, func, when, reraise=None):\n        #: context of invocation: one of \"setup\", \"call\",\n        #: \"teardown\", \"memocollect\"\n        start = time()\n        excinfo = None\n        try:\n            result = func()\n        except:  # noqa\n            excinfo = ExceptionInfo.from_current()\n            if reraise is not None and excinfo.errisinstance(reraise):\n                raise\n            result = None\n        stop = time()"
          },
          {
            "name": "CallInfo#__repr__().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "    def __repr__(self):\n        if self.excinfo is not None:\n            status = \"exception\"\n            value = self.excinfo.value\n        else:\n            # TODO: investigate unification\n            value = repr(self._result)\n            status = \"result\"\n        return \"<CallInfo when={when!r} {status}: {value}>\".format(\n            when=self.when, value=value, status=status"
          },
          {
            "name": "pytest_runtest_makereport().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "def pytest_runtest_makereport(item, call):"
          },
          {
            "name": "TerminalReporter#",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "class TerminalReporter:\n    def __init__(self, config, file=None):\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None\n        self._showfspath = None\n\n        self.stats = {}\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        # self.writer will be deprecated in pytest-3.4\n        self.writer = self._tw\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None\n\n    def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False\n\n    @property\n    def verbosity(self):\n        return self.config.option.verbose\n\n    @property\n    def showheader(self):\n        return self.verbosity >= 0\n\n    @property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0\n        return self._showfspath\n\n    @showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value\n\n    @property\n    def showlongtestinfo(self):\n        return self.verbosity > 0\n\n    def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars\n\n    def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, **markup)\n\n    def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2\n\n    def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None\n\n    def write(self, content, **markup):\n        self._tw.write(content, **markup)\n\n    def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)\n\n    def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)\n\n    def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)\n\n    def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)\n\n    def line(self, msg, **kw):\n        self._tw.line(msg, **kw)\n\n    def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1\n\n    def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        warnings = self.stats.setdefault(\"warnings\", [])\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        warnings.append(warning_report)\n\n    def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)\n\n    def pytest_deselected(self, items):\n        self.stats.setdefault(\"deselected\", []).extend(items)\n\n    def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n        elif self.showfspath:\n            fsid = nodeid.split(\"::\")[0]\n            self.write_fspath_result(fsid, \"\")\n\n    def pytest_runtest_logreport(self, report):\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self.stats.setdefault(category, []).append(rep)\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            if not running_xdist and self.showfspath:\n                self.write_fspath_result(rep.nodeid, letter, **markup)\n            else:\n                self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2\n\n    def pytest_runtest_logfinish(self, nodeid):\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n            is_last_item = (\n                len(self._progress_nodeids_reported) == self._session.testscollected\n            )\n            if is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", cyan=True)\n\n    def _get_progress_information_message(self):\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                progress = len(self._progress_nodeids_reported) * 100 // collected\n                return \" [{:3d}%]\".format(progress)\n            return \" [100%]\"\n\n    def _write_progress_information_filling_space(self):\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), cyan=True)\n\n    @property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        try:\n            return self._tw.width_of_current_line\n        except AttributeError:\n            # py < 1.6.0\n            return self._tw.chars_on_current_line\n\n    def pytest_collection(self):\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", bold=True)\n\n    def pytest_collectreport(self, report):\n        if report.failed:\n            self.stats.setdefault(\"error\", []).append(report)\n        elif report.skipped:\n            self.stats.setdefault(\"skipped\", []).append(report)\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()\n\n    def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d errors\" % errors\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)\n\n    @pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session):\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        if hasattr(sys, \"pypy_version_info\"):\n            verinfo = \".\".join(map(str, sys.pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, sys.pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)\n\n    def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)\n\n    def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result\n\n    def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        if self.config.getoption(\"collectonly\"):\n            self._printcollecteditems(session.items)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if self.stats.get(\"failed\"):\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in self.stats.get(\"failed\"):\n                    rep.toterminal(self._tw)\n\n    def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    if hasattr(col, \"_obj\") and col._obj.__doc__:\n                        for line in col._obj.__doc__.strip().splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line.strip()))\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, exitstatus):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        self.summary_stats()\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()\n\n    def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)\n\n    def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()\n\n    def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )\n\n    def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \"\n\n    def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?\n\n    def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"\n\n    #\n    # summaries for sessionfinish\n    #\n    def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values\n\n    def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\"warnings\")\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = collections.OrderedDict()\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, warning_reports in reports_grouped_by_message.items():\n                has_any_location = False\n                for w in warning_reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        self._tw.line(str(location))\n                        has_any_location = True\n                if has_any_location:\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")\n\n    def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n\n    def print_teardown_sections(self, rep):\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)\n\n    def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                teardown_sections = {}\n                for report in self.getreports(\"\"):\n                    if report.when == \"teardown\":\n                        teardown_sections.setdefault(report.nodeid, []).append(report)\n\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    for report in teardown_sections.get(rep.nodeid, []):\n                        self.print_teardown_sections(report)\n\n    def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)\n\n    def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)\n\n    def summary_stats(self):\n        session_duration = time.time() - self._sessionstarttime\n        (line, color) = build_summary_stats_line(self.stats)\n        msg = \"{} in {}\".format(line, format_session_duration(session_duration))\n        markup = {color: True, \"bold\": True}\n\n        if self.verbosity >= 0:\n            self.write_sep(\"=\", msg, **markup)\n        if self.verbosity == -1:\n            self.write_line(msg, **markup)\n\n    def short_test_summary(self):\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines):\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self.writer.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines):\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines):\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines):\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno + 1, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"F\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"S\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }\n\n        lines = []\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:"
          },
          {
            "name": "TerminalReporter#__init__().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def __init__(self, config, file=None):\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None\n        self._showfspath = None\n\n        self.stats = {}\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        # self.writer will be deprecated in pytest-3.4\n        self.writer = self._tw\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()\n        self._show_progress_info = self._determine_show_progress_info()"
          },
          {
            "name": "TerminalReporter#_determine_show_progress_info().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg"
          },
          {
            "name": "TerminalReporter#verbosity().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @property\n    def verbosity(self):"
          },
          {
            "name": "TerminalReporter#showheader().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @property\n    def showheader(self):"
          },
          {
            "name": "TerminalReporter#showfspath().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0"
          },
          {
            "name": "TerminalReporter#showlongtestinfo().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @property\n    def showlongtestinfo(self):"
          },
          {
            "name": "TerminalReporter#hasopt().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)"
          },
          {
            "name": "TerminalReporter#write_fspath_result().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")"
          },
          {
            "name": "TerminalReporter#write_ensure_prefix().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)"
          },
          {
            "name": "TerminalReporter#ensure_newline().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()"
          },
          {
            "name": "TerminalReporter#write().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def write(self, content, **markup):"
          },
          {
            "name": "TerminalReporter#write_line().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()"
          },
          {
            "name": "TerminalReporter#rewrite().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)"
          },
          {
            "name": "TerminalReporter#write_sep().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()"
          },
          {
            "name": "TerminalReporter#section().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def section(self, title, sep=\"=\", **kw):"
          },
          {
            "name": "TerminalReporter#line().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def line(self, msg, **kw):"
          },
          {
            "name": "TerminalReporter#pytest_internalerror().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)"
          },
          {
            "name": "TerminalReporter#pytest_warning_captured().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        warnings = self.stats.setdefault(\"warnings\", [])\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )"
          },
          {
            "name": "TerminalReporter#pytest_plugin_registered().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line"
          },
          {
            "name": "TerminalReporter#pytest_deselected().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_deselected(self, items):"
          },
          {
            "name": "TerminalReporter#pytest_runtest_logstart().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n        elif self.showfspath:\n            fsid = nodeid.split(\"::\")[0]"
          },
          {
            "name": "TerminalReporter#pytest_runtest_logreport().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_runtest_logreport(self, report):\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self.stats.setdefault(category, []).append(rep)\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            if not running_xdist and self.showfspath:\n                self.write_fspath_result(rep.nodeid, letter, **markup)\n            else:\n                self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)"
          },
          {
            "name": "TerminalReporter#pytest_runtest_logfinish().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_runtest_logfinish(self, nodeid):\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n            is_last_item = (\n                len(self._progress_nodeids_reported) == self._session.testscollected\n            )\n            if is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()"
          },
          {
            "name": "TerminalReporter#_get_progress_information_message().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _get_progress_information_message(self):\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                progress = len(self._progress_nodeids_reported) * 100 // collected\n                return \" [{:3d}%]\".format(progress)"
          },
          {
            "name": "TerminalReporter#_write_progress_information_filling_space().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _write_progress_information_filling_space(self):\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1"
          },
          {
            "name": "TerminalReporter#_width_of_current_line().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        try:\n            return self._tw.width_of_current_line\n        except AttributeError:\n            # py < 1.6.0"
          },
          {
            "name": "TerminalReporter#pytest_collection().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_collection(self):\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:"
          },
          {
            "name": "TerminalReporter#pytest_collectreport().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_collectreport(self, report):\n        if report.failed:\n            self.stats.setdefault(\"error\", []).append(report)\n        elif report.skipped:\n            self.stats.setdefault(\"skipped\", []).append(report)\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:"
          },
          {
            "name": "TerminalReporter#report_collect().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d errors\" % errors\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:"
          },
          {
            "name": "TerminalReporter#pytest_sessionstart().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session):\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        if hasattr(sys, \"pypy_version_info\"):\n            verinfo = \".\".join(map(str, sys.pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, sys.pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )"
          },
          {
            "name": "TerminalReporter#_write_report_lines_from_hooks().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):"
          },
          {
            "name": "TerminalReporter#pytest_report_header().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))"
          },
          {
            "name": "TerminalReporter#pytest_collection_finish().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        if self.config.getoption(\"collectonly\"):\n            self._printcollecteditems(session.items)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if self.stats.get(\"failed\"):\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in self.stats.get(\"failed\"):"
          },
          {
            "name": "TerminalReporter#_printcollecteditems().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    if hasattr(col, \"_obj\") and col._obj.__doc__:\n                        for line in col._obj.__doc__.strip().splitlines():"
          },
          {
            "name": "TerminalReporter#pytest_sessionfinish().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, exitstatus):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo"
          },
          {
            "name": "TerminalReporter#pytest_terminal_summary().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any)."
          },
          {
            "name": "TerminalReporter#pytest_keyboard_interrupt().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_keyboard_interrupt(self, excinfo):"
          },
          {
            "name": "TerminalReporter#pytest_unconfigure().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):"
          },
          {
            "name": "TerminalReporter#_report_keyboardinterrupt().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,"
          },
          {
            "name": "TerminalReporter#_locationline().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\""
          },
          {
            "name": "TerminalReporter#mkrel().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)"
          },
          {
            "name": "TerminalReporter#_getfailureheadline().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line"
          },
          {
            "name": "TerminalReporter#_getcrashline().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:"
          },
          {
            "name": "TerminalReporter#getreports().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)"
          },
          {
            "name": "TerminalReporter#summary_warnings().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\"warnings\")\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = collections.OrderedDict()\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, warning_reports in reports_grouped_by_message.items():\n                has_any_location = False\n                for w in warning_reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        self._tw.line(str(location))\n                        has_any_location = True\n                if has_any_location:\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()"
          },
          {
            "name": "TerminalReporter#summary_passes().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)"
          },
          {
            "name": "TerminalReporter#print_teardown_sections().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def print_teardown_sections(self, rep):\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]"
          },
          {
            "name": "TerminalReporter#summary_failures().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                teardown_sections = {}\n                for report in self.getreports(\"\"):\n                    if report.when == \"teardown\":\n                        teardown_sections.setdefault(report.nodeid, []).append(report)\n\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    for report in teardown_sections.get(rep.nodeid, []):"
          },
          {
            "name": "TerminalReporter#summary_errors().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)"
          },
          {
            "name": "TerminalReporter#_outrep_summary().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]"
          },
          {
            "name": "TerminalReporter#summary_stats().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def summary_stats(self):\n        session_duration = time.time() - self._sessionstarttime\n        (line, color) = build_summary_stats_line(self.stats)\n        msg = \"{} in {}\".format(line, format_session_duration(session_duration))\n        markup = {color: True, \"bold\": True}\n\n        if self.verbosity >= 0:\n            self.write_sep(\"=\", msg, **markup)\n        if self.verbosity == -1:"
          },
          {
            "name": "TerminalReporter#short_test_summary().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def short_test_summary(self):\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines):\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self.writer.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines):\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines):\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines):\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno + 1, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"F\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"S\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }\n\n        lines = []\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:"
          },
          {
            "name": "TerminalReporter#show_simple().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "        def show_simple(stat, lines):\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self.writer.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)"
          },
          {
            "name": "TerminalReporter#show_xfailed().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "        def show_xfailed(lines):\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:"
          },
          {
            "name": "TerminalReporter#show_xpassed().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "        def show_xpassed(lines):\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail"
          },
          {
            "name": "TerminalReporter#show_skipped().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "        def show_skipped(lines):\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno + 1, reason)\n                    )\n                else:"
          },
          {
            "name": "_NodeReporter#append().",
            "file_path": "src/_pytest/junitxml.py",
            "file_content": "    def append(self, node):\n        self.xml.add_stats(type(node).__name__)"
          },
          {
            "name": "_NodeReporter#write_captured_output().",
            "file_path": "src/_pytest/junitxml.py",
            "file_content": "    def write_captured_output(self, report):\n        if not self.xml.log_passing_tests and report.passed:\n            return\n\n        content_out = report.capstdout\n        content_log = report.caplog\n        content_err = report.capstderr\n\n        if content_log or content_out:\n            if content_log and self.xml.logging == \"system-out\":\n                if content_out:\n                    # syncing stdout and the log-output is not done yet. It's\n                    # probably not worth the effort. Therefore, first the captured\n                    # stdout is shown and then the captured logs.\n                    content = \"\\n\".join(\n                        [\n                            \" Captured Stdout \".center(80, \"-\"),\n                            content_out,\n                            \"\",\n                            \" Captured Log \".center(80, \"-\"),\n                            content_log,\n                        ]\n                    )\n                else:\n                    content = content_log\n            else:\n                content = content_out\n\n            if content:\n                tag = getattr(Junit, \"system-out\")\n                self.append(tag(bin_xml_escape(content)))\n\n        if content_log or content_err:\n            if content_log and self.xml.logging == \"system-err\":\n                if content_err:\n                    content = \"\\n\".join(\n                        [\n                            \" Captured Stderr \".center(80, \"-\"),\n                            content_err,\n                            \"\",\n                            \" Captured Log \".center(80, \"-\"),\n                            content_log,\n                        ]\n                    )\n                else:\n                    content = content_log\n            else:\n                content = content_err\n\n            if content:\n                tag = getattr(Junit, \"system-err\")"
          },
          {
            "name": "_NodeReporter#append_failure().",
            "file_path": "src/_pytest/junitxml.py",
            "file_content": "    def append_failure(self, report):\n        # msg = str(report.longrepr.reprtraceback.extraline)\n        if hasattr(report, \"wasxfail\"):\n            self._add_simple(Junit.skipped, \"xfail-marked test passes unexpectedly\")\n        else:\n            if hasattr(report.longrepr, \"reprcrash\"):\n                message = report.longrepr.reprcrash.message\n            elif isinstance(report.longrepr, str):\n                message = report.longrepr\n            else:\n                message = str(report.longrepr)\n            message = bin_xml_escape(message)\n            fail = Junit.failure(message=message)\n            fail.append(bin_xml_escape(report.longrepr))"
          },
          {
            "name": "LogXML#pytest_runtest_logreport().",
            "file_path": "src/_pytest/junitxml.py",
            "file_content": "    def pytest_runtest_logreport(self, report):\n        \"\"\"handle a setup/call/teardown report, generating the appropriate\n        xml tags as necessary.\n\n        note: due to plugins like xdist, this hook may be called in interlaced\n        order with reports from other nodes. for example:\n\n        usual call order:\n            -> setup node1\n            -> call node1\n            -> teardown node1\n            -> setup node2\n            -> call node2\n            -> teardown node2\n\n        possible call order in xdist:\n            -> setup node1\n            -> call node1\n            -> setup node2\n            -> call node2\n            -> teardown node2\n            -> teardown node1\n        \"\"\"\n        close_report = None\n        if report.passed:\n            if report.when == \"call\":  # ignore setup/teardown\n                reporter = self._opentestcase(report)\n                reporter.append_pass(report)\n        elif report.failed:\n            if report.when == \"teardown\":\n                # The following vars are needed when xdist plugin is used\n                report_wid = getattr(report, \"worker_id\", None)\n                report_ii = getattr(report, \"item_index\", None)\n                close_report = next(\n                    (\n                        rep\n                        for rep in self.open_reports\n                        if (\n                            rep.nodeid == report.nodeid\n                            and getattr(rep, \"item_index\", None) == report_ii\n                            and getattr(rep, \"worker_id\", None) == report_wid\n                        )\n                    ),\n                    None,\n                )\n                if close_report:\n                    # We need to open new testcase in case we have failure in\n                    # call and error in teardown in order to follow junit\n                    # schema\n                    self.finalize(close_report)\n                    self.cnt_double_fail_tests += 1\n            reporter = self._opentestcase(report)\n            if report.when == \"call\":\n                reporter.append_failure(report)\n                self.open_reports.append(report)\n            else:\n                reporter.append_error(report)\n        elif report.skipped:\n            reporter = self._opentestcase(report)\n            reporter.append_skipped(report)\n        self.update_testcase_duration(report)\n        if report.when == \"teardown\":\n            reporter = self._opentestcase(report)\n            reporter.write_captured_output(report)\n\n            for propname, propvalue in report.user_properties:\n                reporter.add_property(propname, propvalue)\n\n            self.finalize(report)\n            report_wid = getattr(report, \"worker_id\", None)\n            report_ii = getattr(report, \"item_index\", None)\n            close_report = next(\n                (\n                    rep\n                    for rep in self.open_reports\n                    if (\n                        rep.nodeid == report.nodeid\n                        and getattr(rep, \"item_index\", None) == report_ii\n                        and getattr(rep, \"worker_id\", None) == report_wid\n                    )\n                ),\n                None,\n            )\n            if close_report:"
          }
        ],
        "root_caused_symbols": [
          {
            "name": "BaseReport#toterminal().",
            "file_path": "src/_pytest/reports.py",
            "file_content": "    def toterminal(self, out):\n        if hasattr(self, \"node\"):\n            out.line(getslaveinfoline(self.node))\n\n        longrepr = self.longrepr\n        if longrepr is None:\n            return\n\n        if hasattr(longrepr, \"toterminal\"):\n            longrepr.toterminal(out)\n        else:\n            try:\n                out.line(longrepr)\n            except UnicodeEncodeError:"
          },
          {
            "name": "BaseReport#longreprtext().",
            "file_path": "src/_pytest/reports.py",
            "file_content": "    @property\n    def longreprtext(self):\n        \"\"\"\n        Read-only property that returns the full string representation\n        of ``longrepr``.\n\n        .. versionadded:: 3.0\n        \"\"\"\n        tw = py.io.TerminalWriter(stringio=True)\n        tw.hasmarkup = False\n        self.toterminal(tw)\n        exc = tw.stringio.getvalue()"
          },
          {
            "name": "TestReport#from_item_and_call().",
            "file_path": "src/_pytest/reports.py",
            "file_content": "    @classmethod\n    def from_item_and_call(cls, item, call):\n        \"\"\"\n        Factory method to create and fill a TestReport with standard item and call info.\n        \"\"\"\n        when = call.when\n        duration = call.stop - call.start\n        keywords = {x: 1 for x in item.keywords}\n        excinfo = call.excinfo\n        sections = []\n        if not call.excinfo:\n            outcome = \"passed\"\n            longrepr = None\n        else:\n            if not isinstance(excinfo, ExceptionInfo):\n                outcome = \"failed\"\n                longrepr = excinfo\n            elif excinfo.errisinstance(skip.Exception):\n                outcome = \"skipped\"\n                r = excinfo._getreprcrash()\n                longrepr = (str(r.path), r.lineno, r.message)\n            else:\n                outcome = \"failed\"\n                if call.when == \"call\":\n                    longrepr = item.repr_failure(excinfo)\n                else:  # exception in setup or teardown\n                    longrepr = item._repr_failure_py(\n                        excinfo, style=item.config.getoption(\"tbstyle\", \"auto\")\n                    )\n        for rwhen, key, content in item._report_sections:\n            sections.append((\"Captured {} {}\".format(key, rwhen), content))\n        return cls(\n            item.nodeid,\n            item.location,\n            keywords,\n            outcome,\n            longrepr,\n            when,\n            sections,\n            duration,\n            user_properties=item.user_properties,"
          }
        ]
      }
    },
    {
      "name": "CodeGenV0",
      "metadata": {
        "start": "2024-08-15T18:45:12.601978",
        "usage": "10082.016706466675 ms"
      },
      "request": {
        "related_symbols": [
          {
            "name": "pytest_runtest_call().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "def pytest_runtest_call(item):\n    _update_current_test_var(item, \"call\")\n    sys.last_type, sys.last_value, sys.last_traceback = (None, None, None)\n    try:\n        item.runtest()\n    except Exception:\n        # Store trace info to allow postmortem debugging\n        type, value, tb = sys.exc_info()\n        tb = tb.tb_next  # Skip *this* frame\n        sys.last_type = type\n        sys.last_value = value\n        sys.last_traceback = tb\n        del type, value, tb  # Get rid of these in this frame"
          },
          {
            "name": "pytest_report_teststatus().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "def pytest_report_teststatus(report):\n    if report.when in (\"setup\", \"teardown\"):\n        if report.failed:\n            #      category, shortletter, verbose-word\n            return \"error\", \"E\", \"ERROR\"\n        elif report.skipped:\n            return \"skipped\", \"s\", \"SKIPPED\"\n        else:"
          },
          {
            "name": "check_interactive_exception().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "def check_interactive_exception(call, report):\n    return call.excinfo and not (\n        hasattr(report, \"wasxfail\")\n        or call.excinfo.errisinstance(Skipped)\n        or call.excinfo.errisinstance(bdb.BdbQuit)"
          },
          {
            "name": "CallInfo#",
            "file_path": "src/_pytest/runner.py",
            "file_content": "@attr.s(repr=False)\nclass CallInfo:\n    \"\"\" Result/Exception info a function invocation. \"\"\"\n\n    _result = attr.ib()\n    # Optional[ExceptionInfo]\n    excinfo = attr.ib()\n    start = attr.ib()\n    stop = attr.ib()\n    when = attr.ib()\n\n    @property\n    def result(self):\n        if self.excinfo is not None:\n            raise AttributeError(\"{!r} has no valid result\".format(self))\n        return self._result\n\n    @classmethod\n    def from_call(cls, func, when, reraise=None):\n        #: context of invocation: one of \"setup\", \"call\",\n        #: \"teardown\", \"memocollect\"\n        start = time()\n        excinfo = None\n        try:\n            result = func()\n        except:  # noqa\n            excinfo = ExceptionInfo.from_current()\n            if reraise is not None and excinfo.errisinstance(reraise):\n                raise\n            result = None\n        stop = time()\n        return cls(start=start, stop=stop, when=when, result=result, excinfo=excinfo)\n\n    def __repr__(self):\n        if self.excinfo is not None:\n            status = \"exception\"\n            value = self.excinfo.value\n        else:\n            # TODO: investigate unification\n            value = repr(self._result)\n            status = \"result\"\n        return \"<CallInfo when={when!r} {status}: {value}>\".format(\n            when=self.when, value=value, status=status"
          },
          {
            "name": "CallInfo#result().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "    @property\n    def result(self):\n        if self.excinfo is not None:\n            raise AttributeError(\"{!r} has no valid result\".format(self))"
          },
          {
            "name": "CallInfo#from_call().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "    @classmethod\n    def from_call(cls, func, when, reraise=None):\n        #: context of invocation: one of \"setup\", \"call\",\n        #: \"teardown\", \"memocollect\"\n        start = time()\n        excinfo = None\n        try:\n            result = func()\n        except:  # noqa\n            excinfo = ExceptionInfo.from_current()\n            if reraise is not None and excinfo.errisinstance(reraise):\n                raise\n            result = None\n        stop = time()"
          },
          {
            "name": "CallInfo#__repr__().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "    def __repr__(self):\n        if self.excinfo is not None:\n            status = \"exception\"\n            value = self.excinfo.value\n        else:\n            # TODO: investigate unification\n            value = repr(self._result)\n            status = \"result\"\n        return \"<CallInfo when={when!r} {status}: {value}>\".format(\n            when=self.when, value=value, status=status"
          },
          {
            "name": "pytest_runtest_makereport().",
            "file_path": "src/_pytest/runner.py",
            "file_content": "def pytest_runtest_makereport(item, call):"
          },
          {
            "name": "TerminalReporter#",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "class TerminalReporter:\n    def __init__(self, config, file=None):\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None\n        self._showfspath = None\n\n        self.stats = {}\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        # self.writer will be deprecated in pytest-3.4\n        self.writer = self._tw\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None\n\n    def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False\n\n    @property\n    def verbosity(self):\n        return self.config.option.verbose\n\n    @property\n    def showheader(self):\n        return self.verbosity >= 0\n\n    @property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0\n        return self._showfspath\n\n    @showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value\n\n    @property\n    def showlongtestinfo(self):\n        return self.verbosity > 0\n\n    def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars\n\n    def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, **markup)\n\n    def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2\n\n    def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None\n\n    def write(self, content, **markup):\n        self._tw.write(content, **markup)\n\n    def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)\n\n    def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)\n\n    def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)\n\n    def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)\n\n    def line(self, msg, **kw):\n        self._tw.line(msg, **kw)\n\n    def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1\n\n    def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        warnings = self.stats.setdefault(\"warnings\", [])\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        warnings.append(warning_report)\n\n    def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)\n\n    def pytest_deselected(self, items):\n        self.stats.setdefault(\"deselected\", []).extend(items)\n\n    def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n        elif self.showfspath:\n            fsid = nodeid.split(\"::\")[0]\n            self.write_fspath_result(fsid, \"\")\n\n    def pytest_runtest_logreport(self, report):\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self.stats.setdefault(category, []).append(rep)\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            if not running_xdist and self.showfspath:\n                self.write_fspath_result(rep.nodeid, letter, **markup)\n            else:\n                self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2\n\n    def pytest_runtest_logfinish(self, nodeid):\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n            is_last_item = (\n                len(self._progress_nodeids_reported) == self._session.testscollected\n            )\n            if is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", cyan=True)\n\n    def _get_progress_information_message(self):\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                progress = len(self._progress_nodeids_reported) * 100 // collected\n                return \" [{:3d}%]\".format(progress)\n            return \" [100%]\"\n\n    def _write_progress_information_filling_space(self):\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), cyan=True)\n\n    @property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        try:\n            return self._tw.width_of_current_line\n        except AttributeError:\n            # py < 1.6.0\n            return self._tw.chars_on_current_line\n\n    def pytest_collection(self):\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", bold=True)\n\n    def pytest_collectreport(self, report):\n        if report.failed:\n            self.stats.setdefault(\"error\", []).append(report)\n        elif report.skipped:\n            self.stats.setdefault(\"skipped\", []).append(report)\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()\n\n    def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d errors\" % errors\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)\n\n    @pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session):\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        if hasattr(sys, \"pypy_version_info\"):\n            verinfo = \".\".join(map(str, sys.pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, sys.pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)\n\n    def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)\n\n    def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result\n\n    def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        if self.config.getoption(\"collectonly\"):\n            self._printcollecteditems(session.items)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if self.stats.get(\"failed\"):\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in self.stats.get(\"failed\"):\n                    rep.toterminal(self._tw)\n\n    def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    if hasattr(col, \"_obj\") and col._obj.__doc__:\n                        for line in col._obj.__doc__.strip().splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line.strip()))\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, exitstatus):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        self.summary_stats()\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()\n\n    def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)\n\n    def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()\n\n    def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )\n\n    def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \"\n\n    def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?\n\n    def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"\n\n    #\n    # summaries for sessionfinish\n    #\n    def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values\n\n    def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\"warnings\")\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = collections.OrderedDict()\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, warning_reports in reports_grouped_by_message.items():\n                has_any_location = False\n                for w in warning_reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        self._tw.line(str(location))\n                        has_any_location = True\n                if has_any_location:\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")\n\n    def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n\n    def print_teardown_sections(self, rep):\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)\n\n    def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                teardown_sections = {}\n                for report in self.getreports(\"\"):\n                    if report.when == \"teardown\":\n                        teardown_sections.setdefault(report.nodeid, []).append(report)\n\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    for report in teardown_sections.get(rep.nodeid, []):\n                        self.print_teardown_sections(report)\n\n    def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)\n\n    def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)\n\n    def summary_stats(self):\n        session_duration = time.time() - self._sessionstarttime\n        (line, color) = build_summary_stats_line(self.stats)\n        msg = \"{} in {}\".format(line, format_session_duration(session_duration))\n        markup = {color: True, \"bold\": True}\n\n        if self.verbosity >= 0:\n            self.write_sep(\"=\", msg, **markup)\n        if self.verbosity == -1:\n            self.write_line(msg, **markup)\n\n    def short_test_summary(self):\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines):\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self.writer.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines):\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines):\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines):\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno + 1, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"F\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"S\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }\n\n        lines = []\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:"
          },
          {
            "name": "TerminalReporter#__init__().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def __init__(self, config, file=None):\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None\n        self._showfspath = None\n\n        self.stats = {}\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        # self.writer will be deprecated in pytest-3.4\n        self.writer = self._tw\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()\n        self._show_progress_info = self._determine_show_progress_info()"
          },
          {
            "name": "TerminalReporter#_determine_show_progress_info().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg"
          },
          {
            "name": "TerminalReporter#verbosity().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @property\n    def verbosity(self):"
          },
          {
            "name": "TerminalReporter#showheader().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @property\n    def showheader(self):"
          },
          {
            "name": "TerminalReporter#showfspath().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0"
          },
          {
            "name": "TerminalReporter#showlongtestinfo().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @property\n    def showlongtestinfo(self):"
          },
          {
            "name": "TerminalReporter#hasopt().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)"
          },
          {
            "name": "TerminalReporter#write_fspath_result().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")"
          },
          {
            "name": "TerminalReporter#write_ensure_prefix().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)"
          },
          {
            "name": "TerminalReporter#ensure_newline().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()"
          },
          {
            "name": "TerminalReporter#write().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def write(self, content, **markup):"
          },
          {
            "name": "TerminalReporter#write_line().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()"
          },
          {
            "name": "TerminalReporter#rewrite().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)"
          },
          {
            "name": "TerminalReporter#write_sep().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()"
          },
          {
            "name": "TerminalReporter#section().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def section(self, title, sep=\"=\", **kw):"
          },
          {
            "name": "TerminalReporter#line().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def line(self, msg, **kw):"
          },
          {
            "name": "TerminalReporter#pytest_internalerror().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)"
          },
          {
            "name": "TerminalReporter#pytest_warning_captured().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        warnings = self.stats.setdefault(\"warnings\", [])\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )"
          },
          {
            "name": "TerminalReporter#pytest_plugin_registered().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line"
          },
          {
            "name": "TerminalReporter#pytest_deselected().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_deselected(self, items):"
          },
          {
            "name": "TerminalReporter#pytest_runtest_logstart().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n        elif self.showfspath:\n            fsid = nodeid.split(\"::\")[0]"
          },
          {
            "name": "TerminalReporter#pytest_runtest_logreport().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_runtest_logreport(self, report):\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self.stats.setdefault(category, []).append(rep)\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            if not running_xdist and self.showfspath:\n                self.write_fspath_result(rep.nodeid, letter, **markup)\n            else:\n                self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)"
          },
          {
            "name": "TerminalReporter#pytest_runtest_logfinish().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_runtest_logfinish(self, nodeid):\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n            is_last_item = (\n                len(self._progress_nodeids_reported) == self._session.testscollected\n            )\n            if is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()"
          },
          {
            "name": "TerminalReporter#_get_progress_information_message().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _get_progress_information_message(self):\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                progress = len(self._progress_nodeids_reported) * 100 // collected\n                return \" [{:3d}%]\".format(progress)"
          },
          {
            "name": "TerminalReporter#_write_progress_information_filling_space().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _write_progress_information_filling_space(self):\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1"
          },
          {
            "name": "TerminalReporter#_width_of_current_line().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        try:\n            return self._tw.width_of_current_line\n        except AttributeError:\n            # py < 1.6.0"
          },
          {
            "name": "TerminalReporter#pytest_collection().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_collection(self):\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:"
          },
          {
            "name": "TerminalReporter#pytest_collectreport().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_collectreport(self, report):\n        if report.failed:\n            self.stats.setdefault(\"error\", []).append(report)\n        elif report.skipped:\n            self.stats.setdefault(\"skipped\", []).append(report)\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:"
          },
          {
            "name": "TerminalReporter#report_collect().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d errors\" % errors\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:"
          },
          {
            "name": "TerminalReporter#pytest_sessionstart().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session):\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        if hasattr(sys, \"pypy_version_info\"):\n            verinfo = \".\".join(map(str, sys.pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, sys.pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )"
          },
          {
            "name": "TerminalReporter#_write_report_lines_from_hooks().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):"
          },
          {
            "name": "TerminalReporter#pytest_report_header().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))"
          },
          {
            "name": "TerminalReporter#pytest_collection_finish().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        if self.config.getoption(\"collectonly\"):\n            self._printcollecteditems(session.items)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            if self.stats.get(\"failed\"):\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in self.stats.get(\"failed\"):"
          },
          {
            "name": "TerminalReporter#_printcollecteditems().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    if hasattr(col, \"_obj\") and col._obj.__doc__:\n                        for line in col._obj.__doc__.strip().splitlines():"
          },
          {
            "name": "TerminalReporter#pytest_sessionfinish().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, exitstatus):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo"
          },
          {
            "name": "TerminalReporter#pytest_terminal_summary().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    @pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any)."
          },
          {
            "name": "TerminalReporter#pytest_keyboard_interrupt().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_keyboard_interrupt(self, excinfo):"
          },
          {
            "name": "TerminalReporter#pytest_unconfigure().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):"
          },
          {
            "name": "TerminalReporter#_report_keyboardinterrupt().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,"
          },
          {
            "name": "TerminalReporter#_locationline().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\""
          },
          {
            "name": "TerminalReporter#mkrel().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)"
          },
          {
            "name": "TerminalReporter#_getfailureheadline().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line"
          },
          {
            "name": "TerminalReporter#_getcrashline().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:"
          },
          {
            "name": "TerminalReporter#getreports().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)"
          },
          {
            "name": "TerminalReporter#summary_warnings().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\"warnings\")\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = collections.OrderedDict()\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, warning_reports in reports_grouped_by_message.items():\n                has_any_location = False\n                for w in warning_reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        self._tw.line(str(location))\n                        has_any_location = True\n                if has_any_location:\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()"
          },
          {
            "name": "TerminalReporter#summary_passes().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)"
          },
          {
            "name": "TerminalReporter#print_teardown_sections().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def print_teardown_sections(self, rep):\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]"
          },
          {
            "name": "TerminalReporter#summary_failures().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                teardown_sections = {}\n                for report in self.getreports(\"\"):\n                    if report.when == \"teardown\":\n                        teardown_sections.setdefault(report.nodeid, []).append(report)\n\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    for report in teardown_sections.get(rep.nodeid, []):"
          },
          {
            "name": "TerminalReporter#summary_errors().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)"
          },
          {
            "name": "TerminalReporter#_outrep_summary().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]"
          },
          {
            "name": "TerminalReporter#summary_stats().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def summary_stats(self):\n        session_duration = time.time() - self._sessionstarttime\n        (line, color) = build_summary_stats_line(self.stats)\n        msg = \"{} in {}\".format(line, format_session_duration(session_duration))\n        markup = {color: True, \"bold\": True}\n\n        if self.verbosity >= 0:\n            self.write_sep(\"=\", msg, **markup)\n        if self.verbosity == -1:"
          },
          {
            "name": "TerminalReporter#short_test_summary().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "    def short_test_summary(self):\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines):\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self.writer.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines):\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines):\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines):\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno + 1, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"F\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"S\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }\n\n        lines = []\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:"
          },
          {
            "name": "TerminalReporter#show_simple().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "        def show_simple(stat, lines):\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self.writer.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)"
          },
          {
            "name": "TerminalReporter#show_xfailed().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "        def show_xfailed(lines):\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:"
          },
          {
            "name": "TerminalReporter#show_xpassed().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "        def show_xpassed(lines):\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail"
          },
          {
            "name": "TerminalReporter#show_skipped().",
            "file_path": "src/_pytest/terminal.py",
            "file_content": "        def show_skipped(lines):\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno + 1, reason)\n                    )\n                else:"
          },
          {
            "name": "_NodeReporter#append().",
            "file_path": "src/_pytest/junitxml.py",
            "file_content": "    def append(self, node):\n        self.xml.add_stats(type(node).__name__)"
          },
          {
            "name": "_NodeReporter#write_captured_output().",
            "file_path": "src/_pytest/junitxml.py",
            "file_content": "    def write_captured_output(self, report):\n        if not self.xml.log_passing_tests and report.passed:\n            return\n\n        content_out = report.capstdout\n        content_log = report.caplog\n        content_err = report.capstderr\n\n        if content_log or content_out:\n            if content_log and self.xml.logging == \"system-out\":\n                if content_out:\n                    # syncing stdout and the log-output is not done yet. It's\n                    # probably not worth the effort. Therefore, first the captured\n                    # stdout is shown and then the captured logs.\n                    content = \"\\n\".join(\n                        [\n                            \" Captured Stdout \".center(80, \"-\"),\n                            content_out,\n                            \"\",\n                            \" Captured Log \".center(80, \"-\"),\n                            content_log,\n                        ]\n                    )\n                else:\n                    content = content_log\n            else:\n                content = content_out\n\n            if content:\n                tag = getattr(Junit, \"system-out\")\n                self.append(tag(bin_xml_escape(content)))\n\n        if content_log or content_err:\n            if content_log and self.xml.logging == \"system-err\":\n                if content_err:\n                    content = \"\\n\".join(\n                        [\n                            \" Captured Stderr \".center(80, \"-\"),\n                            content_err,\n                            \"\",\n                            \" Captured Log \".center(80, \"-\"),\n                            content_log,\n                        ]\n                    )\n                else:\n                    content = content_log\n            else:\n                content = content_err\n\n            if content:\n                tag = getattr(Junit, \"system-err\")"
          },
          {
            "name": "_NodeReporter#append_failure().",
            "file_path": "src/_pytest/junitxml.py",
            "file_content": "    def append_failure(self, report):\n        # msg = str(report.longrepr.reprtraceback.extraline)\n        if hasattr(report, \"wasxfail\"):\n            self._add_simple(Junit.skipped, \"xfail-marked test passes unexpectedly\")\n        else:\n            if hasattr(report.longrepr, \"reprcrash\"):\n                message = report.longrepr.reprcrash.message\n            elif isinstance(report.longrepr, str):\n                message = report.longrepr\n            else:\n                message = str(report.longrepr)\n            message = bin_xml_escape(message)\n            fail = Junit.failure(message=message)\n            fail.append(bin_xml_escape(report.longrepr))"
          },
          {
            "name": "LogXML#pytest_runtest_logreport().",
            "file_path": "src/_pytest/junitxml.py",
            "file_content": "    def pytest_runtest_logreport(self, report):\n        \"\"\"handle a setup/call/teardown report, generating the appropriate\n        xml tags as necessary.\n\n        note: due to plugins like xdist, this hook may be called in interlaced\n        order with reports from other nodes. for example:\n\n        usual call order:\n            -> setup node1\n            -> call node1\n            -> teardown node1\n            -> setup node2\n            -> call node2\n            -> teardown node2\n\n        possible call order in xdist:\n            -> setup node1\n            -> call node1\n            -> setup node2\n            -> call node2\n            -> teardown node2\n            -> teardown node1\n        \"\"\"\n        close_report = None\n        if report.passed:\n            if report.when == \"call\":  # ignore setup/teardown\n                reporter = self._opentestcase(report)\n                reporter.append_pass(report)\n        elif report.failed:\n            if report.when == \"teardown\":\n                # The following vars are needed when xdist plugin is used\n                report_wid = getattr(report, \"worker_id\", None)\n                report_ii = getattr(report, \"item_index\", None)\n                close_report = next(\n                    (\n                        rep\n                        for rep in self.open_reports\n                        if (\n                            rep.nodeid == report.nodeid\n                            and getattr(rep, \"item_index\", None) == report_ii\n                            and getattr(rep, \"worker_id\", None) == report_wid\n                        )\n                    ),\n                    None,\n                )\n                if close_report:\n                    # We need to open new testcase in case we have failure in\n                    # call and error in teardown in order to follow junit\n                    # schema\n                    self.finalize(close_report)\n                    self.cnt_double_fail_tests += 1\n            reporter = self._opentestcase(report)\n            if report.when == \"call\":\n                reporter.append_failure(report)\n                self.open_reports.append(report)\n            else:\n                reporter.append_error(report)\n        elif report.skipped:\n            reporter = self._opentestcase(report)\n            reporter.append_skipped(report)\n        self.update_testcase_duration(report)\n        if report.when == \"teardown\":\n            reporter = self._opentestcase(report)\n            reporter.write_captured_output(report)\n\n            for propname, propvalue in report.user_properties:\n                reporter.add_property(propname, propvalue)\n\n            self.finalize(report)\n            report_wid = getattr(report, \"worker_id\", None)\n            report_ii = getattr(report, \"item_index\", None)\n            close_report = next(\n                (\n                    rep\n                    for rep in self.open_reports\n                    if (\n                        rep.nodeid == report.nodeid\n                        and getattr(rep, \"item_index\", None) == report_ii\n                        and getattr(rep, \"worker_id\", None) == report_wid\n                    )\n                ),\n                None,\n            )\n            if close_report:"
          }
        ],
        "root_caused_symbols": [
          {
            "name": "BaseReport#toterminal().",
            "file_path": "src/_pytest/reports.py",
            "file_content": "    def toterminal(self, out):\n        if hasattr(self, \"node\"):\n            out.line(getslaveinfoline(self.node))\n\n        longrepr = self.longrepr\n        if longrepr is None:\n            return\n\n        if hasattr(longrepr, \"toterminal\"):\n            longrepr.toterminal(out)\n        else:\n            try:\n                out.line(longrepr)\n            except UnicodeEncodeError:"
          },
          {
            "name": "BaseReport#longreprtext().",
            "file_path": "src/_pytest/reports.py",
            "file_content": "    @property\n    def longreprtext(self):\n        \"\"\"\n        Read-only property that returns the full string representation\n        of ``longrepr``.\n\n        .. versionadded:: 3.0\n        \"\"\"\n        tw = py.io.TerminalWriter(stringio=True)\n        tw.hasmarkup = False\n        self.toterminal(tw)\n        exc = tw.stringio.getvalue()"
          },
          {
            "name": "TestReport#from_item_and_call().",
            "file_path": "src/_pytest/reports.py",
            "file_content": "    @classmethod\n    def from_item_and_call(cls, item, call):\n        \"\"\"\n        Factory method to create and fill a TestReport with standard item and call info.\n        \"\"\"\n        when = call.when\n        duration = call.stop - call.start\n        keywords = {x: 1 for x in item.keywords}\n        excinfo = call.excinfo\n        sections = []\n        if not call.excinfo:\n            outcome = \"passed\"\n            longrepr = None\n        else:\n            if not isinstance(excinfo, ExceptionInfo):\n                outcome = \"failed\"\n                longrepr = excinfo\n            elif excinfo.errisinstance(skip.Exception):\n                outcome = \"skipped\"\n                r = excinfo._getreprcrash()\n                longrepr = (str(r.path), r.lineno, r.message)\n            else:\n                outcome = \"failed\"\n                if call.when == \"call\":\n                    longrepr = item.repr_failure(excinfo)\n                else:  # exception in setup or teardown\n                    longrepr = item._repr_failure_py(\n                        excinfo, style=item.config.getoption(\"tbstyle\", \"auto\")\n                    )\n        for rwhen, key, content in item._report_sections:\n            sections.append((\"Captured {} {}\".format(key, rwhen), content))\n        return cls(\n            item.nodeid,\n            item.location,\n            keywords,\n            outcome,\n            longrepr,\n            when,\n            sections,\n            duration,\n            user_properties=item.user_properties,"
          }
        ]
      },
      "response": {
        "scratch_pad": "1. The issue described is that when the test run is performed with `xdist`, chained exceptions are not displayed properly. When running without `xdist`, the full traceback is displayed including the chained exceptions, but with `xdist`, only the last exception is shown.\n\n2. This issue is likely caused by how reports are generated and logged in the `pytest` framework when using `xdist`. The reporting mechanism might not properly capture and display the chained exceptions when running tests in parallel across multiple worker nodes.\n\n3. The expected result should be that running the tests (both with and without `xdist`) should display the full traceback including the chained exceptions in a similar manner.\n\n4. To achieve that, we may need to ensure that during the report generation phase (specifically in the sections handling the exception info), chained exceptions are properly captured and retained.\n\n5. Proposed changes would primarily involve modifying either the `pytest_runtest_logreport` method and possibly adjusting exception handling in the reporter classes to ensure that chained exceptions are included in the final output.\n\n6. I will analyze the relevant symbols regarding how testing reports are generated, specifically focusing on the `pytest_runtest_logreport` method and its interaction with the `NodeReporter`, `append_failure` method, and other related functions to implement the necessary adjustments.",
        "patch": "diff --git a/src/_pytest/junitxml.py b/src/_pytest/junitxml.py\nindex abcdef1..1234567 100644\n--- a/src/_pytest/junitxml.py\n+++ b/src/_pytest/junitxml.py\n@@ -300,7 +300,7 @@ def pytest_runtest_logreport(self, report):\n                 self.finalize(close_report)\n                 self.cnt_double_fail_tests += 1\n \n-            reporter = self._opentestcase(report)\n+            reporter = self._opentestcase(report) \n             if report.when == \"call\":\n                 reporter.append_failure(report)\n                 self.open_reports.append(report)\n             else:\n                 reporter.append_error(report)\n             \n         elif report.skipped:\n             reporter = self._opentestcase(report)\n             reporter.append_skipped(report)\n         \n         # Append chained exceptions\n         if report.excinfo is not None:\n             if report.excinfo.typename:  \n                 last_exception_message = report.excinfo.value.args[0]\n                 reporter.append_failure(report)  # Ensuring to log chained exception information\n \n         self.update_testcase_duration(report)\n         if report.when == \"teardown\":\n             reporter = self._opentestcase(report)\n             reporter.write_captured_output(report)"
      }
    }
  ]
}