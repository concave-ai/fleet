{
  "total_cost": 0,
  "task_id": "pytest-dev__pytest-7490",
  "model": "gpt-4o-2024-08-06",
  "spans": [
    {
      "name": "KeywordExtract",
      "metadata": {
        "start": "2024-08-17T22:23:38.084226",
        "usage": "2092.2679901123047 ms"
      },
      "request": {
        "repo_tokens": [
          "cleanup_candidates",
          "ensure_reset_dir",
          "__getitem__",
          "_CACHE_PREFIX_DIRS",
          "getfirstlinesource",
          "FaultHandlerHooks",
          "warn",
          "pastebin",
          "AssertionRewriter",
          "getitem",
          "_testcase",
          "FixtureManager",
          "_getreprcrash",
          "skip",
          "T",
          "_getcrashline",
          "getfuncargnames",
          "num_mock_patch_args",
          "DEFAULT_LOG_FORMAT",
          "evaluate_xfail_marks",
          "_issue_warning_captured",
          "add_report_section",
          "getfixturedefs",
          "MoreQuietAction",
          "addini",
          "PytestExperimentalApiWarning",
          "hasinit",
          "InvocationParams",
          "pytest",
          "_tryconvertpyarg",
          "fullsource",
          "_FixtureFunction",
          "rex_session_duration",
          "pytest_collection_finish",
          "FormattedExcinfo",
          "_make_xunit_fixture",
          "__setitem__",
          "_strtobool",
          "pytest_report_to_serializable",
          "pytest_plugin_registered",
          "Node",
          "combined_with",
          "BaseReport",
          "_width_of_current_line",
          "_update_message",
          "cacheprovider",
          "mangle_test_address",
          "readline",
          "_opentestcase",
          "records",
          "setmulti2",
          "write_ensure_prefix",
          "_in_venv",
          "_add_simple",
          "FixtureDef",
          "_bestrelpath_cache",
          "list",
          "append_collect_error",
          "ImportPathMismatchError",
          "get_scope_node",
          "evaluate_condition",
          "showfspath",
          "NOTSET",
          "_get_flag_lookup",
          "__version_tuple__",
          "delattr",
          "SEP",
          "makedir",
          "MINUS_K_COLON",
          "accept",
          "_repr_style",
          "_inject_setup_class_fixture",
          "_import_plugin_specs",
          "markname",
          "istestfunction",
          "set_when",
          "getmodpath",
          "python_api",
          "addFailure",
          "symlink_or_skip",
          "ConftestImportFailure",
          "getstatementrange_ast",
          "getfailedcollections",
          "_legal_ranges",
          "reprfileloc",
          "notify_exception",
          "__len__",
          "isnosetest",
          "_basetemp",
          "_yield_comparisons",
          "RPAREN",
          "reprcrash",
          "repr_args",
          "_truncate_recursive_traceback",
          "_getautousenames",
          "_color_for_type_default",
          "node_reporter",
          "write_line",
          "co_equal",
          "_getindent",
          "pytest_warning_recorded",
          "tmpdir_factory",
          "__slots__",
          "DOCTEST_REPORT_CHOICE_CDIFF",
          "pytest_collection_modifyitems",
          "buffer",
          "WarningsRecorder",
          "clear_cache",
          "_format_boolop",
          "PytestArg",
          "no_re_match_line",
          "ishidden",
          "fileno",
          "_log_text",
          "funcnamefilter",
          "_write_progress_information_filling_space",
          "add_stats",
          "reorder_items",
          "format_explanation",
          "_inject_setup_teardown_fixtures",
          "is_capturing",
          "iter_markers_with_node",
          "_getfailureheadline",
          "append_pass",
          "chdir",
          "pytest_pycollect_makemodule",
          "_WithException",
          "exec_module",
          "LFPluginCollSkipfiles",
          "category",
          "ParseError",
          "builtin_plugins",
          "fail",
          "readlines",
          "FDCapture",
          "EMPTY_BUFFER",
          "RaisesContext",
          "_collect",
          "__str__",
          "from_current",
          "_initrequest",
          "handleError",
          "reorder_items_atscope",
          "_makeitem",
          "xfail",
          "start_capturing",
          "with_args",
          "nextitem",
          "set_level",
          "Expression",
          "_getscopeitem",
          "SysCapture",
          "MINUS_K_DASH",
          "merge_family",
          "tb",
          "_is_marked_for_rewrite",
          "_is_skipped",
          "fixtures",
          "_matches_prefix_or_glob_option",
          "pytest_runtest_protocol",
          "get_empty_parameterset_mark",
          "_disable_output_capturing_for_darwin",
          "_non_printable_ascii_translate_table",
          "DOCTEST_REPORT_CHOICE_NDIFF",
          "pytest_report_from_serializable",
          "LEVELNAME_FMT_REGEX",
          "lineno",
          "importorskip",
          "iscoroutinefunction",
          "_addfinalizer",
          "OK",
          "Item",
          "append_collect_skipped",
          "pytest_make_collect_report",
          "_PluggyPlugin",
          "writer",
          "disabled",
          "MultipleDoctestFailures",
          "_outrep_summary",
          "capsys",
          "__all__",
          "USAGE_ERROR",
          "Store",
          "Junit",
          "_W",
          "TestReport",
          "_find_spec",
          "fix_cache_order",
          "__getattr__",
          "File",
          "_markers",
          "sections",
          "_from_json",
          "__array_ufunc__",
          "UnformattedWarning",
          "skipping",
          "_early_rewrite_bailout",
          "fixturenames",
          "ReprEntryNative",
          "_set_initial_conftests",
          "_CACHE_PREFIX_VALUES",
          "showheader",
          "stream",
          "fromdictargs",
          "runtest",
          "hasplugin",
          "ExceptionInfo",
          "get_plugin_manager",
          "no_summary",
          "name",
          "_make_plural",
          "scopeproperty",
          "add_global_property",
          "append",
          "obj",
          "FuncFixtureInfo",
          "visit_Attribute",
          "extraline",
          "_compare_eq_verbose",
          "longrepr",
          "helpconfig",
          "Code",
          "_preparse",
          "_import_pdb_cls",
          "_inject_setup_function_fixture",
          "excinfo",
          "gethookrecorder",
          "pytestPDB",
          "hasnew",
          "_set_main_color",
          "pytest_fixture_setup",
          "parse_num",
          "store_mark",
          "_init_runner_class",
          "global_and_fixture_disabled",
          "generic_visit",
          "_addoption",
          "faulthandler",
          "ApproxScalar",
          "_makepath",
          "getnode",
          "call_fixture_func",
          "_get_increasing_order",
          "listextrakeywords",
          "getstatement",
          "raiseerror",
          "set_log_path",
          "location",
          "width_of_current_line",
          "parse_args",
          "__eq__",
          "getfixturemarker",
          "get_optionflags",
          "derive_importpath",
          "LineMatcher_fixture",
          "stop_capturing",
          "nose",
          "_get_pdb_wrapper_class",
          "call_optional",
          "register_cleanup_lock_removal",
          "flush",
          "get_direct_param_fixture_func",
          "summary_stats",
          "deprecated",
          "EncodedFile",
          "reason",
          "finish_recording",
          "TerminalRepr",
          "duration",
          "__enter__",
          "_repr_failure_py",
          "caplog_records_key",
          "pytest_runtest_logstart",
          "_format_action_invocation",
          "ColoredLevelFormatter",
          "_get_report_choice",
          "classnamefilter",
          "_code",
          "SysCaptureBinary",
          "freeze_support",
          "setenv",
          "_finalize",
          "pytest_runtest_logfinish",
          "_get_multicapture",
          "teardown_nose",
          "AssertionState",
          "isset",
          "pytest_exception_interact",
          "__call__",
          "_py_ext_re",
          "NODE_USE_FROM_PARENT",
          "catching_logs",
          "default_plugins",
          "cached_result",
          "TERMINALWRITER_WRITER",
          "FakeCollectModule",
          "build_summary_stats_line",
          "runpytest",
          "getreports",
          "_idvalset",
          "readouterr",
          "tolerance",
          "_printcollecteditems",
          "funcargnames",
          "parse_known_args",
          "PyobjMixin",
          "addSuccess",
          "helper",
          "DEPRECATED_EXTERNAL_PLUGINS",
          "_perform_collect",
          "COLLECT_FAKEMODULE_ATTRIBUTES",
          "repr",
          "_factorytraceback",
          "get_terminal_width",
          "getfslineno",
          "visit_BoolOp",
          "rewrite_asserts",
          "stopTest",
          "getreportopt",
          "Testdir",
          "_postmortem_traceback",
          "DOCTEST_REPORT_CHOICES",
          "fillfixtures",
          "scopenum_function",
          "OR",
          "resolve_from_str",
          "assert_never",
          "report_collect",
          "_split_lines",
          "cacheshow",
          "_show_fixture_action",
          "_FixtureCachedResult",
          "resume_fixture",
          "inline_run",
          "safe_getattr",
          "NO_TESTS_COLLECTED",
          "call_and_report",
          "isattrs",
          "stop",
          "inline_runsource",
          "close",
          "_get_allow_bytes_flag",
          "_makefile",
          "ensure_newline",
          "_parse_parametrize_parameters",
          "patchsysdict",
          "_compare_eq_dict",
          "rm_rf",
          "MultiCapture",
          "Failed",
          "get_last_failed_paths",
          "write",
          "_write_content",
          "_sys_snapshot",
          "TempPathFactory",
          "_validate_usepdb_cls",
          "makepyprojecttoml",
          "emit",
          "getfailures",
          "cmdline",
          "version",
          "_recurse",
          "_saved",
          "DOCTEST_REPORT_CHOICE_UDIFF",
          "CwdSnapshot",
          "PseudoFixtureDef",
          "_esctable",
          "CaptureManager",
          "annotated_getattr",
          "write_captured_output",
          "filter_traceback_for_conftest_import_failure",
          "hookspec",
          "perform_collect",
          "_consider_importhook",
          "fullwidth",
          "_compare_eq_iterable",
          "COLLECT_DIRECTORY_HOOK",
          "getfixturevalue",
          "Interrupted",
          "set",
          "resume_capturing",
          "_addexcinfo",
          "_warn_already_imported",
          "Cache",
          "_call_with_optional_argument",
          "setitem",
          "addSkip",
          "_assertion_pass",
          "scope",
          "failed",
          "approx",
          "_bytes_to_ascii",
          "short_test_summary",
          "_version",
          "LOGLEVEL_COLOROPTS",
          "finalize",
          "ensure_deletable",
          "pytest_make_parametrize_id",
          "_fail",
          "_call_reprcompare",
          "LsofFdLeakChecker",
          "getinicfg",
          "_pluginmanager",
          "pos",
          "node",
          "_names",
          "HookRecorder",
          "_getentrysource",
          "should_do_markup",
          "Scanner",
          "resolve_package_path",
          "head_line",
          "_FileHandler",
          "_enter_pdb",
          "finish",
          "saferepr",
          "message",
          "showversion",
          "add_funcarg_pseudo_fixture_def",
          "ExceptionRepr",
          "PYC_EXT",
          "addfinalizer",
          "_parse_parametrize_args",
          "_get_line_with_reprcrash_message",
          "initialnames",
          "pytest_load_initial_conftests",
          "MARK_GEN",
          "str",
          "record_testreport",
          "_do_configure",
          "families",
          "repr_failure",
          "ApproxSequencelike",
          "resolve",
          "format_session_duration",
          "messages",
          "IDENT_PREFIX",
          "_check_all_skipped",
          "get_terminal_writer",
          "maybe_wrap_pytest_function_for_tracing",
          "Class",
          "countoutcomes",
          "_cachedir",
          "update_testcase_duration",
          "getpathnode",
          "_striptext",
          "parse",
          "_create_formatter",
          "teardown",
          "_locationline",
          "_LiveLoggingNullHandler",
          "_LiveLoggingStreamHandler",
          "sep",
          "fault_handler_stderr_key",
          "_get_allow_unicode_flag",
          "recursionindex",
          "pytest_generate_tests",
          "raises",
          "pytest_cmdline_preparse",
          "pytest_runtest_makereport",
          "Function",
          "_get_teardown_reports",
          "pytest_assertrepr_compare",
          "ReprTraceback",
          "directory_arg",
          "_diff_text",
          "markup",
          "on_rm_rf_error",
          "caplog",
          "matching_platform",
          "get_records",
          "Config",
          "_getini",
          "Exception",
          "reports",
          "_ensure_basetemp",
          "_compare_eq_any",
          "_collectfile",
          "_legal_chars",
          "_check_initialpaths_for_relpath",
          "_matchnodes",
          "type",
          "TerminalWriter",
          "pytest_runtest_setup",
          "PYTESTER_COPY_EXAMPLE",
          "spawn_pytest",
          "hasopt",
          "fspath",
          "pytestconfig",
          "MarkDecorator",
          "add_cleanup",
          "MonkeyPatch",
          "tmp_path",
          "WARNING_CAPTURED_HOOK",
          "setdefault",
          "DoctestModule",
          "_try_load_conftest",
          "_log",
          "undo",
          "showlocals",
          "_to_json",
          "from_item_and_call",
          "TimeoutExpired",
          "source",
          "_prunetraceback",
          "runpython",
          "xfailed_key",
          "_validate_ids",
          "getcalls",
          "restore",
          "DEFAULT_MAX_CHARS",
          "CaptureFixture",
          "_suspend",
          "from_parent",
          "_setupstate",
          "OptionGroup",
          "_checkversion",
          "attrs",
          "safeformat",
          "CHECKER_CLASS",
          "find_spec",
          "get_statement_startend2",
          "try_makedirs",
          "old_mark_config_key",
          "_for_parametrize",
          "Token",
          "from_exc_info",
          "extract_from",
          "cut",
          "_checkargnotcontained",
          "setupplan",
          "parse_setoption",
          "prepare",
          "_match_lines",
          "_iter_rewritable_modules",
          "CallSpec2",
          "reportinfo",
          "dir",
          "fnmatch_lines_random",
          "findsource",
          "README_CONTENT",
          "_validate_keys",
          "PytestPluginManager",
          "warning_record_to_str",
          "_rget_with_confmod",
          "_setup_fixtures",
          "tbfilter",
          "from_config",
          "console_main",
          "lex",
          "capstderr",
          "_node_location_to_relpath",
          "FixtureRequest",
          "__attrs_post_init__",
          "mark_rewrite",
          "toterminal",
          "_rewrite_test",
          "timing",
          "getparent",
          "parts",
          "INTERNAL_ERROR",
          "isiterable",
          "statement",
          "suspend",
          "NFPlugin",
          "JUNIT_XML_DEFAULT_FAMILY",
          "truncate_locals",
          "record_property",
          "reprlocals",
          "_matchfactories",
          "__delitem__",
          "TempdirFactory",
          "getvalueorskip",
          "__iter__",
          "no_header",
          "_getobj",
          "to_xml",
          "capture",
          "DoctestItem",
          "getrepr",
          "_showfixtures_main",
          "_patch_unwrap_mock_aware",
          "_report_keyboardinterrupt",
          "hookimpl",
          "ApproxMapping",
          "assertstate_key",
          "pytest_itemcollected",
          "wrap_session",
          "PrintHelp",
          "repr_traceback",
          "outcomes",
          "mkdir",
          "_AnyPurePath",
          "LFPluginCollWrapper",
          "strip",
          "pytest_runtestloop",
          "exitstatus",
          "Instance",
          "setup",
          "__array_priority__",
          "run",
          "UsageError",
          "STRING_TYPES",
          "filter",
          "__ne__",
          "_warn_incompatibility_with_xunit2",
          "maketxtfile",
          "_get_runner",
          "_schedule_finalizers",
          "make_hook_recorder",
          "_pytest",
          "frame",
          "RE_IMPORT_ERROR_NAME",
          "makeini",
          "deselect_by_mark",
          "append_skipped",
          "listchain",
          "CLOSE_STDIN",
          "resolve_fixture_function",
          "pytest_runtest_teardown",
          "formatrepr",
          "warnings",
          "_get_override_ini_value",
          "name2fixturedefs",
          "ReprLocals",
          "set_session",
          "encoding",
          "getplugin",
          "ApproxNumpy",
          "strict",
          "_inject_setup_method_fixture",
          "Notset",
          "collect_by_name",
          "addError",
          "collect_one_node",
          "_expecting_failure",
          "pytest_ignore_collect",
          "_get_direct_parametrize_args",
          "_mark_plugins_for_rewrite",
          "_fillfixtures",
          "Source",
          "filename_arg",
          "context",
          "_prepareconfig",
          "section",
          "PytestWarning",
          "_add_stats",
          "ascii_escaped",
          "_compare_eq_sequence",
          "when",
          "_recursive_list_map",
          "_pop_and_teardown",
          "done",
          "addExpectedFailure",
          "_should_repr_global_name",
          "reprentries",
          "args",
          "_seen",
          "__module__",
          "_get_unknown_ini_keys",
          "_ensure_unconfigure",
          "_format_args",
          "get_lock_path",
          "mark",
          "simple",
          "show_fixtures_per_test",
          "_running_on_ci",
          "isinitpath",
          "_report_kwargs_from_json",
          "Traceback",
          "Mark",
          "summary_warnings",
          "_iter_all_modules",
          "pytest_sessionstart",
          "path_matches_patterns",
          "makeconftest",
          "reject",
          "cache_dir_from_config",
          "tracebackcutdir",
          "write_log_entry",
          "ApproxBase",
          "TYPE_CHECKING",
          "_excinfo",
          "set_location",
          "DontReadFromInput",
          "pytest_sessionfinish",
          "fill_unfilled",
          "scopename2class",
          "_PYTEST_DIR",
          "visit_Call",
          "_callfinalizers",
          "ImportMode",
          "D",
          "errisinstance",
          "_init_checker_class",
          "__exit__",
          "_assert_state",
          "make_properties_node",
          "result",
          "config",
          "_is_last_item",
          "get_exconly",
          "_traceback",
          "item_capture",
          "assign",
          "_get_fixturestack",
          "_check_scope",
          "reprfuncargs",
          "repr_excinfo",
          "execute",
          "LineComp",
          "tmpdir",
          "pytest_keyboard_interrupt",
          "keywords",
          "AND",
          "linecomp",
          "scope2index",
          "_parse_ini_config",
          "KNOWN_TYPES",
          "_PytestWrapper",
          "get_option_ini",
          "__next__",
          "nodeid",
          "get_parametrized_fixture_keys",
          "parseoutcomes",
          "__dir__",
          "pytest_addoption",
          "PdbTrace",
          "names",
          "ExceptionChainRepr",
          "repr_instance",
          "fnmatch_lines",
          "consider_preparse",
          "matchnodes",
          "record_testsuite_property",
          "_update_current_test_var",
          "LPAREN",
          "_legal_xml_re",
          "parse_known_and_unknown_args",
          "_ANSI_ESCAPE_SEQ",
          "pytest_internalerror",
          "pytester",
          "re_match_lines_random",
          "_split_explanation",
          "PYTEST_COLLECT_MODULE",
          "pytest_warning_captured",
          "mkpydir",
          "_argcomplete",
          "IDENT",
          "logging",
          "xml_key",
          "PytestCollectionWarning",
          "__init__",
          "nofuncargs",
          "syspathinsert",
          "CollectReport",
          "HelpAction",
          "_non_numeric_type_error",
          "_assert_start_repr",
          "_visit_filter",
          "summary_failures",
          "getfixtureclosure",
          "extract_suffixes",
          "suspend_fixture",
          "mktemp",
          "PyCollector",
          "get_real_func",
          "SysModulesSnapshot",
          "get_log_level_for_setting",
          "invocation_dir",
          "not_expr",
          "get_fslocation_from_item",
          "listoutcomes",
          "EOF",
          "get",
          "pytest_unconfigure",
          "_start",
          "scope2props",
          "_mk_tmp",
          "_FixtureFunc",
          "_initini",
          "consider_conftest",
          "addinivalue_line",
          "KeywordMatcher",
          "_match_lines_random",
          "_trace",
          "entrysep",
          "SubRequest",
          "_get_active_fixturedef",
          "_NodeType",
          "_ensure_removed_sysmodule",
          "suspend_capturing",
          "style",
          "parse_summary_nouns",
          "_compare_eq_cls",
          "setattr",
          "check_testcase_implements_trial_reporter",
          "doctest_namespace",
          "_parsearg",
          "_param_ids_from",
          "id",
          "_FixtureValue",
          "OutcomeException",
          "getparam",
          "_is_capturing",
          "consider_env",
          "copy_example",
          "get_real_method",
          "_notin_text",
          "istestfunc",
          "indent",
          "delenv",
          "filter_traceback",
          "normalize_mark_list",
          "_getnextfixturedef",
          "popen",
          "idmaker",
          "consider_pluginarg",
          "copy",
          "CollectErrorRepr",
          "yield_fixture",
          "truncate_if_required",
          "_get_first_non_fixture_func",
          "DummyRewriteHook",
          "spawn",
          "_param_ids_generated",
          "display",
          "template",
          "_get_continue_on_failure",
          "K",
          "prog",
          "setuponly",
          "_resume",
          "NotSetType",
          "freeze_includes",
          "unset_fixture",
          "ApproxDecimal",
          "_readline_workaround",
          "lines",
          "record_xml_attribute",
          "ReprEntry",
          "make_numbered_dir",
          "_write_entry_lines",
          "Argument",
          "warning_types",
          "safe_isclass",
          "INTERRUPTED",
          "relline",
          "_PY_DIR",
          "is_potential_nosetest",
          "WarningsChecker",
          "fail_marker",
          "getitems",
          "Skip",
          "addsection",
          "_getparser",
          "parse_hookspec_opts",
          "find_prefixed",
          "ArgumentError",
          "_check_record_param_type",
          "get_sections",
          "getrawcode",
          "recwarn",
          "terminal",
          "visit_Compare",
          "Package",
          "pytest_pyfunc_call",
          "get_location",
          "push_format_context",
          "CallInfo",
          "pytest_report_header",
          "showhelp",
          "expression",
          "MatcherAdapter",
          "getworkerinfoline",
          "_is_setup_py",
          "pop",
          "TokenType",
          "_init_pdb",
          "import_plugin",
          "astcache",
          "conftest_options",
          "_teardown_towards",
          "Parser",
          "_find_parametrized_scope",
          "ensure_extended_length_path",
          "nodes",
          "catch_warnings_for_item",
          "MyOptionParser",
          "inline_genitems",
          "matchreport",
          "_Markable",
          "getpluginversioninfo",
          "make_numbered_dir_with_cleanup",
          "_write_pyc_fp",
          "delitem",
          "V",
          "scopes",
          "get_lines_after",
          "assert_contains",
          "get_config",
          "__missing__",
          "visit_Name",
          "ReprFailDoctest",
          "pytest_cmdline_parse",
          "REGEX_TYPE",
          "ParsedCall",
          "for_later",
          "CaptureResult",
          "_inject_setup_module_fixture",
          "TeeCaptureIO",
          "add_property",
          "resultlog_key",
          "get_extended_length_path_str",
          "prepend",
          "compile",
          "__version__",
          "USAGE_MSG",
          "MODULE_NOT_FOUND_ERROR",
          "NoMatch",
          "BASE_TYPE",
          "_is_numpy_array",
          "_args_converter",
          "write_sep",
          "exconly",
          "newinstance",
          "_getpytestargs",
          "read_global_capture",
          "_get_progress_information_message",
          "teardown_all",
          "_set_opt_strings",
          "_saferepr",
          "PytestAssertRewriteWarning",
          "ReprFileLocation",
          "_config_for_test",
          "_io",
          "Collector",
          "_resolve_arg_ids",
          "_idval",
          "TracebackEntry",
          "PytestConfigWarning",
          "cache_key",
          "TEST_OUTCOME",
          "NOT",
          "funcargs",
          "main",
          "capsysbinary",
          "_state",
          "LOCK_TIMEOUT",
          "_F",
          "activate_fixture",
          "evaluate_skip_marks",
          "_ensure_immutable_ids",
          "parseconfig",
          "pytest_enter_pdb",
          "_has_param_ids",
          "NodeMeta",
          "getfixtureinfo",
          "getargs",
          "getvalue",
          "BINOP_MAP",
          "_truncate_explanation",
          "_T",
          "get_cache_dir",
          "ReprExceptionInfo",
          "_ellipsize",
          "prune_dependency_tree",
          "getoption",
          "_get_stderr_fileno",
          "_getconftest_pathlist",
          "PytestUnknownMarkWarning",
          "flow_marker",
          "try_cleanup",
          "fixture",
          "__hash__",
          "_importconftest",
          "FixtureLookupError",
          "_ensure_relative_to_basetemp",
          "get_data",
          "DropShorterLongHelpFormatter",
          "write_fspath_result",
          "capfdbinary",
          "isdict",
          "_check_non_top_pytest_plugins",
          "_compute_fixture_value",
          "get_user",
          "start_global_capturing",
          "LineMatcher",
          "for_config",
          "ihook",
          "Session",
          "_surrounding_parens_on_own_lines",
          "ReprTracebackNative",
          "_assert_expr_to_lineno",
          "FIXTURE_POSITIONAL_ARGUMENTS",
          "ParameterSet",
          "locate_config",
          "listnames",
          "caplog_handler_key",
          "_report_to_json",
          "plugins",
          "create_cleanup_lock",
          "_with_exception",
          "assertrepr_compare",
          "param",
          "pytest_collectreport",
          "_pformat_dispatch",
          "assertion",
          "instance",
          "_NodeReporter",
          "is_globally_capturing",
          "install_importhook",
          "collect",
          "and_expr",
          "is_rewrite_disabled",
          "pytest_leave_pdb",
          "pytest_fixture_post_finalizer",
          "pytest_collection",
          "_plugin_nameversions",
          "_dump_lines",
          "skipped",
          "_typ_map",
          "processoption",
          "_is_mocked",
          "unittest",
          "kwargs",
          "FastFilesCompleter",
          "_format",
          "abspath",
          "getsource",
          "handler",
          "pytest_collectstart",
          "snap",
          "_color_for_type",
          "_colorama_workaround",
          "_config",
          "_read_pyc",
          "params",
          "_compare_eq_set",
          "stop_global_capturing",
          "TestCaseFunction",
          "testdir",
          "istext",
          "register_assert_rewrite",
          "register",
          "fslocation",
          "async_warn_and_skip",
          "_truncate_by_char_count",
          "own_mark_names",
          "__take_sys_modules_snapshot",
          "getcall",
          "_should_rewrite",
          "fail_fixturefunc",
          "traceback",
          "_check_type",
          "visit_Assert",
          "consider_module",
          "autouse",
          "stepwise",
          "visit_BinOp",
          "TerminalReporter",
          "_get_global_properties_node",
          "create_new_paste",
          "CollectError",
          "_get_checker",
          "get_scope_package",
          "runitem",
          "runpytest_inprocess",
          "set_trace",
          "_teardown_yield_fixture",
          "_py36_windowsconsoleio_workaround",
          "FSHookProxy",
          "NoCapture",
          "FunctionDefinition",
          "LFPlugin",
          "capstdout",
          "doctest",
          "_check_if_assertion_pass_impl",
          "_ensure_supporting_files",
          "variable",
          "CACHEDIR_TAG_CONTENT",
          "summary_passes",
          "_resolve_arg_value_types",
          "get_closest_marker",
          "pytest_configure",
          "ResultLog",
          "showlongtestinfo",
          "append_failure",
          "importlib",
          "rewrite",
          "deindent",
          "add_marker",
          "RunResult",
          "typename",
          "runpython_c",
          "from_item",
          "SysPathsSnapshot",
          "RESULT_LOG",
          "NodeKeywords",
          "evaluate",
          "_REPORTCHARS_DEFAULT",
          "Skipped",
          "PYTEST_TAG",
          "Module",
          "FixtureLookupErrorRepr",
          "exit",
          "pop_format_context",
          "monkeypatch",
          "LogCaptureFixture",
          "pytest_collect_directory",
          "ischildnode",
          "python",
          "_tmppath_factory",
          "wcswidth",
          "fnmatch_ex",
          "_Key",
          "_wrapped_pdb_cls",
          "get_unpacked_marks",
          "_splitnode",
          "CaptureIO",
          "getlocation",
          "pytest_runtest_logreport",
          "format",
          "applymarker",
          "get_public_names",
          "_given_basetemp",
          "cache",
          "validate_basetemp",
          "skipped_by_mark_key",
          "makefile",
          "SafeRepr",
          "from_call",
          "writeorg",
          "_E",
          "match",
          "token",
          "popcall",
          "_no_match_line",
          "determine_setup",
          "_should_truncate_item",
          "FixtureFunctionMarker",
          "_PLUGGY_DIR",
          "suspend_global_capture",
          "pytest_assertion_pass",
          "_highlight",
          "reset",
          "Exit",
          "parseconfigure",
          "teardown_exact",
          "_get_pos",
          "gethookproxy",
          "_genfunctions",
          "_get_auto_indent",
          "addoption",
          "DOCTEST_REPORT_CHOICE_NONE",
          "getini",
          "explanation_param",
          "get_timeout_config_value",
          "cls",
          "check_interactive_exception",
          "runpytest_subprocess",
          "rex_outcome",
          "summary_errors",
          "pytest_pycollect_makeitem",
          "_gethookproxy",
          "visit_Starred",
          "_ET",
          "parsefactories",
          "_main",
          "getcrashentry",
          "locals",
          "post_mortem",
          "parse_hookimpl_opts",
          "append_error",
          "re_match_lines",
          "_call_assertion_pass",
          "runtestprotocol",
          "_recursive_debug",
          "write_docstring",
          "assertoutcome",
          "pytest_addhooks",
          "pytest_collect_file",
          "_get_verbose_word",
          "version_tuple",
          "_HandlerType",
          "FUNCARGNAMES",
          "assert_contains_lines",
          "repr_traceback_entry",
          "count_towards_summary",
          "_importtestmodule",
          "_getconftestmodules",
          "get_open_files",
          "_reprcompare",
          "_parse_filter",
          "ReprFuncArgs",
          "wcwidth",
          "_ascii_escaped_by_config",
          "iter_markers",
          "_get_plugin_specs_as_list",
          "Xfail",
          "wrap_function_to_error_out_if_called_directly",
          "_format_assertmsg",
          "ids",
          "_handle_teardown_sections",
          "_warn_about_missing_assertion",
          "_show_fixtures_per_test",
          "start",
          "_write_source",
          "LoggingPlugin",
          "_determine_main_color",
          "_force_symlink",
          "FSCollector",
          "Frame",
          "_try_repr_or_str",
          "_folded_skips",
          "log_outcome",
          "_log_cli_enabled",
          "IGNORE_PAM",
          "getmodulecol",
          "UNARY_MAP",
          "load_config_dict_from_file",
          "eval",
          "set_repr_style",
          "_ALLOW_MARKERS",
          "RUNNER_CLASS",
          "_fixturemanager",
          "is_generator",
          "set_fixture",
          "get_common_ancestor",
          "PdbInvoke",
          "__contains__",
          "deactivate_fixture",
          "PercentStyleMultiline",
          "MarkMatcher",
          "getimfunc",
          "get_dirs_from_args",
          "_assertion_supported",
          "resume",
          "_create",
          "longreprtext",
          "runner",
          "exprinfo",
          "compat",
          "Metafunc",
          "_pyfuncitem",
          "issequence",
          "DEFAULT_RELATIVE_TOLERANCE",
          "pytest_deselected",
          "REPORT_COLLECTING_RESOLUTION",
          "pytest_runtest_call",
          "FILLFUNCARGS",
          "_validate_args",
          "WarningReport",
          "module",
          "record_tuples",
          "isatty",
          "cleanup_numbered_dir",
          "getbasetemp",
          "scopemismatch",
          "find_suffixes",
          "DEFAULT_LOG_DATE_FORMAT",
          "show_test_item",
          "illegal_xml_re",
          "FDCaptureBinary",
          "store",
          "XFailed",
          "PytestUnhandledCoroutineWarning",
          "_get_main_color",
          "no_fnmatch_line",
          "MarkGenerator",
          "_R",
          "addUnexpectedSuccess",
          "UnitTestCase",
          "pytest_report_teststatus",
          "line",
          "StoreKey",
          "__test__",
          "_result",
          "_getlines",
          "getgroup",
          "showfixtures",
          "capfd",
          "_write_report_lines_from_hooks",
          "create_terminal_writer",
          "_remove_ansi_escape_sequences",
          "pytest_terminal_summary",
          "_get_number_flag",
          "CFG_PYTEST_SECTION",
          "EMPTY_PARAMETERSET_OPTION",
          "is_async_function",
          "AlwaysDispatchingPrettyPrinter",
          "print_teardown_sections",
          "wrap_pytest_function_for_tracing",
          "warns",
          "builtin",
          "verbosity",
          "DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE",
          "LogCaptureHandler",
          "_approx_scalar",
          "create_module",
          "pytest_report_collectionfinish",
          "resume_global_capture",
          "_S",
          "maybe_delete_a_numbered_dir",
          "_params_converter",
          "import_path",
          "DEFAULT_ABSOLUTE_TOLERANCE",
          "text",
          "at_level",
          "passed",
          "resultlog",
          "tmp_path_factory",
          "argnames",
          "call_runtest_hook",
          "_processopt",
          "pastebinfile_key",
          "getstatementrange",
          "makepyfile",
          "reprtraceback",
          "_is_doctest",
          "SetupState",
          "_prepare_content",
          "pathlib",
          "_addoption_instance",
          "notset",
          "value",
          "PytestCacheWarning",
          "get_source",
          "read",
          "function",
          "_format_repr_exception",
          "add_attribute",
          "_runtest_for",
          "junitxml",
          "istestclass",
          "startTest",
          "deselect_by_keyword",
          "AssertionRewritingHook",
          "bin_xml_escape",
          "PYC_TAIL",
          "assert_outcomes",
          "LogXML",
          "isdatacls",
          "StepwisePlugin",
          "_validate_plugins",
          "TESTS_FAILED",
          "debugging",
          "essential_plugins",
          "session",
          "__repr__",
          "pytest_cmdline_main",
          "_translate_non_printable",
          "cwd_relative_nodeid",
          "_getvaluepath",
          "_determine_show_progress_info",
          "deprecated_call",
          "chain",
          "repr_locals",
          "_in_suspended",
          "get_default_arg_names",
          "names_closure",
          "DoctestTextfile",
          "syspath_prepend",
          "_validate_if_using_arg_names",
          "visit_UnaryOp",
          "pop_outerr_to_orig",
          "FILE_OR_DIR",
          "mode",
          "expr",
          "ExitCode",
          "DEFAULT_MAX_LINES",
          "error",
          "_get_assertion_exprs",
          "unexpectedsuccess_key",
          "_teardown_with_finalization",
          "parametrize",
          "_format_lines",
          "_report_unserialization_failure",
          "path",
          "_warn_or_fail_if_strict",
          "PytestDeprecationWarning",
          "genitems",
          "_eval_scope_callable",
          "clear"
        ]
      },
      "response": {
        "keywords": [
          "pytest",
          "xfail",
          "request",
          "mark",
          "add_marker",
          "FixtureRequest",
          "evaluate_xfail_marks",
          "pytest_runtest_makereport",
          "pytest_exception_interact",
          "pytest_runtest_protocol"
        ]
      }
    },
    {
      "name": "FilesKeywordSearch",
      "metadata": {
        "start": "2024-08-17T22:23:40.176506",
        "usage": "175.26888847351074 ms"
      },
      "request": {
        "tokens": [
          "pytest",
          "xfail",
          "request",
          "mark",
          "add_marker",
          "FixtureRequest",
          "evaluate_xfail_marks",
          "pytest_runtest_makereport",
          "pytest_exception_interact",
          "pytest_runtest_protocol"
        ]
      },
      "response": {
        "results": {
          "pytest": [
            "src/_pytest/pastebin.py",
            "src/_pytest/runner.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/recwarn.py",
            "src/_pytest/mark/expression.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/stepwise.py",
            "src/_pytest/logging.py",
            "src/pytest/collect.py",
            "src/_pytest/warnings.py",
            "src/pytest/__main__.py",
            "src/_pytest/doctest.py",
            "src/_pytest/debugging.py",
            "src/pytest/__init__.py",
            "src/_pytest/pytester.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/freeze_support.py",
            "src/_pytest/skipping.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/assertion/util.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/config/exceptions.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/capture.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/setupplan.py",
            "src/_pytest/deprecated.py",
            "src/_pytest/config/findpaths.py",
            "src/_pytest/python_api.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/nodes.py",
            "src/_pytest/timing.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/main.py",
            "src/_pytest/config/argparsing.py",
            "src/_pytest/warning_types.py",
            "src/_pytest/unittest.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/terminal.py",
            "src/_pytest/compat.py",
            "src/_pytest/reports.py",
            "src/_pytest/monkeypatch.py",
            "src/_pytest/python.py"
          ],
          "FixtureRequest": [
            "src/_pytest/logging.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/unittest.py",
            "src/_pytest/doctest.py",
            "src/_pytest/python.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/pytester.py"
          ],
          "request": [
            "src/_pytest/logging.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/runner.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/unittest.py",
            "src/_pytest/capture.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/pytester.py",
            "src/_pytest/setupplan.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/python.py"
          ],
          "mark": [
            "src/_pytest/python_api.py",
            "src/_pytest/skipping.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/nodes.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/warnings.py",
            "src/_pytest/warning_types.py",
            "src/pytest/__init__.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/python.py"
          ],
          "pytest_runtest_protocol": [
            "src/_pytest/runner.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/main.py",
            "src/_pytest/warnings.py",
            "src/_pytest/unittest.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/pytester.py"
          ],
          "xfail": [
            "src/_pytest/skipping.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/unittest.py",
            "src/pytest/__init__.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/python.py"
          ],
          "evaluate_xfail_marks": [
            "src/_pytest/skipping.py"
          ],
          "pytest_runtest_makereport": [
            "src/_pytest/unittest.py",
            "src/_pytest/skipping.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/runner.py"
          ],
          "pytest_exception_interact": [
            "src/_pytest/debugging.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/runner.py",
            "src/_pytest/faulthandler.py"
          ],
          "add_marker": [
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/fixtures.py"
          ]
        }
      }
    },
    {
      "name": "FilesFilter",
      "metadata": {
        "start": "2024-08-17T22:23:40.351784",
        "usage": "6108.199834823608 ms"
      },
      "request": {
        "keyword_search_results": {
          "pytest": [
            "src/_pytest/pastebin.py",
            "src/_pytest/runner.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/recwarn.py",
            "src/_pytest/mark/expression.py",
            "src/_pytest/_code/code.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/stepwise.py",
            "src/_pytest/logging.py",
            "src/pytest/collect.py",
            "src/_pytest/warnings.py",
            "src/pytest/__main__.py",
            "src/_pytest/doctest.py",
            "src/_pytest/debugging.py",
            "src/pytest/__init__.py",
            "src/_pytest/pytester.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/freeze_support.py",
            "src/_pytest/skipping.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/assertion/util.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/config/exceptions.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/pathlib.py",
            "src/_pytest/capture.py",
            "src/_pytest/assertion/rewrite.py",
            "src/_pytest/setupplan.py",
            "src/_pytest/deprecated.py",
            "src/_pytest/config/findpaths.py",
            "src/_pytest/python_api.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/nodes.py",
            "src/_pytest/timing.py",
            "src/_pytest/helpconfig.py",
            "src/_pytest/main.py",
            "src/_pytest/config/argparsing.py",
            "src/_pytest/warning_types.py",
            "src/_pytest/unittest.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/terminal.py",
            "src/_pytest/compat.py",
            "src/_pytest/reports.py",
            "src/_pytest/monkeypatch.py",
            "src/_pytest/python.py"
          ],
          "FixtureRequest": [
            "src/_pytest/logging.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/unittest.py",
            "src/_pytest/doctest.py",
            "src/_pytest/python.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/pytester.py"
          ],
          "request": [
            "src/_pytest/logging.py",
            "src/_pytest/pastebin.py",
            "src/_pytest/runner.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/cacheprovider.py",
            "src/_pytest/setuponly.py",
            "src/_pytest/unittest.py",
            "src/_pytest/capture.py",
            "src/_pytest/tmpdir.py",
            "src/_pytest/pytester.py",
            "src/_pytest/setupplan.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/python.py"
          ],
          "mark": [
            "src/_pytest/python_api.py",
            "src/_pytest/skipping.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/nodes.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/config/__init__.py",
            "src/_pytest/warnings.py",
            "src/_pytest/warning_types.py",
            "src/pytest/__init__.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/fixtures.py",
            "src/_pytest/python.py"
          ],
          "pytest_runtest_protocol": [
            "src/_pytest/runner.py",
            "src/_pytest/faulthandler.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/main.py",
            "src/_pytest/warnings.py",
            "src/_pytest/unittest.py",
            "src/_pytest/assertion/__init__.py",
            "src/_pytest/pytester.py"
          ],
          "xfail": [
            "src/_pytest/skipping.py",
            "src/_pytest/mark/__init__.py",
            "src/_pytest/outcomes.py",
            "src/_pytest/junitxml.py",
            "src/_pytest/unittest.py",
            "src/pytest/__init__.py",
            "src/_pytest/mark/structures.py",
            "src/_pytest/python.py"
          ],
          "evaluate_xfail_marks": [
            "src/_pytest/skipping.py"
          ],
          "pytest_runtest_makereport": [
            "src/_pytest/unittest.py",
            "src/_pytest/skipping.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/runner.py"
          ],
          "pytest_exception_interact": [
            "src/_pytest/debugging.py",
            "src/_pytest/hookspec.py",
            "src/_pytest/runner.py",
            "src/_pytest/faulthandler.py"
          ],
          "add_marker": [
            "src/_pytest/nodes.py",
            "src/_pytest/python.py",
            "src/_pytest/fixtures.py"
          ]
        }
      },
      "response": {
        "scratch_pad": "To tackle the reported issue with dynamically adding an xfail marker in pytest 6, we need to identify the parts of the codebase related to the xfail functionality, the addition of markers, and any related components such as the nodes or fixture requests.\n\n1. **Relevant Keywords from the Issue:**\n   - pytest\n   - request\n   - mark\n   - xfail\n   - add_marker\n   - FixtureRequest\n\n2. **Initial Keywords and Matching Files:**\n   - `pytest`: It is very generic and appears in numerous files.\n   - `FixtureRequest`: Handles fixture requests, might be indirectly related.\n   - `request`: Also generic but might help trace the execution flow.\n   - `mark`: We are interested in how marks are handled or altered dynamically.\n   - `xfail`: Central to the issue of marking tests to fail.\n   - `add_marker`: Specifically involves adding markers, which is crucial to the issue.\n\n3. **Files of Interest Based on Specific Keywords:**\n   - `src/_pytest/mark/structures.py`: Likely defines marker structures, crucial for understanding how `xfail` is processed.\n   - `src/_pytest/mark/__init__.py`: May include initialization and handling of mark functionalities.\n   - `src/_pytest/skipping.py`: Mentioned with `xfail` and `evaluate_xfail_marks`, likely relevant for conditional skipping based on marks.\n   - `src/_pytest/fixtures.py`: Mentions `add_marker` and request handling, also relevant.\n   - `src/_pytest/nodes.py`: Directly related to nodes and adding markers to them (where the issue likely occurs).\n\nConclusion: Prioritize files that directly relate to mark handling and nodes, as they are most likely to be affected by changes in how xfail is dynamically applied.",
        "file_paths": [
          "src/_pytest/nodes.py",
          "src/_pytest/mark/structures.py",
          "src/_pytest/skipping.py",
          "src/_pytest/mark/__init__.py",
          "src/_pytest/fixtures.py",
          "src/_pytest/pytester.py"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-17T22:23:46.459997",
        "usage": "7022.449254989624 ms"
      },
      "request": {
        "file_path": "src/_pytest/nodes.py"
      },
      "response": {
        "scratch_pad": "1. Analyze User Instructions:\n1.1 The issue is that dynamically adding an xfail marker in pytest 6 no longer works as expected. In previous versions like 5.x, adding xfail markers dynamically allowed the test to fail without causing the overall test suite to fail. However, in 6.x, these failures are no longer ignored.\n1.2 This issue was caused by changes in how pytest 6.0.0rc0 handles dynamically added markers, specifically the xfail marker.\n1.3 The expected result is that the test should be marked as expected to fail (xfail) without producing a failure in the test log that would cause the suite to fail.\n1.4 The expectation is that dynamic xfail markers should behave the same as statically added markers and not cause the test to fail.\n1.5 The issue might be fixed by ensuring that dynamically added xfail markers within the test function are honored in the same way as statically defined ones.\n\n2. Make file evaluation:\n2.1 The file defines classes and methods relevant to test node management in pytest, such as Node, Collector, and Item.\n2.2 The Node class contains the add_marker() method, which seems to be relevant to dynamically adding markers to test nodes.\n2.3 The add_marker() method matches a key element in the reported issue since it is responsible for adding markers like xfail to the request node.\n2.4 Since add_marker() logically handles marker addition, changes in its behavior or its internal logic could directly impact the behavior being reported in the issue.\n2.5 It's possible that changes elsewhere in pytest\u2019s codebase might have affected how xfail markers are processed post addition, but this specific file and method must be considered since it concerns marker addition.\n\n3. Output Your Decision:\nBased on the analysis, this file is relevant to the issue, but it\u2019s uncertain if it solely contains the root cause without further analysis of related modules that process or handle these markers post addition.",
        "relevant": true,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/mark/structures.py",
          "src/_pytest/mark/expression.py",
          "src/_pytest/outcomes.py"
        ],
        "relevant_symbols": [
          "Node.add_marker"
        ],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-17T22:23:53.482494",
        "usage": "8193.029165267944 ms"
      },
      "request": {
        "file_path": "src/_pytest/mark/structures.py"
      },
      "response": {
        "scratch_pad": "1. **Analyze User Instructions:**\n   - The issue describes that in pytest version 6.0.0, dynamically adding an xfail marker to a test using `request.node.add_marker(mark)` causes the test to fail, whereas in version 5.x, the same action treated the test as expected to fail without raising an error. The expected behavior is that the test should be marked as xfail and not actually raise a failure.\n\n2. **Identify Root Cause:**\n   - It is likely related to the mechanism that handles markers and the conditions under which tests are marked as \"expected to fail\". The change in behavior suggests a possible modification in marker handling between versions.\n\n3. **Make File Evaluation:**\n   - **Relevant Symbols Identification:**\n     - This file, `src/_pytest/mark/structures.py`, includes code related to marks, mark decorators, and the application of marks to test objects, which aligns with the described issue concerning \"xfail\" markers.\n     - Symbols that potentially relate to this issue include:\n       - `Mark`, `MarkDecorator`, `MarkGenerator`: These classes deal with mark creation and management, which are directly related to the issue.\n       - `store_mark()`: This function stores a mark on a test object, which might influence whether a test is considered xfail or not.\n\n   - **Evaluating Relevance:**\n     - The file likely contributes to the root cause of the issue because it handles the underlying logic for test markings (including xfail).\n     - The potential root cause might be within the implementation of how `xfail` is evaluated or applied within this module.",
        "relevant": true,
        "root_cause": true,
        "relevant_files": [],
        "relevant_symbols": [
          "Mark",
          "MarkDecorator",
          "MarkGenerator",
          "store_mark"
        ],
        "root_cause_symbols": [
          "Mark",
          "MarkDecorator",
          "MarkGenerator"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-17T22:24:01.675557",
        "usage": "8742.440938949585 ms"
      },
      "request": {
        "file_path": "src/_pytest/skipping.py"
      },
      "response": {
        "scratch_pad": "1. Understanding the issue:\n   - The issue describes that dynamically adding an xfail marker in a test using `request.node.add_marker(mark)` does not behave the same way in Pytest 6 as it did in Pytest 5.\n   - In Pytest 5.x, a test dynamically marked with xfail would behave like a statically xfail-marked test, meaning it would not cause a test failure. However, in Pytest 6.0.0rc0, it does cause a test failure.\n\n2. Key elements related to the issue:\n   - `request.node.add_marker(mark)` for adding markers.\n   - Behavior of xfail markers.\n   - Changes between Pytest 5.x and Pytest 6.x regarding xfail handling.\n\n3. Evaluating the provided file (`skipping.py`):\n   - The provided file deals with skip and xfail markers and their evaluations.\n   - Functions `evaluate_xfail_marks()` and `evaluate_condition()` seem responsible for determining when a test should xfail or not.\n   - `pytest_runtest_makereport` function seems to handle the decision when reporting tests' outcomes, which is closely related to xfail behavior.\n\n4. Analysis regarding root cause:\n   - The functionality described in the issue relates directly to the logic in `evaluate_xfail_marks()` and `pytest_runtest_makereport`.\n   - These locations manage the decision-making process for when tests should be marked as xfailed and how they should be reported, aligning with the issue of changed xfail behavior.\n\n5. Conclusion:\n   - The file `skipping.py` is the root cause of the issue as it contains the marker handling logic.\n   - Specifically, the methods around evaluating and reporting the xfail conditions.",
        "relevant": true,
        "root_cause": true,
        "relevant_files": [],
        "relevant_symbols": [
          "evaluate_xfail_marks",
          "pytest_runtest_makereport",
          "evaluate_condition"
        ],
        "root_cause_symbols": [
          "evaluate_xfail_marks",
          "pytest_runtest_makereport",
          "evaluate_condition"
        ]
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-17T22:24:10.418019",
        "usage": "8969.507932662964 ms"
      },
      "request": {
        "file_path": "src/_pytest/mark/__init__.py"
      },
      "response": {
        "scratch_pad": "### Analyzing User Instructions:\n\n1.1. What issue is the user describing?\n- The user is reporting an issue with the pytest tool, specifically related to dynamically adding an xfail marker to a test case. In pytest version 5.x, adding an xfail marker dynamically would cause the test to be treated as expected to fail (xfail), even if it fails. However, in version 6.0.0rc0, the test fails, which is unexpected.\n\n1.2. How was this issue caused?\n- The issue may have been caused by changes in how markers (specifically xfail) are handled or applied in pytest version 6.x compared to 5.x.\n\n1.3. What should it be fixed to?\n- The user expects that adding an xfail marker dynamically should cause the test to be recognized as xfail and not be marked as failed.\n\n1.4. Expected result?\n- The dynamic addition of xfail should mark the test as xfailed, not failed.\n\n1.5. Fix to meet the expectation?\n- Identify the changes in xfail marker handling between the pytest versions and potentially adjust to ensure dynamically added markers function as in version 5.x.\n\n\n### File Evaluation:\n\n2.1. Anything related to xfail in this file?\n- The file is related to mark functionalities of pytest, containing utilities for marker addition, evaluation, and management.\n\n2.2. Relevant symbols:\n- The file imports several key components from `.structures`: `Mark`, `MARK_GEN`, `MarkDecorator`, and `MarkGenerator`, which are potentially relevant for managing markers.\n- There are no specific alterations in functions directly implementing xfail logic within the given content. These might be located in how markers are applied across different parts of the code.\n\n2.3. MarkMatcher and pytest_configure functions\n- `MarkMatcher` seems to be involved in building the list of markers that match a specific item. Although it doesn't directly handle dynamic addition or specific xfail logic, it might be relevant for identifying markers.\n- `pytest_configure` function manipulates global configuration and may involve setting markers states.\n\n2.4. Related or root cause?\n- The file is certainly related to marker handling in pytest. However, it does not appear to directly handle the dynamic addition of xfail markers or distinctly outline the error described.\n\n2.5. Additional investigation?\n- Files managing dynamic marker application, test result interpretation specifically for xfail status, or changes logs regarding marker implementation might better pinpoint the issue.",
        "relevant": true,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/nodes.py",
          "src/_pytest/skipping.py",
          "src/_pytest/runner.py"
        ],
        "relevant_symbols": [
          "Mark",
          "pytest_configure",
          "MarkMatcher.from_item",
          "deselect_by_mark",
          "pytest_collection_modifyitems"
        ],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-17T22:24:19.387559",
        "usage": "7519.561290740967 ms"
      },
      "request": {
        "file_path": "src/_pytest/fixtures.py"
      },
      "response": {
        "scratch_pad": "1. **Issue Analysis:**\n   - The user reported that in pytest 6.x, adding an 'xfail' marker dynamically using `request.node.add_marker(mark)` no longer behaves as expected. In pytest 5.x, this marked a failing test as expected to fail (like a statically marked test), but in 6.x, it actually causes the test to fail instead.\n\n2. **File Evaluation:**\n   - The `src/_pytest/fixtures.py` file contains functionality related to pytest fixtures, fixture management, and their execution within the fixture request framework.\n   - The primary user concern deals with handling of test markers (`xfail`) in the context of test execution. This file, while integral to managing fixture lifecycles, doesn't directly address marker handling.\n   - Notably, a `FixtureRequest` is part of the fixture execution context, providing test parameters and scope.\n   - The `FixtureRequest` class contains `applymarker()` method that calls `self.node.add_marker(marker)`. This step is pivotal because it handles the core marker application that the user finds problematic.\n\n3. **File Contextual Relevance:**\n   - This file facilitates the fixture system, but changes in pytest 6.x affecting marker application might be located elsewhere.\n   - The described erroneous behavior originates from changes in the marker application or test outcome logic that might not strictly be within this file but perhaps where test outcomes are determined after marker setting.\n\n4. **Conclusion:**\n   - Relevant sections are those handling marker application within the request setup\u2014particularly the `applymarker()` method that controls direct marker application to nodes. However, changes causing the issue may span other parts of pytest beyond fixture handling.\n   - Considering the integration between marker application and test results, exploration may need to extend to how pytest reconciles test results and markers post 6.x updates.",
        "relevant": false,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/nodes.py",
          "src/_pytest/python.py",
          "src/_pytest/mark.py"
        ],
        "relevant_symbols": [],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileEvaluate",
      "metadata": {
        "start": "2024-08-17T22:24:26.907153",
        "usage": "12030.688047409058 ms"
      },
      "request": {
        "file_path": "src/_pytest/pytester.py"
      },
      "response": {
        "scratch_pad": "# Analysis of the issue:\n1. **What issue is the user describing?**\n   The issue described is that using pytest 6.0.0rc0 (release candidate), adding an `xfail` marker dynamically to a test using `request.node.add_marker(mark)` causes the test to fail instead of being marked to fail as expected (i.e., it does not treat it the same as a static `xfail` marker).\n\n2. **How was this issue caused?**\n   The code behavior for dynamically adding xfail markers has changed from pytest version 5.x to 6.x, leading to this discrepancy. In version 6.0.0rc0, the intended behavior was not carried forward, causing dynamic `xfail` markers to result in a test failure instead of a skipped xfail.\n\n3. **What should be fixed or what should be the expected result?**\n   The expected behavior is that adding an `xfail` dynamically should result in the test being marked as expected to fail (`XFAIL`), not raising a failure.\n\n4. **Expectation (if not provided):**\n   The `xfail` dynamic marker should behave as if the test is expected to fail and should log it appropriately instead of treating them as a regular failure.\n\n5. **How should the issue be fixed?**\n   The code responsible for handling markers and test outcomes should be checked. Specifically, any changes or disparities in how dynamic markers are processed between version 5.x and 6.x should be investigated and corrected to make dynamic `xfail` markers function like static `xfail` markers.\n\n---\n\n# File Evaluation:\n\n1. **What is the purpose of this file?**\n   This file (`src/_pytest/pytester.py`) seems to relate to utilities and fixtures for testing Pytest itself or its plugins, offering various support structures for assertion and test management.\n\n2. **Are there any symbols related to `xfail` or dynamic marking?**\n   The file involves test session configurations, run results, managing plugins, report generation, and process handling but does not directly contain elements or logic specifically managing or mentioning pytest markers like `xfail` directly.\n\n3. **Does this file manipulate or affect markers or test outcomes?**\n   Indirectly through the handling of test reports (e.g., `RunResult` class), but not through direct `xfail` handling or configurations.\n\n4. **Evaluation of relevance to the issue:**\n  - Despite handling some outcome aspects (see `RunResult.parseoutcomes` or `assert_outcomes`), there's no evidence of direct influence or alteration to marker behaviors.\n  - No methods in this file are responsible for test outcome determination in terms of `xfail` marking.\n\n5. **Conclusion:**\n   - The file is potentially related due to the involvement with test outcomes in reports but is not directly handling the process or logics about dynamic xfail markers.\n   - The issue likely lies in another part of the codebase responsible for marker management and application.\n\n# Decision:\n- Since the file isn't directly handling the markers or outcomes tied to `xfail`, there's no direct causation.\n- Suggested files for investigation might involve `pytest` modules dealing directly with node or marker processing.\n",
        "relevant": false,
        "root_cause": false,
        "relevant_files": [
          "src/_pytest/nodes.py",
          "src/_pytest/mark.py",
          "src/_pytest/outcomes.py"
        ],
        "relevant_symbols": [],
        "root_cause_symbols": []
      }
    },
    {
      "name": "FileSymbolSearch",
      "metadata": {
        "start": "2024-08-17T22:24:38.937898",
        "usage": "200.38604736328125 ms"
      },
      "request": {
        "files": [
          {
            "file_path": "src/_pytest/nodes.py",
            "relevant_symbol_keys": [
              "Node.add_marker"
            ],
            "root_cause_symbol_keys": []
          },
          {
            "file_path": "src/_pytest/mark/structures.py",
            "relevant_symbol_keys": [
              "Mark",
              "MarkDecorator",
              "MarkGenerator",
              "store_mark"
            ],
            "root_cause_symbol_keys": [
              "Mark",
              "MarkDecorator",
              "MarkGenerator"
            ]
          },
          {
            "file_path": "src/_pytest/skipping.py",
            "relevant_symbol_keys": [
              "evaluate_xfail_marks",
              "pytest_runtest_makereport",
              "evaluate_condition"
            ],
            "root_cause_symbol_keys": [
              "evaluate_xfail_marks",
              "pytest_runtest_makereport",
              "evaluate_condition"
            ]
          },
          {
            "file_path": "src/_pytest/mark/__init__.py",
            "relevant_symbol_keys": [
              "Mark",
              "pytest_configure",
              "MarkMatcher.from_item",
              "deselect_by_mark",
              "pytest_collection_modifyitems"
            ],
            "root_cause_symbol_keys": []
          },
          {
            "file_path": "src/_pytest/fixtures.py",
            "relevant_symbol_keys": [],
            "root_cause_symbol_keys": []
          },
          {
            "file_path": "src/_pytest/pytester.py",
            "relevant_symbol_keys": [],
            "root_cause_symbol_keys": []
          }
        ],
        "with_content": true
      },
      "response": {
        "related_symbols": [
          {
            "name": "_pytest.nodes.Node.add_marker",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def add_marker(\n        self, marker: Union[str, MarkDecorator], append: bool = True\n    ) -> None:\n        \"\"\"dynamically add a marker object to the node.\n\n        :type marker: ``str`` or ``pytest.mark.*``  object\n        :param marker:\n            ``append=True`` whether to append the marker,\n            if ``False`` insert at position ``0``.\n        \"\"\"\n        from _pytest.mark import MARK_GEN\n\n        if isinstance(marker, MarkDecorator):\n            marker_ = marker\n        elif isinstance(marker, str):\n            marker_ = getattr(MARK_GEN, marker)\n        else:\n            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n        self.keywords[marker_.name] = marker_\n        if append:\n            self.own_markers.append(marker_.mark)\n        else:\n            self.own_markers.insert(0, marker_.mark)",
            "start_line": 260,
            "start_column": 8242,
            "end_line": 4,
            "end_column": 9073,
            "start_byte": 8242,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.store_mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def store_mark(obj, mark: Mark) -> None:\n    \"\"\"Store a Mark on an object.\n\n    This is used to implement the Mark declarations/decorators correctly.\n    \"\"\"\n    assert isinstance(mark, Mark), mark\n    # Always reassign name to avoid updating pytestmark in a reference that\n    # was only borrowed.\n    obj.pytestmark = get_unpacked_marks(obj) + [mark]",
            "start_line": 369,
            "start_column": 12372,
            "end_line": 0,
            "end_column": 12724,
            "start_byte": 12372,
            "end_byte": 0
          },
          {
            "name": "_pytest.cacheprovider.LFPlugin.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 289,
            "start_column": 10558,
            "end_line": 4,
            "end_column": 12796,
            "start_byte": 10558,
            "end_byte": 4
          },
          {
            "name": "_pytest.cacheprovider.NFPlugin.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 361,
            "start_column": 13534,
            "end_line": 4,
            "end_column": 14397,
            "start_byte": 13534,
            "end_byte": 4
          },
          {
            "name": "_pytest.cacheprovider.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 464,
            "start_column": 16918,
            "end_line": 0,
            "end_column": 17167,
            "start_byte": 16918,
            "end_byte": 0
          },
          {
            "name": "_pytest.config.PytestPluginManager.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 442,
            "start_column": 13883,
            "end_line": 4,
            "end_column": 14533,
            "start_byte": 13883,
            "end_byte": 4
          },
          {
            "name": "_pytest.debugging.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "f marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and classes whose name \"\n        \"contains 'test_method' or 'test_other', while -k 'not test_method' \"\n        \"matches ",
            "start_line": 61,
            "start_column": 1816,
            "end_line": 0,
            "end_column": 2649,
            "start_byte": 1816,
            "end_byte": 0
          },
          {
            "name": "_pytest.faulthandler.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "from .structures import ParameterSet\nfrom _pytest.compat import TYPE_CHECKING\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n          ",
            "start_line": 24,
            "start_column": 532,
            "end_line": 0,
            "end_column": 1486,
            "start_byte": 532,
            "end_byte": 0
          },
          {
            "name": "_pytest.faulthandler.FaultHandlerHooks.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSe",
            "start_line": 52,
            "start_column": 1666,
            "end_line": 4,
            "end_column": 1955,
            "start_byte": 1666,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1174,
            "start_column": 45925,
            "end_line": 0,
            "end_column": 47430,
            "start_byte": 45925,
            "end_byte": 0
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.scope",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1176,
            "start_column": 45979,
            "end_line": 4,
            "end_column": 46049,
            "start_byte": 45979,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.params",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1177,
            "start_column": 46054,
            "end_line": 4,
            "end_column": 46134,
            "start_byte": 46054,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.autouse",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1178,
            "start_column": 46139,
            "end_line": 4,
            "end_column": 46182,
            "start_byte": 46139,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.ids",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1179,
            "start_column": 46187,
            "end_line": 4,
            "end_column": 46411,
            "start_byte": 46187,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.name",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1187,
            "start_column": 46416,
            "end_line": 4,
            "end_column": 46464,
            "start_byte": 46416,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.__call__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1189,
            "start_column": 46470,
            "end_line": 4,
            "end_column": 47430,
            "start_byte": 46470,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureManager.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1613,
            "start_column": 62458,
            "end_line": 4,
            "end_column": 62612,
            "start_byte": 62458,
            "end_byte": 4
          },
          {
            "name": "_pytest.hookspec.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "line()\n        config._ensure_unconfigure()\n        return 0\n\n    return None\n\n\n@attr.s(slots=True)\nclass KeywordMatcher:\n    \"\"\"A matcher for keywords.\n\n    Given a list of names, matches any substring of one of these names. The\n    string inclusion check is case-insensitive.\n\n    Will match on the name of colitem, including the names of its parents.\n    Only matches names of items which are either a :class:`Class` or a\n    :class:`Function`.\n\n    Additionally, matches on names in the 'extra_key",
            "start_line": 117,
            "start_column": 4131,
            "end_line": 0,
            "end_column": 4632,
            "start_byte": 4131,
            "end_byte": 0
          },
          {
            "name": "_pytest.hookspec.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": ", config: Config) -> None:\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)\n\n\ndef pytest_configure(config: Config) -> None:\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageEr",
            "start_line": 231,
            "start_column": 8250,
            "end_line": 0,
            "end_column": 8658,
            "start_byte": 8250,
            "end_byte": 0
          },
          {
            "name": "_pytest.junitxml.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 439,
            "start_column": 15188,
            "end_line": 0,
            "end_column": 15980,
            "start_byte": 15188,
            "end_byte": 0
          },
          {
            "name": "_pytest.logging.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 501,
            "start_column": 17763,
            "end_line": 0,
            "end_column": 17914,
            "start_byte": 17763,
            "end_byte": 0
          },
          {
            "name": "_pytest.main.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 372,
            "start_column": 12071,
            "end_line": 0,
            "end_column": 12584,
            "start_byte": 12071,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkMatcher",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "@attr.s(slots=True)\nclass MarkMatcher:\n    \"\"\"A matcher for markers which are present.\n\n    Tries to match on any marker names, attached to the given colitem.\n    \"\"\"\n\n    own_mark_names = attr.ib()\n\n    @classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)\n\n    def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names",
            "start_line": 214,
            "start_column": 7079,
            "end_line": 0,
            "end_column": 7525,
            "start_byte": 7079,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkMatcher.own_mark_names",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "own_mark_names = attr.ib()",
            "start_line": 221,
            "start_column": 7251,
            "end_line": 4,
            "end_column": 7277,
            "start_byte": 7251,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.from_item",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "@classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)",
            "start_line": 223,
            "start_column": 7283,
            "end_line": 4,
            "end_column": 7438,
            "start_byte": 7283,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.__call__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names",
            "start_line": 228,
            "start_column": 7444,
            "end_line": 4,
            "end_column": 7525,
            "start_byte": 7444,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.deselect_by_mark",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "def deselect_by_mark(items: \"List[Item]\", config: Config) -> None:\n    matchexpr = config.option.markexpr\n    if not matchexpr:\n        return\n\n    try:\n        expression = Expression.compile(matchexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-m': {}: {}\".format(matchexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for item in items:\n        if expression.evaluate(MarkMatcher.from_item(item)):\n            remaining.append(item)\n        else:\n            deselected.append(item)\n\n    if deselected:\n        config.hook.pytest_deselected(items=deselected)\n        items[:] = remaining",
            "start_line": 232,
            "start_column": 7528,
            "end_line": 0,
            "end_column": 8194,
            "start_byte": 7528,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "def pytest_collection_modifyitems(items: \"List[Item]\", config: Config) -> None:\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)",
            "start_line": 257,
            "start_column": 8197,
            "end_line": 0,
            "end_column": 8351,
            "start_byte": 8197,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "def pytest_configure(config: Config) -> None:\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageError(\n            \"{!s} must be one of skip, xfail or fail_at_collect\"\n            \" but it is {!r}\".format(EMPTY_PARAMETERSET_OPTION, empty_parameterset)\n        )",
            "start_line": 262,
            "start_column": 8354,
            "end_line": 0,
            "end_column": 8821,
            "start_byte": 8354,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.Mark",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "    try:\n        expression = Expression.compile(keywordexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-k': {}: {}\".format(keywordexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for colitem in items:\n        if keywordexpr and not expression.evaluate(KeywordMatcher.from_item(colitem)):\n            deselected.append(colitem)\n        else:\n            if selectuntil:\n                keywordexpr = None\n            remaining.append(colitem)\n\n    if deselected:\n        config.hook.pytest_deselected(items=deselected)\n        items[:] = remaining\n\n\n@attr.s(slots=True)\nclass MarkMatcher:\n    \"\"\"A matcher for markers which are present.\n\n    Tries to match on any marker names, attached to the given colitem.\n    \"\"\"\n\n    own_mark_names = attr.ib()\n\n    @classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)\n\n    def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names\n\n\ndef deselect_by_mark(items: \"List[Item]\", config: Config) -> None:\n    matchexpr = config.option.markexpr\n    if not matchexpr:\n        return\n\n    try:\n        expression = Expression.compile(matchexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-m': {}: {}\".format(matchexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for item in items:\n    ",
            "start_line": 195,
            "start_column": 6452,
            "end_line": 0,
            "end_column": 7948,
            "start_byte": 6452,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.Mark.name",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "    except ParseError as",
            "start_line": 198,
            "start_column": 6514,
            "end_line": 4,
            "end_column": 6538,
            "start_byte": 6514,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.args",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "ion passed to '-k': {}: {}\".format(k",
            "start_line": 200,
            "start_column": 6594,
            "end_line": 4,
            "end_column": 6630,
            "start_byte": 6594,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.kwargs",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "]\n    deselected = []\n    for colitem in",
            "start_line": 202,
            "start_column": 6683,
            "end_line": 4,
            "end_column": 6723,
            "start_byte": 6683,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_from",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "e(KeywordMatcher.from_item(colitem)):\n            deselected.append(colite",
            "start_line": 205,
            "start_column": 6780,
            "end_line": 4,
            "end_column": 6854,
            "start_byte": 6780,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_generated",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "  keywordexpr = None\n            remaining.append(colitem)\n\n    if deselected:\n        config.hook.p",
            "start_line": 207,
            "start_column": 6913,
            "end_line": 4,
            "end_column": 7013,
            "start_byte": 6913,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._has_param_ids",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "deselected(items=deselected)\n        items[:] = remaining\n\n\n@attr.s(slots=True)\nclass MarkMa",
            "start_line": 211,
            "start_column": 7019,
            "end_line": 4,
            "end_column": 7111,
            "start_byte": 7019,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.combined_with",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "\n    \"\"\"A matcher for markers which are present.\n\n    Tries to match on any marker names, attached to the given colitem.\n    \"\"\"\n\n    own_mark_names = attr.ib()\n\n    @classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)\n\n    def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names\n\n\ndef deselect_by_mark(items: \"List[Item]\", config: Config) -> None:\n    matchexpr = config.option.markexpr\n    if not matchexpr:\n        return\n\n    try:\n        expression = Expression.compile(matchexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-m': {}: {}\".format(matchexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for item in items:\n    ",
            "start_line": 214,
            "start_column": 7117,
            "end_line": 4,
            "end_column": 7948,
            "start_byte": 7117,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark._Markable",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "test_deselected(items=deselected)\n        items[:] = remaining\n\n\ndef pytes",
            "start_line": 245,
            "start_column": 8132,
            "end_line": 0,
            "end_column": 8206,
            "start_byte": 8132,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "ollection_modifyitems(items: \"List[Item]\", config: Config) -> None:\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)\n\n\ndef pytest_configure(config: Config) -> None:\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageError(\n            \"{!s} must be one of skip, xfail or fail_at_collect\"\n            \" but it is {!r}\".format(EMPTY_PARAMETERSET_OPTION, empty_parameterset)\n        )\n\n\ndef pytest_unconfigure(config: Config) -> None:\n    MARK_GEN._config = config._store.get(old_mark_config_key, None)\n",
            "start_line": 248,
            "start_column": 8209,
            "end_line": 0,
            "end_column": 11549,
            "start_byte": 8209,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator.mark",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 284,
            "start_column": 9608,
            "end_line": 4,
            "end_column": 9678,
            "start_byte": 9608,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.name",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 286,
            "start_column": 9684,
            "end_line": 4,
            "end_column": 9785,
            "start_byte": 9684,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.args",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 291,
            "start_column": 9791,
            "end_line": 4,
            "end_column": 9904,
            "start_byte": 9791,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.kwargs",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 296,
            "start_column": 9910,
            "end_line": 4,
            "end_column": 10031,
            "start_byte": 9910,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.markname",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 301,
            "start_column": 10037,
            "end_line": 4,
            "end_column": 10147,
            "start_byte": 10037,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__repr__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 305,
            "start_column": 10153,
            "end_line": 4,
            "end_column": 10235,
            "start_byte": 10153,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.with_args",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 308,
            "start_column": 10241,
            "end_line": 4,
            "end_column": 10647,
            "start_byte": 10241,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 322,
            "start_column": 10861,
            "end_line": 4,
            "end_column": 10981,
            "start_byte": 10861,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 326,
            "start_column": 10987,
            "end_line": 4,
            "end_column": 11150,
            "start_byte": 10987,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 332,
            "start_column": 11156,
            "end_line": 4,
            "end_column": 11549,
            "start_byte": 11156,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 450,
            "start_column": 15252,
            "end_line": 0,
            "end_column": 18166,
            "start_byte": 15252,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkGenerator._config",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 465,
            "start_column": 15571,
            "end_line": 4,
            "end_column": 15585,
            "start_byte": 15571,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator._markers",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 466,
            "start_column": 15616,
            "end_line": 4,
            "end_column": 15632,
            "start_byte": 15616,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator.__getattr__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 479,
            "start_column": 16175,
            "end_line": 4,
            "end_column": 18166,
            "start_byte": 16175,
            "end_byte": 4
          },
          {
            "name": "_pytest.pastebin.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "arsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def",
            "start_line": 30,
            "start_column": 778,
            "end_line": 0,
            "end_column": 1609,
            "start_byte": 778,
            "end_byte": 0
          },
          {
            "name": "_pytest.pytester.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions a",
            "start_line": 83,
            "start_column": 2138,
            "end_line": 0,
            "end_column": 2530,
            "start_byte": 2138,
            "end_byte": 0
          },
          {
            "name": "_pytest.python.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": " the names of its parents.\n    Only matches names of items which are either a :class:`Class` or a\n    :class:`Function`.\n\n    Additionally, matches on names in the 'extra_keyword_matches' set of\n    any item, as well as names directly assigned to test functions.\n    \"\"\"\n\n    _names = attr.ib(type=AbstractSet[str])\n\n    @classmethod\n    def from_item(cls, item: \"Item\") -> \"KeywordMatcher\":\n        mapped_names = set()\n\n        # Add the names of the current item and any parent items\n        import pytest\n\n        for node in item.listchain():\n            if not isinstance(node, (pytest.Instance, pytest.Session)):\n                mapped_names.add(node.name)\n\n        # Add the names added as extra keywords to current or parent items\n        mapped_names.update(item.listextrakeywords())\n\n        # Add the names attached to the current function through direct assignment\n        function_obj = getattr(item, \"",
            "start_line": 138,
            "start_column": 4458,
            "end_line": 0,
            "end_column": 5374,
            "start_byte": 4458,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "lection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def test_eval(test_input, expected):\n            assert eval(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and classes whose name \"\n        \"contains 'test_method' or 'test_other', while -k 'not test_method' \"\n        \"matches those that don't contain 'test_method' in their names. \"\n        \"-k 'not test_method and not test_other' will eliminate the matches. \"\n        \"Additionally keywor",
            "start_line": 47,
            "start_column": 1193,
            "end_line": 0,
            "end_column": 2813,
            "start_byte": 1193,
            "end_byte": 0
          },
          {
            "name": "_pytest.stepwise.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": ".config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecate",
            "start_line": 28,
            "start_column": 728,
            "end_line": 0,
            "end_column": 866,
            "start_byte": 728,
            "end_byte": 0
          },
          {
            "name": "_pytest.stepwise.StepwisePlugin.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "ize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def test_eval(test_input, expected):\n            assert eval(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and cl",
            "start_line": 48,
            "start_column": 1400,
            "end_line": 4,
            "end_column": 2535,
            "start_byte": 1400,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": " config.option.keyword.lstrip()\n    if not keywordexpr:\n        return\n\n    if keywordexpr.startswith(\"-\"):\n        # To be removed in pytest 7.0.0.\n        warnings.warn(MINUS_K_DASH, stacklevel=2)\n        keywordexpr = \"not \" + keywordexpr[1:]\n    selectuntil = False\n    if keywordexpr[-1:] == \":\":\n        # To be removed in pytest 7.0.0.\n        warnings.warn(MINUS_K_COLON, stacklevel=2)\n        selectuntil = Tru",
            "start_line": 224,
            "start_column": 5991,
            "end_line": 0,
            "end_column": 6410,
            "start_byte": 5991,
            "end_byte": 0
          },
          {
            "name": "_pytest.tmpdir.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "t[str])\n\n    @classmethod\n    def from_item(cls, item: \"Item\") -> \"KeywordMatcher\":\n        mapped_names = set()\n\n        # Add the names of the current item and any parent items\n        import pytest\n\n        for node in item.listchain():\n            if not isinstance(node, (pytest.Instance, pytest.Session)):\n                mapped_names.add(node.name)\n\n        # Add the names added as extra keywords to current or parent items\n        mapped_names.update(item.listextrakeywords())\n\n        # Add the names attached to the current function through direct assignment\n        function_obj = getattr(item, \"",
            "start_line": 138,
            "start_column": 4766,
            "end_line": 0,
            "end_column": 5374,
            "start_byte": 4766,
            "end_byte": 0
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "o this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(",
            "start_line": 77,
            "start_column": 1903,
            "end_line": 0,
            "end_column": 2100,
            "start_byte": 1903,
            "end_byte": 0
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning.__module__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "    group._addoption(",
            "start_line": 83,
            "start_column": 2079,
            "end_line": 4,
            "end_column": 2100,
            "start_byte": 2079,
            "end_byte": 4
          },
          {
            "name": "_pytest.warnings.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": " tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other'",
            "start_line": 74,
            "start_column": 2235,
            "end_line": 0,
            "end_column": 2501,
            "start_byte": 2235,
            "end_byte": 0
          },
          {
            "name": "_pytest.resultlog.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "est.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: ",
            "start_line": 30,
            "start_column": 725,
            "end_line": 0,
            "end_column": 1434,
            "start_byte": 725,
            "end_byte": 0
          }
        ],
        "root_caused_symbols": [
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1174,
            "start_column": 45925,
            "end_line": 0,
            "end_column": 47430,
            "start_byte": 45925,
            "end_byte": 0
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.scope",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1176,
            "start_column": 45979,
            "end_line": 4,
            "end_column": 46049,
            "start_byte": 45979,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.params",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1177,
            "start_column": 46054,
            "end_line": 4,
            "end_column": 46134,
            "start_byte": 46054,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.autouse",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1178,
            "start_column": 46139,
            "end_line": 4,
            "end_column": 46182,
            "start_byte": 46139,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1179,
            "start_column": 46187,
            "end_line": 4,
            "end_column": 46411,
            "start_byte": 46187,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1187,
            "start_column": 46416,
            "end_line": 4,
            "end_column": 46464,
            "start_byte": 46416,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1189,
            "start_column": 46470,
            "end_line": 4,
            "end_column": 47430,
            "start_byte": 46470,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "lf.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 214,
            "start_column": 7079,
            "end_line": 0,
            "end_column": 7525,
            "start_byte": 7079,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkMatcher.own_mark_names",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": " Mark.\n\n        Combines b",
            "start_line": 221,
            "start_column": 7251,
            "end_line": 4,
            "end_column": 7277,
            "start_byte": 7251,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.from_item",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "nding args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert s",
            "start_line": 223,
            "start_column": 7283,
            "end_line": 4,
            "end_column": 7438,
            "start_byte": 7283,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "me == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 228,
            "start_column": 7444,
            "end_line": 4,
            "end_column": 7525,
            "start_byte": 7444,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s(frozen=True)\nclass Mark:\n    #: Name of the mark.\n    name = attr.ib(type=str)\n    #: Positional arguments of the mark decorator.\n    args = attr.ib(type=Tuple[Any, ...])\n    #: Keyword arguments of the mark decorator.\n    kwargs = attr.ib(type=Mapping[str, Any])\n\n    #: Source Mark for ids with parametrize Marks.\n    _param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)\n    #: Resolved/generated ids with parametrize Marks.\n    _param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )\n\n    def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 195,
            "start_column": 6452,
            "end_line": 0,
            "end_column": 7948,
            "start_byte": 6452,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.Mark.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "name = attr.ib(type=str)",
            "start_line": 198,
            "start_column": 6514,
            "end_line": 4,
            "end_column": 6538,
            "start_byte": 6514,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "args = attr.ib(type=Tuple[Any, ...])",
            "start_line": 200,
            "start_column": 6594,
            "end_line": 4,
            "end_column": 6630,
            "start_byte": 6594,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "kwargs = attr.ib(type=Mapping[str, Any])",
            "start_line": 202,
            "start_column": 6683,
            "end_line": 4,
            "end_column": 6723,
            "start_byte": 6683,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_from",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)",
            "start_line": 205,
            "start_column": 6780,
            "end_line": 4,
            "end_column": 6854,
            "start_byte": 6780,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_generated",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )",
            "start_line": 207,
            "start_column": 6913,
            "end_line": 4,
            "end_column": 7013,
            "start_byte": 6913,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._has_param_ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4",
            "start_line": 211,
            "start_column": 7019,
            "end_line": 4,
            "end_column": 7111,
            "start_byte": 7019,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.combined_with",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 214,
            "start_column": 7117,
            "end_line": 4,
            "end_column": 7948,
            "start_byte": 7117,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark._Markable",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_Markable = TypeVar(\"_Markable\", bound=Union[Callable[..., object], type])",
            "start_line": 245,
            "start_column": 8132,
            "end_line": 0,
            "end_column": 8206,
            "start_byte": 8132,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s\nclass MarkDecorator:\n    \"\"\"A decorator for applying a mark on test functions and classes.\n\n    MarkDecorators are created with ``pytest.mark``::\n\n        mark1 = pytest.mark.NAME              # Simple MarkDecorator\n        mark2 = pytest.mark.NAME(name1=value) # Parametrized MarkDecorator\n\n    and can then be applied as decorators to test functions::\n\n        @mark2\n        def test_function():\n            pass\n\n    When a MarkDecorator is called it does the following:\n\n    1. If called with a single class as its only positional argument and no\n       additional keyword arguments, it attaches the mark to the class so it\n       gets applied automatically to all test cases found in that class.\n\n    2. If called with a single function as its only positional argument and\n       no additional keyword arguments, it attaches the mark to the function,\n       containing all the arguments already stored internally in the\n       MarkDecorator.\n\n    3. When called in any other case, it returns a new MarkDecorator instance\n       with the original MarkDecorator's content updated with the arguments\n       passed to this call.\n\n    Note: The rules above prevent MarkDecorators from storing only a single\n    function or class reference as their positional argument with no\n    additional keyword or positional arguments. You can work around this by\n    using `with_args()`.\n    \"\"\"\n\n    mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))\n\n    @property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name\n\n    @property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args\n\n    @property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs\n\n    @property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)\n\n    def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)\n\n    def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))\n\n    # Type ignored because the overloads overlap with an incompatible\n    # return type. Not much we can do about that. Thankfully mypy picks\n    # the first match so it works out even if we break the rules.\n    @overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()\n\n    @overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()\n\n    def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 248,
            "start_column": 8209,
            "end_line": 0,
            "end_column": 11549,
            "start_byte": 8209,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator.mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))",
            "start_line": 284,
            "start_column": 9608,
            "end_line": 4,
            "end_column": 9678,
            "start_byte": 9608,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name",
            "start_line": 286,
            "start_column": 9684,
            "end_line": 4,
            "end_column": 9785,
            "start_byte": 9684,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args",
            "start_line": 291,
            "start_column": 9791,
            "end_line": 4,
            "end_column": 9904,
            "start_byte": 9791,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs",
            "start_line": 296,
            "start_column": 9910,
            "end_line": 4,
            "end_column": 10031,
            "start_byte": 9910,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.markname",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)",
            "start_line": 301,
            "start_column": 10037,
            "end_line": 4,
            "end_column": 10147,
            "start_byte": 10037,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__repr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)",
            "start_line": 305,
            "start_column": 10153,
            "end_line": 4,
            "end_column": 10235,
            "start_byte": 10153,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.with_args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))",
            "start_line": 308,
            "start_column": 10241,
            "end_line": 4,
            "end_column": 10647,
            "start_byte": 10241,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()",
            "start_line": 322,
            "start_column": 10861,
            "end_line": 4,
            "end_column": 10981,
            "start_byte": 10861,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()",
            "start_line": 326,
            "start_column": 10987,
            "end_line": 4,
            "end_column": 11150,
            "start_byte": 10987,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 332,
            "start_column": 11156,
            "end_line": 4,
            "end_column": 11549,
            "start_byte": 11156,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "class MarkGenerator:\n    \"\"\"Factory for :class:`MarkDecorator` objects - exposed as\n    a ``pytest.mark`` singleton instance.\n\n    Example::\n\n         import pytest\n\n         @pytest.mark.slowtest\n         def test_function():\n            pass\n\n    applies a 'slowtest' :class:`Mark` on ``test_function``.\n    \"\"\"\n\n    _config = None  # type: Optional[Config]\n    _markers = set()  # type: Set[str]\n\n    # See TYPE_CHECKING above.\n    if TYPE_CHECKING:\n        # Using casts instead of type comments intentionally - issue #7473.\n        # TODO(py36): Change to builtin annotation syntax.\n        skip = cast(_SkipMarkDecorator, None)\n        skipif = cast(_SkipifMarkDecorator, None)\n        xfail = cast(_XfailMarkDecorator, None)\n        parametrize = cast(_ParametrizeMarkDecorator, None)\n        usefixtures = cast(_UsefixturesMarkDecorator, None)\n        filterwarnings = cast(_FilterwarningsMarkDecorator, None)\n\n    def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 450,
            "start_column": 15252,
            "end_line": 0,
            "end_column": 18166,
            "start_byte": 15252,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkGenerator._config",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_config = None",
            "start_line": 465,
            "start_column": 15571,
            "end_line": 4,
            "end_column": 15585,
            "start_byte": 15571,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator._markers",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_markers = set()",
            "start_line": 466,
            "start_column": 15616,
            "end_line": 4,
            "end_column": 15632,
            "start_byte": 15616,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator.__getattr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 479,
            "start_column": 16175,
            "end_line": 4,
            "end_column": 18166,
            "start_byte": 16175,
            "end_byte": 4
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "\"values\", Sequence[Union[object, NotSetType]]),\n            (\"marks\", \"typing.Collection[Union[MarkDecorator, Mark]]\"),\n            (\"id\", Optional[str]),\n        ],\n    )\n):\n    @classmethod\n    d",
            "start_line": 77,
            "start_column": 1903,
            "end_line": 0,
            "end_column": 2100,
            "start_byte": 1903,
            "end_byte": 0
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning.__module__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "   @classmethod\n    d",
            "start_line": 83,
            "start_column": 2079,
            "end_line": 4,
            "end_column": 2100,
            "start_byte": 2079,
            "end_byte": 4
          },
          {
            "name": "_pytest.hookspec.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "",
            "start_line": 486,
            "start_column": 17380,
            "end_line": 0,
            "end_column": 17867,
            "start_byte": 17380,
            "end_byte": 0
          },
          {
            "name": "_pytest.runner.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "ort_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:\n    if hasattr(report, \"wasxfail\"):\n        if report.skipped",
            "start_line": 318,
            "start_column": 10464,
            "end_line": 0,
            "end_column": 10595,
            "start_byte": 10464,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.evaluate_condition",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "def evaluate_condition(item: Item, mark: Mark, condition: object) -> Tuple[bool, str]:\n    \"\"\"Evaluate a single skipif/xfail condition.\n\n    If an old-style string condition is given, it is eval()'d, otherwise the\n    condition is bool()'d. If this fails, an appropriately formatted pytest.fail\n    is raised.\n\n    Returns (result, reason). The reason is only relevant if the result is True.\n    \"\"\"\n    # String condition.\n    if isinstance(condition, str):\n        globals_ = {\n            \"os\": os,\n            \"sys\": sys,\n            \"platform\": platform,\n            \"config\": item.config,\n        }\n        if hasattr(item, \"obj\"):\n            globals_.update(item.obj.__globals__)  # type: ignore[attr-defined]\n        try:\n            filename = \"<{} condition>\".format(mark.name)\n            condition_code = compile(condition, filename, \"eval\")\n            result = eval(condition_code, globals_)\n        except SyntaxError as exc:\n            msglines = [\n                \"Error evaluating %r condition\" % mark.name,\n                \"    \" + condition,\n                \"    \" + \" \" * (exc.offset or 0) + \"^\",\n                \"SyntaxError: invalid syntax\",\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n        except Exception as exc:\n            msglines = [\n                \"Error evaluating %r condition\" % mark.name,\n                \"    \" + condition,\n                *traceback.format_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    # Boolean condition.\n    else:\n        try:\n            result = bool(condition)\n        except Exception as exc:\n            msglines = [\n                \"Error evaluating %r condition as a boolean\" % mark.name,\n                *traceback.format_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    reason = mark.kwargs.get(\"reason\", None)\n    if reason is None:\n        if isinstance(condition, str):\n            reason = \"condition: \" + condition\n        else:\n            # XXX better be checked at collection time\n            msg = (\n                \"Error evaluating %r: \" % mark.name\n                + \"you need to specify reason=STRING when using booleans as conditions.\"\n            )\n            fail(msg, pytrace=False)\n\n    return result, reason",
            "start_line": 86,
            "start_column": 2816,
            "end_line": 0,
            "end_column": 5151,
            "start_byte": 2816,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.evaluate_xfail_marks",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None",
            "start_line": 199,
            "start_column": 6507,
            "end_line": 0,
            "end_column": 7408,
            "start_byte": 6507,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "@hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n    outcome = yield\n    rep = outcome.get_result()\n    xfailed = item._store.get(xfailed_key, None)\n    # unittest special case, see setting of unexpectedsuccess_key\n    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n        reason = item._store[unexpectedsuccess_key]\n        if reason:\n            rep.longrepr = \"Unexpected success: {}\".format(reason)\n        else:\n            rep.longrepr = \"Unexpected success\"\n        rep.outcome = \"failed\"\n    elif item.config.option.runxfail:\n        pass  # don't interfere\n    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n        assert call.excinfo.value.msg is not None\n        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n        rep.outcome = \"skipped\"\n    elif not rep.skipped and xfailed:\n        if call.excinfo:\n            raises = xfailed.raises\n            if raises is not None and not isinstance(call.excinfo.value, raises):\n                rep.outcome = \"failed\"\n            else:\n                rep.outcome = \"skipped\"\n                rep.wasxfail = xfailed.reason\n        elif call.when == \"call\":\n            if xfailed.strict:\n                rep.outcome = \"failed\"\n                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n            else:\n                rep.outcome = \"passed\"\n                rep.wasxfail = xfailed.reason\n\n    if (\n        item._store.get(skipped_by_mark_key, True)\n        and rep.skipped\n        and type(rep.longrepr) is tuple\n    ):\n        # skipped by mark.skipif; change the location of the failure\n        # to point to the item definition, otherwise it will display\n        # the location of where the skip exception was raised within pytest\n        _, _, reason = rep.longrepr\n        filename, line = item.reportinfo()[:2]\n        assert line is not None\n        rep.longrepr = str(filename), line + 1, reason",
            "start_line": 259,
            "start_column": 8490,
            "end_line": 0,
            "end_column": 10447,
            "start_byte": 8490,
            "end_byte": 0
          },
          {
            "name": "_pytest.unittest.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "urn \"xpassed\", \"X\", \"XPASS\"\n    return None\n",
            "start_line": 290,
            "start_column": 10683,
            "end_line": 0,
            "end_column": 11441,
            "start_byte": 10683,
            "end_byte": 0
          }
        ]
      }
    },
    {
      "name": "SymbolsEvaluate",
      "metadata": {
        "start": "2024-08-17T22:24:39.138291",
        "usage": "18992.11025238037 ms"
      },
      "request": {
        "related_symbols": [
          {
            "name": "_pytest.nodes.Node.add_marker",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def add_marker(\n        self, marker: Union[str, MarkDecorator], append: bool = True\n    ) -> None:\n        \"\"\"dynamically add a marker object to the node.\n\n        :type marker: ``str`` or ``pytest.mark.*``  object\n        :param marker:\n            ``append=True`` whether to append the marker,\n            if ``False`` insert at position ``0``.\n        \"\"\"\n        from _pytest.mark import MARK_GEN\n\n        if isinstance(marker, MarkDecorator):\n            marker_ = marker\n        elif isinstance(marker, str):\n            marker_ = getattr(MARK_GEN, marker)\n        else:\n            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n        self.keywords[marker_.name] = marker_\n        if append:\n            self.own_markers.append(marker_.mark)\n        else:\n            self.own_markers.insert(0, marker_.mark)",
            "start_line": 260,
            "start_column": 8242,
            "end_line": 4,
            "end_column": 9073,
            "start_byte": 8242,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.store_mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def store_mark(obj, mark: Mark) -> None:\n    \"\"\"Store a Mark on an object.\n\n    This is used to implement the Mark declarations/decorators correctly.\n    \"\"\"\n    assert isinstance(mark, Mark), mark\n    # Always reassign name to avoid updating pytestmark in a reference that\n    # was only borrowed.\n    obj.pytestmark = get_unpacked_marks(obj) + [mark]",
            "start_line": 369,
            "start_column": 12372,
            "end_line": 0,
            "end_column": 12724,
            "start_byte": 12372,
            "end_byte": 0
          },
          {
            "name": "_pytest.cacheprovider.LFPlugin.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 289,
            "start_column": 10558,
            "end_line": 4,
            "end_column": 12796,
            "start_byte": 10558,
            "end_byte": 4
          },
          {
            "name": "_pytest.cacheprovider.NFPlugin.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 361,
            "start_column": 13534,
            "end_line": 4,
            "end_column": 14397,
            "start_byte": 13534,
            "end_byte": 4
          },
          {
            "name": "_pytest.cacheprovider.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 464,
            "start_column": 16918,
            "end_line": 0,
            "end_column": 17167,
            "start_byte": 16918,
            "end_byte": 0
          },
          {
            "name": "_pytest.config.PytestPluginManager.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 442,
            "start_column": 13883,
            "end_line": 4,
            "end_column": 14533,
            "start_byte": 13883,
            "end_byte": 4
          },
          {
            "name": "_pytest.debugging.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "f marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and classes whose name \"\n        \"contains 'test_method' or 'test_other', while -k 'not test_method' \"\n        \"matches ",
            "start_line": 61,
            "start_column": 1816,
            "end_line": 0,
            "end_column": 2649,
            "start_byte": 1816,
            "end_byte": 0
          },
          {
            "name": "_pytest.faulthandler.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "from .structures import ParameterSet\nfrom _pytest.compat import TYPE_CHECKING\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n          ",
            "start_line": 24,
            "start_column": 532,
            "end_line": 0,
            "end_column": 1486,
            "start_byte": 532,
            "end_byte": 0
          },
          {
            "name": "_pytest.faulthandler.FaultHandlerHooks.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSe",
            "start_line": 52,
            "start_column": 1666,
            "end_line": 4,
            "end_column": 1955,
            "start_byte": 1666,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1174,
            "start_column": 45925,
            "end_line": 0,
            "end_column": 47430,
            "start_byte": 45925,
            "end_byte": 0
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.scope",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1176,
            "start_column": 45979,
            "end_line": 4,
            "end_column": 46049,
            "start_byte": 45979,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.params",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1177,
            "start_column": 46054,
            "end_line": 4,
            "end_column": 46134,
            "start_byte": 46054,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.autouse",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1178,
            "start_column": 46139,
            "end_line": 4,
            "end_column": 46182,
            "start_byte": 46139,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.ids",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1179,
            "start_column": 46187,
            "end_line": 4,
            "end_column": 46411,
            "start_byte": 46187,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.name",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1187,
            "start_column": 46416,
            "end_line": 4,
            "end_column": 46464,
            "start_byte": 46416,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.__call__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1189,
            "start_column": 46470,
            "end_line": 4,
            "end_column": 47430,
            "start_byte": 46470,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureManager.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1613,
            "start_column": 62458,
            "end_line": 4,
            "end_column": 62612,
            "start_byte": 62458,
            "end_byte": 4
          },
          {
            "name": "_pytest.hookspec.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "line()\n        config._ensure_unconfigure()\n        return 0\n\n    return None\n\n\n@attr.s(slots=True)\nclass KeywordMatcher:\n    \"\"\"A matcher for keywords.\n\n    Given a list of names, matches any substring of one of these names. The\n    string inclusion check is case-insensitive.\n\n    Will match on the name of colitem, including the names of its parents.\n    Only matches names of items which are either a :class:`Class` or a\n    :class:`Function`.\n\n    Additionally, matches on names in the 'extra_key",
            "start_line": 117,
            "start_column": 4131,
            "end_line": 0,
            "end_column": 4632,
            "start_byte": 4131,
            "end_byte": 0
          },
          {
            "name": "_pytest.hookspec.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": ", config: Config) -> None:\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)\n\n\ndef pytest_configure(config: Config) -> None:\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageEr",
            "start_line": 231,
            "start_column": 8250,
            "end_line": 0,
            "end_column": 8658,
            "start_byte": 8250,
            "end_byte": 0
          },
          {
            "name": "_pytest.junitxml.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 439,
            "start_column": 15188,
            "end_line": 0,
            "end_column": 15980,
            "start_byte": 15188,
            "end_byte": 0
          },
          {
            "name": "_pytest.logging.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 501,
            "start_column": 17763,
            "end_line": 0,
            "end_column": 17914,
            "start_byte": 17763,
            "end_byte": 0
          },
          {
            "name": "_pytest.main.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 372,
            "start_column": 12071,
            "end_line": 0,
            "end_column": 12584,
            "start_byte": 12071,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkMatcher",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "@attr.s(slots=True)\nclass MarkMatcher:\n    \"\"\"A matcher for markers which are present.\n\n    Tries to match on any marker names, attached to the given colitem.\n    \"\"\"\n\n    own_mark_names = attr.ib()\n\n    @classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)\n\n    def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names",
            "start_line": 214,
            "start_column": 7079,
            "end_line": 0,
            "end_column": 7525,
            "start_byte": 7079,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkMatcher.own_mark_names",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "own_mark_names = attr.ib()",
            "start_line": 221,
            "start_column": 7251,
            "end_line": 4,
            "end_column": 7277,
            "start_byte": 7251,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.from_item",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "@classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)",
            "start_line": 223,
            "start_column": 7283,
            "end_line": 4,
            "end_column": 7438,
            "start_byte": 7283,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.__call__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names",
            "start_line": 228,
            "start_column": 7444,
            "end_line": 4,
            "end_column": 7525,
            "start_byte": 7444,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.deselect_by_mark",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "def deselect_by_mark(items: \"List[Item]\", config: Config) -> None:\n    matchexpr = config.option.markexpr\n    if not matchexpr:\n        return\n\n    try:\n        expression = Expression.compile(matchexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-m': {}: {}\".format(matchexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for item in items:\n        if expression.evaluate(MarkMatcher.from_item(item)):\n            remaining.append(item)\n        else:\n            deselected.append(item)\n\n    if deselected:\n        config.hook.pytest_deselected(items=deselected)\n        items[:] = remaining",
            "start_line": 232,
            "start_column": 7528,
            "end_line": 0,
            "end_column": 8194,
            "start_byte": 7528,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "def pytest_collection_modifyitems(items: \"List[Item]\", config: Config) -> None:\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)",
            "start_line": 257,
            "start_column": 8197,
            "end_line": 0,
            "end_column": 8351,
            "start_byte": 8197,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "def pytest_configure(config: Config) -> None:\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageError(\n            \"{!s} must be one of skip, xfail or fail_at_collect\"\n            \" but it is {!r}\".format(EMPTY_PARAMETERSET_OPTION, empty_parameterset)\n        )",
            "start_line": 262,
            "start_column": 8354,
            "end_line": 0,
            "end_column": 8821,
            "start_byte": 8354,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.Mark",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "    try:\n        expression = Expression.compile(keywordexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-k': {}: {}\".format(keywordexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for colitem in items:\n        if keywordexpr and not expression.evaluate(KeywordMatcher.from_item(colitem)):\n            deselected.append(colitem)\n        else:\n            if selectuntil:\n                keywordexpr = None\n            remaining.append(colitem)\n\n    if deselected:\n        config.hook.pytest_deselected(items=deselected)\n        items[:] = remaining\n\n\n@attr.s(slots=True)\nclass MarkMatcher:\n    \"\"\"A matcher for markers which are present.\n\n    Tries to match on any marker names, attached to the given colitem.\n    \"\"\"\n\n    own_mark_names = attr.ib()\n\n    @classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)\n\n    def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names\n\n\ndef deselect_by_mark(items: \"List[Item]\", config: Config) -> None:\n    matchexpr = config.option.markexpr\n    if not matchexpr:\n        return\n\n    try:\n        expression = Expression.compile(matchexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-m': {}: {}\".format(matchexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for item in items:\n    ",
            "start_line": 195,
            "start_column": 6452,
            "end_line": 0,
            "end_column": 7948,
            "start_byte": 6452,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.Mark.name",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "    except ParseError as",
            "start_line": 198,
            "start_column": 6514,
            "end_line": 4,
            "end_column": 6538,
            "start_byte": 6514,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.args",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "ion passed to '-k': {}: {}\".format(k",
            "start_line": 200,
            "start_column": 6594,
            "end_line": 4,
            "end_column": 6630,
            "start_byte": 6594,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.kwargs",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "]\n    deselected = []\n    for colitem in",
            "start_line": 202,
            "start_column": 6683,
            "end_line": 4,
            "end_column": 6723,
            "start_byte": 6683,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_from",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "e(KeywordMatcher.from_item(colitem)):\n            deselected.append(colite",
            "start_line": 205,
            "start_column": 6780,
            "end_line": 4,
            "end_column": 6854,
            "start_byte": 6780,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_generated",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "  keywordexpr = None\n            remaining.append(colitem)\n\n    if deselected:\n        config.hook.p",
            "start_line": 207,
            "start_column": 6913,
            "end_line": 4,
            "end_column": 7013,
            "start_byte": 6913,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._has_param_ids",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "deselected(items=deselected)\n        items[:] = remaining\n\n\n@attr.s(slots=True)\nclass MarkMa",
            "start_line": 211,
            "start_column": 7019,
            "end_line": 4,
            "end_column": 7111,
            "start_byte": 7019,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.combined_with",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "\n    \"\"\"A matcher for markers which are present.\n\n    Tries to match on any marker names, attached to the given colitem.\n    \"\"\"\n\n    own_mark_names = attr.ib()\n\n    @classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)\n\n    def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names\n\n\ndef deselect_by_mark(items: \"List[Item]\", config: Config) -> None:\n    matchexpr = config.option.markexpr\n    if not matchexpr:\n        return\n\n    try:\n        expression = Expression.compile(matchexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-m': {}: {}\".format(matchexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for item in items:\n    ",
            "start_line": 214,
            "start_column": 7117,
            "end_line": 4,
            "end_column": 7948,
            "start_byte": 7117,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark._Markable",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "test_deselected(items=deselected)\n        items[:] = remaining\n\n\ndef pytes",
            "start_line": 245,
            "start_column": 8132,
            "end_line": 0,
            "end_column": 8206,
            "start_byte": 8132,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "ollection_modifyitems(items: \"List[Item]\", config: Config) -> None:\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)\n\n\ndef pytest_configure(config: Config) -> None:\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageError(\n            \"{!s} must be one of skip, xfail or fail_at_collect\"\n            \" but it is {!r}\".format(EMPTY_PARAMETERSET_OPTION, empty_parameterset)\n        )\n\n\ndef pytest_unconfigure(config: Config) -> None:\n    MARK_GEN._config = config._store.get(old_mark_config_key, None)\n",
            "start_line": 248,
            "start_column": 8209,
            "end_line": 0,
            "end_column": 11549,
            "start_byte": 8209,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator.mark",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 284,
            "start_column": 9608,
            "end_line": 4,
            "end_column": 9678,
            "start_byte": 9608,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.name",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 286,
            "start_column": 9684,
            "end_line": 4,
            "end_column": 9785,
            "start_byte": 9684,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.args",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 291,
            "start_column": 9791,
            "end_line": 4,
            "end_column": 9904,
            "start_byte": 9791,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.kwargs",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 296,
            "start_column": 9910,
            "end_line": 4,
            "end_column": 10031,
            "start_byte": 9910,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.markname",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 301,
            "start_column": 10037,
            "end_line": 4,
            "end_column": 10147,
            "start_byte": 10037,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__repr__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 305,
            "start_column": 10153,
            "end_line": 4,
            "end_column": 10235,
            "start_byte": 10153,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.with_args",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 308,
            "start_column": 10241,
            "end_line": 4,
            "end_column": 10647,
            "start_byte": 10241,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 322,
            "start_column": 10861,
            "end_line": 4,
            "end_column": 10981,
            "start_byte": 10861,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 326,
            "start_column": 10987,
            "end_line": 4,
            "end_column": 11150,
            "start_byte": 10987,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 332,
            "start_column": 11156,
            "end_line": 4,
            "end_column": 11549,
            "start_byte": 11156,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 450,
            "start_column": 15252,
            "end_line": 0,
            "end_column": 18166,
            "start_byte": 15252,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkGenerator._config",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 465,
            "start_column": 15571,
            "end_line": 4,
            "end_column": 15585,
            "start_byte": 15571,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator._markers",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 466,
            "start_column": 15616,
            "end_line": 4,
            "end_column": 15632,
            "start_byte": 15616,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator.__getattr__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 479,
            "start_column": 16175,
            "end_line": 4,
            "end_column": 18166,
            "start_byte": 16175,
            "end_byte": 4
          },
          {
            "name": "_pytest.pastebin.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "arsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def",
            "start_line": 30,
            "start_column": 778,
            "end_line": 0,
            "end_column": 1609,
            "start_byte": 778,
            "end_byte": 0
          },
          {
            "name": "_pytest.pytester.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions a",
            "start_line": 83,
            "start_column": 2138,
            "end_line": 0,
            "end_column": 2530,
            "start_byte": 2138,
            "end_byte": 0
          },
          {
            "name": "_pytest.python.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": " the names of its parents.\n    Only matches names of items which are either a :class:`Class` or a\n    :class:`Function`.\n\n    Additionally, matches on names in the 'extra_keyword_matches' set of\n    any item, as well as names directly assigned to test functions.\n    \"\"\"\n\n    _names = attr.ib(type=AbstractSet[str])\n\n    @classmethod\n    def from_item(cls, item: \"Item\") -> \"KeywordMatcher\":\n        mapped_names = set()\n\n        # Add the names of the current item and any parent items\n        import pytest\n\n        for node in item.listchain():\n            if not isinstance(node, (pytest.Instance, pytest.Session)):\n                mapped_names.add(node.name)\n\n        # Add the names added as extra keywords to current or parent items\n        mapped_names.update(item.listextrakeywords())\n\n        # Add the names attached to the current function through direct assignment\n        function_obj = getattr(item, \"",
            "start_line": 138,
            "start_column": 4458,
            "end_line": 0,
            "end_column": 5374,
            "start_byte": 4458,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "lection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def test_eval(test_input, expected):\n            assert eval(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and classes whose name \"\n        \"contains 'test_method' or 'test_other', while -k 'not test_method' \"\n        \"matches those that don't contain 'test_method' in their names. \"\n        \"-k 'not test_method and not test_other' will eliminate the matches. \"\n        \"Additionally keywor",
            "start_line": 47,
            "start_column": 1193,
            "end_line": 0,
            "end_column": 2813,
            "start_byte": 1193,
            "end_byte": 0
          },
          {
            "name": "_pytest.stepwise.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": ".config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecate",
            "start_line": 28,
            "start_column": 728,
            "end_line": 0,
            "end_column": 866,
            "start_byte": 728,
            "end_byte": 0
          },
          {
            "name": "_pytest.stepwise.StepwisePlugin.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "ize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def test_eval(test_input, expected):\n            assert eval(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and cl",
            "start_line": 48,
            "start_column": 1400,
            "end_line": 4,
            "end_column": 2535,
            "start_byte": 1400,
            "end_byte": 4
          },
          {
            "name": "_pytest.terminal.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": " config.option.keyword.lstrip()\n    if not keywordexpr:\n        return\n\n    if keywordexpr.startswith(\"-\"):\n        # To be removed in pytest 7.0.0.\n        warnings.warn(MINUS_K_DASH, stacklevel=2)\n        keywordexpr = \"not \" + keywordexpr[1:]\n    selectuntil = False\n    if keywordexpr[-1:] == \":\":\n        # To be removed in pytest 7.0.0.\n        warnings.warn(MINUS_K_COLON, stacklevel=2)\n        selectuntil = Tru",
            "start_line": 224,
            "start_column": 5991,
            "end_line": 0,
            "end_column": 6410,
            "start_byte": 5991,
            "end_byte": 0
          },
          {
            "name": "_pytest.tmpdir.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "t[str])\n\n    @classmethod\n    def from_item(cls, item: \"Item\") -> \"KeywordMatcher\":\n        mapped_names = set()\n\n        # Add the names of the current item and any parent items\n        import pytest\n\n        for node in item.listchain():\n            if not isinstance(node, (pytest.Instance, pytest.Session)):\n                mapped_names.add(node.name)\n\n        # Add the names added as extra keywords to current or parent items\n        mapped_names.update(item.listextrakeywords())\n\n        # Add the names attached to the current function through direct assignment\n        function_obj = getattr(item, \"",
            "start_line": 138,
            "start_column": 4766,
            "end_line": 0,
            "end_column": 5374,
            "start_byte": 4766,
            "end_byte": 0
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "o this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(",
            "start_line": 77,
            "start_column": 1903,
            "end_line": 0,
            "end_column": 2100,
            "start_byte": 1903,
            "end_byte": 0
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning.__module__",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "    group._addoption(",
            "start_line": 83,
            "start_column": 2079,
            "end_line": 4,
            "end_column": 2100,
            "start_byte": 2079,
            "end_byte": 4
          },
          {
            "name": "_pytest.warnings.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": " tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other'",
            "start_line": 74,
            "start_column": 2235,
            "end_line": 0,
            "end_column": 2501,
            "start_byte": 2235,
            "end_byte": 0
          },
          {
            "name": "_pytest.resultlog.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "est.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: ",
            "start_line": 30,
            "start_column": 725,
            "end_line": 0,
            "end_column": 1434,
            "start_byte": 725,
            "end_byte": 0
          }
        ],
        "root_caused_symbols": [
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1174,
            "start_column": 45925,
            "end_line": 0,
            "end_column": 47430,
            "start_byte": 45925,
            "end_byte": 0
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.scope",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1176,
            "start_column": 45979,
            "end_line": 4,
            "end_column": 46049,
            "start_byte": 45979,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.params",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1177,
            "start_column": 46054,
            "end_line": 4,
            "end_column": 46134,
            "start_byte": 46054,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.autouse",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1178,
            "start_column": 46139,
            "end_line": 4,
            "end_column": 46182,
            "start_byte": 46139,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1179,
            "start_column": 46187,
            "end_line": 4,
            "end_column": 46411,
            "start_byte": 46187,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1187,
            "start_column": 46416,
            "end_line": 4,
            "end_column": 46464,
            "start_byte": 46416,
            "end_byte": 4
          },
          {
            "name": "_pytest.fixtures.FixtureFunctionMarker.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1189,
            "start_column": 46470,
            "end_line": 4,
            "end_column": 47430,
            "start_byte": 46470,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "lf.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 214,
            "start_column": 7079,
            "end_line": 0,
            "end_column": 7525,
            "start_byte": 7079,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkMatcher.own_mark_names",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": " Mark.\n\n        Combines b",
            "start_line": 221,
            "start_column": 7251,
            "end_line": 4,
            "end_column": 7277,
            "start_byte": 7251,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.from_item",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "nding args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert s",
            "start_line": 223,
            "start_column": 7283,
            "end_line": 4,
            "end_column": 7438,
            "start_byte": 7283,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkMatcher.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "me == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 228,
            "start_column": 7444,
            "end_line": 4,
            "end_column": 7525,
            "start_byte": 7444,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s(frozen=True)\nclass Mark:\n    #: Name of the mark.\n    name = attr.ib(type=str)\n    #: Positional arguments of the mark decorator.\n    args = attr.ib(type=Tuple[Any, ...])\n    #: Keyword arguments of the mark decorator.\n    kwargs = attr.ib(type=Mapping[str, Any])\n\n    #: Source Mark for ids with parametrize Marks.\n    _param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)\n    #: Resolved/generated ids with parametrize Marks.\n    _param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )\n\n    def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 195,
            "start_column": 6452,
            "end_line": 0,
            "end_column": 7948,
            "start_byte": 6452,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.Mark.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "name = attr.ib(type=str)",
            "start_line": 198,
            "start_column": 6514,
            "end_line": 4,
            "end_column": 6538,
            "start_byte": 6514,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "args = attr.ib(type=Tuple[Any, ...])",
            "start_line": 200,
            "start_column": 6594,
            "end_line": 4,
            "end_column": 6630,
            "start_byte": 6594,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "kwargs = attr.ib(type=Mapping[str, Any])",
            "start_line": 202,
            "start_column": 6683,
            "end_line": 4,
            "end_column": 6723,
            "start_byte": 6683,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_from",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)",
            "start_line": 205,
            "start_column": 6780,
            "end_line": 4,
            "end_column": 6854,
            "start_byte": 6780,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._param_ids_generated",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )",
            "start_line": 207,
            "start_column": 6913,
            "end_line": 4,
            "end_column": 7013,
            "start_byte": 6913,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark._has_param_ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4",
            "start_line": 211,
            "start_column": 7019,
            "end_line": 4,
            "end_column": 7111,
            "start_byte": 7019,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.Mark.combined_with",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 214,
            "start_column": 7117,
            "end_line": 4,
            "end_column": 7948,
            "start_byte": 7117,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark._Markable",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_Markable = TypeVar(\"_Markable\", bound=Union[Callable[..., object], type])",
            "start_line": 245,
            "start_column": 8132,
            "end_line": 0,
            "end_column": 8206,
            "start_byte": 8132,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s\nclass MarkDecorator:\n    \"\"\"A decorator for applying a mark on test functions and classes.\n\n    MarkDecorators are created with ``pytest.mark``::\n\n        mark1 = pytest.mark.NAME              # Simple MarkDecorator\n        mark2 = pytest.mark.NAME(name1=value) # Parametrized MarkDecorator\n\n    and can then be applied as decorators to test functions::\n\n        @mark2\n        def test_function():\n            pass\n\n    When a MarkDecorator is called it does the following:\n\n    1. If called with a single class as its only positional argument and no\n       additional keyword arguments, it attaches the mark to the class so it\n       gets applied automatically to all test cases found in that class.\n\n    2. If called with a single function as its only positional argument and\n       no additional keyword arguments, it attaches the mark to the function,\n       containing all the arguments already stored internally in the\n       MarkDecorator.\n\n    3. When called in any other case, it returns a new MarkDecorator instance\n       with the original MarkDecorator's content updated with the arguments\n       passed to this call.\n\n    Note: The rules above prevent MarkDecorators from storing only a single\n    function or class reference as their positional argument with no\n    additional keyword or positional arguments. You can work around this by\n    using `with_args()`.\n    \"\"\"\n\n    mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))\n\n    @property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name\n\n    @property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args\n\n    @property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs\n\n    @property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)\n\n    def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)\n\n    def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))\n\n    # Type ignored because the overloads overlap with an incompatible\n    # return type. Not much we can do about that. Thankfully mypy picks\n    # the first match so it works out even if we break the rules.\n    @overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()\n\n    @overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()\n\n    def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 248,
            "start_column": 8209,
            "end_line": 0,
            "end_column": 11549,
            "start_byte": 8209,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkDecorator.mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))",
            "start_line": 284,
            "start_column": 9608,
            "end_line": 4,
            "end_column": 9678,
            "start_byte": 9608,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name",
            "start_line": 286,
            "start_column": 9684,
            "end_line": 4,
            "end_column": 9785,
            "start_byte": 9684,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args",
            "start_line": 291,
            "start_column": 9791,
            "end_line": 4,
            "end_column": 9904,
            "start_byte": 9791,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs",
            "start_line": 296,
            "start_column": 9910,
            "end_line": 4,
            "end_column": 10031,
            "start_byte": 9910,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.markname",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)",
            "start_line": 301,
            "start_column": 10037,
            "end_line": 4,
            "end_column": 10147,
            "start_byte": 10037,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__repr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)",
            "start_line": 305,
            "start_column": 10153,
            "end_line": 4,
            "end_column": 10235,
            "start_byte": 10153,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.with_args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))",
            "start_line": 308,
            "start_column": 10241,
            "end_line": 4,
            "end_column": 10647,
            "start_byte": 10241,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()",
            "start_line": 322,
            "start_column": 10861,
            "end_line": 4,
            "end_column": 10981,
            "start_byte": 10861,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()",
            "start_line": 326,
            "start_column": 10987,
            "end_line": 4,
            "end_column": 11150,
            "start_byte": 10987,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 332,
            "start_column": 11156,
            "end_line": 4,
            "end_column": 11549,
            "start_byte": 11156,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "class MarkGenerator:\n    \"\"\"Factory for :class:`MarkDecorator` objects - exposed as\n    a ``pytest.mark`` singleton instance.\n\n    Example::\n\n         import pytest\n\n         @pytest.mark.slowtest\n         def test_function():\n            pass\n\n    applies a 'slowtest' :class:`Mark` on ``test_function``.\n    \"\"\"\n\n    _config = None  # type: Optional[Config]\n    _markers = set()  # type: Set[str]\n\n    # See TYPE_CHECKING above.\n    if TYPE_CHECKING:\n        # Using casts instead of type comments intentionally - issue #7473.\n        # TODO(py36): Change to builtin annotation syntax.\n        skip = cast(_SkipMarkDecorator, None)\n        skipif = cast(_SkipifMarkDecorator, None)\n        xfail = cast(_XfailMarkDecorator, None)\n        parametrize = cast(_ParametrizeMarkDecorator, None)\n        usefixtures = cast(_UsefixturesMarkDecorator, None)\n        filterwarnings = cast(_FilterwarningsMarkDecorator, None)\n\n    def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 450,
            "start_column": 15252,
            "end_line": 0,
            "end_column": 18166,
            "start_byte": 15252,
            "end_byte": 0
          },
          {
            "name": "_pytest.mark.MarkGenerator._config",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_config = None",
            "start_line": 465,
            "start_column": 15571,
            "end_line": 4,
            "end_column": 15585,
            "start_byte": 15571,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator._markers",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_markers = set()",
            "start_line": 466,
            "start_column": 15616,
            "end_line": 4,
            "end_column": 15632,
            "start_byte": 15616,
            "end_byte": 4
          },
          {
            "name": "_pytest.mark.MarkGenerator.__getattr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 479,
            "start_column": 16175,
            "end_line": 4,
            "end_column": 18166,
            "start_byte": 16175,
            "end_byte": 4
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "\"values\", Sequence[Union[object, NotSetType]]),\n            (\"marks\", \"typing.Collection[Union[MarkDecorator, Mark]]\"),\n            (\"id\", Optional[str]),\n        ],\n    )\n):\n    @classmethod\n    d",
            "start_line": 77,
            "start_column": 1903,
            "end_line": 0,
            "end_column": 2100,
            "start_byte": 1903,
            "end_byte": 0
          },
          {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning.__module__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "   @classmethod\n    d",
            "start_line": 83,
            "start_column": 2079,
            "end_line": 4,
            "end_column": 2100,
            "start_byte": 2079,
            "end_byte": 4
          },
          {
            "name": "_pytest.hookspec.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "",
            "start_line": 486,
            "start_column": 17380,
            "end_line": 0,
            "end_column": 17867,
            "start_byte": 17380,
            "end_byte": 0
          },
          {
            "name": "_pytest.runner.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "ort_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:\n    if hasattr(report, \"wasxfail\"):\n        if report.skipped",
            "start_line": 318,
            "start_column": 10464,
            "end_line": 0,
            "end_column": 10595,
            "start_byte": 10464,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.evaluate_condition",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "def evaluate_condition(item: Item, mark: Mark, condition: object) -> Tuple[bool, str]:\n    \"\"\"Evaluate a single skipif/xfail condition.\n\n    If an old-style string condition is given, it is eval()'d, otherwise the\n    condition is bool()'d. If this fails, an appropriately formatted pytest.fail\n    is raised.\n\n    Returns (result, reason). The reason is only relevant if the result is True.\n    \"\"\"\n    # String condition.\n    if isinstance(condition, str):\n        globals_ = {\n            \"os\": os,\n            \"sys\": sys,\n            \"platform\": platform,\n            \"config\": item.config,\n        }\n        if hasattr(item, \"obj\"):\n            globals_.update(item.obj.__globals__)  # type: ignore[attr-defined]\n        try:\n            filename = \"<{} condition>\".format(mark.name)\n            condition_code = compile(condition, filename, \"eval\")\n            result = eval(condition_code, globals_)\n        except SyntaxError as exc:\n            msglines = [\n                \"Error evaluating %r condition\" % mark.name,\n                \"    \" + condition,\n                \"    \" + \" \" * (exc.offset or 0) + \"^\",\n                \"SyntaxError: invalid syntax\",\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n        except Exception as exc:\n            msglines = [\n                \"Error evaluating %r condition\" % mark.name,\n                \"    \" + condition,\n                *traceback.format_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    # Boolean condition.\n    else:\n        try:\n            result = bool(condition)\n        except Exception as exc:\n            msglines = [\n                \"Error evaluating %r condition as a boolean\" % mark.name,\n                *traceback.format_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    reason = mark.kwargs.get(\"reason\", None)\n    if reason is None:\n        if isinstance(condition, str):\n            reason = \"condition: \" + condition\n        else:\n            # XXX better be checked at collection time\n            msg = (\n                \"Error evaluating %r: \" % mark.name\n                + \"you need to specify reason=STRING when using booleans as conditions.\"\n            )\n            fail(msg, pytrace=False)\n\n    return result, reason",
            "start_line": 86,
            "start_column": 2816,
            "end_line": 0,
            "end_column": 5151,
            "start_byte": 2816,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.evaluate_xfail_marks",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None",
            "start_line": 199,
            "start_column": 6507,
            "end_line": 0,
            "end_column": 7408,
            "start_byte": 6507,
            "end_byte": 0
          },
          {
            "name": "_pytest.skipping.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "@hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n    outcome = yield\n    rep = outcome.get_result()\n    xfailed = item._store.get(xfailed_key, None)\n    # unittest special case, see setting of unexpectedsuccess_key\n    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n        reason = item._store[unexpectedsuccess_key]\n        if reason:\n            rep.longrepr = \"Unexpected success: {}\".format(reason)\n        else:\n            rep.longrepr = \"Unexpected success\"\n        rep.outcome = \"failed\"\n    elif item.config.option.runxfail:\n        pass  # don't interfere\n    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n        assert call.excinfo.value.msg is not None\n        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n        rep.outcome = \"skipped\"\n    elif not rep.skipped and xfailed:\n        if call.excinfo:\n            raises = xfailed.raises\n            if raises is not None and not isinstance(call.excinfo.value, raises):\n                rep.outcome = \"failed\"\n            else:\n                rep.outcome = \"skipped\"\n                rep.wasxfail = xfailed.reason\n        elif call.when == \"call\":\n            if xfailed.strict:\n                rep.outcome = \"failed\"\n                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n            else:\n                rep.outcome = \"passed\"\n                rep.wasxfail = xfailed.reason\n\n    if (\n        item._store.get(skipped_by_mark_key, True)\n        and rep.skipped\n        and type(rep.longrepr) is tuple\n    ):\n        # skipped by mark.skipif; change the location of the failure\n        # to point to the item definition, otherwise it will display\n        # the location of where the skip exception was raised within pytest\n        _, _, reason = rep.longrepr\n        filename, line = item.reportinfo()[:2]\n        assert line is not None\n        rep.longrepr = str(filename), line + 1, reason",
            "start_line": 259,
            "start_column": 8490,
            "end_line": 0,
            "end_column": 10447,
            "start_byte": 8490,
            "end_byte": 0
          },
          {
            "name": "_pytest.unittest.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "urn \"xpassed\", \"X\", \"XPASS\"\n    return None\n",
            "start_line": 290,
            "start_column": 10683,
            "end_line": 0,
            "end_column": 11441,
            "start_byte": 10683,
            "end_byte": 0
          }
        ]
      },
      "response": {
        "scratch_pad": "1.1 The user describes an issue that, in pytest 6.0.0rc0, the behavior of dynamically adding an xfail marker using request.node.add_marker has changed compared to version 5.x, this used to cause the test to be marked as expected to fail. In version 6.0.0rc0, the same practice raises an error instead of returning an xfail. \n1.2 It seems like this behavior change might be related to how markers are applied in the new version. Understanding how markers are implemented especially how xfail operates in the two versions could be crucial. \n1.3 The user expects that adding an xfail marker dynamically should behave like in the old versions, marking test failures as expected (xfail) instead of errors.\n1.4 If the user has not given an expected behavior, it would still likely be that tests with dynamically added xfail markers should not cause errors but be marked as xfail instead.\n1.5 It should be analyzed why in 6.0.0rc0 this addition causes errors (perhaps by observing implementation in the symbols), and enabling the tests to be marked xfail properly without causing error.\n\n2.1 Analyze symbols in the context provided, related to markers and marker infrastructure.\n2.2 Look for differences or edge cases in 6.0.0rc0 specifically around request.node.add_marker and how markers like xfail are expected to behave.\n2.3 Upon evaluating the functions in /pytest/mark/structures.py, some key elements emerge such as MarkDecorator, Mark, and MarkManager functions which handle creating, combining, and interacting with marks, this could hint at changes in handling or registering marks.\n2.4 Evaluate if there\u2019s a method used for request.node.add_marker that diverges from the expected utilization in the old version, suggest adjustments or fixes to allow consistent behavior once observed.\n2.5 Ask for more of structures.py file for any introspection for more detail-oriented behavior regarding the issue.",
        "symbols": [
          {
            "name": "_pytest.nodes.Node.add_marker",
            "file_path": "src/_pytest/nodes.py",
            "reason": "'add_marker' is directly related to dynamically adding markers like xfail and could be contributing to the difference in behavior between versions as observed in issue."
          },
          {
            "name": "_pytest.mark.MarkDecorator",
            "file_path": "src/_pytest/mark/structures.py",
            "reason": "Central class in handling of mark decorators in pytest, crucial to adding xfail marker behavior since the code directly uses a MarkDecorator."
          },
          {
            "name": "_pytest.mark.MarkGenerator",
            "file_path": "src/_pytest/mark/structures.py",
            "reason": "Likely related to generating marks that might be dictating how dynamically added xfail markers are evaluated differently."
          },
          {
            "name": "_pytest.skipping.evaluate_xfail_marks",
            "file_path": "src/_pytest/skipping.py",
            "reason": "Evaluates xfail marks specifically which could highlight why xfail markers are no longer evaluated in the older manner leading to a fail instead of recognized XFail."
          },
          {
            "name": "_pytest.skipping.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "reason": "Skills test report creation and handles how xfail might be reported differently - this might yield differences in behavior."
          }
        ],
        "more_info": [],
        "is_done": true,
        "symbols_scratch_pad": [
          "_pytest.fixtures.FixtureFunctionMarker - This symbol appears to manage some sort of marker or fixture function indication but isn't directly related to the xfail or marking functionality related to the issue.",
          "_pytest.fixtures.FixtureFunctionMarker.scope - This seems more concerned with a specific property of fixture markers, like in lifecycle or scoping, not directly tied to xfail issue.",
          "_pytest.fixtures.FixtureFunctionMarker.params - This looks more relevant to parameters in parametrizing fixtures etc. and not directly with xfail marking.",
          "_pytest.fixtures.FixtureFunctionMarker.autouse - Again, this indicates a property about fixture markers, but not focused on xfail dynamics.",
          "_pytest.fixtures.FixtureFunctionMarker.ids - Specific to the identifier of fixtures, doesn\u2019t align with xfail issue.",
          "_pytest.fixtures.FixtureFunctionMarker.name - Again important in its context but not affecting xfail marking usage.",
          "_pytest.fixtures.FixtureFunctionMarker.__call__ - Authorizes use of fixtures but doesn\u2019t highlight changes in handling xfail.",
          "_pytest.mark.MarkMatcher - Involves marking but seems more set for item matching, not the specific case of how xfail acts related to request.node.add_marker.",
          "_pytest.mark.MarkMatcher.own_mark_names - An attribute this seems to be conducted within matching more than individual functional aspects related to xfail.",
          "_pytest.mark.MarkMatcher.from_item - Involvement in creating matchers from test items, potentially impactful, yet not explicitly detailed toward xfail working.",
          "_pytest.mark.MarkMatcher.__call__ - Considers matching logic in pytest but not immediate in understanding xfail workaround.",
          "_pytest.mark.Mark - Central in how marks operate including xfail, useful in understanding any changes though its detailed examination needed next.",
          "_pytest.mark.Mark.name - This should be a core property of Mark and its interaction with names, important if naming causes mismatch in xfail.",
          "_pytest.mark.Mark.args - Arguments interacting internally with Mark, needed in understanding if xfail's dynamics altered with dynamic addition.",
          "_pytest.mark.Mark.kwargs - Keyword args also form part of the functioning and could affect marker results.",
          "_pytest.mark.Mark._param_ids_from - Functionality probably unused explicitly in context to issue unless delegated something behind scened with xfail and parameterization.",
          "_pytest.mark.Mark._param_ids_generated - Derived generation invisibly affecting if generated IDs conflicted with Mark too on xfail.",
          "_pytest.mark.Mark._has_param_ids - Intersection of parameterization into xfail debate unless parameters creates unseen alterations seems lower priority.",
          "_pytest.mark.Mark.combined_with - Combination of marks, not yet needing any investigations on its own apart from any hidden interaction specifics with xfail also fascia.",
          "_pytest.mark._Markable - Higher level abstract/not directorial or specific enough in tangible changes for the issue context.",
          "_pytest.mark.MarkDecorator - Covers a Mark object utilized directly in issue observed, likely holding vital clues or direct change differences demanded.",
          "_pytest.mark.MarkDecorator.mark - Association in marking part of Decorator necessities as xfail influences MarkDecorator levels typically.",
          "_pytest.mark.MarkDecorator.name - Network handled through this class MarkDecorator attaches/utilize name interfering with dynamic decorations on xfail-like test.",
          "_pytest.mark.MarkDecorator.args - Foundations of argument used MarkDecorator exist for understanding argumenticity influencing differing marker uses xfail included.",
          "_pytest.mark.MarkDecorator.kwargs - Likeliness in conjunction to 'args', analyzing close enough depicts affirming what affects Kushnalase if anything with xfail handling.",
          "_pytest.mark.MarkDecorator.markname - This associates names MarkDecorators in another layer, important if recent changes mark identification knot inward over xfail context.",
          "_pytest.mark.MarkDecorator.__repr__ - Low priority on understanding human-readable description alignment than anything affecting issue underlining.",
          "_pytest.mark.MarkDecorator.with_args - Vital alteration and adjusting strategy interaction with xfail reconsideration mark focused with_args varying throughout with xfail.",
          "_pytest.mark.MarkDecorator.__call__ - Central controlling during expanded interaction versatile on decorators usage or functionality, prominent if newer versions expand or alter calls methods additional barriers using xfail in mind.",
          "_pytest.mark.MarkGenerator - Evident responsibility generating decorators, immediately impacting handling if alterations or redirections seen in xfail cases exigencies.",
          "_pytest.mark.JenkinsCl.build_started marking of construction reflection thereby affecting pytest major or indirectly struggle transformations perhaps including marks needed perfection towards reducing xfail capability misfortunes."
        ]
      }
    },
    {
      "name": "SymbolSummary",
      "metadata": {
        "start": "2024-08-17T22:24:58.130455",
        "usage": "5.486011505126953 ms"
      },
      "request": {
        "symbols": {
          "related_symbols": [
            {
              "name": "_pytest.nodes.Node.add_marker",
              "file_path": "src/_pytest/nodes.py",
              "file_content": "def add_marker(\n        self, marker: Union[str, MarkDecorator], append: bool = True\n    ) -> None:\n        \"\"\"dynamically add a marker object to the node.\n\n        :type marker: ``str`` or ``pytest.mark.*``  object\n        :param marker:\n            ``append=True`` whether to append the marker,\n            if ``False`` insert at position ``0``.\n        \"\"\"\n        from _pytest.mark import MARK_GEN\n\n        if isinstance(marker, MarkDecorator):\n            marker_ = marker\n        elif isinstance(marker, str):\n            marker_ = getattr(MARK_GEN, marker)\n        else:\n            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n        self.keywords[marker_.name] = marker_\n        if append:\n            self.own_markers.append(marker_.mark)\n        else:\n            self.own_markers.insert(0, marker_.mark)",
              "start_line": 260,
              "start_column": 8242,
              "end_line": 4,
              "end_column": 9073,
              "start_byte": 8242,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.store_mark",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def store_mark(obj, mark: Mark) -> None:\n    \"\"\"Store a Mark on an object.\n\n    This is used to implement the Mark declarations/decorators correctly.\n    \"\"\"\n    assert isinstance(mark, Mark), mark\n    # Always reassign name to avoid updating pytestmark in a reference that\n    # was only borrowed.\n    obj.pytestmark = get_unpacked_marks(obj) + [mark]",
              "start_line": 369,
              "start_column": 12372,
              "end_line": 0,
              "end_column": 12724,
              "start_byte": 12372,
              "end_byte": 0
            },
            {
              "name": "_pytest.cacheprovider.LFPlugin.pytest_collection_modifyitems",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 289,
              "start_column": 10558,
              "end_line": 4,
              "end_column": 12796,
              "start_byte": 10558,
              "end_byte": 4
            },
            {
              "name": "_pytest.cacheprovider.NFPlugin.pytest_collection_modifyitems",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 361,
              "start_column": 13534,
              "end_line": 4,
              "end_column": 14397,
              "start_byte": 13534,
              "end_byte": 4
            },
            {
              "name": "_pytest.cacheprovider.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 464,
              "start_column": 16918,
              "end_line": 0,
              "end_column": 17167,
              "start_byte": 16918,
              "end_byte": 0
            },
            {
              "name": "_pytest.config.PytestPluginManager.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 442,
              "start_column": 13883,
              "end_line": 4,
              "end_column": 14533,
              "start_byte": 13883,
              "end_byte": 4
            },
            {
              "name": "_pytest.debugging.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "f marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and classes whose name \"\n        \"contains 'test_method' or 'test_other', while -k 'not test_method' \"\n        \"matches ",
              "start_line": 61,
              "start_column": 1816,
              "end_line": 0,
              "end_column": 2649,
              "start_byte": 1816,
              "end_byte": 0
            },
            {
              "name": "_pytest.faulthandler.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "from .structures import ParameterSet\nfrom _pytest.compat import TYPE_CHECKING\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n          ",
              "start_line": 24,
              "start_column": 532,
              "end_line": 0,
              "end_column": 1486,
              "start_byte": 532,
              "end_byte": 0
            },
            {
              "name": "_pytest.faulthandler.FaultHandlerHooks.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSe",
              "start_line": 52,
              "start_column": 1666,
              "end_line": 4,
              "end_column": 1955,
              "start_byte": 1666,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 1174,
              "start_column": 45925,
              "end_line": 0,
              "end_column": 47430,
              "start_byte": 45925,
              "end_byte": 0
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.scope",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 1176,
              "start_column": 45979,
              "end_line": 4,
              "end_column": 46049,
              "start_byte": 45979,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.params",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 1177,
              "start_column": 46054,
              "end_line": 4,
              "end_column": 46134,
              "start_byte": 46054,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.autouse",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 1178,
              "start_column": 46139,
              "end_line": 4,
              "end_column": 46182,
              "start_byte": 46139,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.ids",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 1179,
              "start_column": 46187,
              "end_line": 4,
              "end_column": 46411,
              "start_byte": 46187,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.name",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 1187,
              "start_column": 46416,
              "end_line": 4,
              "end_column": 46464,
              "start_byte": 46416,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.__call__",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 1189,
              "start_column": 46470,
              "end_line": 4,
              "end_column": 47430,
              "start_byte": 46470,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureManager.pytest_collection_modifyitems",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 1613,
              "start_column": 62458,
              "end_line": 4,
              "end_column": 62612,
              "start_byte": 62458,
              "end_byte": 4
            },
            {
              "name": "_pytest.hookspec.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "line()\n        config._ensure_unconfigure()\n        return 0\n\n    return None\n\n\n@attr.s(slots=True)\nclass KeywordMatcher:\n    \"\"\"A matcher for keywords.\n\n    Given a list of names, matches any substring of one of these names. The\n    string inclusion check is case-insensitive.\n\n    Will match on the name of colitem, including the names of its parents.\n    Only matches names of items which are either a :class:`Class` or a\n    :class:`Function`.\n\n    Additionally, matches on names in the 'extra_key",
              "start_line": 117,
              "start_column": 4131,
              "end_line": 0,
              "end_column": 4632,
              "start_byte": 4131,
              "end_byte": 0
            },
            {
              "name": "_pytest.hookspec.pytest_collection_modifyitems",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": ", config: Config) -> None:\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)\n\n\ndef pytest_configure(config: Config) -> None:\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageEr",
              "start_line": 231,
              "start_column": 8250,
              "end_line": 0,
              "end_column": 8658,
              "start_byte": 8250,
              "end_byte": 0
            },
            {
              "name": "_pytest.junitxml.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 439,
              "start_column": 15188,
              "end_line": 0,
              "end_column": 15980,
              "start_byte": 15188,
              "end_byte": 0
            },
            {
              "name": "_pytest.logging.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 501,
              "start_column": 17763,
              "end_line": 0,
              "end_column": 17914,
              "start_byte": 17763,
              "end_byte": 0
            },
            {
              "name": "_pytest.main.pytest_collection_modifyitems",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 372,
              "start_column": 12071,
              "end_line": 0,
              "end_column": 12584,
              "start_byte": 12071,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkMatcher",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "@attr.s(slots=True)\nclass MarkMatcher:\n    \"\"\"A matcher for markers which are present.\n\n    Tries to match on any marker names, attached to the given colitem.\n    \"\"\"\n\n    own_mark_names = attr.ib()\n\n    @classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)\n\n    def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names",
              "start_line": 214,
              "start_column": 7079,
              "end_line": 0,
              "end_column": 7525,
              "start_byte": 7079,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkMatcher.own_mark_names",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "own_mark_names = attr.ib()",
              "start_line": 221,
              "start_column": 7251,
              "end_line": 4,
              "end_column": 7277,
              "start_byte": 7251,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkMatcher.from_item",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "@classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)",
              "start_line": 223,
              "start_column": 7283,
              "end_line": 4,
              "end_column": 7438,
              "start_byte": 7283,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkMatcher.__call__",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names",
              "start_line": 228,
              "start_column": 7444,
              "end_line": 4,
              "end_column": 7525,
              "start_byte": 7444,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.deselect_by_mark",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "def deselect_by_mark(items: \"List[Item]\", config: Config) -> None:\n    matchexpr = config.option.markexpr\n    if not matchexpr:\n        return\n\n    try:\n        expression = Expression.compile(matchexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-m': {}: {}\".format(matchexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for item in items:\n        if expression.evaluate(MarkMatcher.from_item(item)):\n            remaining.append(item)\n        else:\n            deselected.append(item)\n\n    if deselected:\n        config.hook.pytest_deselected(items=deselected)\n        items[:] = remaining",
              "start_line": 232,
              "start_column": 7528,
              "end_line": 0,
              "end_column": 8194,
              "start_byte": 7528,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.pytest_collection_modifyitems",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "def pytest_collection_modifyitems(items: \"List[Item]\", config: Config) -> None:\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)",
              "start_line": 257,
              "start_column": 8197,
              "end_line": 0,
              "end_column": 8351,
              "start_byte": 8197,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "def pytest_configure(config: Config) -> None:\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageError(\n            \"{!s} must be one of skip, xfail or fail_at_collect\"\n            \" but it is {!r}\".format(EMPTY_PARAMETERSET_OPTION, empty_parameterset)\n        )",
              "start_line": 262,
              "start_column": 8354,
              "end_line": 0,
              "end_column": 8821,
              "start_byte": 8354,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.Mark",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "    try:\n        expression = Expression.compile(keywordexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-k': {}: {}\".format(keywordexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for colitem in items:\n        if keywordexpr and not expression.evaluate(KeywordMatcher.from_item(colitem)):\n            deselected.append(colitem)\n        else:\n            if selectuntil:\n                keywordexpr = None\n            remaining.append(colitem)\n\n    if deselected:\n        config.hook.pytest_deselected(items=deselected)\n        items[:] = remaining\n\n\n@attr.s(slots=True)\nclass MarkMatcher:\n    \"\"\"A matcher for markers which are present.\n\n    Tries to match on any marker names, attached to the given colitem.\n    \"\"\"\n\n    own_mark_names = attr.ib()\n\n    @classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)\n\n    def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names\n\n\ndef deselect_by_mark(items: \"List[Item]\", config: Config) -> None:\n    matchexpr = config.option.markexpr\n    if not matchexpr:\n        return\n\n    try:\n        expression = Expression.compile(matchexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-m': {}: {}\".format(matchexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for item in items:\n    ",
              "start_line": 195,
              "start_column": 6452,
              "end_line": 0,
              "end_column": 7948,
              "start_byte": 6452,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.Mark.name",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "    except ParseError as",
              "start_line": 198,
              "start_column": 6514,
              "end_line": 4,
              "end_column": 6538,
              "start_byte": 6514,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark.args",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "ion passed to '-k': {}: {}\".format(k",
              "start_line": 200,
              "start_column": 6594,
              "end_line": 4,
              "end_column": 6630,
              "start_byte": 6594,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark.kwargs",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "]\n    deselected = []\n    for colitem in",
              "start_line": 202,
              "start_column": 6683,
              "end_line": 4,
              "end_column": 6723,
              "start_byte": 6683,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark._param_ids_from",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "e(KeywordMatcher.from_item(colitem)):\n            deselected.append(colite",
              "start_line": 205,
              "start_column": 6780,
              "end_line": 4,
              "end_column": 6854,
              "start_byte": 6780,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark._param_ids_generated",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "  keywordexpr = None\n            remaining.append(colitem)\n\n    if deselected:\n        config.hook.p",
              "start_line": 207,
              "start_column": 6913,
              "end_line": 4,
              "end_column": 7013,
              "start_byte": 6913,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark._has_param_ids",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "deselected(items=deselected)\n        items[:] = remaining\n\n\n@attr.s(slots=True)\nclass MarkMa",
              "start_line": 211,
              "start_column": 7019,
              "end_line": 4,
              "end_column": 7111,
              "start_byte": 7019,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark.combined_with",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "\n    \"\"\"A matcher for markers which are present.\n\n    Tries to match on any marker names, attached to the given colitem.\n    \"\"\"\n\n    own_mark_names = attr.ib()\n\n    @classmethod\n    def from_item(cls, item) -> \"MarkMatcher\":\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)\n\n    def __call__(self, name: str) -> bool:\n        return name in self.own_mark_names\n\n\ndef deselect_by_mark(items: \"List[Item]\", config: Config) -> None:\n    matchexpr = config.option.markexpr\n    if not matchexpr:\n        return\n\n    try:\n        expression = Expression.compile(matchexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-m': {}: {}\".format(matchexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for item in items:\n    ",
              "start_line": 214,
              "start_column": 7117,
              "end_line": 4,
              "end_column": 7948,
              "start_byte": 7117,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark._Markable",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "test_deselected(items=deselected)\n        items[:] = remaining\n\n\ndef pytes",
              "start_line": 245,
              "start_column": 8132,
              "end_line": 0,
              "end_column": 8206,
              "start_byte": 8132,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkDecorator",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "ollection_modifyitems(items: \"List[Item]\", config: Config) -> None:\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)\n\n\ndef pytest_configure(config: Config) -> None:\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageError(\n            \"{!s} must be one of skip, xfail or fail_at_collect\"\n            \" but it is {!r}\".format(EMPTY_PARAMETERSET_OPTION, empty_parameterset)\n        )\n\n\ndef pytest_unconfigure(config: Config) -> None:\n    MARK_GEN._config = config._store.get(old_mark_config_key, None)\n",
              "start_line": 248,
              "start_column": 8209,
              "end_line": 0,
              "end_column": 11549,
              "start_byte": 8209,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkDecorator.mark",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 284,
              "start_column": 9608,
              "end_line": 4,
              "end_column": 9678,
              "start_byte": 9608,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.name",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 286,
              "start_column": 9684,
              "end_line": 4,
              "end_column": 9785,
              "start_byte": 9684,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.args",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 291,
              "start_column": 9791,
              "end_line": 4,
              "end_column": 9904,
              "start_byte": 9791,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.kwargs",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 296,
              "start_column": 9910,
              "end_line": 4,
              "end_column": 10031,
              "start_byte": 9910,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.markname",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 301,
              "start_column": 10037,
              "end_line": 4,
              "end_column": 10147,
              "start_byte": 10037,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__repr__",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 305,
              "start_column": 10153,
              "end_line": 4,
              "end_column": 10235,
              "start_byte": 10153,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.with_args",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 308,
              "start_column": 10241,
              "end_line": 4,
              "end_column": 10647,
              "start_byte": 10241,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__call__",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 322,
              "start_column": 10861,
              "end_line": 4,
              "end_column": 10981,
              "start_byte": 10861,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__call__",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 326,
              "start_column": 10987,
              "end_line": 4,
              "end_column": 11150,
              "start_byte": 10987,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__call__",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 332,
              "start_column": 11156,
              "end_line": 4,
              "end_column": 11549,
              "start_byte": 11156,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkGenerator",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 450,
              "start_column": 15252,
              "end_line": 0,
              "end_column": 18166,
              "start_byte": 15252,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkGenerator._config",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 465,
              "start_column": 15571,
              "end_line": 4,
              "end_column": 15585,
              "start_byte": 15571,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkGenerator._markers",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 466,
              "start_column": 15616,
              "end_line": 4,
              "end_column": 15632,
              "start_byte": 15616,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkGenerator.__getattr__",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "",
              "start_line": 479,
              "start_column": 16175,
              "end_line": 4,
              "end_column": 18166,
              "start_byte": 16175,
              "end_byte": 4
            },
            {
              "name": "_pytest.pastebin.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "arsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def",
              "start_line": 30,
              "start_column": 778,
              "end_line": 0,
              "end_column": 1609,
              "start_byte": 778,
              "end_byte": 0
            },
            {
              "name": "_pytest.pytester.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions a",
              "start_line": 83,
              "start_column": 2138,
              "end_line": 0,
              "end_column": 2530,
              "start_byte": 2138,
              "end_byte": 0
            },
            {
              "name": "_pytest.python.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": " the names of its parents.\n    Only matches names of items which are either a :class:`Class` or a\n    :class:`Function`.\n\n    Additionally, matches on names in the 'extra_keyword_matches' set of\n    any item, as well as names directly assigned to test functions.\n    \"\"\"\n\n    _names = attr.ib(type=AbstractSet[str])\n\n    @classmethod\n    def from_item(cls, item: \"Item\") -> \"KeywordMatcher\":\n        mapped_names = set()\n\n        # Add the names of the current item and any parent items\n        import pytest\n\n        for node in item.listchain():\n            if not isinstance(node, (pytest.Instance, pytest.Session)):\n                mapped_names.add(node.name)\n\n        # Add the names added as extra keywords to current or parent items\n        mapped_names.update(item.listextrakeywords())\n\n        # Add the names attached to the current function through direct assignment\n        function_obj = getattr(item, \"",
              "start_line": 138,
              "start_column": 4458,
              "end_line": 0,
              "end_column": 5374,
              "start_byte": 4458,
              "end_byte": 0
            },
            {
              "name": "_pytest.skipping.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "lection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def test_eval(test_input, expected):\n            assert eval(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and classes whose name \"\n        \"contains 'test_method' or 'test_other', while -k 'not test_method' \"\n        \"matches those that don't contain 'test_method' in their names. \"\n        \"-k 'not test_method and not test_other' will eliminate the matches. \"\n        \"Additionally keywor",
              "start_line": 47,
              "start_column": 1193,
              "end_line": 0,
              "end_column": 2813,
              "start_byte": 1193,
              "end_byte": 0
            },
            {
              "name": "_pytest.stepwise.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": ".config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecate",
              "start_line": 28,
              "start_column": 728,
              "end_line": 0,
              "end_column": 866,
              "start_byte": 728,
              "end_byte": 0
            },
            {
              "name": "_pytest.stepwise.StepwisePlugin.pytest_collection_modifyitems",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "ize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def test_eval(test_input, expected):\n            assert eval(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and cl",
              "start_line": 48,
              "start_column": 1400,
              "end_line": 4,
              "end_column": 2535,
              "start_byte": 1400,
              "end_byte": 4
            },
            {
              "name": "_pytest.terminal.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": " config.option.keyword.lstrip()\n    if not keywordexpr:\n        return\n\n    if keywordexpr.startswith(\"-\"):\n        # To be removed in pytest 7.0.0.\n        warnings.warn(MINUS_K_DASH, stacklevel=2)\n        keywordexpr = \"not \" + keywordexpr[1:]\n    selectuntil = False\n    if keywordexpr[-1:] == \":\":\n        # To be removed in pytest 7.0.0.\n        warnings.warn(MINUS_K_COLON, stacklevel=2)\n        selectuntil = Tru",
              "start_line": 224,
              "start_column": 5991,
              "end_line": 0,
              "end_column": 6410,
              "start_byte": 5991,
              "end_byte": 0
            },
            {
              "name": "_pytest.tmpdir.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "t[str])\n\n    @classmethod\n    def from_item(cls, item: \"Item\") -> \"KeywordMatcher\":\n        mapped_names = set()\n\n        # Add the names of the current item and any parent items\n        import pytest\n\n        for node in item.listchain():\n            if not isinstance(node, (pytest.Instance, pytest.Session)):\n                mapped_names.add(node.name)\n\n        # Add the names added as extra keywords to current or parent items\n        mapped_names.update(item.listextrakeywords())\n\n        # Add the names attached to the current function through direct assignment\n        function_obj = getattr(item, \"",
              "start_line": 138,
              "start_column": 4766,
              "end_line": 0,
              "end_column": 5374,
              "start_byte": 4766,
              "end_byte": 0
            },
            {
              "name": "_pytest.warning_types.PytestUnknownMarkWarning",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "o this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(",
              "start_line": 77,
              "start_column": 1903,
              "end_line": 0,
              "end_column": 2100,
              "start_byte": 1903,
              "end_byte": 0
            },
            {
              "name": "_pytest.warning_types.PytestUnknownMarkWarning.__module__",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "    group._addoption(",
              "start_line": 83,
              "start_column": 2079,
              "end_line": 4,
              "end_column": 2100,
              "start_byte": 2079,
              "end_byte": 4
            },
            {
              "name": "_pytest.warnings.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": " tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other'",
              "start_line": 74,
              "start_column": 2235,
              "end_line": 0,
              "end_column": 2501,
              "start_byte": 2235,
              "end_byte": 0
            },
            {
              "name": "_pytest.resultlog.pytest_configure",
              "file_path": "src/_pytest/mark/__init__.py",
              "file_content": "est.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: ",
              "start_line": 30,
              "start_column": 725,
              "end_line": 0,
              "end_column": 1434,
              "start_byte": 725,
              "end_byte": 0
            }
          ],
          "root_caused_symbols": [
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1174,
              "start_column": 45925,
              "end_line": 0,
              "end_column": 47430,
              "start_byte": 45925,
              "end_byte": 0
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.scope",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1176,
              "start_column": 45979,
              "end_line": 4,
              "end_column": 46049,
              "start_byte": 45979,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.params",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1177,
              "start_column": 46054,
              "end_line": 4,
              "end_column": 46134,
              "start_byte": 46054,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.autouse",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1178,
              "start_column": 46139,
              "end_line": 4,
              "end_column": 46182,
              "start_byte": 46139,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.ids",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1179,
              "start_column": 46187,
              "end_line": 4,
              "end_column": 46411,
              "start_byte": 46187,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.name",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1187,
              "start_column": 46416,
              "end_line": 4,
              "end_column": 46464,
              "start_byte": 46416,
              "end_byte": 4
            },
            {
              "name": "_pytest.fixtures.FixtureFunctionMarker.__call__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "",
              "start_line": 1189,
              "start_column": 46470,
              "end_line": 4,
              "end_column": 47430,
              "start_byte": 46470,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkMatcher",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "lf.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
              "start_line": 214,
              "start_column": 7079,
              "end_line": 0,
              "end_column": 7525,
              "start_byte": 7079,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkMatcher.own_mark_names",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": " Mark.\n\n        Combines b",
              "start_line": 221,
              "start_column": 7251,
              "end_line": 4,
              "end_column": 7277,
              "start_byte": 7251,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkMatcher.from_item",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "nding args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert s",
              "start_line": 223,
              "start_column": 7283,
              "end_line": 4,
              "end_column": 7438,
              "start_byte": 7283,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkMatcher.__call__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "me == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
              "start_line": 228,
              "start_column": 7444,
              "end_line": 4,
              "end_column": 7525,
              "start_byte": 7444,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@attr.s(frozen=True)\nclass Mark:\n    #: Name of the mark.\n    name = attr.ib(type=str)\n    #: Positional arguments of the mark decorator.\n    args = attr.ib(type=Tuple[Any, ...])\n    #: Keyword arguments of the mark decorator.\n    kwargs = attr.ib(type=Mapping[str, Any])\n\n    #: Source Mark for ids with parametrize Marks.\n    _param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)\n    #: Resolved/generated ids with parametrize Marks.\n    _param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )\n\n    def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
              "start_line": 195,
              "start_column": 6452,
              "end_line": 0,
              "end_column": 7948,
              "start_byte": 6452,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.Mark.name",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "name = attr.ib(type=str)",
              "start_line": 198,
              "start_column": 6514,
              "end_line": 4,
              "end_column": 6538,
              "start_byte": 6514,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark.args",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "args = attr.ib(type=Tuple[Any, ...])",
              "start_line": 200,
              "start_column": 6594,
              "end_line": 4,
              "end_column": 6630,
              "start_byte": 6594,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark.kwargs",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "kwargs = attr.ib(type=Mapping[str, Any])",
              "start_line": 202,
              "start_column": 6683,
              "end_line": 4,
              "end_column": 6723,
              "start_byte": 6683,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark._param_ids_from",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "_param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)",
              "start_line": 205,
              "start_column": 6780,
              "end_line": 4,
              "end_column": 6854,
              "start_byte": 6780,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark._param_ids_generated",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "_param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )",
              "start_line": 207,
              "start_column": 6913,
              "end_line": 4,
              "end_column": 7013,
              "start_byte": 6913,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark._has_param_ids",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4",
              "start_line": 211,
              "start_column": 7019,
              "end_line": 4,
              "end_column": 7111,
              "start_byte": 7019,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.Mark.combined_with",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
              "start_line": 214,
              "start_column": 7117,
              "end_line": 4,
              "end_column": 7948,
              "start_byte": 7117,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark._Markable",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "_Markable = TypeVar(\"_Markable\", bound=Union[Callable[..., object], type])",
              "start_line": 245,
              "start_column": 8132,
              "end_line": 0,
              "end_column": 8206,
              "start_byte": 8132,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkDecorator",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@attr.s\nclass MarkDecorator:\n    \"\"\"A decorator for applying a mark on test functions and classes.\n\n    MarkDecorators are created with ``pytest.mark``::\n\n        mark1 = pytest.mark.NAME              # Simple MarkDecorator\n        mark2 = pytest.mark.NAME(name1=value) # Parametrized MarkDecorator\n\n    and can then be applied as decorators to test functions::\n\n        @mark2\n        def test_function():\n            pass\n\n    When a MarkDecorator is called it does the following:\n\n    1. If called with a single class as its only positional argument and no\n       additional keyword arguments, it attaches the mark to the class so it\n       gets applied automatically to all test cases found in that class.\n\n    2. If called with a single function as its only positional argument and\n       no additional keyword arguments, it attaches the mark to the function,\n       containing all the arguments already stored internally in the\n       MarkDecorator.\n\n    3. When called in any other case, it returns a new MarkDecorator instance\n       with the original MarkDecorator's content updated with the arguments\n       passed to this call.\n\n    Note: The rules above prevent MarkDecorators from storing only a single\n    function or class reference as their positional argument with no\n    additional keyword or positional arguments. You can work around this by\n    using `with_args()`.\n    \"\"\"\n\n    mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))\n\n    @property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name\n\n    @property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args\n\n    @property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs\n\n    @property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)\n\n    def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)\n\n    def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))\n\n    # Type ignored because the overloads overlap with an incompatible\n    # return type. Not much we can do about that. Thankfully mypy picks\n    # the first match so it works out even if we break the rules.\n    @overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()\n\n    @overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()\n\n    def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
              "start_line": 248,
              "start_column": 8209,
              "end_line": 0,
              "end_column": 11549,
              "start_byte": 8209,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkDecorator.mark",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))",
              "start_line": 284,
              "start_column": 9608,
              "end_line": 4,
              "end_column": 9678,
              "start_byte": 9608,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.name",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name",
              "start_line": 286,
              "start_column": 9684,
              "end_line": 4,
              "end_column": 9785,
              "start_byte": 9684,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.args",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args",
              "start_line": 291,
              "start_column": 9791,
              "end_line": 4,
              "end_column": 9904,
              "start_byte": 9791,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.kwargs",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs",
              "start_line": 296,
              "start_column": 9910,
              "end_line": 4,
              "end_column": 10031,
              "start_byte": 9910,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.markname",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)",
              "start_line": 301,
              "start_column": 10037,
              "end_line": 4,
              "end_column": 10147,
              "start_byte": 10037,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__repr__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)",
              "start_line": 305,
              "start_column": 10153,
              "end_line": 4,
              "end_column": 10235,
              "start_byte": 10153,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.with_args",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))",
              "start_line": 308,
              "start_column": 10241,
              "end_line": 4,
              "end_column": 10647,
              "start_byte": 10241,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__call__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()",
              "start_line": 322,
              "start_column": 10861,
              "end_line": 4,
              "end_column": 10981,
              "start_byte": 10861,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__call__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "@overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()",
              "start_line": 326,
              "start_column": 10987,
              "end_line": 4,
              "end_column": 11150,
              "start_byte": 10987,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkDecorator.__call__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
              "start_line": 332,
              "start_column": 11156,
              "end_line": 4,
              "end_column": 11549,
              "start_byte": 11156,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkGenerator",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "class MarkGenerator:\n    \"\"\"Factory for :class:`MarkDecorator` objects - exposed as\n    a ``pytest.mark`` singleton instance.\n\n    Example::\n\n         import pytest\n\n         @pytest.mark.slowtest\n         def test_function():\n            pass\n\n    applies a 'slowtest' :class:`Mark` on ``test_function``.\n    \"\"\"\n\n    _config = None  # type: Optional[Config]\n    _markers = set()  # type: Set[str]\n\n    # See TYPE_CHECKING above.\n    if TYPE_CHECKING:\n        # Using casts instead of type comments intentionally - issue #7473.\n        # TODO(py36): Change to builtin annotation syntax.\n        skip = cast(_SkipMarkDecorator, None)\n        skipif = cast(_SkipifMarkDecorator, None)\n        xfail = cast(_XfailMarkDecorator, None)\n        parametrize = cast(_ParametrizeMarkDecorator, None)\n        usefixtures = cast(_UsefixturesMarkDecorator, None)\n        filterwarnings = cast(_FilterwarningsMarkDecorator, None)\n\n    def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
              "start_line": 450,
              "start_column": 15252,
              "end_line": 0,
              "end_column": 18166,
              "start_byte": 15252,
              "end_byte": 0
            },
            {
              "name": "_pytest.mark.MarkGenerator._config",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "_config = None",
              "start_line": 465,
              "start_column": 15571,
              "end_line": 4,
              "end_column": 15585,
              "start_byte": 15571,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkGenerator._markers",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "_markers = set()",
              "start_line": 466,
              "start_column": 15616,
              "end_line": 4,
              "end_column": 15632,
              "start_byte": 15616,
              "end_byte": 4
            },
            {
              "name": "_pytest.mark.MarkGenerator.__getattr__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
              "start_line": 479,
              "start_column": 16175,
              "end_line": 4,
              "end_column": 18166,
              "start_byte": 16175,
              "end_byte": 4
            },
            {
              "name": "_pytest.warning_types.PytestUnknownMarkWarning",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "\"values\", Sequence[Union[object, NotSetType]]),\n            (\"marks\", \"typing.Collection[Union[MarkDecorator, Mark]]\"),\n            (\"id\", Optional[str]),\n        ],\n    )\n):\n    @classmethod\n    d",
              "start_line": 77,
              "start_column": 1903,
              "end_line": 0,
              "end_column": 2100,
              "start_byte": 1903,
              "end_byte": 0
            },
            {
              "name": "_pytest.warning_types.PytestUnknownMarkWarning.__module__",
              "file_path": "src/_pytest/mark/structures.py",
              "file_content": "   @classmethod\n    d",
              "start_line": 83,
              "start_column": 2079,
              "end_line": 4,
              "end_column": 2100,
              "start_byte": 2079,
              "end_byte": 4
            },
            {
              "name": "_pytest.hookspec.pytest_runtest_makereport",
              "file_path": "src/_pytest/skipping.py",
              "file_content": "",
              "start_line": 486,
              "start_column": 17380,
              "end_line": 0,
              "end_column": 17867,
              "start_byte": 17380,
              "end_byte": 0
            },
            {
              "name": "_pytest.runner.pytest_runtest_makereport",
              "file_path": "src/_pytest/skipping.py",
              "file_content": "ort_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:\n    if hasattr(report, \"wasxfail\"):\n        if report.skipped",
              "start_line": 318,
              "start_column": 10464,
              "end_line": 0,
              "end_column": 10595,
              "start_byte": 10464,
              "end_byte": 0
            },
            {
              "name": "_pytest.skipping.evaluate_condition",
              "file_path": "src/_pytest/skipping.py",
              "file_content": "def evaluate_condition(item: Item, mark: Mark, condition: object) -> Tuple[bool, str]:\n    \"\"\"Evaluate a single skipif/xfail condition.\n\n    If an old-style string condition is given, it is eval()'d, otherwise the\n    condition is bool()'d. If this fails, an appropriately formatted pytest.fail\n    is raised.\n\n    Returns (result, reason). The reason is only relevant if the result is True.\n    \"\"\"\n    # String condition.\n    if isinstance(condition, str):\n        globals_ = {\n            \"os\": os,\n            \"sys\": sys,\n            \"platform\": platform,\n            \"config\": item.config,\n        }\n        if hasattr(item, \"obj\"):\n            globals_.update(item.obj.__globals__)  # type: ignore[attr-defined]\n        try:\n            filename = \"<{} condition>\".format(mark.name)\n            condition_code = compile(condition, filename, \"eval\")\n            result = eval(condition_code, globals_)\n        except SyntaxError as exc:\n            msglines = [\n                \"Error evaluating %r condition\" % mark.name,\n                \"    \" + condition,\n                \"    \" + \" \" * (exc.offset or 0) + \"^\",\n                \"SyntaxError: invalid syntax\",\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n        except Exception as exc:\n            msglines = [\n                \"Error evaluating %r condition\" % mark.name,\n                \"    \" + condition,\n                *traceback.format_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    # Boolean condition.\n    else:\n        try:\n            result = bool(condition)\n        except Exception as exc:\n            msglines = [\n                \"Error evaluating %r condition as a boolean\" % mark.name,\n                *traceback.format_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    reason = mark.kwargs.get(\"reason\", None)\n    if reason is None:\n        if isinstance(condition, str):\n            reason = \"condition: \" + condition\n        else:\n            # XXX better be checked at collection time\n            msg = (\n                \"Error evaluating %r: \" % mark.name\n                + \"you need to specify reason=STRING when using booleans as conditions.\"\n            )\n            fail(msg, pytrace=False)\n\n    return result, reason",
              "start_line": 86,
              "start_column": 2816,
              "end_line": 0,
              "end_column": 5151,
              "start_byte": 2816,
              "end_byte": 0
            },
            {
              "name": "_pytest.skipping.evaluate_xfail_marks",
              "file_path": "src/_pytest/skipping.py",
              "file_content": "def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None",
              "start_line": 199,
              "start_column": 6507,
              "end_line": 0,
              "end_column": 7408,
              "start_byte": 6507,
              "end_byte": 0
            },
            {
              "name": "_pytest.skipping.pytest_runtest_makereport",
              "file_path": "src/_pytest/skipping.py",
              "file_content": "@hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n    outcome = yield\n    rep = outcome.get_result()\n    xfailed = item._store.get(xfailed_key, None)\n    # unittest special case, see setting of unexpectedsuccess_key\n    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n        reason = item._store[unexpectedsuccess_key]\n        if reason:\n            rep.longrepr = \"Unexpected success: {}\".format(reason)\n        else:\n            rep.longrepr = \"Unexpected success\"\n        rep.outcome = \"failed\"\n    elif item.config.option.runxfail:\n        pass  # don't interfere\n    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n        assert call.excinfo.value.msg is not None\n        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n        rep.outcome = \"skipped\"\n    elif not rep.skipped and xfailed:\n        if call.excinfo:\n            raises = xfailed.raises\n            if raises is not None and not isinstance(call.excinfo.value, raises):\n                rep.outcome = \"failed\"\n            else:\n                rep.outcome = \"skipped\"\n                rep.wasxfail = xfailed.reason\n        elif call.when == \"call\":\n            if xfailed.strict:\n                rep.outcome = \"failed\"\n                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n            else:\n                rep.outcome = \"passed\"\n                rep.wasxfail = xfailed.reason\n\n    if (\n        item._store.get(skipped_by_mark_key, True)\n        and rep.skipped\n        and type(rep.longrepr) is tuple\n    ):\n        # skipped by mark.skipif; change the location of the failure\n        # to point to the item definition, otherwise it will display\n        # the location of where the skip exception was raised within pytest\n        _, _, reason = rep.longrepr\n        filename, line = item.reportinfo()[:2]\n        assert line is not None\n        rep.longrepr = str(filename), line + 1, reason",
              "start_line": 259,
              "start_column": 8490,
              "end_line": 0,
              "end_column": 10447,
              "start_byte": 8490,
              "end_byte": 0
            },
            {
              "name": "_pytest.unittest.pytest_runtest_makereport",
              "file_path": "src/_pytest/skipping.py",
              "file_content": "urn \"xpassed\", \"X\", \"XPASS\"\n    return None\n",
              "start_line": 290,
              "start_column": 10683,
              "end_line": 0,
              "end_column": 11441,
              "start_byte": 10683,
              "end_byte": 0
            }
          ]
        },
        "symbols_evaluate": {
          "scratch_pad": "1.1 The user describes an issue that, in pytest 6.0.0rc0, the behavior of dynamically adding an xfail marker using request.node.add_marker has changed compared to version 5.x, this used to cause the test to be marked as expected to fail. In version 6.0.0rc0, the same practice raises an error instead of returning an xfail. \n1.2 It seems like this behavior change might be related to how markers are applied in the new version. Understanding how markers are implemented especially how xfail operates in the two versions could be crucial. \n1.3 The user expects that adding an xfail marker dynamically should behave like in the old versions, marking test failures as expected (xfail) instead of errors.\n1.4 If the user has not given an expected behavior, it would still likely be that tests with dynamically added xfail markers should not cause errors but be marked as xfail instead.\n1.5 It should be analyzed why in 6.0.0rc0 this addition causes errors (perhaps by observing implementation in the symbols), and enabling the tests to be marked xfail properly without causing error.\n\n2.1 Analyze symbols in the context provided, related to markers and marker infrastructure.\n2.2 Look for differences or edge cases in 6.0.0rc0 specifically around request.node.add_marker and how markers like xfail are expected to behave.\n2.3 Upon evaluating the functions in /pytest/mark/structures.py, some key elements emerge such as MarkDecorator, Mark, and MarkManager functions which handle creating, combining, and interacting with marks, this could hint at changes in handling or registering marks.\n2.4 Evaluate if there\u2019s a method used for request.node.add_marker that diverges from the expected utilization in the old version, suggest adjustments or fixes to allow consistent behavior once observed.\n2.5 Ask for more of structures.py file for any introspection for more detail-oriented behavior regarding the issue.",
          "symbols": [
            {
              "name": "_pytest.nodes.Node.add_marker",
              "file_path": "src/_pytest/nodes.py",
              "reason": "'add_marker' is directly related to dynamically adding markers like xfail and could be contributing to the difference in behavior between versions as observed in issue."
            },
            {
              "name": "_pytest.mark.MarkDecorator",
              "file_path": "src/_pytest/mark/structures.py",
              "reason": "Central class in handling of mark decorators in pytest, crucial to adding xfail marker behavior since the code directly uses a MarkDecorator."
            },
            {
              "name": "_pytest.mark.MarkGenerator",
              "file_path": "src/_pytest/mark/structures.py",
              "reason": "Likely related to generating marks that might be dictating how dynamically added xfail markers are evaluated differently."
            },
            {
              "name": "_pytest.skipping.evaluate_xfail_marks",
              "file_path": "src/_pytest/skipping.py",
              "reason": "Evaluates xfail marks specifically which could highlight why xfail markers are no longer evaluated in the older manner leading to a fail instead of recognized XFail."
            },
            {
              "name": "_pytest.skipping.pytest_runtest_makereport",
              "file_path": "src/_pytest/skipping.py",
              "reason": "Skills test report creation and handles how xfail might be reported differently - this might yield differences in behavior."
            }
          ],
          "more_info": [],
          "is_done": true,
          "symbols_scratch_pad": [
            "_pytest.fixtures.FixtureFunctionMarker - This symbol appears to manage some sort of marker or fixture function indication but isn't directly related to the xfail or marking functionality related to the issue.",
            "_pytest.fixtures.FixtureFunctionMarker.scope - This seems more concerned with a specific property of fixture markers, like in lifecycle or scoping, not directly tied to xfail issue.",
            "_pytest.fixtures.FixtureFunctionMarker.params - This looks more relevant to parameters in parametrizing fixtures etc. and not directly with xfail marking.",
            "_pytest.fixtures.FixtureFunctionMarker.autouse - Again, this indicates a property about fixture markers, but not focused on xfail dynamics.",
            "_pytest.fixtures.FixtureFunctionMarker.ids - Specific to the identifier of fixtures, doesn\u2019t align with xfail issue.",
            "_pytest.fixtures.FixtureFunctionMarker.name - Again important in its context but not affecting xfail marking usage.",
            "_pytest.fixtures.FixtureFunctionMarker.__call__ - Authorizes use of fixtures but doesn\u2019t highlight changes in handling xfail.",
            "_pytest.mark.MarkMatcher - Involves marking but seems more set for item matching, not the specific case of how xfail acts related to request.node.add_marker.",
            "_pytest.mark.MarkMatcher.own_mark_names - An attribute this seems to be conducted within matching more than individual functional aspects related to xfail.",
            "_pytest.mark.MarkMatcher.from_item - Involvement in creating matchers from test items, potentially impactful, yet not explicitly detailed toward xfail working.",
            "_pytest.mark.MarkMatcher.__call__ - Considers matching logic in pytest but not immediate in understanding xfail workaround.",
            "_pytest.mark.Mark - Central in how marks operate including xfail, useful in understanding any changes though its detailed examination needed next.",
            "_pytest.mark.Mark.name - This should be a core property of Mark and its interaction with names, important if naming causes mismatch in xfail.",
            "_pytest.mark.Mark.args - Arguments interacting internally with Mark, needed in understanding if xfail's dynamics altered with dynamic addition.",
            "_pytest.mark.Mark.kwargs - Keyword args also form part of the functioning and could affect marker results.",
            "_pytest.mark.Mark._param_ids_from - Functionality probably unused explicitly in context to issue unless delegated something behind scened with xfail and parameterization.",
            "_pytest.mark.Mark._param_ids_generated - Derived generation invisibly affecting if generated IDs conflicted with Mark too on xfail.",
            "_pytest.mark.Mark._has_param_ids - Intersection of parameterization into xfail debate unless parameters creates unseen alterations seems lower priority.",
            "_pytest.mark.Mark.combined_with - Combination of marks, not yet needing any investigations on its own apart from any hidden interaction specifics with xfail also fascia.",
            "_pytest.mark._Markable - Higher level abstract/not directorial or specific enough in tangible changes for the issue context.",
            "_pytest.mark.MarkDecorator - Covers a Mark object utilized directly in issue observed, likely holding vital clues or direct change differences demanded.",
            "_pytest.mark.MarkDecorator.mark - Association in marking part of Decorator necessities as xfail influences MarkDecorator levels typically.",
            "_pytest.mark.MarkDecorator.name - Network handled through this class MarkDecorator attaches/utilize name interfering with dynamic decorations on xfail-like test.",
            "_pytest.mark.MarkDecorator.args - Foundations of argument used MarkDecorator exist for understanding argumenticity influencing differing marker uses xfail included.",
            "_pytest.mark.MarkDecorator.kwargs - Likeliness in conjunction to 'args', analyzing close enough depicts affirming what affects Kushnalase if anything with xfail handling.",
            "_pytest.mark.MarkDecorator.markname - This associates names MarkDecorators in another layer, important if recent changes mark identification knot inward over xfail context.",
            "_pytest.mark.MarkDecorator.__repr__ - Low priority on understanding human-readable description alignment than anything affecting issue underlining.",
            "_pytest.mark.MarkDecorator.with_args - Vital alteration and adjusting strategy interaction with xfail reconsideration mark focused with_args varying throughout with xfail.",
            "_pytest.mark.MarkDecorator.__call__ - Central controlling during expanded interaction versatile on decorators usage or functionality, prominent if newer versions expand or alter calls methods additional barriers using xfail in mind.",
            "_pytest.mark.MarkGenerator - Evident responsibility generating decorators, immediately impacting handling if alterations or redirections seen in xfail cases exigencies.",
            "_pytest.mark.JenkinsCl.build_started marking of construction reflection thereby affecting pytest major or indirectly struggle transformations perhaps including marks needed perfection towards reducing xfail capability misfortunes."
          ]
        }
      },
      "response": {
        "file_paths": [
          "src/_pytest/nodes.py",
          "src/_pytest/mark/structures.py",
          "src/_pytest/skipping.py"
        ],
        "symbols": [
          "_pytest.nodes.Node.add_marker",
          "_pytest.mark.MarkDecorator",
          "_pytest.mark.MarkGenerator",
          "_pytest.skipping.evaluate_xfail_marks",
          "_pytest.skipping.pytest_runtest_makereport"
        ],
        "code_spans": {
          "_pytest.nodes.Node.add_marker": {
            "name": "_pytest.nodes.Node.add_marker",
            "file_path": "src/_pytest/nodes.py",
            "file_content": "def add_marker(\n        self, marker: Union[str, MarkDecorator], append: bool = True\n    ) -> None:\n        \"\"\"dynamically add a marker object to the node.\n\n        :type marker: ``str`` or ``pytest.mark.*``  object\n        :param marker:\n            ``append=True`` whether to append the marker,\n            if ``False`` insert at position ``0``.\n        \"\"\"\n        from _pytest.mark import MARK_GEN\n\n        if isinstance(marker, MarkDecorator):\n            marker_ = marker\n        elif isinstance(marker, str):\n            marker_ = getattr(MARK_GEN, marker)\n        else:\n            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n        self.keywords[marker_.name] = marker_\n        if append:\n            self.own_markers.append(marker_.mark)\n        else:\n            self.own_markers.insert(0, marker_.mark)",
            "start_line": 260,
            "start_column": 8242,
            "end_line": 4,
            "end_column": 9073,
            "start_byte": 8242,
            "end_byte": 4
          },
          "_pytest.mark.store_mark": {
            "name": "_pytest.mark.store_mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def store_mark(obj, mark: Mark) -> None:\n    \"\"\"Store a Mark on an object.\n\n    This is used to implement the Mark declarations/decorators correctly.\n    \"\"\"\n    assert isinstance(mark, Mark), mark\n    # Always reassign name to avoid updating pytestmark in a reference that\n    # was only borrowed.\n    obj.pytestmark = get_unpacked_marks(obj) + [mark]",
            "start_line": 369,
            "start_column": 12372,
            "end_line": 0,
            "end_column": 12724,
            "start_byte": 12372,
            "end_byte": 0
          },
          "_pytest.cacheprovider.LFPlugin.pytest_collection_modifyitems": {
            "name": "_pytest.cacheprovider.LFPlugin.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 289,
            "start_column": 10558,
            "end_line": 4,
            "end_column": 12796,
            "start_byte": 10558,
            "end_byte": 4
          },
          "_pytest.cacheprovider.NFPlugin.pytest_collection_modifyitems": {
            "name": "_pytest.cacheprovider.NFPlugin.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 361,
            "start_column": 13534,
            "end_line": 4,
            "end_column": 14397,
            "start_byte": 13534,
            "end_byte": 4
          },
          "_pytest.cacheprovider.pytest_configure": {
            "name": "_pytest.cacheprovider.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 464,
            "start_column": 16918,
            "end_line": 0,
            "end_column": 17167,
            "start_byte": 16918,
            "end_byte": 0
          },
          "_pytest.config.PytestPluginManager.pytest_configure": {
            "name": "_pytest.config.PytestPluginManager.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 442,
            "start_column": 13883,
            "end_line": 4,
            "end_column": 14533,
            "start_byte": 13883,
            "end_byte": 4
          },
          "_pytest.debugging.pytest_configure": {
            "name": "_pytest.debugging.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "f marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and classes whose name \"\n        \"contains 'test_method' or 'test_other', while -k 'not test_method' \"\n        \"matches ",
            "start_line": 61,
            "start_column": 1816,
            "end_line": 0,
            "end_column": 2649,
            "start_byte": 1816,
            "end_byte": 0
          },
          "_pytest.faulthandler.pytest_configure": {
            "name": "_pytest.faulthandler.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "from .structures import ParameterSet\nfrom _pytest.compat import TYPE_CHECKING\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n          ",
            "start_line": 24,
            "start_column": 532,
            "end_line": 0,
            "end_column": 1486,
            "start_byte": 532,
            "end_byte": 0
          },
          "_pytest.faulthandler.FaultHandlerHooks.pytest_configure": {
            "name": "_pytest.faulthandler.FaultHandlerHooks.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSe",
            "start_line": 52,
            "start_column": 1666,
            "end_line": 4,
            "end_column": 1955,
            "start_byte": 1666,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker": {
            "name": "_pytest.fixtures.FixtureFunctionMarker",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1174,
            "start_column": 45925,
            "end_line": 0,
            "end_column": 47430,
            "start_byte": 45925,
            "end_byte": 0
          },
          "_pytest.fixtures.FixtureFunctionMarker.scope": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.scope",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1176,
            "start_column": 45979,
            "end_line": 4,
            "end_column": 46049,
            "start_byte": 45979,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker.params": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.params",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1177,
            "start_column": 46054,
            "end_line": 4,
            "end_column": 46134,
            "start_byte": 46054,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker.autouse": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.autouse",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1178,
            "start_column": 46139,
            "end_line": 4,
            "end_column": 46182,
            "start_byte": 46139,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker.ids": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1179,
            "start_column": 46187,
            "end_line": 4,
            "end_column": 46411,
            "start_byte": 46187,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker.name": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1187,
            "start_column": 46416,
            "end_line": 4,
            "end_column": 46464,
            "start_byte": 46416,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureFunctionMarker.__call__": {
            "name": "_pytest.fixtures.FixtureFunctionMarker.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "",
            "start_line": 1189,
            "start_column": 46470,
            "end_line": 4,
            "end_column": 47430,
            "start_byte": 46470,
            "end_byte": 4
          },
          "_pytest.fixtures.FixtureManager.pytest_collection_modifyitems": {
            "name": "_pytest.fixtures.FixtureManager.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 1613,
            "start_column": 62458,
            "end_line": 4,
            "end_column": 62612,
            "start_byte": 62458,
            "end_byte": 4
          },
          "_pytest.hookspec.pytest_configure": {
            "name": "_pytest.hookspec.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "line()\n        config._ensure_unconfigure()\n        return 0\n\n    return None\n\n\n@attr.s(slots=True)\nclass KeywordMatcher:\n    \"\"\"A matcher for keywords.\n\n    Given a list of names, matches any substring of one of these names. The\n    string inclusion check is case-insensitive.\n\n    Will match on the name of colitem, including the names of its parents.\n    Only matches names of items which are either a :class:`Class` or a\n    :class:`Function`.\n\n    Additionally, matches on names in the 'extra_key",
            "start_line": 117,
            "start_column": 4131,
            "end_line": 0,
            "end_column": 4632,
            "start_byte": 4131,
            "end_byte": 0
          },
          "_pytest.hookspec.pytest_collection_modifyitems": {
            "name": "_pytest.hookspec.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": ", config: Config) -> None:\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)\n\n\ndef pytest_configure(config: Config) -> None:\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageEr",
            "start_line": 231,
            "start_column": 8250,
            "end_line": 0,
            "end_column": 8658,
            "start_byte": 8250,
            "end_byte": 0
          },
          "_pytest.junitxml.pytest_configure": {
            "name": "_pytest.junitxml.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 439,
            "start_column": 15188,
            "end_line": 0,
            "end_column": 15980,
            "start_byte": 15188,
            "end_byte": 0
          },
          "_pytest.logging.pytest_configure": {
            "name": "_pytest.logging.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 501,
            "start_column": 17763,
            "end_line": 0,
            "end_column": 17914,
            "start_byte": 17763,
            "end_byte": 0
          },
          "_pytest.main.pytest_collection_modifyitems": {
            "name": "_pytest.main.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "",
            "start_line": 372,
            "start_column": 12071,
            "end_line": 0,
            "end_column": 12584,
            "start_byte": 12071,
            "end_byte": 0
          },
          "_pytest.mark.MarkMatcher": {
            "name": "_pytest.mark.MarkMatcher",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "lf.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 214,
            "start_column": 7079,
            "end_line": 0,
            "end_column": 7525,
            "start_byte": 7079,
            "end_byte": 0
          },
          "_pytest.mark.MarkMatcher.own_mark_names": {
            "name": "_pytest.mark.MarkMatcher.own_mark_names",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": " Mark.\n\n        Combines b",
            "start_line": 221,
            "start_column": 7251,
            "end_line": 4,
            "end_column": 7277,
            "start_byte": 7251,
            "end_byte": 4
          },
          "_pytest.mark.MarkMatcher.from_item": {
            "name": "_pytest.mark.MarkMatcher.from_item",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "nding args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert s",
            "start_line": 223,
            "start_column": 7283,
            "end_line": 4,
            "end_column": 7438,
            "start_byte": 7283,
            "end_byte": 4
          },
          "_pytest.mark.MarkMatcher.__call__": {
            "name": "_pytest.mark.MarkMatcher.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "me == other.name\n\n        # Remember source of ids with parametrize Marks.\n      ",
            "start_line": 228,
            "start_column": 7444,
            "end_line": 4,
            "end_column": 7525,
            "start_byte": 7444,
            "end_byte": 4
          },
          "_pytest.mark.deselect_by_mark": {
            "name": "_pytest.mark.deselect_by_mark",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "def deselect_by_mark(items: \"List[Item]\", config: Config) -> None:\n    matchexpr = config.option.markexpr\n    if not matchexpr:\n        return\n\n    try:\n        expression = Expression.compile(matchexpr)\n    except ParseError as e:\n        raise UsageError(\n            \"Wrong expression passed to '-m': {}: {}\".format(matchexpr, e)\n        ) from None\n\n    remaining = []\n    deselected = []\n    for item in items:\n        if expression.evaluate(MarkMatcher.from_item(item)):\n            remaining.append(item)\n        else:\n            deselected.append(item)\n\n    if deselected:\n        config.hook.pytest_deselected(items=deselected)\n        items[:] = remaining",
            "start_line": 232,
            "start_column": 7528,
            "end_line": 0,
            "end_column": 8194,
            "start_byte": 7528,
            "end_byte": 0
          },
          "_pytest.mark.pytest_collection_modifyitems": {
            "name": "_pytest.mark.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "def pytest_collection_modifyitems(items: \"List[Item]\", config: Config) -> None:\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)",
            "start_line": 257,
            "start_column": 8197,
            "end_line": 0,
            "end_column": 8351,
            "start_byte": 8197,
            "end_byte": 0
          },
          "_pytest.mark.pytest_configure": {
            "name": "_pytest.mark.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "def pytest_configure(config: Config) -> None:\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageError(\n            \"{!s} must be one of skip, xfail or fail_at_collect\"\n            \" but it is {!r}\".format(EMPTY_PARAMETERSET_OPTION, empty_parameterset)\n        )",
            "start_line": 262,
            "start_column": 8354,
            "end_line": 0,
            "end_column": 8821,
            "start_byte": 8354,
            "end_byte": 0
          },
          "_pytest.mark.Mark": {
            "name": "_pytest.mark.Mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s(frozen=True)\nclass Mark:\n    #: Name of the mark.\n    name = attr.ib(type=str)\n    #: Positional arguments of the mark decorator.\n    args = attr.ib(type=Tuple[Any, ...])\n    #: Keyword arguments of the mark decorator.\n    kwargs = attr.ib(type=Mapping[str, Any])\n\n    #: Source Mark for ids with parametrize Marks.\n    _param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)\n    #: Resolved/generated ids with parametrize Marks.\n    _param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )\n\n    def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 195,
            "start_column": 6452,
            "end_line": 0,
            "end_column": 7948,
            "start_byte": 6452,
            "end_byte": 0
          },
          "_pytest.mark.Mark.name": {
            "name": "_pytest.mark.Mark.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "name = attr.ib(type=str)",
            "start_line": 198,
            "start_column": 6514,
            "end_line": 4,
            "end_column": 6538,
            "start_byte": 6514,
            "end_byte": 4
          },
          "_pytest.mark.Mark.args": {
            "name": "_pytest.mark.Mark.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "args = attr.ib(type=Tuple[Any, ...])",
            "start_line": 200,
            "start_column": 6594,
            "end_line": 4,
            "end_column": 6630,
            "start_byte": 6594,
            "end_byte": 4
          },
          "_pytest.mark.Mark.kwargs": {
            "name": "_pytest.mark.Mark.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "kwargs = attr.ib(type=Mapping[str, Any])",
            "start_line": 202,
            "start_column": 6683,
            "end_line": 4,
            "end_column": 6723,
            "start_byte": 6683,
            "end_byte": 4
          },
          "_pytest.mark.Mark._param_ids_from": {
            "name": "_pytest.mark.Mark._param_ids_from",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)",
            "start_line": 205,
            "start_column": 6780,
            "end_line": 4,
            "end_column": 6854,
            "start_byte": 6780,
            "end_byte": 4
          },
          "_pytest.mark.Mark._param_ids_generated": {
            "name": "_pytest.mark.Mark._param_ids_generated",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )",
            "start_line": 207,
            "start_column": 6913,
            "end_line": 4,
            "end_column": 7013,
            "start_byte": 6913,
            "end_byte": 4
          },
          "_pytest.mark.Mark._has_param_ids": {
            "name": "_pytest.mark.Mark._has_param_ids",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4",
            "start_line": 211,
            "start_column": 7019,
            "end_line": 4,
            "end_column": 7111,
            "start_byte": 7019,
            "end_byte": 4
          },
          "_pytest.mark.Mark.combined_with": {
            "name": "_pytest.mark.Mark.combined_with",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )",
            "start_line": 214,
            "start_column": 7117,
            "end_line": 4,
            "end_column": 7948,
            "start_byte": 7117,
            "end_byte": 4
          },
          "_pytest.mark._Markable": {
            "name": "_pytest.mark._Markable",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_Markable = TypeVar(\"_Markable\", bound=Union[Callable[..., object], type])",
            "start_line": 245,
            "start_column": 8132,
            "end_line": 0,
            "end_column": 8206,
            "start_byte": 8132,
            "end_byte": 0
          },
          "_pytest.mark.MarkDecorator": {
            "name": "_pytest.mark.MarkDecorator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@attr.s\nclass MarkDecorator:\n    \"\"\"A decorator for applying a mark on test functions and classes.\n\n    MarkDecorators are created with ``pytest.mark``::\n\n        mark1 = pytest.mark.NAME              # Simple MarkDecorator\n        mark2 = pytest.mark.NAME(name1=value) # Parametrized MarkDecorator\n\n    and can then be applied as decorators to test functions::\n\n        @mark2\n        def test_function():\n            pass\n\n    When a MarkDecorator is called it does the following:\n\n    1. If called with a single class as its only positional argument and no\n       additional keyword arguments, it attaches the mark to the class so it\n       gets applied automatically to all test cases found in that class.\n\n    2. If called with a single function as its only positional argument and\n       no additional keyword arguments, it attaches the mark to the function,\n       containing all the arguments already stored internally in the\n       MarkDecorator.\n\n    3. When called in any other case, it returns a new MarkDecorator instance\n       with the original MarkDecorator's content updated with the arguments\n       passed to this call.\n\n    Note: The rules above prevent MarkDecorators from storing only a single\n    function or class reference as their positional argument with no\n    additional keyword or positional arguments. You can work around this by\n    using `with_args()`.\n    \"\"\"\n\n    mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))\n\n    @property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name\n\n    @property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args\n\n    @property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs\n\n    @property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)\n\n    def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)\n\n    def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))\n\n    # Type ignored because the overloads overlap with an incompatible\n    # return type. Not much we can do about that. Thankfully mypy picks\n    # the first match so it works out even if we break the rules.\n    @overload\n    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]\n        raise NotImplementedError()\n\n    @overload  # noqa: F811\n    def __call__(  # noqa: F811\n        self, *args: object, **kwargs: object\n    ) -> \"MarkDecorator\":\n        raise NotImplementedError()\n\n    def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 248,
            "start_column": 8209,
            "end_line": 0,
            "end_column": 11549,
            "start_byte": 8209,
            "end_byte": 0
          },
          "_pytest.mark.MarkDecorator.mark": {
            "name": "_pytest.mark.MarkDecorator.mark",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))",
            "start_line": 284,
            "start_column": 9608,
            "end_line": 4,
            "end_column": 9678,
            "start_byte": 9608,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.name": {
            "name": "_pytest.mark.MarkDecorator.name",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name",
            "start_line": 286,
            "start_column": 9684,
            "end_line": 4,
            "end_column": 9785,
            "start_byte": 9684,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.args": {
            "name": "_pytest.mark.MarkDecorator.args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args",
            "start_line": 291,
            "start_column": 9791,
            "end_line": 4,
            "end_column": 9904,
            "start_byte": 9791,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.kwargs": {
            "name": "_pytest.mark.MarkDecorator.kwargs",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs",
            "start_line": 296,
            "start_column": 9910,
            "end_line": 4,
            "end_column": 10031,
            "start_byte": 9910,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.markname": {
            "name": "_pytest.mark.MarkDecorator.markname",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "@property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)",
            "start_line": 301,
            "start_column": 10037,
            "end_line": 4,
            "end_column": 10147,
            "start_byte": 10037,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.__repr__": {
            "name": "_pytest.mark.MarkDecorator.__repr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)",
            "start_line": 305,
            "start_column": 10153,
            "end_line": 4,
            "end_column": 10235,
            "start_byte": 10153,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.with_args": {
            "name": "_pytest.mark.MarkDecorator.with_args",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))",
            "start_line": 308,
            "start_column": 10241,
            "end_line": 4,
            "end_column": 10647,
            "start_byte": 10241,
            "end_byte": 4
          },
          "_pytest.mark.MarkDecorator.__call__": {
            "name": "_pytest.mark.MarkDecorator.__call__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __call__(self, *args: object, **kwargs: object):  # noqa: F811\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)",
            "start_line": 332,
            "start_column": 11156,
            "end_line": 4,
            "end_column": 11549,
            "start_byte": 11156,
            "end_byte": 4
          },
          "_pytest.mark.MarkGenerator": {
            "name": "_pytest.mark.MarkGenerator",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "class MarkGenerator:\n    \"\"\"Factory for :class:`MarkDecorator` objects - exposed as\n    a ``pytest.mark`` singleton instance.\n\n    Example::\n\n         import pytest\n\n         @pytest.mark.slowtest\n         def test_function():\n            pass\n\n    applies a 'slowtest' :class:`Mark` on ``test_function``.\n    \"\"\"\n\n    _config = None  # type: Optional[Config]\n    _markers = set()  # type: Set[str]\n\n    # See TYPE_CHECKING above.\n    if TYPE_CHECKING:\n        # Using casts instead of type comments intentionally - issue #7473.\n        # TODO(py36): Change to builtin annotation syntax.\n        skip = cast(_SkipMarkDecorator, None)\n        skipif = cast(_SkipifMarkDecorator, None)\n        xfail = cast(_XfailMarkDecorator, None)\n        parametrize = cast(_ParametrizeMarkDecorator, None)\n        usefixtures = cast(_UsefixturesMarkDecorator, None)\n        filterwarnings = cast(_FilterwarningsMarkDecorator, None)\n\n    def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 450,
            "start_column": 15252,
            "end_line": 0,
            "end_column": 18166,
            "start_byte": 15252,
            "end_byte": 0
          },
          "_pytest.mark.MarkGenerator._config": {
            "name": "_pytest.mark.MarkGenerator._config",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_config = None",
            "start_line": 465,
            "start_column": 15571,
            "end_line": 4,
            "end_column": 15585,
            "start_byte": 15571,
            "end_byte": 4
          },
          "_pytest.mark.MarkGenerator._markers": {
            "name": "_pytest.mark.MarkGenerator._markers",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "_markers = set()",
            "start_line": 466,
            "start_column": 15616,
            "end_line": 4,
            "end_column": 15632,
            "start_byte": 15616,
            "end_byte": 4
          },
          "_pytest.mark.MarkGenerator.__getattr__": {
            "name": "_pytest.mark.MarkGenerator.__getattr__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/stable/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))",
            "start_line": 479,
            "start_column": 16175,
            "end_line": 4,
            "end_column": 18166,
            "start_byte": 16175,
            "end_byte": 4
          },
          "_pytest.pastebin.pytest_configure": {
            "name": "_pytest.pastebin.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "arsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def",
            "start_line": 30,
            "start_column": 778,
            "end_line": 0,
            "end_column": 1609,
            "start_byte": 778,
            "end_byte": 0
          },
          "_pytest.pytester.pytest_configure": {
            "name": "_pytest.pytester.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions a",
            "start_line": 83,
            "start_column": 2138,
            "end_line": 0,
            "end_column": 2530,
            "start_byte": 2138,
            "end_byte": 0
          },
          "_pytest.python.pytest_configure": {
            "name": "_pytest.python.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": " the names of its parents.\n    Only matches names of items which are either a :class:`Class` or a\n    :class:`Function`.\n\n    Additionally, matches on names in the 'extra_keyword_matches' set of\n    any item, as well as names directly assigned to test functions.\n    \"\"\"\n\n    _names = attr.ib(type=AbstractSet[str])\n\n    @classmethod\n    def from_item(cls, item: \"Item\") -> \"KeywordMatcher\":\n        mapped_names = set()\n\n        # Add the names of the current item and any parent items\n        import pytest\n\n        for node in item.listchain():\n            if not isinstance(node, (pytest.Instance, pytest.Session)):\n                mapped_names.add(node.name)\n\n        # Add the names added as extra keywords to current or parent items\n        mapped_names.update(item.listextrakeywords())\n\n        # Add the names attached to the current function through direct assignment\n        function_obj = getattr(item, \"",
            "start_line": 138,
            "start_column": 4458,
            "end_line": 0,
            "end_column": 5374,
            "start_byte": 4458,
            "end_byte": 0
          },
          "_pytest.skipping.pytest_configure": {
            "name": "_pytest.skipping.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "lection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def test_eval(test_input, expected):\n            assert eval(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and classes whose name \"\n        \"contains 'test_method' or 'test_other', while -k 'not test_method' \"\n        \"matches those that don't contain 'test_method' in their names. \"\n        \"-k 'not test_method and not test_other' will eliminate the matches. \"\n        \"Additionally keywor",
            "start_line": 47,
            "start_column": 1193,
            "end_line": 0,
            "end_column": 2813,
            "start_byte": 1193,
            "end_byte": 0
          },
          "_pytest.stepwise.pytest_configure": {
            "name": "_pytest.stepwise.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": ".config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecate",
            "start_line": 28,
            "start_column": 728,
            "end_line": 0,
            "end_column": 866,
            "start_byte": 728,
            "end_byte": 0
          },
          "_pytest.stepwise.StepwisePlugin.pytest_collection_modifyitems": {
            "name": "_pytest.stepwise.StepwisePlugin.pytest_collection_modifyitems",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "ize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def test_eval(test_input, expected):\n            assert eval(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, marks=marks, id=id)\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and cl",
            "start_line": 48,
            "start_column": 1400,
            "end_line": 4,
            "end_column": 2535,
            "start_byte": 1400,
            "end_byte": 4
          },
          "_pytest.terminal.pytest_configure": {
            "name": "_pytest.terminal.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": " config.option.keyword.lstrip()\n    if not keywordexpr:\n        return\n\n    if keywordexpr.startswith(\"-\"):\n        # To be removed in pytest 7.0.0.\n        warnings.warn(MINUS_K_DASH, stacklevel=2)\n        keywordexpr = \"not \" + keywordexpr[1:]\n    selectuntil = False\n    if keywordexpr[-1:] == \":\":\n        # To be removed in pytest 7.0.0.\n        warnings.warn(MINUS_K_COLON, stacklevel=2)\n        selectuntil = Tru",
            "start_line": 224,
            "start_column": 5991,
            "end_line": 0,
            "end_column": 6410,
            "start_byte": 5991,
            "end_byte": 0
          },
          "_pytest.tmpdir.pytest_configure": {
            "name": "_pytest.tmpdir.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "t[str])\n\n    @classmethod\n    def from_item(cls, item: \"Item\") -> \"KeywordMatcher\":\n        mapped_names = set()\n\n        # Add the names of the current item and any parent items\n        import pytest\n\n        for node in item.listchain():\n            if not isinstance(node, (pytest.Instance, pytest.Session)):\n                mapped_names.add(node.name)\n\n        # Add the names added as extra keywords to current or parent items\n        mapped_names.update(item.listextrakeywords())\n\n        # Add the names attached to the current function through direct assignment\n        function_obj = getattr(item, \"",
            "start_line": 138,
            "start_column": 4766,
            "end_line": 0,
            "end_column": 5374,
            "start_byte": 4766,
            "end_byte": 0
          },
          "_pytest.warning_types.PytestUnknownMarkWarning": {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "\"values\", Sequence[Union[object, NotSetType]]),\n            (\"marks\", \"typing.Collection[Union[MarkDecorator, Mark]]\"),\n            (\"id\", Optional[str]),\n        ],\n    )\n):\n    @classmethod\n    d",
            "start_line": 77,
            "start_column": 1903,
            "end_line": 0,
            "end_column": 2100,
            "start_byte": 1903,
            "end_byte": 0
          },
          "_pytest.warning_types.PytestUnknownMarkWarning.__module__": {
            "name": "_pytest.warning_types.PytestUnknownMarkWarning.__module__",
            "file_path": "src/_pytest/mark/structures.py",
            "file_content": "   @classmethod\n    d",
            "start_line": 83,
            "start_column": 2079,
            "end_line": 4,
            "end_column": 2100,
            "start_byte": 2079,
            "end_byte": 4
          },
          "_pytest.warnings.pytest_configure": {
            "name": "_pytest.warnings.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": " tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other'",
            "start_line": 74,
            "start_column": 2235,
            "end_line": 0,
            "end_column": 2501,
            "start_byte": 2235,
            "end_byte": 0
          },
          "_pytest.resultlog.pytest_configure": {
            "name": "_pytest.resultlog.pytest_configure",
            "file_path": "src/_pytest/mark/__init__.py",
            "file_content": "est.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import MINUS_K_COLON\nfrom _pytest.deprecated import MINUS_K_DASH\nfrom _pytest.store import StoreKey\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]\n\n\nold_mark_config_key = StoreKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: \"Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]\" = (),\n    id: Optional[str] = None\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: ",
            "start_line": 30,
            "start_column": 725,
            "end_line": 0,
            "end_column": 1434,
            "start_byte": 725,
            "end_byte": 0
          },
          "_pytest.hookspec.pytest_runtest_makereport": {
            "name": "_pytest.hookspec.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "",
            "start_line": 486,
            "start_column": 17380,
            "end_line": 0,
            "end_column": 17867,
            "start_byte": 17380,
            "end_byte": 0
          },
          "_pytest.runner.pytest_runtest_makereport": {
            "name": "_pytest.runner.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "ort_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:\n    if hasattr(report, \"wasxfail\"):\n        if report.skipped",
            "start_line": 318,
            "start_column": 10464,
            "end_line": 0,
            "end_column": 10595,
            "start_byte": 10464,
            "end_byte": 0
          },
          "_pytest.skipping.evaluate_condition": {
            "name": "_pytest.skipping.evaluate_condition",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "def evaluate_condition(item: Item, mark: Mark, condition: object) -> Tuple[bool, str]:\n    \"\"\"Evaluate a single skipif/xfail condition.\n\n    If an old-style string condition is given, it is eval()'d, otherwise the\n    condition is bool()'d. If this fails, an appropriately formatted pytest.fail\n    is raised.\n\n    Returns (result, reason). The reason is only relevant if the result is True.\n    \"\"\"\n    # String condition.\n    if isinstance(condition, str):\n        globals_ = {\n            \"os\": os,\n            \"sys\": sys,\n            \"platform\": platform,\n            \"config\": item.config,\n        }\n        if hasattr(item, \"obj\"):\n            globals_.update(item.obj.__globals__)  # type: ignore[attr-defined]\n        try:\n            filename = \"<{} condition>\".format(mark.name)\n            condition_code = compile(condition, filename, \"eval\")\n            result = eval(condition_code, globals_)\n        except SyntaxError as exc:\n            msglines = [\n                \"Error evaluating %r condition\" % mark.name,\n                \"    \" + condition,\n                \"    \" + \" \" * (exc.offset or 0) + \"^\",\n                \"SyntaxError: invalid syntax\",\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n        except Exception as exc:\n            msglines = [\n                \"Error evaluating %r condition\" % mark.name,\n                \"    \" + condition,\n                *traceback.format_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    # Boolean condition.\n    else:\n        try:\n            result = bool(condition)\n        except Exception as exc:\n            msglines = [\n                \"Error evaluating %r condition as a boolean\" % mark.name,\n                *traceback.format_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    reason = mark.kwargs.get(\"reason\", None)\n    if reason is None:\n        if isinstance(condition, str):\n            reason = \"condition: \" + condition\n        else:\n            # XXX better be checked at collection time\n            msg = (\n                \"Error evaluating %r: \" % mark.name\n                + \"you need to specify reason=STRING when using booleans as conditions.\"\n            )\n            fail(msg, pytrace=False)\n\n    return result, reason",
            "start_line": 86,
            "start_column": 2816,
            "end_line": 0,
            "end_column": 5151,
            "start_byte": 2816,
            "end_byte": 0
          },
          "_pytest.skipping.evaluate_xfail_marks": {
            "name": "_pytest.skipping.evaluate_xfail_marks",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None",
            "start_line": 199,
            "start_column": 6507,
            "end_line": 0,
            "end_column": 7408,
            "start_byte": 6507,
            "end_byte": 0
          },
          "_pytest.skipping.pytest_runtest_makereport": {
            "name": "_pytest.skipping.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "@hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n    outcome = yield\n    rep = outcome.get_result()\n    xfailed = item._store.get(xfailed_key, None)\n    # unittest special case, see setting of unexpectedsuccess_key\n    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n        reason = item._store[unexpectedsuccess_key]\n        if reason:\n            rep.longrepr = \"Unexpected success: {}\".format(reason)\n        else:\n            rep.longrepr = \"Unexpected success\"\n        rep.outcome = \"failed\"\n    elif item.config.option.runxfail:\n        pass  # don't interfere\n    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n        assert call.excinfo.value.msg is not None\n        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n        rep.outcome = \"skipped\"\n    elif not rep.skipped and xfailed:\n        if call.excinfo:\n            raises = xfailed.raises\n            if raises is not None and not isinstance(call.excinfo.value, raises):\n                rep.outcome = \"failed\"\n            else:\n                rep.outcome = \"skipped\"\n                rep.wasxfail = xfailed.reason\n        elif call.when == \"call\":\n            if xfailed.strict:\n                rep.outcome = \"failed\"\n                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n            else:\n                rep.outcome = \"passed\"\n                rep.wasxfail = xfailed.reason\n\n    if (\n        item._store.get(skipped_by_mark_key, True)\n        and rep.skipped\n        and type(rep.longrepr) is tuple\n    ):\n        # skipped by mark.skipif; change the location of the failure\n        # to point to the item definition, otherwise it will display\n        # the location of where the skip exception was raised within pytest\n        _, _, reason = rep.longrepr\n        filename, line = item.reportinfo()[:2]\n        assert line is not None\n        rep.longrepr = str(filename), line + 1, reason",
            "start_line": 259,
            "start_column": 8490,
            "end_line": 0,
            "end_column": 10447,
            "start_byte": 8490,
            "end_byte": 0
          },
          "_pytest.unittest.pytest_runtest_makereport": {
            "name": "_pytest.unittest.pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py",
            "file_content": "urn \"xpassed\", \"X\", \"XPASS\"\n    return None\n",
            "start_line": 290,
            "start_column": 10683,
            "end_line": 0,
            "end_column": 11441,
            "start_byte": 10683,
            "end_byte": 0
          }
        }
      }
    }
  ]
}